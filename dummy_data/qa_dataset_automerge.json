{
    "queries": {
        "f75238a7-2b43-44db-8689-822d51cacfad": "Explain the concept of multilingual denoising pre-training and its significance in machine translation tasks.",
        "a352edb8-cfc9-4922-ae2c-3e6ccb1a080f": "How does mBART differ from previous approaches to pre-training in machine translation?",
        "f3d986cd-d22a-4de5-9127-6bcee1d344e6": "Discuss the benefits of pre-training a complete autoregressive model like mBART for machine translation tasks.",
        "5f2bc3c4-a846-4469-ba64-9f35e6e2bb75": "How does mBART initialization impact performance in low-resource machine translation settings?",
        "a4c695cb-4e0f-4348-9305-bd5fbb78e517": "What are the key findings and results presented in the paper regarding the effectiveness of mBART in various machine translation tasks?",
        "84137b2e-502b-4f07-b3f3-06e3888ff932": "How does multilingual denoising pre-training, specifically with mBART, contribute to performance gains in machine translation tasks?",
        "23d6cfa0-00e0-4385-bfef-8405f02e2e24": "What is the significance of pre-training a complete sequence-to-sequence model like mBART for machine translation, compared to previous approaches that focused on specific parts of the model?",
        "44c9ed66-7839-4c17-b051-b3e5f51d4604": "How does adding mBART initialization impact performance in low-resource machine translation settings?",
        "becbc11b-55e4-49b2-bb42-a171d8b8b37d": "Can you explain how mBART enables new types of transfer to language pairs with no bi-text or that were not in the pre-training corpus?",
        "0a397257-ff20-4d22-9be4-a1ca3bfa0d69": "Why is self-supervised pretraining not yet common practice in machine translation, despite its wide adoption in other NLP tasks?",
        "446518b5-5d85-4463-8367-dc514602b4c8": "Explain the difference between existing MT approaches that only pre-train parts of the model and the approach presented in the document that pre-trains a complete autoregressive model with an objective that noises and reconstructs full texts across many languages.",
        "317393e4-7029-4899-9143-a057703910e4": "How does mBART differ from other pre-training approaches for MT, such as those that only pre-train the encoder or decoder, or focus on English corpora?",
        "3f264fa8-b819-4232-a1d1-78edc0d7a487": "Describe the training process of mBART as a multilingual sequence-to-sequence denoising auto-encoder, including how the input texts are noised and how the Transformer model is learned to recover the texts.",
        "faf37889-0b41-488d-b0ea-459760cc8f15": "What are the benefits of using mBART for supervised sentence-level MT, according to the document?",
        "5ac93628-63e6-451d-b4a4-04e7b3c2994d": "How does mBART perform in terms of gains in low/medium-resource pairs compared to high-resource settings, based on the experiments mentioned in the document?",
        "b43b75d4-4f88-427b-9144-af733e73f81d": "How does back-translation (BT) contribute to improving results in machine translation, specifically on WMT16 English-Romanian and the FloRes test sets?",
        "9cc289d5-05c3-4568-adcb-f883e49d5df3": "What is the significance of document-level pre-training in improving machine translation results, and by how much does it improve results?",
        "5bfd9076-9732-404d-8592-b58a9c60adfa": "How does mBART compare to previous pre-training schemes in terms of performance in machine translation tasks, according to the context information provided?",
        "1b094e4b-df51-441c-a12e-ba787376e971": "What is the main focus of the research described in the document?",
        "cc0611af-c7d1-4a7f-a5f7-7080e60a2daf": "Who are the authors of the research paper?",
        "5ae7158e-e0e8-49ac-bd14-bdd5f2787bfc": "What organization is the research affiliated with?",
        "29bdd8b0-2245-49d3-9250-40a2fc193051": "Can you identify any specific techniques or methods mentioned in the document?",
        "e0ba67bd-a7a6-4aa3-81f1-416dc8bc8351": "How many authors are listed in the document?",
        "e4c7af1e-38af-4d4b-bead-d3f1f6db6fc9": "How does multilingual denoising pre-training impact performance in machine translation tasks?",
        "b5843d7f-5001-4a90-ad33-9aa4303b0013": "What is the significance of the findings presented in the abstract for the field of machine translation?",
        "4f31525c-7cd6-4ae9-b0d8-b649dee864d7": "How is mBART pre-trained?",
        "8165ea22-8e72-4ec6-8106-582bb011749d": "What is the objective used for pre-training mBART?",
        "e6dd59b2-0b5f-4d6f-85c5-4586bf64b284": "Can you explain the significance of using large-scale monolingual corpora in pre-training mBART?",
        "4e1abfa8-bf81-4402-baf3-e30e2cbcb835": "How does mBART differ from other sequence-to-sequence models?",
        "e46d4941-c09d-4950-b243-f775edf16ec7": "What is the potential impact of using mBART in natural language processing tasks?",
        "91738561-6a99-4b12-afa0-ac913cff7491": "How does mBART differ from previous approaches in pre-training sequence-to-sequence models?",
        "016698d2-dd19-4b6a-842a-978b236111d5": "What is the main focus of mBART in terms of denoising full texts in multiple languages?",
        "0656a652-6c91-49a1-adb1-57265602bb54": "Can you explain the significance of pre-training a complete sequence-to-sequence model in the context of mBART's approach?",
        "582de25f-0b72-4ebd-b1a6-8933d59905f2": "How does pre-training a complete model benefit its ability to be directly fine-tuned for supervised and unsupervised machine translation?",
        "c7069e1a-0ec3-42f6-b8e3-92f40cf9c686": "Can a pre-trained model be used for both sentence-level and document-level machine translation without any task-specific modifications?",
        "368d35e3-08fb-4db2-ba64-934804cffb3f": "How does adding mBART initialization impact performance in machine translation tasks?",
        "201f8424-3445-4c89-93b5-b815f807ed9a": "In which settings do we see the most significant performance gains from adding mBART initialization?",
        "b92c6cdd-81fa-4bd4-8ae7-8cc06b67dc89": "What is the maximum BLEU point improvement observed for low resource machine translation tasks after adding mBART initialization?",
        "b2f74080-04b4-44bd-9536-786832b1d0ae": "How does the performance improvement vary across different types of models after adding mBART initialization?",
        "32456d11-97c6-40a6-ba33-5a70f72b852e": "Can you explain the significance of the performance gains observed in document-level and unsupervised models after adding mBART initialization?",
        "92b585b8-b835-4805-a331-6e3a5a0e61f4": "How does pre-training enable new types of transfer to language pairs with no bi-text or that were not in the pre-training corpus?",
        "bd6f6046-f50d-4e61-96bc-4e818086ed2a": "What factors contribute the most to effective pre-training according to the extensive analysis presented in the document?",
        "8664bff5-3d3c-4be0-853a-d93f81d288ca": "Why is self-supervised pretraining not yet common practice in machine translation despite its wide adoption in other NLP tasks?",
        "b9404e3a-f435-4928-8ca9-ad7e2107bec9": "How have recent studies (Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019; Lewis et al., 2019; Raffel et al., 2019) utilized self-supervised pretraining in NLP tasks?",
        "19cb0d40-7179-4de8-9629-53cdc044f44b": "What are some existing approaches in machine translation that only pre-train parts of the model?",
        "d70715df-24a7-451d-941c-af431b40417c": "How do Lample and Conneau (2019) approach pre-training in machine translation?",
        "5c9007d2-d4a4-4785-8af8-944f97d6286c": "What are some limitations of existing machine translation approaches mentioned in the context?",
        "d2e1c246-e479-4b90-bdce-2a9362026050": "How do Edunov et al. (2019) differ in their approach to pre-training compared to other researchers mentioned?",
        "b02ff23e-56da-48f9-94d7-a485184de48a": "How do Lewis et al. (2019) and Raffel et al. (2019) focus on pre-training objectives in machine translation?",
        "cd515677-0f66-47f4-bb50-3dc2e41ea340": "How does pre-training a complete autoregressive model with an objective of noise and reconstructing full texts across multiple languages lead to significant performance gains?",
        "742c8cd0-8730-4f47-abc5-81a52af63387": "Can you explain the concept of mBART and how it functions as a multilingual sequence-to-sequence denoising auto-encoder?",
        "ae571592-e64f-4b49-97ee-2b07d16523d5": "How is mBART trained and what is the role of BART in the training process?",
        "c5c5c17a-f5ce-4816-a97c-efe56c0426dc": "What techniques are used to noise the input texts in mBART training?",
        "9c936446-d0c5-4ca3-a7b1-e2c26f5b7400": "Can you explain the purpose of permuting sentences in the training of mBART?",
        "ea80b72d-f691-480c-8434-d65d27fb6d9f": "How does mBART utilize a single Transformer model in recovering the texts?",
        "c8ae474a-f7de-4048-8d44-7b801851bdf1": "How does mBART differ from other pre-training approaches for machine translation?",
        "a7fc691a-d500-4e6f-a783-3280e6c35849": "What type of model does mBART pre-train?",
        "e643fac1-128b-426d-b403-f394dc507fee": "Can you explain the concept of autoregressive Seq2Seq modeling in the context of mBART pre-training?",
        "6c60d775-71fa-411d-8260-ef849eebd801": "How does mBART differ from traditional machine translation models in terms of training and fine-tuning for different language pairs?",
        "1e9a58e3-7034-4b6a-a514-1364055b7ce6": "Can you explain the significance of mBART being trained once for all languages in both supervised and unsupervised settings?",
        "e0bb9b15-9e27-485e-9420-bcbab7a4ce4c": "What do the extensive experiments mentioned in the context information demonstrate about the effectiveness of mBART?",
        "92ef1255-92b1-4e65-8b8d-1e65e11269d0": "How does mBART perform on existing machine translation benchmarks compared to other models?",
        "82c1968a-7e5c-4c3c-a0d5-8e262e743cad": "Can you discuss the simplicity of the approach used by mBART and its impact on the results of the experiments mentioned in the context information?",
        "b05d9afa-bd91-4e42-9f2f-efa7b492a7ec": "How does mBART initialization impact supervised sentence-level MT benchmarks?",
        "8829f39d-8083-4106-b910-da243a3c1321": "What are the potential gains in BLEU points when using mBART initialization for low/medium-resource pairs in MT?",
        "62358ea4-22d1-468c-a2b4-cf46831ae66a": "How does the performance of MT models differ between low/medium-resource pairs and high-resource settings when using mBART initialization?",
        "d8cc7226-1057-457c-a54f-3844b361dc9a": "How does back-translation (BT) contribute to improving results in English-Romanian translation on the WMT16 dataset?",
        "8cdc8632-19c1-4abd-b480-40958d41d20d": "What new state-of-the-art achievement was set by the results of back-translation on the WMT16 English-Romanian and FloRes test sets?",
        "f707eb12-11d9-4ec8-b8e0-bd6106a55020": "How much improvement in results was achieved for document-level machine translation through document-level pre-training?",
        "5240532d-904f-461b-b03f-0491196a73d2": "How do the results for unsupervised learning compare to supervised learning in the given context?",
        "550b7df6-3369-4c8f-98ca-c743a126af90": "What is the significance of the 9.5 BLEU gain on the Nepali-English language pair?",
        "82baba5c-f9f5-4bf1-b39c-56f71bc848e7": "How do the gains in less related language pairs impact the overall findings of the study?",
        "08cb9684-90f6-42ca-8b09-252de56b727a": "How does mBART compare to previous pre-training schemes in terms of performance?",
        "7fe52b36-56ff-454c-ba58-a172e8e91a02": "What tasks have previous pre-training schemes considered in comparison to mBART?",
        "1975bf2a-5f66-48e5-810f-4582185953b0": "Can you explain why mBART consistently performs the best in comparison to other pre-training schemes?",
        "2e98f615-92dd-42f2-a379-9054ac65f1cf": "How does fine-tuning on bi-text in one language pair, such as Korean-English, enable a model to translate from all other languages in the monolingual pre-training set, like Italian-English, with no further training?",
        "46f824cb-3727-49a3-9ee2-4fdf88016b34": "What is the significance of the CC25 corpus in the multilingual denoising pre-training process?",
        "cb6218f7-6c23-41f1-99bc-57c6abc38510": "Explain the tokenization process using a sentence-piece model and its role in supporting fine-tuning on additional languages.",
        "8bda4bf3-bfbf-46d5-bb55-9317d86f875d": "Describe the architecture of the mBART model and its key components in the sequence-to-sequence Transformer architecture.",
        "77ee9c10-09e8-4204-b429-c138ce3c0e97": "How is the training data structured in the learning process, and what is the objective of maximizing L\u03b8 in the context of pre-training BART models?",
        "1f79a636-e414-4292-b7b2-5c38bb9e76d2": "How does fine-tuning on bi-text in one language pair, such as Korean-English, enable a model to translate from all other languages in the monolingual pre-training set, like Italian-English, without further training?",
        "ee2c6a6a-a414-42b1-8936-320714ce5247": "What is the significance of using a large-scale Common Crawl (CC) corpus for pre-training BART models, and how does the CC25 corpus play a role in this process?",
        "c674578b-04f3-4f6c-911f-83f9c39cb46a": "How does the re-balancing of the CC25 corpus by up/down-sampling text from each language with a specific ratio contribute to the effectiveness of pre-training BART models?",
        "d798af8a-ef80-43f5-ab69-7ae061f89ed7": "What role does the sentence-piece model (SPM) tokenization, learned on the full CC data with 250,000 subword tokens, play in supporting fine-tuning on additional languages for the BART models?",
        "eb73a532-8d00-4507-899e-65323145533f": "How does the study suggest that languages not included in the pre-training corpora can benefit from mBART, and what does this imply about the universality of the model's initialization process?",
        "f16c2131-a46c-4225-af5f-8abc1cbe41e1": "How does the mBART model differ from the BART model in terms of pre-training for different languages?",
        "ab2b41ec-ebc7-446e-b0f6-3af2ec1f5785": "Can you explain the architecture of the sequence-to-sequence Transformer used in the mBART model?",
        "9f00379a-806c-4030-9585-b50c5ce8cf5f": "What are some of the languages included in the CC25 Corpus, and how are they ranked based on monolingual corpus size?",
        "85d8a5ef-5fc1-411d-8768-79bd8e099668": "How many layers of encoder and decoder are used in the mBART model, and what is the model dimension?",
        "dbbbc094-5b6e-4e44-af51-fb9c6acf40cf": "Why are the token counts for Chinese and Japanese different from other languages in the CC25 Corpus?",
        "2463312e-f328-4a60-b806-38f8f0e6c79d": "How does the additional layer-normalization layer on top of both the encoder and decoder contribute to stabilizing training at FP16 precision?",
        "123fc80a-c638-4a61-9e8f-860d2861767e": "What is the purpose of the noising function g in the training process described in the document?",
        "42ddc1cf-fa83-44e1-b3c1-201b3e05e105": "Explain the training data D={D1,...,DK} and how it is utilized in the training of the model.",
        "16a6692b-c01a-4c64-8282-73f699a05c16": "How is the model trained to predict the original text X given g(X)?",
        "3739df82-d348-4c52-a058-bf44dc74a349": "Can you explain the distributionP defined by the Seq2Seq model in the context of maximizing L\u03b8?",
        "b69b0de0-0de5-4136-864b-bd715d6e4ec7": "How does fine-tuning on bi-text in one language pair using mBART enable translation across multiple languages without further training?",
        "299643b1-32f9-4080-aec5-cb842c7f6294": "Can you explain how mBART allows for new types of transfer across language pairs, using the example provided in the context information?",
        "81d49b34-d0c2-4669-95e4-67cda5709a91": "How does the study demonstrate that languages not included in pre-training corpora can benefit from mBART?",
        "39435fca-9661-4024-b988-672b383fd828": "What does the analysis in the document reveal about the factors that contribute the most to effective pre-training?",
        "064e0c75-a1d8-436f-9fb7-8d8af2f09d85": "How does the study utilize a large-scale common crawl corpus for pre-training BART models?",
        "c73c10a3-510c-479c-89b2-c5516a4c8fe6": "What is the significance of fine-tuning models pre-trained on different subsets of languages from the common crawl corpus in the experiments mentioned in the document?",
        "5d4f2d62-bca7-4099-a2e6-b2d00d019d2f": "What is the CC25 corpus and where was it extracted from?",
        "5c56d0f5-e305-431e-94d7-7d91c11a9417": "How many languages are included in the CC25 corpus and what are some characteristics of these languages?",
        "4449e7b7-e522-4677-a8ea-53057b88f975": "Can you explain the significance of pre-training on a diverse set of languages like those in the CC25 corpus?",
        "9cc9ce1f-eb09-40ae-b239-82e074199265": "How does the CC25 corpus contribute to the field of natural language processing research?",
        "f1525c22-e235-4f7f-9b35-b7b91749186f": "What are some potential challenges or limitations of using the CC25 corpus for pre-training models?",
        "d14a7ff9-93b3-4b4d-9ece-bb1dd83832ca": "How did the authors of the document rebalance the corpus of languages in CC25?",
        "5678fde9-02c2-40e8-b412-1da5c1a01225": "What formula did the authors use to calculate the ratio \u03bbi for each language in the corpus?",
        "b0b1c86b-0fa6-4f71-a081-8cb403ac90ae": "How did Lample and Conneau influence the methodology used in rebalancing the corpus of languages in CC25?",
        "3d77dba4-96ea-46f7-9915-a327fa1537a9": "How does the use of the smoothing parameter \u03b1= 0.7 impact the language model?",
        "d13ee044-1b46-40f3-a9fa-6349d5ce2467": "Can you explain the process of tokenization using a sentence-piece model (SPM) as described in the document?",
        "0c463a76-d9d9-4f48-b164-a696c80eee01": "How many subword tokens are included in the full CC data used for pre-training?",
        "6b4ebf7f-94f6-479c-a861-c6f143cfcb72": "How does the tokenization process support fine-tuning on additional languages according to the document?",
        "6e95bb1e-3ff6-47cf-8935-ee4084db95cf": "What is the significance of using a sentence-piece model (SPM) learned on the full CC data for natural language processing tasks?",
        "1c61c6b8-c4dc-4f48-87d7-a651b8f51127": "Why is it mentioned that no additional preprocessing is applied in the document?",
        "5b9cdfe2-4d2d-4ef3-9b50-83d61e6d1c02": "How might true-casing or normalizing punctuation/characters impact the data processing in this context?",
        "6d268f3d-5b9a-41e3-ab8f-7a6f163737c0": "How does the mBART model differ from the BART model?",
        "b46c9278-a976-45e2-95bd-ede63dd7a0d3": "What pre-training scheme does the mBART model follow?",
        "095171af-72b2-4ef9-b3ec-de487ef05d56": "What language was BART originally pre-trained for?",
        "3417c863-39ce-43da-b5c2-cbcccb016c01": "How does the study systematically examine the effects of pre-training on different languages?",
        "dc22fffc-ace5-436c-96bd-23124576578f": "What is the size of the English language model in terms of tokens and GB?",
        "705cc4e0-a937-460a-a312-9e56f6662542": "How does the size of the Japanese language data compare to the other languages listed?",
        "b8c38055-98cb-4ed5-8f28-c98f89a83050": "Which language has the highest number of tokens?",
        "2022ff32-f8bc-458f-8090-e3da78a22ea2": "What is the size of the Vietnamese language data in gigabytes?",
        "a9a867c7-df3b-4d54-923a-bca22212d3d0": "Which language has the smallest number of tokens?",
        "b0d4127d-072f-4dfb-90fb-bfd05096d1f1": "Compare the size of the German language data to the Romanian language data.",
        "b8884b2a-14bd-4edb-acd5-ea52c3760293": "What is the language with the highest number of speakers in the given list?",
        "f05936cd-99b2-42be-a044-ee52882856fe": "Which language has the lowest percentage of speakers in the list?",
        "4977e8f2-70a5-4cad-b6c8-d95b5505c3f3": "How many languages have a percentage of speakers below 30%?",
        "dc826c66-326e-4891-97fa-a9d9d886b3e6": "What is the total number of speakers for all the languages listed?",
        "d115061f-9708-4200-8e2c-d8e51acf5339": "Which language has the second highest number of speakers in the list?",
        "91b67297-e646-4644-af5a-d874bb076597": "What is the population of Kazakh speakers in the given context?",
        "2c218fdf-24fc-4b99-8f54-0d50c05dca7e": "Which language has the highest percentage of speakers in the given context?",
        "0925a6c6-ecb1-4763-b3c9-d0b800e7b4c8": "How does the population of Gujarati speakers compare to Sinhala speakers in the given context?",
        "8351a8f4-59cc-4892-afc2-399e2cc7c524": "Which language has the lowest percentage of speakers in the given context?",
        "796d3c8f-ab21-459d-b551-0d01f030709f": "Calculate the total population of speakers for all the languages listed in the given context.",
        "32494132-23e7-44ed-a8ea-f24c7e0e2887": "What is the ISO code for the Gujarati language in the CC25 Corpus?",
        "b176cbc1-8633-4f97-84ce-27c65d9f9d69": "How does the monolingual corpus size of the My Burmese language compare to that of the Gujarati language in the CC25 Corpus?",
        "269739c1-1882-4ed4-ba27-0c5000a96a41": "Can you explain the significance of using ISO codes for language names in the context of the CC25 Corpus?",
        "695c84a5-c953-4fc8-9317-245b92a619b1": "How many languages are listed in Table 1 of the CC25 Corpus, and how are they ranked?",
        "fd3074ae-7484-40ea-91c7-06d2c623b205": "Discuss the importance of having diverse language representation in a corpus like the CC25 Corpus.",
        "2b275762-dc73-4cf0-9ef5-af2a12c1b003": "How many layers of encoder and decoder are used in the standard sequence-to-sequence Transformer architecture?",
        "2a91366e-3ff8-4b65-9a0a-16a135468297": "What is the model dimension used in the architecture?",
        "306c3b51-0cf5-4232-9dba-2a90af0d9450": "Why are the language names replaced with their ISO codes in the paper?",
        "6d8f53ad-46d2-46cc-b70a-63bbbaf43b07": "How many parameters are there in the Transformer architecture described in the context?",
        "4bd48fd7-66bc-40bb-8b11-6195e2bd5efc": "Why are the Chinese and Japanese corpora not segmented in the study?",
        "d158bb97-8107-458c-8d7a-6c3c1f722120": "How did the inclusion of an additional layer-normalization layer on both the encoder and decoder impact training at FP16 precision?",
        "661c2dfd-0847-48a6-baf2-183400ae6d36": "Why was it necessary to add a layer-normalization layer on top of both the encoder and decoder in this study?",
        "21e81d45-10b6-438a-93a4-2b887236da6b": "How does the training data for the model in the context consist of Klanguages?",
        "bcf4d16c-6f7c-495b-aebf-09d04c675b1f": "Can you explain the role of the noising function g in the training process of the model?",
        "411c3ecc-e455-4974-8f82-439c2caa23f8": "How is the objective function L\u03b8 defined in the context?",
        "a4a6d124-8125-4a96-b87e-a61a3fbacf93": "What does the symbol Di represent in the equation for L\u03b8?",
        "c696171d-eaa1-40d3-a330-812650fb2918": "Explain the significance of the distribution P in the context of the Seq2Seq model.",
        "f271a979-2181-4729-aee6-ebe2b021d4e6": "Explain the noise function used in the Transformer Encoder-Decoder model for Multilingual Denoising Pre-Training.",
        "a97524fb-b56b-4872-9c79-9f49885da4b6": "What is the instance format for each batch in the pre-training process?",
        "4e7a746c-98dc-4d9d-ac67-4da16ee8ec14": "Compare and contrast the mBART25, mBART06, and mBART02 pre-trained models in terms of their language coverage and batch size.",
        "d0c2b425-8fd8-4833-afb3-170a3bb03271": "How is the optimization process carried out for the full model during training, including details on the optimizer, learning rate decay, and dropout?",
        "6588557f-661e-41d0-a650-1ff43d8eafb7": "Discuss the significance of using a large vocabulary in pre-training models for multilingual settings, as mentioned in the document.",
        "1b5daa9f-80cd-4771-bb5c-2b2aa817d979": "Explain the concept of Transformer Encoder and Transformer Decoder as mentioned in the context.",
        "1cea773f-ff10-4424-bc59-98bbff36e4f3": "How does the Multilingual Denoising Pre-Training (mBART) work and what is its significance in machine translation?",
        "711b6892-29e1-4e1d-96c5-d96c6676c4cc": "Describe the framework for Multilingual Denoising Pre-training and fine-tuning on downstream MT tasks as illustrated in Figure 1.",
        "001be1d9-0fce-4278-9ace-d59701641120": "What is the purpose of using sentence permutation and word-span masking as injected noise in the pre-training model?",
        "f3539d53-08d9-4406-a854-95b3a34e2b00": "How does the noise function, as described in the context, contribute to the overall training process according to Lewis et al. (2019)?",
        "b1f941b3-a532-4510-98bc-7226b115e76a": "How is the masking of words done in each instance during pre-training?",
        "4c0ee949-46cf-4c25-b9aa-04e225804609": "What noise types are mentioned as possible alternatives to the Poisson distribution for masking words?",
        "cad3436a-b422-43e6-998e-9dccddc3b3e7": "How is the language id symbol <LID> used in the instance format?",
        "8d86f751-612d-4b5d-a1dd-ec8e963b09c3": "What is the purpose of pre-training at the \"multi-sentence\" level?",
        "91fbebe7-01e7-4ee9-8e7c-9fcd9f4c1ee3": "Can you explain the optimization process for training the full model, including the number of GPUs used and the training time?",
        "7814abce-589c-4cbe-8437-75473474aa8c": "What are the different pre-trained models built to measure the effects of multilinguality during pre-training?",
        "2384f235-f265-4371-b565-454a07d61790": "How does the batch size differ between mBART25, mBART06, and mBART02 models?",
        "7e78d5ac-d42f-4ed5-832c-96edb01ebb45": "What is the purpose of training the BART-En/Ro models on the same English and Romanian corpus?",
        "3a8f96a7-87ff-4920-b423-bb5dddfb80a3": "How do the hyper-parameters vary when grid-searching for the best non-pretrained configuration?",
        "43c7f4e6-7edb-4e02-bfa5-7e956b381b54": "How does the use of the same vocabulary benefit the models in multilingual settings according to the context information?",
        "0ec5b9ea-ebdf-4e40-a145-83dc0d0df9cb": "Where did the phrase \"Who am I? Where did I come from?\" originate from in the given text?",
        "888d91c0-d35c-4edc-8a50-151ffcf3c5b8": "How does the Transformer Encoder-Decoder model play a role in the context provided?",
        "9c34875f-2fca-44e3-9f84-93d837b57bbb": "What are the components of the Transformer model mentioned in the context information?",
        "76ea313e-3723-47ec-ba56-4b9b5428b6d2": "How is the Transformer Encoder different from the Transformer Decoder?",
        "3b63814d-ed1a-47d4-95c4-28214df9eb66": "Can you explain the significance of the characters and symbols used in the context information?",
        "e1c1c736-6cdf-47fe-89a9-ef6271b1d5a0": "What is the purpose of the <Ja> tag in the text?",
        "cb8becd2-0664-4255-9de9-b8ded0bed247": "How does the context information relate to the field of natural language processing or machine learning?",
        "3fa12716-b8b5-45c8-9e6c-a5a70fc4812b": "What is the name of the pre-training method mentioned in the context?",
        "be7d54c2-753a-4ea9-8613-3003c916d045": "How does mBART differ from traditional machine translation models?",
        "9e73693f-cb30-4c9d-a677-70efc7132378": "Can you explain the components of the Transformer Encoder and Transformer Decoder mentioned in the context?",
        "131ab2c3-1c48-4826-8523-bceb6cca7295": "How is fine-tuning used in the context of machine translation?",
        "63972ce4-dc5b-428c-9de6-74f62a4df24b": "What is the significance of multilingual denoising pre-training in the context of mBART?",
        "8938f915-3843-490d-9c21-9db75e89088c": "What is the role of the Transformer Encoder and Transformer Decoder in the context provided?",
        "4e98742c-6d89-4e4e-9320-3c7abedbe199": "Can you explain the significance of the phrase \"See you tomorrow\" in the given text?",
        "3305db2e-0040-4340-ab12-dd8a7605370b": "How does the framework for Multilingual Denoising Pre-training differ from the fine-tuning on downstream MT tasks?",
        "ee6acdbe-8182-4bd3-850e-41dd473d062b": "What are the two types of noise injection used in the framework?",
        "39232b1e-0194-47ce-a7ed-10116b16d86f": "How is a special language id token utilized in the framework?",
        "53ddd453-e252-4d96-8868-6ede82bd114c": "Can you explain the concept of sentence permutation in the context of the framework?",
        "fffb81aa-fb8f-41b6-8ae5-2335826c0d07": "How does the use of one multilingual pre-trained model benefit all tasks in the framework?",
        "d83c0bf2-76cb-4b9c-a72e-3336c5d554e7": "How is noise incorporated into the pre-trained model according to Lewis et al. (2019)?",
        "34d4fb5a-3229-4c2f-ac52-5658c721b336": "What are the two types of noise used in the model's noise function?",
        "07e8706f-5b05-4dcb-8e2a-d47e3fc41579": "Can you explain the process of removing spans of text and replacing them with a mask token in the model?",
        "49805ba9-52cf-439a-8c9f-c9c8f2c6a874": "How does the use of a multilingual pre-trained model benefit the tasks mentioned in the context information?",
        "60e4b6ab-49f0-42ac-a59d-dcc30213f69b": "How do the different types of noise introduced in the model contribute to its overall performance?",
        "375991c8-6241-46c9-a39d-18ccea2e885e": "How is the masking of words in each instance done in the text?",
        "4597fb41-ed58-4c7d-aaa4-cee81c3e157b": "What distribution is used to determine the span length for masking words?",
        "7b48bd9a-5f72-4ce9-ab2b-01b6c6c3e796": "How is the order of sentences permuted within each instance?",
        "624019ac-2fb4-4099-af82-8429b4ee7d7b": "What is the decoder input for the text?",
        "0de2d76a-3b10-413b-898c-7462e8c8c9e8": "What is the purpose of the language id symbol <LID> in the text?",
        "027eb436-1981-46a8-8b63-45b569c71ba9": "What are some examples of noise types that can be used in addition to those mentioned in Lample et al. (2018c)?",
        "8275c17a-99cd-45bd-b63a-06dffd311dd3": "Why is the exploration of the optimal noising strategy left to future work according to the context information provided?",
        "530747df-5197-4e9a-bda8-5bcbe7d6c6ee": "How is the language id symbol <LID> sampled for each instance of a batch?",
        "c35b5412-2f32-43ed-a446-30b8282e6b12": "What determines the number of consecutive sentences packed into each instance?",
        "c7a5d16c-bc11-4b9b-99fa-3eac4f24cb61": "What are the two conditions that determine when sentences are packed into an instance?",
        "651f2736-77aa-4480-9110-6bc218ee2e5f": "How are sentences separated within an instance?",
        "ceadae88-93d6-4dcd-add5-c42e61e85e4b": "Can you explain the significance of the 512 max token length in the context of packing sentences into instances?",
        "55038f41-95da-4c7d-816c-03e8a905694e": "How does pre-training at the \"multi-sentence\" level benefit the translation process?",
        "f8eda07f-7f12-4a23-9eb2-9765711cdc5b": "What hardware was used for training the full model, including 25 languages?",
        "67e2b89f-b261-4a2f-9dce-85850fbce864": "How many steps was the full model trained for?",
        "73067615-4c62-4fdb-8e59-72649569bcb9": "Can you explain the significance of appending the selected <LID> token at the end of the instance?",
        "6cf0a717-47b0-48f0-97bc-af0708ca036c": "How does working at both sentence and document translation levels improve the overall translation process?",
        "3ad02f47-4cbc-4dfd-85e1-9bbd573f9306": "What is the total batch size used in the training process, and how does it compare to the configuration of BART?",
        "905919c2-76e1-4042-9df0-d9c85cd5f99b": "What optimizer is used in the training process, and what are the specific values for \u03f5 and \u03b22?",
        "e4cdc669-00b9-4f74-9e89-8cc3b1d2fe78": "How is the learning rate decay scheduled in the training process?",
        "72b723dd-3204-493a-a3c1-65f96053cbbb": "How long was the total training time for the model, and what was the approximate duration?",
        "52ea1dc2-7653-47bf-b51f-37b337f98615": "How does the total batch size per GPU in this study compare to other similar models in the field?",
        "6424aa1d-fc5a-4f49-85c4-5dc49630106c": "How long was the total training time for the project?",
        "5ee458b4-c4ef-4835-ac68-c25a87ab5194": "At what step was the dropout reduced to 0.05?",
        "a23ee0e1-63de-418d-b2cc-d708860f646e": "What was the dropout set to at 400K steps during training?",
        "daa66898-4be7-438a-978f-bf53ec6597c3": "How are the experiments in the document conducted, and what tool is used for them?",
        "6f4606b2-1b2f-4e47-a566-bde6393fae7f": "What is the purpose of pre-training models in the context of multilinguality?",
        "5539d346-071a-4572-95bb-9bf025254539": "Can you explain the process of pre-training the mBART25 model on all 25 languages as described in the document?",
        "c515a967-6c14-4083-a9e2-c550cd86fa88": "How does pre-training on a subset of six European languages affect the performance of the model?",
        "1060071a-e62f-48e3-8c70-405b779ea844": "What languages are included in the subset for pre-training in the mBART06 model?",
        "15c4e5dc-0ad9-49d5-988f-9a55088fdebf": "How does the batch size for pre-training in mBART06 compare to the batch size in mBART25?",
        "1621d3a0-5855-41c4-86f3-1eb31d01e4e8": "Why is it important to have the same number of updates per language during pre-training for a fair comparison?",
        "7ac4efc7-d93c-4322-bccd-8738c714413b": "How might pre-training on related languages benefit the overall performance of the model?",
        "95957b23-d259-496a-9d4d-d7317fd913c4": "What is the difference in batch size between the mBART02 bilingual models and the mBART25 models?",
        "0daa7d76-acb4-4a36-a35d-cecc7d2b11d7": "How many language pairs are pre-trained in the mBART02 model?",
        "29fe09b9-560c-483e-8533-323bd09791a0": "What is the purpose of training monolingual BART models on the En and Ro corpus in the context provided?",
        "7834bdf8-329e-4ddb-9ba5-715773058e82": "What is the purpose of including a comparison with a randomly initialized model without pre-training in the translation tasks?",
        "c5663509-c6fd-4f3e-8fbb-fb357fc8b315": "How do the researchers ensure that the best non-pretrained configuration is found for each downstream dataset?",
        "1a1486fd-1454-475b-a0c3-12f6cbf9cdaf": "Can you explain the significance of using the same vocabulary for all models in this study?",
        "7e0dec2f-125b-4a5e-a150-7e0385001194": "How do hyper-parameters such as architecture and dropout play a role in the grid-search process for finding the best non-pretrained configuration?",
        "bc9d8ca8-7408-4df7-a833-865cc5ee176c": "Why is it important to have diverse baselines, including a randomly initialized model, in the evaluation of pre-trained models for translation tasks?",
        "ea28c667-2155-42cc-afc1-61f224ce6050": "How does the use of the same vocabulary benefit all models in the context of pre-training?",
        "af45681d-a0d7-4b2f-ae3d-8328cf335aad": "Why is it important for all tokens to be included in the large vocabulary, even if they do not frequently occur in all pre-training corpora?",
        "08348b93-1d97-45f9-b0da-1f0cf949f731": "How do later experiments demonstrate the potential for improved generalization in multilingual settings, even for unseen languages, with a large vocabulary?",
        "a1fd3416-9253-4e31-9676-6b5be8e3fb06": "How does mBART pre-training impact low to medium resource machine translation performance compared to randomly initialized baselines?",
        "3234b533-933e-4f01-89f6-bc4f8f67fa3a": "What experimental settings were used for fine-tuning and decoding in the sentence-level machine translation experiments?",
        "c963dbe7-96bf-438c-a7c7-880f1521be66": "Can you explain the dataset categorization into low resource, medium resource, and high resource for the machine translation experiments?",
        "5f62bdc6-6760-4454-8ad0-ae2613ae2224": "What are the key findings regarding the performance gains of mBART pre-training on different language pairs in the machine translation experiments?",
        "0d5491c9-354b-4ce5-ab99-93a62a22b058": "How does fine-tuning with mBART pre-trained weights improve translation performance on low resource language pairs like En-Vi and En-Tr?",
        "38d1d241-5f62-4c42-bf44-a027f39e12bd": "What is the size of the data source for the language pair En-Ko?",
        "3e5b11a3-055d-47e2-ac09-760a61911592": "How does the percentage of random data compare between the language pair En-It and En-Lt?",
        "ffa754ee-ff1f-482e-90d8-770d273f5909": "Which language pair has the largest data source size in the document?",
        "d1908cab-fa5b-4215-bd25-81cd8bb479ac": "Compare the percentage of random data for the language pair En-Ar and En-Lv.",
        "1d7b9eda-baf6-4881-9a0d-23df572bfda3": "How does the mBART25 percentage differ between the language pairs En-My and En-Si?",
        "e87cfec6-f930-45b4-ada9-62bf8e49106e": "How does mBART pre-training compare to randomly initialized baselines in low to medium resource machine translation, particularly on low resource language pairs like Vi-En?",
        "a61f6d6c-2ef8-4a67-9c7b-092e1b9a5d3a": "What are the sizes of the datasets used in the high resource machine translation evaluation, and how do the translation performance results differ between randomly initialized models and mBART25?",
        "ca65be3d-7024-4c5a-82e2-d4233fc9bb50": "How does mBART pre-training impact sentence-level machine translation in low to medium resource settings, including bi-text only and back translation, compared to other pre-training schemes?",
        "8c94e486-2bdf-48b8-a085-720112fad2ff": "Can you explain the experimental settings in terms of the datasets used for the machine translation evaluations, including the sources of the parallel corpora and the languages covered?",
        "bd12527f-c32b-48e3-b074-27bca976b93d": "How does the study show that pre-training can improve performance for languages not present in the pre-training data at all, based on the detailed analysis presented in the document?",
        "8d06d22e-a544-4827-9870-6717a7ea61c2": "How are the datasets divided based on the number of sentence pairs in the context information?",
        "e58b3c11-78e0-4b0f-988a-b57f885fb0f2": "What are the key components of the fine-tuning and decoding process described in the document?",
        "56eb1903-9304-4cf6-9ac4-f42636fcbc52": "How does initializing with pre-trained mBART25 weights impact the performance on low and medium resource pairs?",
        "62f14be2-2bee-478a-86a2-3a8b218f5ce3": "Can you explain the challenges faced in fine-tuning in extremely low-resource settings, as mentioned in the context information?",
        "f794f434-baca-456d-8602-17350c839ec4": "How is the performance of the models evaluated in the document, and what metric is used for reporting the results?",
        "023c5bbf-414d-4a96-9e9b-6144d91545e8": "How does the size of the data sources vary across the different language pairs?",
        "dc46cc13-e5c1-4cc4-a131-26a73938ddfb": "Can you explain the significance of the \"Direction\" information provided in the context?",
        "3641b8dd-6130-4f9f-983e-cc0bab419e19": "What is the importance of having diverse language sources in translation tasks?",
        "7790ca39-12fb-41c3-a7ac-9779b63ae9ea": "How does the random value impact the data sources in the context provided?",
        "b3616607-53cd-433f-aafc-3e30d1b9b3a8": "Discuss the potential challenges that may arise when working with data from different language sources.",
        "c95878ce-58cc-4b17-af3f-2d1fd30c1e19": "What are the values listed in the first line of the context information?",
        "f1a5e89c-7050-4c4e-97c9-a74f045d0936": "What is the value of mBART25 in the second line of the context information?",
        "178347b2-94f4-442c-ad00-35eb192339bd": "Calculate the average of the values in the first line of the context information.",
        "0854d23e-0bd8-49c8-8006-3b304f030b49": "Compare the values of the first line and the second line of the context information. What differences do you notice?",
        "da71a8c4-5480-425b-bca7-4f988a5599b4": "How would you interpret the values in the context information in a real-world scenario?",
        "a4fd731b-c364-4b3d-9bc0-b37d4992ae1c": "What are the languages included in the dataset provided?",
        "e4b24e8b-246b-4ee6-a5b1-7fb0dcb97687": "What is the size of the data source for the En-My language pair?",
        "1aac4c72-ffd9-443a-814f-49f4d35e2879": "Which direction is the data source for the En-Nl language pair?",
        "031e768e-ec68-4326-a523-6a0a3cd4a098": "Can you identify the data sources for the En-Ar and En-It language pairs?",
        "8a19b284-1e6f-4ed3-aba0-d8fd54de0535": "How many languages are represented in the dataset?",
        "0e7b9aa5-4070-4d26-9de4-9cd052df5ceb": "What are the values listed in the first set of numbers provided in the context information?",
        "3acd148e-29e7-459a-af97-5541b4c62df5": "What is the name of the model mentioned in the second set of numbers?",
        "177569c1-013d-4095-a1de-fc8b107a1f0a": "Can you identify the highest value in the first set of numbers?",
        "864fc6bc-ff96-43b4-9731-f561e04deab3": "How many numbers are listed in the first set of numbers?",
        "00fa352f-fcbb-4f22-950f-3fdcedbba35f": "What is the average value of the numbers in the second set provided in the context information?",
        "f15afc9c-63eb-4268-b359-6ae85f3ae495": "What are the languages included in the dataset provided?",
        "be2fb6da-9301-43dc-9859-1060b2c58e72": "What are the different data sources for the language pairs in the dataset?",
        "e43f3a4c-5740-47da-938f-bfcfb20310ff": "Can you provide the size of the data for each language pair in the dataset?",
        "6530a7ad-06bf-4f76-8dfb-92a7d0ccb6c7": "How does the size of the En-Lv language pair compare to the other language pairs in the dataset?",
        "5b8cc74e-d0c3-4d83-b894-5114bd031441": "How many language pairs are included in the dataset?",
        "79ffb640-e128-4b12-95ae-35c3902368f4": "Calculate the average of the numbers provided in the first line of the context information.",
        "62e84cba-26f3-4a67-ba62-df5bb0329bc3": "What is the pattern or trend in the direction indicators provided in the second line of the context information?",
        "a57bc2c4-58d6-43e2-9bfb-6146d1b9a399": "What is the significance of the random numbers listed in the third line of the context information?",
        "a225a501-fd6d-4797-9301-e5df24d82d75": "How would you interpret the relationship between the numbers in the first line and the random numbers in the third line of the context information?",
        "ed2556c7-4e95-4972-b43e-986667f02a1a": "Can you identify any outliers in the data provided in the context information? If so, explain their impact on the overall dataset.",
        "a793c174-eecc-493d-b6e2-c5bb6b0b349e": "What is the average of the numbers provided in the first set of data?",
        "81979fb4-1f75-4cb3-b75e-a83b7f1dcd01": "How many numbers are there in the second set of data for mBART25?",
        "7d6f72d3-effc-4097-a7e7-f5a47b31171e": "What is the highest number in the second set of data for mBART25?",
        "6f9c4753-8222-4617-a293-610650fa96e7": "Calculate the range of the numbers in the first set of data.",
        "698f5dd5-479e-418e-8339-1b4733318d76": "Compare the average of the two sets of data and discuss any patterns or differences you observe.",
        "9908084e-51ed-44a8-86e4-6c708c81fec6": "How does Low/Medium Resource Machine Translation Pre-training compare to a randomly initialized baseline in terms of performance improvement?",
        "1ecc63f7-9128-47b0-afd9-708111a17597": "Which language pair shows particularly large gains with Low/Medium Resource Machine Translation Pre-training?",
        "fe423b53-eb26-48e1-80fc-b3affc73d687": "What are the sizes of the language models for the languages Cs, Es, Zh, De, Ru, and Fr?",
        "24cfbf2f-03f2-407e-9d47-5c62795b6bcd": "What is the performance score of the randomly initialized baseline for the language pair mentioned in the context?",
        "900e34fe-7599-4fd5-9bbc-fcdf5a7fa4b9": "What datasets were used in the evaluation of the models in the context provided?",
        "81e8ace4-d3c5-490c-941d-711e13d2e045": "Which specific translation task was the focus of the evaluation in the context?",
        "6e0d631e-d8a2-4818-92c8-bf01650e7f60": "Can you identify the model that achieved the highest score in the evaluation?",
        "565b0d41-cdfa-4bbc-b6e8-bd1a51e4e1eb": "How does the context suggest the models were evaluated in terms of resource availability?",
        "f8cfd6d5-05dc-4b72-a393-d6fa98b2c412": "What competition were the datasets sourced from in the context provided?",
        "6ddfd7ff-e99e-44ae-a6b8-6c5a52fd259a": "How does mBART pre-training impact performance in low to medium resource sentence-level machine translation settings?",
        "341d350a-c830-4b05-9c92-434d8a5d20a5": "What are some methods mentioned in the document for improving machine translation performance, and how does mBART compare to them?",
        "c58517ef-253f-48ca-831f-a5432a0ba718": "Can you explain the significance of evaluating models only on En-X translation in the context of machine translation research?",
        "e14e3b37-8aa3-4b3a-ab96-b9ae005379eb": "How many pairs of publicly available parallel corpora were gathered for the experiment?",
        "1ca25f7e-a863-49f2-a25e-59c730debb5c": "Can pre-training improve performance for languages that were not present in the pre-training data at all?",
        "2f26c025-5a0e-4ebc-925d-c0cb18bcdff4": "How many language pairs are mentioned from previous WMT and IWSLT competitions?",
        "c5772051-208a-4700-b7c6-4ce7ff97511a": "Can you name three language pairs that have competed in both WMT and IWSLT competitions?",
        "30369ed8-2c0b-4ffa-b206-756a469195f8": "Which language pair has not competed in either WMT or IWSLT competitions?",
        "e4939a4d-5268-469d-b1d2-bf764ca07626": "How many language pairs are involved in the WMT competition?",
        "7d578867-c531-415f-bbae-e5facdc5d6a1": "Can you list two language pairs that have competed in the IWSLT competition?",
        "98c127a4-b66c-4faf-a16e-4eae82a97163": "What are some of the language pairs used in the study by Guzm\u00e1n et al. (2019)?",
        "76ff5397-752b-4d5e-b43f-d36d1c5f4a50": "Can you name the dataset used for the En-Hi language pair in the study?",
        "8c4417a8-50b6-453d-9e80-730a1796e187": "How many different language pairs are mentioned in the context information provided?",
        "659bf38a-a558-436e-8cec-273e639342d3": "How are the datasets divided based on the number of sentence pairs?",
        "3487f54d-1a1b-469e-a076-aebdaedc8f43": "What is the process of fine-tuning the multilingual pre-trained models described in the document?",
        "87b41ceb-f304-42cd-8096-e1855eb0518f": "Can you explain the role of the encoder and decoder in the fine-tuning and decoding process?",
        "6ac119b8-5d48-436e-b623-0e8361c81acf": "What are the specific training techniques used for the MT model in the context provided?",
        "f9d57c8e-2dc1-4427-88b0-68923780d216": "How does the use of dropout and label smoothing contribute to the training process of the MT model?",
        "f35c5ca3-b7c5-4c3f-bdcc-d0ccc3d2f400": "What is the significance of warm-up steps in the training of the MT model?",
        "54742a09-fad8-4db7-8ba1-c2e0ba053a9f": "How does the maximum learning rate impact the training of the MT model?",
        "49f6a12b-1ba3-40dd-adef-8622b73c8fab": "How do the number of training updates differ for low, medium, and high resource pairs in the context provided?",
        "c67d2c2b-e11c-49da-b8c4-c2e156a71b6c": "How are the final models selected in the context of the document?",
        "87e5adec-d3cf-474a-942c-5a42fbacd041": "What decoding method is used in the document, and what is the beam size for all directions?",
        "44ba2a02-9d51-443c-ab77-d833414abb98": "How are the final results reported in the document, and what specific settings are used for language-specific BLEU scores?",
        "f6f1e40a-5536-4028-b6d8-7d51912818c8": "How do the gains in BLEU scores compare between initializing with pre-trained mBART25 weights and randomly initialized baselines for low and medium resource pairs?",
        "2955bb49-3c24-4e80-afd6-a2177deebd41": "Which language pairs showed gains of 12+ BLEU when initializing with pre-trained mBART25 weights?",
        "af9c49b1-d4db-451f-b88f-b0a5703065ae": "Can you explain the significance of observing gains on low resource pairs and noisily aligned pairs in machine translation tasks?",
        "ae68f120-0ae4-469e-a30d-b2575b837784": "How does fine-tuning perform in extremely low-resource settings like En-Gu?",
        "6a9def58-fe36-4fff-b0c0-d88e8c27c6ab": "What is the approximate number of examples available in En-Gu for fine-tuning?",
        "92d042b4-fba3-4ac4-a567-922ec406d8e9": "How does back-translation (BT) contribute to improving translation performance in low-resource language pairs, according to the information provided?",
        "9824521b-480c-4583-bdd4-3d5382a9b040": "Compare the performance of mBART models with other pre-training approaches on WMT16 Ro-En translation. What conclusions can be drawn from the comparison?",
        "2ebf1650-5783-4814-a5fd-a88d3f10daad": "In what scenarios does pre-training on multiple languages prove to be beneficial, and when does it have a negative impact on the final results, based on the analysis presented?",
        "4ed72206-427f-4e9c-802f-f366d7e35ec6": "How does the number of pre-training steps affect the performance of the Ro-En translation model, as shown in Figure 3? What trends can be observed in the model's improvement over time?",
        "f918c5e5-3fdc-4d3f-b97f-7554b553d70d": "Compare the performance of different pre-training approaches on WMT16 Ro-En translation tasks based on the table provided.",
        "7c674722-e74a-4238-9bc1-1d55eb6b8df7": "Discuss the impact of pre-training on translation performance in low resource settings, as mentioned in the document.",
        "1dada06b-922d-43ed-aed1-18184c985c7f": "How does back-translation (BT) contribute to improving translation results in low resource language pairs like En-Si and En-Ne?",
        "90a29253-0867-4520-aaab-f24f075d763a": "In what ways does pre-training with mBART25 parameters lead to state-of-the-art results in translation tasks, as shown in the document?",
        "42b18c4b-8b1b-40fe-88b2-9a2eedc2c976": "How does the mBART model compare to other pre-trained models in En-Ro translation, both with and without BT augmentation?",
        "63bb78f4-73de-46b2-82dc-541631cb35bc": "According to the document, when is it most beneficial to include languages other than the targeted language pair during pre-training, and why?",
        "349561f8-8cbc-4e41-81e6-81b9d6af7c90": "How does pre-training on multiple languages affect the final results in cases where monolingual data is plentiful?",
        "fd4242eb-2907-42e3-98f4-0c58dd53a96a": "What does the plot of Ro-En BLEU score versus pre-training steps show in Figure 3?",
        "8ae19823-d74f-4f4b-bd6f-16dd17770801": "What is the impact of pre-training on the models' performance after just 25K steps?",
        "d223f16b-4448-42df-90ce-600e9708fba3": "How does the performance of mBART25 compare to the baseline model?",
        "ffeb8df7-2a6e-450b-821b-e9baaed57149": "Why is pre-training with similar languages considered particularly helpful based on the results with mBART06 and mBART02 on Ro-En translation?",
        "cc4da85d-9c29-430f-8ffc-e5acf59ff457": "What is the purpose of the \"+BT iterations\" in the context information provided?",
        "58b4499b-0465-49c2-b76f-c281789bf7f0": "Compare the BLEU scores for En-Ne and Ne-En translations after fine-tuning.",
        "dbd48569-ebfe-4cac-a73c-4a70864dcdad": "How does the mBART25 model perform in comparison to random initialization in the context provided?",
        "85bc52d2-7a86-4e6e-b0fe-2077afdaeca4": "Explain the significance of the different BT iterations mentioned in the context information.",
        "023f62a8-bb03-42c4-ba2f-194f0ebb85ce": "Discuss the impact of fine-tuning on the BLEU scores for En-Ne and Ne-En translations.",
        "e6bbc08b-1ffe-43ac-b1eb-55aaf3e28043": "What is the significance of using two iterations of Back Translation (BT) in the pre-training process on FLoRes with mBART25?",
        "479df248-9cc3-4065-a927-930bc0e83e0d": "How does the use of randomization play a role in the pre-training process described in the context information?",
        "d3e2c8dd-f09b-4910-99ee-b886be7b9fb2": "Can you explain the purpose of the \"+BT iterations101520\" mentioned in the context information?",
        "5333089a-0887-4482-8453-7b20243f2a11": "What is the difference between the En-Si and Si-En models mentioned in the context information, and how do they contribute to the pre-training process?",
        "5d85170c-7fd2-43de-b611-2dd62ac2d54f": "How does the use of mBART25 contribute to the overall pre-training and back translation process described in the context information?",
        "1544e8b0-1dd8-490d-9b5a-a7ae09dfbac8": "What is the difference in BLEU score between the pre-training fine-tuning model with random initialization and the XLM-R model on the Ro\u2192En translation task?",
        "ad72cafd-ebc6-40a5-acad-086719585649": "Which model achieved the highest BLEU score on the En\u2192Ro translation task in the given context information?",
        "53cf0bad-e132-4781-ac3c-fe26a2a8d28b": "Can you explain the significance of pre-training and fine-tuning in the context of machine translation models?",
        "16fc9297-cf33-4da2-b910-f101d812b40d": "How does the performance of the BART model compare to other models mentioned in the context information?",
        "d8ef7cb6-42e8-4560-b21d-f89f4e7d087d": "What dataset was used for pre-training the XLM-R model in the given context information?",
        "6f724a77-1997-4e09-92f4-90146860a1ba": "What are the different models mentioned in the context information?",
        "1ef6596e-7662-4d0c-9f46-9c1f3d853716": "What is the highest score achieved by any model in the given data?",
        "048e226a-0c9c-4b52-b0ed-f6c2cdc5c82d": "Which model has the highest score for the CC25 dataset?",
        "8882bf11-7934-43b7-b820-0255fc7253f5": "Can you identify the language pairs used for training the mBART02 model?",
        "1a848b1a-00d2-49c0-a94b-31741fe6f3e1": "How does the performance of BART-En compare to BART-Ro in the given data?",
        "7aeab9d5-2f1f-4f43-82e7-d7a7757fb17f": "How does unsupervised translation compare to other pre-training approaches on WMT16 Ro-En according to Table 4?",
        "344d31c7-8ee4-4293-9c13-6a43ad1ee4d2": "Why is unsupervised translation considered more appropriate in certain settings, as mentioned in the context?",
        "e252862f-ac69-4418-b269-4a2dc70f361b": "Can you explain the significance of the examples provided for tuning in the context?",
        "019177ee-7807-4189-a758-64e0291aec06": "How does mBART25 CC25 perform in comparison to other pre-training approaches on WMT16 Ro-En, based on the information given?",
        "8879ee9c-cf0f-4a18-8632-bf2d32a5f519": "What implications can be drawn from the comparison with other pre-training approaches on WMT16 Ro-En, as discussed in the context?",
        "83f02247-012f-4362-8fb7-68618569e8d3": "Why is unsupervised translation considered more appropriate in certain settings, as mentioned in the context?",
        "89220be5-0274-47f0-9850-5fa96fab3b9d": "In what cases do we not observe consistent gains in high resource scenarios, according to the information provided?",
        "f553bfd7-a7e2-492f-95fb-9f9e51060469": "How does the presence of a significant amount of bi-text data impact the performance of pre-training in translation tasks, based on the context information?",
        "7117b07a-2f6e-49ef-9e07-cbfa111b9d01": "How does back-translation help augment bi-text with target side monolingual data?",
        "d29ef299-f3a3-4fb7-a8d9-f5ad6419beab": "How was pre-training combined with back-translation tested on low resource language pairs En-Si and En-Ne?",
        "1f01bdaa-c6e2-470a-aed8-1c3baac696a7": "What dataset was used for testing the pre-training with back-translation on low resource language pairs?",
        "a6c15101-4f42-47ed-b074-85216d14d0e5": "How does initializing the model with mBART25 pre-trained parameters impact BLEU scores in back translation iterations?",
        "e8349c00-a242-4268-b48c-1e2489361a7a": "How do the results of the translation directions compare to the previous state-of-the-art results?",
        "bcea2cd5-41d7-4388-9f5d-db949802d273": "What mono-lingual data was used to generate BT data in this study?",
        "654206f6-2977-47a5-ad79-9735c64bc8df": "How does the use of the same mono-lingual data as (Guzm\u00e1n et al., 2019) contribute to a fair comparison in this study?",
        "99ed0a29-c679-4b3c-80a2-c64196292e60": "How does the mBART model compare to other pre-trained models in terms of performance in En-Ro translation?",
        "7abb4e36-539a-4e49-9eed-51a23d53b105": "What is the significance of considering En-Ro translation as the only pair with established results in the comparison of pre-trained models?",
        "b106006a-4557-421a-9ba2-16a2bde109cb": "How does the mBART model perform in comparison to other self-supervised pre-training methods, both with and without BT augmentation?",
        "e35822d0-cde4-40c8-9b93-a81a513c448d": "How do the results of the conventional BART model compare to the mBART model in terms of performance on En and Ro data?",
        "ed22d48f-955c-44f4-a5bb-31d0e2019859": "Why is pre-training in a multilingual setting considered essential for achieving better results in machine translation?",
        "af5c5ee2-5532-4446-8a45-199e45e710da": "What additional gains were achieved by combining BT in the study, leading to a new state-of-the-art for Ro-En translation?",
        "065efa5d-0d3e-4e1c-bb7e-6e6dd9d405d1": "How does the study investigate the effectiveness of pre-training on multiple languages?",
        "b0b1098c-8a0e-4dbc-9c75-43c049f14613": "What does Table 5 show in terms of performance on four X-En pairs?",
        "16f3874a-2169-43a1-831c-1b8a52e92799": "How does pre-training on more languages impact performance on X-En pairs?",
        "9fff82f4-4d40-4965-82fb-1af4a7a20b36": "In what scenario does pre-training on more languages have the most significant impact on performance?",
        "f32bd394-f754-48af-8c5a-8621b9582d33": "What is the size of the My language data compared to the En language data in the context provided?",
        "2a56770f-81bc-44e4-a136-aee216ce37c6": "How does the limited size of the My language data affect the pre-training process for X-En pairs?",
        "57223901-bd6b-4614-97d7-08885cb9c00e": "How does the size of the My language compare to the En language in terms of percentage?",
        "7887fb7c-cad3-4361-bc18-37e3651bb2a2": "How does pre-training on multiple languages affect the final results when monolingual data is plentiful in languages like De and Ro?",
        "815034aa-f818-4001-a16c-fb4f69ac8292": "Why does pre-training on multiple languages slightly hurt the final results in cases where monolingual data is plentiful?",
        "a4bad5ad-a9a4-44ce-8982-0a7218576b62": "How do additional languages potentially impact the capacity available for each test language in pre-training scenarios?",
        "e1ce2742-c3c1-471a-85e7-0398f5c1bbd0": "How does the performance of mBART06 compare to mBART02 on the Ro-En task?",
        "09158262-68c2-4bbb-a43b-35d154d68bfe": "According to the text, why is pre-training with similar languages considered helpful for mBART models?",
        "0d1a9c0d-e21d-40ac-a9d0-e4e43d10d030": "What is the focus of the plot mentioned in the text regarding Ro-En BLEU score?",
        "44caaa64-bf4d-4105-b692-36fa43dd94fb": "How does the Ro-En BLEU score change in relation to the number of pre-training steps in Figure 3?",
        "73ca2706-9c1e-4ecb-aa74-1c7b2124c10f": "What is the impact of not using any pre-training on the model's performance compared to the baseline?",
        "804c4e8b-0191-4a03-a55e-8c3a2fe03f79": "How often are the checkpoints saved during the pre-training process?",
        "1c1e7876-e339-4a1b-89f6-a1fb54876d78": "Can you explain the fine-tuning process described in \u00a73.1?",
        "efef5ec3-fd4b-4432-8fac-96337df80f34": "What is the significance of applying the same fine-tuning process to saved checkpoints every 25K steps?",
        "756c08b0-09b6-4cc1-9122-a353235b4309": "How do the two models mentioned in the context compare to the best baseline after just 25K steps of training?",
        "d35cbfdd-cf16-4a83-9330-b4f42980691f": "How much do the models improve by after the initial 25K steps, and have they fully converged after 500K steps?",
        "864fa996-5d91-4ecd-9892-1940922d6a50": "Can you explain the performance of mBART25 compared to the baseline models throughout the training process?",
        "4f8e2435-d1dc-47f0-96af-7358c2c15355": "How does the size of bitexts influence the gain from pre-training, as discussed in the document?",
        "9ad427b7-b2d9-44ab-84a2-c9c3b7c8e575": "Can you explain the trend of performance improvement for low and medium resource language pairs with pre-training, as shown in Tables 2 and 3?",
        "12056360-bd4b-4cc2-932a-47608d4ea9d8": "How does the combination of pre-trained models with iterative back-translation (BT) impact translation performance, according to the findings in the document?",
        "14e61a08-897d-49d0-b15f-3747bf3d1185": "What is the significance of fine-tuning curves for Ro-En and En-De along with the size of bitext, as illustrated in Figures 3 and 4?",
        "28d7f632-9d93-4763-a2a4-8ea88d7a816b": "How does the document demonstrate the generalization of mBART to languages not included in the pre-training corpora?",
        "22524f50-aab7-47f8-9199-ae7924a1a197": "How does the size of bitexts influence the gain from pre-training, according to the information provided in the document?",
        "76762738-e659-4405-91ec-413fad5ac72e": "Can you explain the trend of pre-training consistently improving for low and medium resource language pairs, as mentioned in the document?",
        "ac75888d-6548-4112-bc0a-830a0a4e015a": "How does the performance of the pre-trained model compare to the baseline system when different sized subsets of the En-De dataset are used for training, as shown in Figure 4?",
        "0298520c-46a1-4bf1-8aab-3c4dff459f4c": "What is the significance of achieving over 20 BLEU with only 10K training examples for the pre-trained model, as mentioned in the document?",
        "80b0d9f4-287e-448c-9733-88b2ad8fe9e7": "How does increasing the size of the bi-text corpus impact the performance of both the pre-trained model and the baseline system, according to the information provided?",
        "b51264ae-e045-4323-8d41-846f186e0a3a": "How does the performance gap between the pre-trained model and baseline models change with increasing amounts of bi-text, especially after 10M sentence pairs?",
        "8dcc48c5-7db9-4aa2-aae0-412360d16066": "Can pre-training be considered complementary to iterative back-translation (BT) based on the results presented in the document?",
        "642fe7aa-dd73-4934-8769-87cde55813ef": "What are the findings regarding the performance of mBART pre-training compared to BT when using the same amount of monolingual data for En\u2192My and My\u2192En translation tasks?",
        "b54c4eeb-fab5-4412-833e-4b2be776bc54": "How do the estimated training costs compare between using BT and the mBART02 model for translation tasks, considering the pipeline involving training a baseline system, translating monolingual data, and formal training?",
        "0251b150-608d-4d70-8310-28219e699157": "How can the training costs of mBART be adjusted to be more efficient, according to the text?",
        "e061b3e7-f6f2-4599-9d20-113041af7fec": "How does the study show that mBART can improve performance for languages not included in the pre-training corpora?",
        "7a6f0f3d-073f-45ca-8857-7f7014e739eb": "Can you explain the significance of the language universal aspects mentioned in the context?",
        "33d65f52-4db1-4e8d-b0e0-2e1b0aa280a5": "What is the size of the language models mBART02, mBART06, and mBART25 in gigabytes?",
        "533c8d2b-43f4-4410-9c67-396978d8a7c8": "Which language model has the largest size among mBART02, mBART06, and mBART25?",
        "db0b9270-5c73-4266-8b3b-d3653472dbaa": "How many languages are included in the pretraining for mBART06?",
        "876218db-274f-4b2e-b74e-ba0613ee1ee3": "What is the total size of all languages in the document?",
        "98a3034d-b1a7-4101-ad8a-e2b85567a3fb": "Which language model has the highest size-to-language ratio?",
        "cbd37fe5-9096-438f-b9dc-928a8ae396bf": "How does the size of monolingual data for X compare to the size of En as shown in the reference?",
        "fc8ee21c-a23c-4ba0-9e39-df997ecda49b": "How were all the pretrained models controlled during training to ensure they saw the same number of English instances?",
        "d395d7a1-1b69-47cb-ace7-78d2ce130b7f": "What was the training cost in GPU hours for the Random (2019) model, both with and without back-translation (BT)?",
        "206cf94b-fcc5-4f08-9fff-1a5af4d60246": "What is the training cost in GPU hours for the mBART02 model?",
        "f74a5e52-3b4c-4c35-b5c0-7fd3c0d38fa7": "How does the mBART02 model compare to back-translation in terms of translation quality on the My-En dataset?",
        "097ccc32-6077-4d45-922d-7bc5b10863cf": "What is the estimated computational cost for both pre-training and back-translation based on Nvidia V100 GPUs?",
        "1e843066-399e-49fd-9cec-2ecd29960c40": "Can you explain the significance of using the same mono-lingual data for translation in the context of the document?",
        "cccb101f-b403-472d-af93-dcb5973f14c3": "How does the addition of 7, 5, 300, and 350 result in the equation provided in the context information?",
        "1bf79129-6e49-4fe5-a9cd-dba797199d4f": "What is the range of values for the mBART02 model in the context information?",
        "8d7c3362-12fe-49a1-842f-f1adad75bcc3": "How does the size of bitexts influence the gain from pre-training according to the information provided?",
        "f68b21a0-dde9-4535-97aa-a35092ae8d58": "Can you explain the trend of pre-training consistently improving for low and medium resource language pairs as shown in Tables 2 and 3?",
        "f027596f-9560-4b0a-9338-0d20644790f7": "How many pairs are included in the full En-De corpus?",
        "44b555f2-2bf1-4bea-ac90-4fb59872adae": "What sizes of datasets were randomly sampled from the full En-De corpus?",
        "5c292f8c-0d09-4983-a864-080521831ab1": "How does the performance without pre-training compare to the mBART02 results?",
        "8decb837-7f5b-483e-9bb9-35c3611de551": "Can you explain the significance of comparing different dataset sizes in this study?",
        "d2336d9e-3b59-4d6f-ae33-ca28cbf3ccde": "How do the results vary across the different dataset sizes sampled from the En-De corpus?",
        "c3959835-c655-4fb8-8ab9-2b62a7dfdb17": "How does the pre-trained model perform in terms of BLEU score compared to the baseline system?",
        "5b3a7c82-6a1a-46dc-bcbf-045a7cb898c4": "What is the impact of increasing the size of the bi-text corpus on both the pre-trained model and the baseline system?",
        "7b7d437e-fac2-484b-a87c-85c0dfec4a18": "How many training examples are needed for the pre-trained model to achieve a BLEU score of over 20?",
        "4efc2515-49fc-491f-bab9-0933d1032843": "What is the significance of the BLEU score in evaluating the performance of machine translation models?",
        "78cc8776-fa12-4313-b858-22be3a7d8666": "How does the performance of the pre-trained model with 10K training examples compare to the baseline system?",
        "49982ad8-9974-4cd3-b181-edbdbdc918e9": "How does the performance of the pre-trained model compare to baseline models, and how does this performance gap change with increasing amounts of bi-text?",
        "12aa510c-6585-44c3-a293-6ae4a2c061ae": "What observation was confirmed regarding the effectiveness of pre-training for translation in high-resource pairs?",
        "b8f7c972-f1dd-451f-9e0a-280b2ae6c456": "Is pre-training considered complementary to BT based on the results discussed in the context information?",
        "1ef76681-f640-4866-8592-a8c1caef6a41": "How can pre-trained models be combined with iterative back-translation (BT) on additional data?",
        "354e6d24-d521-4d5c-91ee-a638bbb2cc5b": "Why is it mentioned that the comparison between pre-training and BT is not fair in Figure 2?",
        "003d9865-4854-4398-8853-3ba68bbee15c": "How do the results of mBART25 and mBART02 compare to the best baseline system after 25K pretraining steps?",
        "a1a4eb64-b6a0-4c45-b47d-b935ba7fb15d": "What is the significance of the pretraining steps in the context of fine-tuning BLEU scores for Ro-En translation?",
        "98b6b790-ad38-4a12-b658-ca9794ace3d0": "Can you explain the trend shown in Figure 3 regarding the fine-tuning curves for Ro-En translation?",
        "2fd5cfa9-3b0a-4e79-9214-f389647ea58f": "How do mBART25 and mBART02 perform in comparison to a random baseline system in the context of pretraining steps and fine-tuning BLEU scores?",
        "66947fb0-cfc3-42b6-ae2d-58eafe697d80": "How does the size of the bitext affect the finetuning BLEU score in the context of En-De language pairs?",
        "23b5143e-c493-4215-b0b9-81a05e175fc3": "Can you explain the significance of the fine-tuning curves for En-De in the context of mBART02?",
        "92611f50-63e3-4355-b694-855963a0d313": "What is the trend observed in the finetuning BLEU scores as the size of the bitext increases in the context of En-De language pairs?",
        "a03352b9-a148-45e1-8a57-6740bcfcffce": "How does the random baseline compare to the mBART02 model in terms of finetuning BLEU scores for En-De language pairs?",
        "03aef07d-d853-4882-97d1-b065a03436c1": "Why is the x-axis in the figure shown on a log scale in the context of fine-tuning curves for En-De language pairs?",
        "20d7df73-b6f8-4df6-ab1b-e2245ccbc6c5": "How does the use of a log scale on the x-axis impact the data analysis in this study?",
        "629e24a7-8eed-456c-95ad-81f08c9e32e3": "What is the difference in performance between mBART and BT in translating from English to Malay, and from Malay to English?",
        "84cc5982-9bfd-4081-a23c-5b09321afb75": "How does the amount of monolingual corpus data affect the performance of BT in translation tasks?",
        "b491640b-5f65-4de8-8e71-7069dfe70820": "Can you explain why mBART achieves the same performance as BT in translating from English to Malay, but performs worse in translating from Malay to English?",
        "4bfe1815-e6ee-4ecf-8f19-6302dd14ea8f": "How does the study's methodology compare to that of Chen et al. (2019) in terms of data usage and performance evaluation?",
        "4c731a40-9146-4f76-9de8-073f824224be": "How does BT benefit from bigger monolingual data in the context mentioned?",
        "f43678aa-a16c-4d7c-bbb5-49d5e675f35f": "How do the gains further increase when combining the mBART02 model with BT?",
        "de5a6de1-f861-4d2e-a8d6-dcaf04be7d45": "Can you explain the estimated training costs for BT, including the time involved in training a baseline system, translating monolingual data, and formal training?",
        "43221aad-4c20-4510-af86-c22d03511ff0": "How do the training costs of mBART primarily lie in the pre-training part?",
        "fa11dfbd-e63a-404e-a95d-9eca169004db": "How can the training costs of mBART be adjusted to be more efficient?",
        "f3f2bc9a-4843-4aca-876e-59e694a73773": "How does the study demonstrate that mBART can enhance performance even when fine-tuned for languages not included in the pre-training data?",
        "911280ab-3079-46b5-a935-364c8169f003": "What does the study suggest about the language universal aspects of the pre-training in mBART, particularly within the Transformer layers?",
        "32f54477-722b-4eeb-8287-3fe28fd2bcfd": "How does pre-training on different language pairs impact the generalization to unseen languages in machine translation models like mBART25?",
        "057a1be1-4434-4124-8a23-0e1c8f1a6914": "What are the implications of using document-level machine translation tasks in improving translation performance, as discussed in the document?",
        "f5b234d1-65fc-444f-88ea-9088df55ed7d": "How does the presence of unseen vocabularies, such as Arabic, affect the performance of machine translation models like mBART02 and mBART06?",
        "b31151db-4f43-4338-bd1f-f98fa0ec6a82": "Discuss the differences in performance when unseen languages are on the source side, target side, or both sides during pre-training of machine translation models.",
        "bd2e1ad0-2620-46ab-8857-c3652c72fcd0": "How does the use of document fragments up to 512 tokens during pre-training contribute to learning dependencies between sentences in machine translation models like mBART?",
        "4e9e7afe-c963-4b6f-906f-ef385a973f3c": "How does mBART25 differ from mBART06 and mBART02 in terms of language transfer results and pre-training data?",
        "1b3299cc-f851-4df6-b0d5-7ea7a5363eba": "What are the three language pairs analyzed in the experiment, and which models were used for each pair?",
        "f8fd2c12-2373-4ce0-a262-f8ef7b9d65c3": "How do the mBART06 and EnRo Bilingual models differ in terms of containing Arabic, German, and Dutch data during pre-training?",
        "ca63fa2e-ca98-48c8-adf4-81f9aad404f1": "What is the significance of including all languages during pre-training in mBART25 compared to other settings with at least one unseen language pair?",
        "3a35fcac-3fc3-4644-83e6-9353f852aa4f": "How are the European languages German and Dutch related to the languages in the mBART06 pre-training data?",
        "5acdfd01-8ed6-4c76-b7b1-01f1ba4f931e": "How do the results of pre-training on English-Romanian impact the translation of unseen languages such as Arabic, German, and Dutch in the study?",
        "8a30c65e-2953-4df2-9e75-e3ff6d811529": "What is the significance of pre-training on both test languages compared to pre-training on other languages in the context of mBART models?",
        "50255251-b740-4f68-bc75-8eace7864adc": "How do the results differ when translating unseen languages on the source side, target side, or both sides in the study?",
        "12711d86-a0a9-4ab0-bf56-e838ae69b808": "What is the impact of fine-tuning unseen languages on the source side in document-level machine translation tasks according to the findings?",
        "e5737226-db4b-4de5-946d-77abb7ecc91d": "How does pre-training with document fragments up to 512 tokens improve document-level translation in the study?",
        "13f8f73c-754b-4e14-b9c6-b6edb5b3af24": "How does pre-training impact document-level translation according to the study?",
        "161a9983-3584-4ed9-a7e5-7ff09cfd1f25": "What datasets were used to evaluate performance in document-level MT in the study?",
        "39aa38d8-d0ff-4e7d-84ac-34b8998cbdf4": "How was pre-processing conducted in the study for document-level translation?",
        "10097212-6bfd-4c9e-8e8d-e627dcfc44b2": "Describe the fine-tuning and decoding process used in the study for document-level translation.",
        "e6dae53d-d4c8-4e2a-9c33-81eb42f5e588": "How does the performance of the mBART02 model compare to the Random model in the Nl-En language pair?",
        "e67b2b70-be6c-4048-8b12-5155ec62bb08": "What is the difference in performance between the En-Nl and Nl-De language pairs for the Random model?",
        "0ed1bef3-2754-4dfe-8ce2-c140a86adc80": "In which language pair does the mBART02 model achieve the highest score, and what is that score?",
        "06e2af1f-f0a7-40e1-a357-e3c006c978c2": "How does the performance of the Random model in the Ar-En language pair compare to its performance in the En-Ar language pair?",
        "c664e3a7-4677-4f56-8b02-c904749b4763": "What is the overall trend in performance for the Random model across the different language pairs mentioned in the context information?",
        "b323d91a-6351-447c-99ab-dc33ac626099": "What are the language pairs supported by mBART02 and mBART06 models?",
        "ac2e81d7-6041-4924-8492-634e707934dc": "What are the BLEU scores for the language pairs evaluated for mBART02 and mBART06 models?",
        "034ddd48-944f-439f-9cea-48de6f01faef": "How do the BLEU scores for mBART02 and mBART06 models compare in terms of performance?",
        "7aeb4068-dc3f-4e88-beb4-32fc3708439b": "What is the significance of the numbers in parentheses next to the BLEU scores in the context information?",
        "a490f8d6-5427-4e7d-9694-d1c2ba3303ec": "How does the inclusion of additional languages in mBART06 impact its overall performance compared to mBART02?",
        "f74f20f5-525f-4cee-bcaf-ef975a10de96": "How do the language transfer results for mBART25 compare to the results for the individual languages listed in the table?",
        "649e98e7-6340-449f-8660-4167afeefb5c": "What do the numbers in parentheses next to each language represent in the context of the table?",
        "46bb7c48-f9e7-41eb-a71b-68bbae4ab921": "Can you explain the significance of the numbers listed under mBART25 All in the table?",
        "cda2017f-6052-4127-b88d-a6ae6f42bdb4": "How does the generalization to unseen languages impact the overall findings of the study?",
        "95de8a82-acd7-4d61-8716-2a8e3fb9a6f9": "Discuss the potential implications of the variations in performance across different languages as shown in the table.",
        "924d9304-1dd2-4bfd-b0ef-2654328a98ac": "How does mBART25 differ from other models in terms of pre-training on unseen language pairs?",
        "fa2b491a-4a5a-4fb9-ae9b-6b7a3126237b": "Can you explain the significance of fine-tuning on language-pairs without pre-training on them?",
        "f3b9c7db-040d-4dc8-8cb2-8101916b5f8a": "What is the gap between the results of mBART25 and other models in the context of generalization to unseen languages?",
        "2329a286-c3a6-4795-8314-3193d7b26415": "What are the three pairs of languages analyzed in the study?",
        "19e8b710-70d8-4654-afec-1722c7290636": "How do the mBART25, mBART06, and mBART02 models compare in terms of results for the Nl-En, Ar-En, and De-Nl language pairs?",
        "9e2accf4-58fc-49a4-81e8-c58554a40de7": "What is the experimental setting for analyzing the results of the language pairs in the study?",
        "37ad5a84-ecaf-44c0-920b-cf308931f445": "How does the mBART25 model compare to the mBART06 and mBART02 models in terms of performance for the language pairs?",
        "4bd1ca3e-898e-4dbd-9c71-67ddc8798b6b": "How does the language composition differ between mBART06, EnRo Bilingual, and mBART25 during pre-training?",
        "8d05648f-f9dd-4b60-9d16-abef0a993c61": "Why are Arabic (Ar), German (De), and Dutch (Nl) not included in mBART06 and EnRo Bilingual pre-training data?",
        "cb661c62-8483-4c7d-b5e1-f365e85084c8": "How does the inclusion of all languages in pre-training affect the performance of mBART25 compared to other settings with at least one unseen language?",
        "202a3cf3-327c-4246-927c-7b02acd59df0": "How do pre-training on English-Romanian impact the translation of unseen languages like Arabic, German, and Dutch?",
        "91681c94-1147-4207-a209-253c7e8d2739": "What were the results when pre-training included both test languages compared to pre-training on other languages?",
        "efc8fa8a-9c9a-451c-838b-c1e8cd1913e0": "Can you explain the surprising competitiveness of pre-training on other languages in the context of translating unseen languages?",
        "dad1e8a3-8a90-4167-a7bc-25b6aea725b9": "How is Unseen Vocabularies Arabic related to the languages in mBART02 and mBART06?",
        "93994702-a3b4-451c-812d-064b92793940": "Why are the word embeddings of Unseen Vocabularies Arabic largely untrained?",
        "8a804230-9d59-4eb7-a222-0d8751167b77": "What does the improvement on Ar-En pairs suggest about the pre-trained Transformer layers?",
        "161058a3-be85-4ee5-9d13-ebcfa5c5eb94": "How do the results on Nl-En pairs compare to those on Ar-En pairs?",
        "942a8b0a-58d7-45c2-94be-9ac14bf5faaa": "What does the document suggest about the universal properties of language learned by pre-trained Transformer layers?",
        "52d361bd-8bda-4382-82b3-1d44d64e3b04": "How does the performance of mBART25 differ when unseen languages are on the source side, target side, or both sides?",
        "7bb0d513-906d-4bbc-b050-ace8b60a6fb0": "What is the impact on performance when both sides of the unseen languages are present compared to when at least one language is seen during pre-training?",
        "66e26295-0926-4baa-8de4-8ee51f4f5736": "How does mBART06 compare to mBART02 in terms of performance on X-En pairs?",
        "486b0f46-4187-4d14-932c-884f1d3722e2": "Can you explain the difference in performance between mBART06 and mBART02 on X-En pairs?",
        "143c99ba-7f3b-48a7-9d6f-16fb06d5a329": "What makes fine-tuning unseen languages on the source side more difficult compared to other languages?",
        "0a1e50e8-bc96-432e-ac22-e83f6f216426": "How many documents, instances, and sentences are included in the WMT19 En-De dataset?",
        "6798e893-c63b-497b-97d9-25644080c7dc": "What is the significance of conducting extensive future study on fine-tuning unseen languages?",
        "d09ec54b-7564-437c-8491-08756dd87661": "How does the size of the TED15 Zh-En dataset compare to the WMT19 En-De dataset in terms of documents, instances, and sentences?",
        "af5d635c-794d-4d49-aa37-90448bd88f41": "Why is it important to consider the statistics of the document-level corpus when working with language datasets like WMT19 En-De and TED15 Zh-En?",
        "e3dca307-a5b4-4652-9d3a-1289816cdd19": "How does mBART perform on document-level machine translation tasks?",
        "794fdbe5-b38e-46af-bc2e-061f91c0d522": "What is the goal of document-level machine translation?",
        "99291476-fc0e-4bcb-b114-c7c3115cd9e2": "How many tokens are document fragments limited to during pre-training?",
        "2e4f9bbf-ac6f-4082-98c1-03028cb643a5": "Why is it important for models to learn dependencies between sentences in document-level machine translation tasks?",
        "659861e0-aef2-415f-b462-1039c86088d5": "How does pre-training impact document-level translation?",
        "6cab749e-8ed7-40e0-9219-1f8106fc43d5": "What are the potential benefits of pre-training for document-level translation?",
        "2d0eebd6-f019-471d-8abf-68e25810f9db": "How does pre-training impact document-level translation according to the study?",
        "5e1c6bf0-c426-464e-9176-1acc1249ba24": "Which datasets were used to evaluate performance in the experiment?",
        "e509e225-099c-4858-9aa3-99a85bc8966d": "What are the statistics for the WMT19 En-De dataset?",
        "2df27e20-16b0-4788-88fa-5458af0b7940": "What are the statistics for the TED15 Zh-En dataset?",
        "790d951d-4056-4ef2-8edc-d6977a8326e6": "What dataset was used for training the En-De model?",
        "92cd0350-eddd-48b4-bfde-774440ae7781": "Where did the Zh-En dataset come from?",
        "64b08ec3-2497-49df-a378-420f86141215": "How was the test set selected for the model?",
        "8780d056-8de7-4916-837d-26419e651030": "Can you explain the significance of using the WMT19 and IWSLT datasets in training the model?",
        "661666e5-c9ec-44a7-9d84-67f8652d5fdf": "How does the approach of using document data differ from sentence-level data in training the model?",
        "cf9b8d18-f1e5-486d-b4bf-c6ba5f98c636": "How is the test set for the model in this study defined?",
        "12a9c3a0-1cfb-4f41-88be-7bc1764a1b8d": "Can you explain the pre-processing steps used in this study?",
        "0470874c-ad29-474e-8dd3-25692e17489d": "What symbols are used to separate sentences in each block of the data?",
        "dd7add59-02b3-443f-9451-b7a4fa7c8d06": "How is the entire instance ended in the pre-processing step?",
        "2bc58d67-3c16-4dd8-a6af-b5a23f679631": "What is the purpose of using a specific language id at the end of each instance?",
        "3f573720-d4d9-4394-9be8-0e6ca9953d52": "How many instances, on average, is every document split into according to Table 8?",
        "dc1952e3-3d03-4b2c-a4e9-2ec9a419739a": "Describe the fine-tuning scheme used for sentence-level translation in the document.",
        "5eaa50be-0eab-41b0-8095-1e14a2a252a7": "What task-specific techniques developed by previous work are not used in the fine-tuning and decoding process mentioned in the context?",
        "6d604f4b-ed04-4027-ae48-049f8585744c": "Explain the difference between sentence-level and document-level BLEU scores in machine translation, using examples from the provided context.",
        "d7ee352d-34dc-4496-827e-a0fd5954eedd": "Compare the performance of randomly initialized machine translation models with pre-trained models, citing specific results from the document.",
        "b8fde8a1-b5d1-47e3-b855-c5b7e332ebfa": "Discuss the importance of pre-training for document-level machine translation models, based on the results presented in Table 9.",
        "eb057023-f2bb-4cdb-8eed-df29378b9d50": "Describe the approach used for decoding in the document-level machine translation models, highlighting any unique features mentioned in the text.",
        "4648609e-25e9-4a5f-be3f-0a3a080ecad8": "Evaluate the performance of mBART25 models in comparison to HAN (Hierarchical Attention Networks) for document-level translation on the Zh-En language pair, as discussed in the document.",
        "82d6b3b4-18be-4d79-8001-daad46e36cb4": "Explain the difference between sentence-level and document-level BLEU scores in machine translation, using examples from the En-De and Zh-En language pairs.",
        "1aa452b0-3ca2-490b-898a-b44fa99d9526": "How does the use of constrained contexts or restricted attention impact machine translation models, according to the information provided?",
        "17dccdb7-dd4e-4a94-8690-48b201e9b743": "Describe the decoding process for the document-level machine translation model discussed in the context.",
        "67332738-625f-4859-829a-ef10478d6215": "Discuss the challenges faced in evaluating document-level BLEU scores for the Zh-En language pair, as mentioned in the document.",
        "b9b9f507-c807-49d2-b408-f400436149c9": "Compare and contrast the performance of the document-level (Doc-) MT model and the sentence-level (Sent-) MT model, both with and without pre-training, based on the information provided.",
        "d4975b55-22d2-4d0c-b2af-72813943864a": "How do the d-BLEU scores compare between the models in this study?",
        "fa03c118-03dd-423c-a212-bf5fadc5315b": "What is the significance of pre-trained weights in improving the performance of machine translation models?",
        "53a9a5b7-7999-4927-9d41-d5242900cf55": "How do the mBART25 Doc-MT models perform compared to HAN in document-level translation?",
        "6c88a6ee-3684-4d60-a299-d1986e9fb340": "Why is pre-training considered critical for document-level machine translation performance?",
        "5da218a1-c579-4491-b505-3b2f671223c7": "How is unsupervised machine translation evaluated in this study?",
        "07f7372c-3dd8-4ed1-9ac6-3e94dacc8e7c": "How can back-translation be utilized in the absence of bi-text for a target pair?",
        "093b97e5-589f-4abc-803d-c109417c4240": "What is the potential benefit of using mBART as an initialization scheme for translation methods?",
        "ad0f1b9e-6ee1-422f-88b5-b4a09745a26f": "How has previous research demonstrated the possibility of zero-shot transfer in translation tasks?",
        "6501f092-7ab3-457a-84ec-158c22107416": "What is the limitation of the focus in this study regarding building MT models for single language pairs?",
        "95b0ef71-594b-4ba0-a8b5-4414fda9249d": "How can 3d-BLEU be recomputed based on the provided system output in the context of machine translation?",
        "edea2a07-3083-4b95-8de4-df8413a24f17": "Explain the difference between sentence-level BLEU scores and document-level BLEU scores in the context of En-De translation.",
        "41198372-404f-4f75-ab9f-8b2021883564": "Compare the performance of the Sent-MT model and the Doc-MT model in terms of BLEU scores for En-De translation.",
        "0c4429a2-e294-4304-9db7-3d2362c65f3e": "Discuss the significance of the difference in BLEU scores between the Random mBART model and the s-BLEU model for En-De translation.",
        "5e379ad7-3371-4ae4-8aef-540657d88c94": "How does the s-BLEU score for document-level translation compare to the sentence-level translation in the context of En-De translation?",
        "00e57918-f0fd-46dd-b335-a2e517f3c64b": "What can be inferred from the lower BLEU scores of the Doc-MT\u00d7 model compared to the other models for En-De translation?",
        "81ab2f96-8ab5-4258-917a-f25297c222ac": "Explain the significance of document-level BLEU scores in machine translation and how they differ from sentence-level BLEU scores.",
        "71184d77-8c8f-4e30-8192-1ff5d2d1d4d4": "Compare and contrast the performance of the Random mBART25 and HAN (2018) models in document-level machine translation for En-De and Zh-En language pairs.",
        "175cbc85-9f32-4475-9885-943cbb822b9e": "Discuss the implications of the differences in d-BLEU scores for Sent-MT and Doc-MT in the context of machine translation evaluation.",
        "0a6ea92c-3b21-4342-9420-571a5dd49b68": "How does the performance of the HAN (2018) model in document-level machine translation for Zh-En compare to its performance in En-De translation?",
        "9fc05aa3-b232-4b18-a882-e6f97b6a97bd": "Analyze the potential reasons behind the higher d-BLEU score for the HAN (2018) model in Zh-En Doc-MT compared to Sent-MT.",
        "a251cb58-85a0-4808-9b51-f825b2e0a543": "How does the randomly initialized Doc-MT model impact the translation process in document-level machine translation?",
        "f0a02d8c-f511-4b7d-9650-a7c5f57d5339": "What are some potential limitations of the Doc-MT model mentioned in the context?",
        "89ed69ea-a9f9-488d-bb90-1d6c8e6f14fa": "Explain the approach used for decoding in document-level machine translation as described in the context.",
        "156f94da-61fe-4475-9e67-e6c578730844": "How do constrained contexts and restricted attention play a role in improving machine translation performance, according to the context information?",
        "6b35baef-c980-49b5-ad9a-d650a4ffa5f3": "Can you describe the process of translating instance blocks autoregressively in document-level machine translation, as mentioned in the context?",
        "6050885e-864c-4e31-8abf-1acfd1a211af": "How does the model determine when to stop decoding during sentence generation?",
        "4f16248c-044f-43b2-b488-0e3e8e94a825": "What is the default beam size used in the model?",
        "74a77a86-47b8-4e6c-930d-4842c56894b2": "What are the two types of MT models trained in the study?",
        "7a5a248e-c3f5-4ba1-be8a-ba940c9684df": "How does pre-training impact the performance of the MT models?",
        "4ec538a2-6af2-4e83-bf20-6870a7cc1daa": "Can you explain the difference between the document-level and sentence-level MT models?",
        "d5637243-103e-4aef-861d-a19bcd1039c3": "How is mBART25 used as a common pre-trained model for En-De and Zh-En translation?",
        "5356c70c-e168-426e-87aa-09c8ebf41e2d": "Can you explain how the mBART25 Doc-MT model decodes multiple sentences together in the context of En-De translation?",
        "141cae02-bbc1-4bc7-bb7c-69f40c88640c": "How are BLEU scores evaluated in the context of En-De translation, both on sentence-level and document-level?",
        "3bed213e-5d27-4364-ab69-e610f77c66d4": "What is the significance of being able to align translated sentences to source sentences in the evaluation process?",
        "5770ab2d-08cb-4e6f-b186-42fe0ce54d99": "How does the use of mBART25 contribute to the overall translation quality in En-De and Zh-En translation tasks?",
        "58c0c0ec-c0e5-429f-b1f0-d16ec39bcbbb": "Why is it mentioned that the same number of translated sentences cannot be produced for Zh-En compared to the reference?",
        "7c0ae6a1-de7a-4518-9f0c-b026cf18e000": "What is the significance of d-BLEU scores in evaluating translation quality in the Zh-En direction?",
        "05665f64-7d76-4444-ad2b-b11594aea606": "How do alignment errors in test data impact the translation process for Zh-En language pairs?",
        "3a626526-5fd8-4584-bd73-51f8bceed7da": "How do the d-BLEU scores compare between the models discussed in the document?",
        "3a306eeb-cd3e-4b72-bb5f-7db090d93f5e": "What is the approach used by Hierarchical Attention Networks (HAN) for document-level translation?",
        "2054b201-178a-41a0-8c68-c211bf77ddc2": "How many layers of attention are combined in the HAN model for Zh-En translation?",
        "41e410e1-1e06-430d-be8a-09018e7ff361": "What is the significance of comparing the models with HAN in the context of document-level translation?",
        "85c61ae9-0e0f-46e6-a74a-d64bdf4f879e": "How does the HAN model differ from other non-pretraining approaches for document-level translation?",
        "d7a628b8-1de7-452c-868a-3ff744296a81": "Explain the concept of attention in machine translation models and how it is utilized within and across sentences.",
        "51fbe082-75d3-4ba8-884e-64ee9e13f586": "Compare the performance of machine translation models initialized with pre-trained weights versus randomly initialized models, citing specific examples from the results presented in Table 9.",
        "cf34b67b-f268-4709-98b5-bb34abc4145d": "How do the mBART25 models compare to the HAN model in terms of performance in document-level machine translation?",
        "ec9013a3-7252-43b8-9ea3-bbe14aec026a": "What is the significance of the fact that the mBART25 models were not customized for document-level MT?",
        "23a663b7-1ccf-4fd4-8670-229a6cdfe239": "Can you explain the difference between standard BLEU scores and document-level BLEU scores in the context of machine translation evaluation?",
        "f622dd81-bd08-41fd-9561-23be7dafa22c": "How do the mBART25 models achieve better results compared to the HAN model, despite not being specifically tailored for document-level MT?",
        "3f510c16-a682-4403-8bf9-c736b9f51b52": "What implications do the superior performance of the mBART25 models have for the field of machine translation research and development?",
        "f8be00c8-d1dc-4d9c-b0e9-9bd0200e5096": "Compare the performance of mBART25 Doc-MT models and sentence-level fine-tuned models in cases of En-De and En-Zh datasets.",
        "d378c8a0-9676-4142-9bb3-6d78d2578ff8": "What is the outcome when randomly initialized Doc-MT models are used for the datasets mentioned in the context?",
        "bb24b49a-56dd-4687-8785-254b3e55dfc6": "How do the results differ between models with pre-training and models without pre-training in the context of En-De and En-Zh datasets?",
        "1cb46303-3400-4e16-933e-3e464f133474": "Discuss the importance of pre-training in the context of machine translation models based on the information provided.",
        "27e1c989-870e-470d-8b31-d4374f6a622f": "Why is pre-training considered critical for document-level performance in machine translation tasks?",
        "63557a16-1f14-44f5-b9e4-a37a03fb2cfb": "What challenges are associated with collecting high quality document-level data in large quantities?",
        "bdbf6ecf-3217-47d7-b1c5-a0d2a3f3a958": "How does the evaluation of the model extend to tasks where no bi-text is available for the target language pair?",
        "87416b6b-3708-4184-b2a2-b60e16f39d04": "Can you provide an example of the sampled example mentioned in the document?",
        "e69d3e7d-3008-4181-b8c2-3727866f5749": "How do large performance gaps in machine translation tasks suggest the importance of pre-training for future work?",
        "c6c5b543-cb01-4de9-b2df-6e60b3d757b7": "How would you define unsupervised translation according to the context information provided?",
        "f43e40f8-51ae-4365-847b-47e890d04ae4": "Can you explain the first type of unsupervised translation as outlined in the document?",
        "698f6d99-4b0f-4adf-9d42-a4a64710e416": "How can back-translation be used as a solution for learning in the context of the document?",
        "12dbe42d-327b-4d50-8386-3057b72079f0": "How does mBART contribute to providing an effective initialization scheme for methods like back-translation?",
        "50259719-75d2-45de-9e08-014081a26b50": "How has previous research shown that zero-shot transfer is possible in machine translation?",
        "9455e181-1eb4-492d-b33f-1170577ae911": "What are some methods that have been used for zero-shot transfer in machine translation, according to the context information?",
        "c6c8bfeb-6c57-447e-a33a-c6a8d31ba53b": "Why does the focus of the study only involve building machine translation models for single language pairs?",
        "1a372927-90a2-49c1-a990-e1f082153101": "What is the plan for multi-lingual pre-training in the future work?",
        "937e41f0-fbdf-4e0d-acc2-a22c8cd2c535": "How is 3d-BLEU recomputed in the study when bi-text for the target pair is not available?",
        "75e76ce1-8ea0-43ac-91cf-71aa5adabfc7": "Explain the concept of unsupervised machine translation and how it is achieved through back-translation and language transfer, using examples from the document.",
        "7c0c8fee-c298-4c35-a40c-bb02cb85073c": "Compare and contrast the results of unsupervised machine translation via back-translation for similar and dissimilar language pairs, as discussed in the document.",
        "d91f2fd6-ef73-4aab-8c26-f3954498604f": "Describe the process of unsupervised machine translation via language transfer, including the datasets used and the results obtained for different language pairs.",
        "7d5495cb-f025-4ef9-a2ec-a9fdb377d280": "Discuss the importance of multilingual pre-training in achieving successful unsupervised machine translation, as highlighted in the document.",
        "eb816074-2cd4-475f-8374-6d33bb435598": "How does mBART support effective transfer in unsupervised machine translation, even when the source language lacks any form of bi-text?",
        "de54ce67-adfb-4816-9ba7-095c81b74978": "Explain the concept of unsupervised machine translation and how mBART supports effective transfer even without a source language bi-text.",
        "9c587d54-a22d-4027-b7f4-0d9ce5df2e1a": "Describe the frameworks illustrated in Figure 5 for unsupervised machine translation via back-translation and language transfer.",
        "2b64890d-1740-4518-80ad-9ae56518db9a": "Discuss the datasets used for evaluating pre-trained models in unsupervised machine translation, including both similar and dissimilar language pairs.",
        "13514cef-459d-46a0-a3b8-dd10efb5390e": "Compare the learning procedure for unsupervised machine translation via back-translation as described in Lample et al. (2018c) and Lample and Conneau (2019) with the approach used for mBART's pre-trained seq2seq model.",
        "204298fa-3fa2-4789-a765-fd0d16b3c38d": "How does the mBART model constrain token generation during on-the-fly back translation to avoid copying the source text?",
        "209e7858-7b96-4a37-9efc-beab4226333d": "What are the results of the unsupervised translation compared to non-pretrained models and models with existing pre-training methods?",
        "d035adbc-765b-4703-9270-5961eff983ab": "How does the mBART model perform in unsupervised machine translation via language transfer for different language pairs?",
        "f6fc6141-55fc-418e-9848-439f460034db": "How does the mBART model achieve reasonable transferring scores in unsupervised machine translation, and in which cases does it outperform supervised models?",
        "6393a96e-1dae-4ba7-8336-0d7844d228ef": "How does the mBART model's performance compare to other pre-trained models like XLM and MASS in unsupervised machine translation scenarios?",
        "f0162586-ca1c-42b2-8e53-866775af22d7": "Why is multilingual pre-training considered essential in the context of the document?",
        "08b13e28-0fa8-48b9-a578-fe0a82bbe4d5": "What is the significance of producing universal representations across languages in machine translation models?",
        "b4302c0b-aea5-4878-b1e4-2f45029443cb": "How do randomly initialized models without pre-training perform in comparison to models with multilingual pre-training, according to the document?",
        "614c9562-3bab-426e-aaca-afaa39b57798": "Explain the concept of unsupervised machine translation and how it is achieved through back-translation and language transfer.",
        "3072918f-63ab-44f4-826a-37ecad540b62": "How does the use of Ne-En language pairs play a role in unsupervised machine translation?",
        "585d9326-8905-486f-92f8-ccdfda1ab7c2": "Compare and contrast the frameworks of back-translation and language transfer in the context of unsupervised machine translation.",
        "1a91a0e1-192c-4998-af9e-506b43c52d70": "How does mBART support effective transfer in the context of translation via back-translation and language transfer?",
        "faaf1168-edd8-4c68-be27-bfa6a0411940": "Can you explain the significance of using Ne-En translation as an example in the evaluation regime described in the document?",
        "29a739b3-3b41-4f8c-a3ad-fe47f1b17b15": "How does multilingual pre-training, such as mBART25, play a role in the transfer process mentioned in the context information?",
        "d50e8650-3e81-4aaf-a5bf-6353eeca8911": "What is the main argument presented in the document regarding the effectiveness of mBART in supporting transfer, even without a source language bi-text?",
        "c61b3beb-3e88-41a1-bba1-05868f5ba838": "How does the document propose to demonstrate the effectiveness of mBART in supporting transfer in the absence of a source language bi-text?",
        "f5e333fd-66b7-4bc2-8f42-94f4288021ed": "How does multilingual pre-training demonstrate effectiveness in unsupervised machine translation?",
        "45a9ae6f-976a-47b7-a92a-145a59224d18": "Explain the concept of back-translation in the context of unsupervised machine translation.",
        "ddfdf4bb-b05c-4c97-9145-40f79134f08d": "What is the significance of language transfer in the effectiveness of multilingual pre-training for unsupervised machine translation?",
        "fd0f5fdb-52b7-4659-844d-0ab4d945428c": "How does the approach of unsupervised machine translation via back-translation work?",
        "86ad7e1c-04b0-461b-acec-aa819cde28cd": "What types of datasets were used to evaluate the pre-trained models in the study?",
        "0617f108-4287-4db3-938c-dc0b72f3e8be": "How were the similar and dissimilar language pairs determined in the evaluation of the pre-trained models?",
        "642f5549-30a6-4b76-a7cc-a0bdff8dafa0": "Can you explain the significance of measuring the subword units shared between source and target languages in the study?",
        "0149dc08-41e2-4b3e-bed2-6fe6ca83e800": "How do the authors ensure that they are using the same test sets as the supervised benchmarks in their study?",
        "a8cae3b6-20eb-4ebd-8aa1-aef45059502b": "Why do the authors choose to directly use the pre-training data for back-translation in their research?",
        "746703a1-7aae-4bdc-ad3f-0e8922b32284": "Can you explain the procedure described in Lample et al. that the authors follow in their study?",
        "71c60b74-1cb6-4b4f-9f6c-c860e3615402": "How is the translation model initialized in the procedure described in Lample et al. (2018c) and Lample and Conneau (2019)?",
        "30367ca8-0ad4-4bd8-bb4e-1c2685afa51b": "What is the purpose of learning to predict monolingual sentences conditioned on source sentences generated by on-the-fly back-translation (BT)?",
        "276dfccc-f6f6-4ee0-b195-34baf3d4e2b8": "Why did Lample and Conneau (2019) only pre-train an encoder?",
        "d77f55bf-c125-41fb-8b40-6b78182a3f91": "What additional training step did Lample and Conneau perform to learn a seq2seq model?",
        "2df10a72-6a80-4293-8216-1da58dd279f8": "How does mBART's pre-trained seq2seq model differ from the approach taken by Lample and Conneau (2019)?",
        "17dd1136-4cdc-4ea0-afe0-e065b9327147": "How does the constraint placed on mBART during on-the-fly back translation prevent it from simply copying the source text?",
        "cdcc94e9-2395-4184-8c25-9b8b76a1a929": "Why is mBART limited to generating tokens in the target language for the first 1000 steps of on-the-fly back translation?",
        "11db8368-8421-4118-b5c4-148e86ed52ea": "How does the constraint on mBART contribute to the effectiveness of the back translation process?",
        "7c493d61-472a-4664-811f-7a1cf378e26b": "What potential challenges or limitations may arise from restricting mBART's token generation to the target language for a specific number of steps during back translation?",
        "5ec81c0e-bd3e-4de1-883b-c72e3c68bc27": "How do the unsupervised translation results compare to non-pretrained models and models with existing pre-training methods?",
        "eb405520-3000-48cd-8790-8fd9eea3ab24": "What approach was taken to mask out the output probability of predicting tokens in the target monolingual corpus?",
        "1d76ea38-d692-474f-8dd3-9777e49f3faf": "Can you explain the significance of using existing pre-training methods in the context of translation results?",
        "34d7444e-2cc2-4003-8596-7b5c13ce2871": "How do the pretrained models discussed in the document compare to non-pretrained models in terms of performance?",
        "db51dac3-d639-4062-96ef-912d5f00b464": "In which specific pairs do the models discussed in the document outperform XLM significantly?",
        "d24c76ca-a45a-4162-a67f-fa4ca7edd3f2": "How do the models perform in similar pairs compared to XLM and MASS, according to the document?",
        "a5b80ca8-80b3-4a5c-96fc-093831417789": "Can you explain why the existing approaches completely fail for dissimilar pairs (En-Ne, En-Si) according to the document?",
        "3526b2fe-2898-4425-863c-332a045e295d": "What are the strengths of the models discussed in the document when it comes to En-X pairs?",
        "23b3b34b-cc1b-427d-944d-ab646159ea1f": "How does the second case of unsupervised machine translation differ from the first case?",
        "0301410c-97b4-4419-8ff9-06207574cfc8": "Can you explain the concept of unsupervised machine translation via language transfer?",
        "d4fd7f29-b386-4dd1-a8ce-f9ec788f1554": "What is the significance of having the target language appear in a bitext corpus with another source language for unsupervised machine translation?",
        "6310afd7-c05d-4db4-a1d4-974f03ef3dff": "Can you list the 12 language pairs that are considered for translation in the dataset?",
        "95c777dc-b9df-4c7b-9ef7-f130ae47cf20": "How many Indic languages are included in the dataset for translation?",
        "be3f874f-f069-458f-bbff-280605953357": "Which language pairs cover European languages in the dataset?",
        "762a1aa5-7aa6-4b68-be2d-64dfcd4dd4f7": "What are the East Asian languages included in the dataset for translation?",
        "6d921640-9686-45e5-8614-3f679bb97c29": "Can you explain why only X \u2192En translation is considered in this study?",
        "4ae9b02c-095c-4707-96c9-80d81f1878d2": "How is the pre-trained mBART25 model utilized in the study?",
        "edf94837-6283-4fff-b84c-85697b77fa8c": "Can you explain the process of fine-tuning the mBART25 model for each language pair?",
        "cd927a76-3459-4dd5-83a1-3872c8273c12": "What is the significance of directly applying the fine-tuned models to the rest of the language pairs?",
        "f2383c24-16cd-415b-9610-ec6364d9bdfd": "How does the direct fine-tuning performance on the diagonal serve as a reference point in the study?",
        "49c13283-e01c-4e60-a272-a9a3357b9be5": "What is the overall trend in transferring scores at all pairs over different fine-tuned models, according to the context information?",
        "22eb640d-e8e8-4230-abbe-4abc3b7003bb": "Why does the supervised model fail in the Gu-En pair, as mentioned in the text?",
        "a6d9a45d-40cc-43fd-8b2e-ca78a7802476": "How do the results achieved in the Cs-En pair compare to the supervised results?",
        "8c17b9d9-66ac-4b0f-b75d-e5bcb148d8e2": "What is the significance of achieving much better results in the Ne-En and Gu-En pairs compared to the supervised results?",
        "bdcf4f1e-5077-4ecd-9f16-7a64f09258a2": "How do the transferring scores vary across different pairs of languages in the context information provided?",
        "456fbd83-b34b-4d0b-a158-5efe4468a98b": "Why is multilingual pre-training considered essential in producing universal representations across languages?",
        "b58e40de-78f8-444b-9f07-d88e2089f842": "What is the outcome when randomly initialized models without pre-training are applied in the context mentioned?",
        "e029e3ed-7954-4ec5-a0b3-141cb2b960af": "How does the ability to translate one language to English indicate the success of multilingual pre-training?",
        "72b0e059-0392-4182-92f7-48f35a51c96d": "How does the XLM model compare to other models in terms of performance in unsupervised machine translation?",
        "de2f00a7-412c-4bac-b48f-f2f0b7322874": "In what scenarios is language transfer shown to be useful in unsupervised machine translation?",
        "a9455638-8721-4833-85c2-de0101fc63d8": "Can you explain the significance of vocabulary sharing in language transfer for effective results in machine translation?",
        "f56ddf0c-dbb5-4d87-9d52-78dc2ed560cc": "How do the results of unsupervised machine translation with back-translation compare to language transfer in Table 12?",
        "ffeb5b1c-4676-483b-b9c9-0b92fd138c30": "How can combining both back-translation and language transfer techniques improve the results of unsupervised machine translation?",
        "e1c7caec-6fac-4613-9107-bdf09c21027b": "How does the performance of the XLM model compare to the MASS and mBART models in terms of similar and dissimilar pairs for different language pairs?",
        "d331564a-2310-4b90-a597-084432886a4a": "What is the purpose of unsupervised machine translation via back-translation, and how does mBART perform in this task compared to other models?",
        "38b559ed-f686-43fa-b94e-e60a5ef2d7b9": "Can you explain the fine-tuning languages used in the testing phase and their respective domains?",
        "3e4df84e-570b-4567-afb0-5c040d5e3cda": "How does the performance of the mBART model vary when fine-tuned on different testing languages such as Zh, Ja, and Ko?",
        "a87087f4-f501-4994-8428-616ba2435473": "What insights can be drawn from the table regarding the performance of different models in unsupervised machine translation tasks across various language pairs?",
        "e9dc63cc-7ec5-4a21-abf9-c86c53e2e740": "How does the model perform in unsupervised machine translation via language transfer on X-En translations?",
        "4c9fda47-6052-47b6-b566-d8c87ae72053": "What is the significance of using gray and lightgray colors in the table provided?",
        "30a5b7df-5528-47cf-9975-b892fa957e79": "Can you explain the concept of direct fine-tuning and language transfer within similar language groups in the context of machine translation?",
        "76861533-434d-445a-a4d5-7519fab78c45": "How is the highest transferring score determined for each language pair in the table?",
        "449640f9-8188-47f7-bfcf-8deb26e68ad8": "Discuss the implications of fine-tuning a model on one language pair and testing it on another in the context of unsupervised machine translation.",
        "c12707e7-99fc-4d74-abdd-79004c8e45a0": "How does language transfer play a role in unsupervised machine translation, according to the document?",
        "14383229-5ddb-426a-842e-d7b426a26107": "In what scenarios is language transfer considered useful, based on the findings presented?",
        "784e98ac-60ff-4d3a-a2a9-bd9544a9a6b4": "How do back-translation and language transfer compare in terms of effectiveness for unsupervised machine translation, as discussed in Table 12?",
        "f56882ea-afbc-443f-8ad7-a353b11a1d9f": "Can you explain the potential benefits of combining back-translation and language transfer techniques, as mentioned in the document?",
        "bf29c046-4324-43d2-8753-e8622f05dc49": "How does the performance of the XLM model compare to random selection in terms of similarity and dissimilarity pairs for different language pairs?",
        "a2381bb5-29de-4b64-abb0-5637eb630a95": "Can you explain the significance of the numbers provided in the table for the XLM model in relation to the En-De language pair?",
        "9492b885-89a8-472a-8b74-3a3094212a64": "What can be inferred about the effectiveness of the XLM model based on the data presented for the En-Ro language pair?",
        "fc6741e2-ef2d-4123-8c23-a101598ffd4a": "How does the XLM model perform in comparison to random selection for the En-Ne language pair?",
        "021bdf9e-0d1f-4c60-b73a-86534fa42abe": "Discuss the implications of the results for the En-Si language pair and the XLM model.",
        "8e243682-fa8a-43b3-8ba1-b6c68f27ba88": "Compare the performance of MASS (2019) and mBART in terms of their scores for the different metrics mentioned in the context information.",
        "537dba5e-2ff3-4308-83b7-83d95c3ab5a8": "What is the difference in the score for the first metric between MASS (2019) and mBART?",
        "a01bef87-8d70-4cd7-bc3a-586e3d64ca80": "Which model performed better in terms of the second metric, MASS (2019) or mBART?",
        "1adc8b90-b5f2-49d9-a82e-fbd6786e2211": "Discuss the strengths and weaknesses of the models based on their scores for the various metrics provided.",
        "c64ce0e8-966a-4b0b-abdb-b4c2aea2ab57": "How do the scores for the third metric differ between MASS (2019) and mBART?",
        "52ce3183-2a55-4c81-95e0-d73ad34bc463": "What is the approach used for unsupervised machine translation in the document?",
        "2b3fdfd0-b38e-4cd5-8384-87a01c2ce08c": "Which languages are initialized by mBART02 in the unsupervised machine translation process?",
        "fb292328-01cb-4d51-9443-a80998d4db40": "Which models are trained on monolingual data used in pre-training in the document?",
        "16e76459-291a-4051-b29a-05c6f5ae6c23": "How are the models trained in this context?",
        "48974b05-a151-4687-b3eb-410bfbfb575c": "What languages are included in the fine-tuning process?",
        "5c2aa13d-27a5-460a-a24a-c9165df2ff83": "What are the performance scores for the testing languages in the given context?",
        "6eaae6fd-60e7-453b-9737-93fcbb300821": "Can you explain the significance of using monolingual data in pre-training?",
        "ce10d19e-c32d-4daa-a8ac-41a523a58fe1": "How do the performance scores vary across different languages in the fine-tuning process?",
        "d83aeb8b-ebab-4820-b3ec-0f675ba04ba5": "What are the values listed after the first line of numbers in the context information?",
        "bf14d2fa-c5a7-4b56-abfb-d82a335b154e": "How many numbers are listed after the second line of characters \"Ja\" in the context information?",
        "2e686e7e-2cd6-417a-97dc-5c8e44bb2824": "What is the average of the numbers listed after the third line of characters \"Ko\" in the context information?",
        "36b6a1c6-fb1f-4eaa-9a5c-2fdc1805f89c": "Can you identify any patterns or trends in the numbers listed in the context information?",
        "30130c0f-3a7f-4abf-9888-b447cfa8ec56": "How many total numbers are listed in the context information provided?",
        "a47424c7-3f51-4c07-812b-8e6a4ce5dd25": "What is the average value of the numbers listed in the first line of the context information?",
        "f3847573-9c46-43a0-86ed-32aad22ff15a": "What is the highest value in the second line of the context information?",
        "ec5c5918-eb06-44a0-add1-a2aaa9a6d368": "How many numbers are listed in the first line of the context information?",
        "d987bc76-c65b-4918-8a92-0f66f1592e59": "What is the abbreviation \"Cs\" most likely referring to in the second line of the context information?",
        "5fccc15b-49ce-45f8-84a2-e1f8643d9920": "What is the missing number in the third line of the context information?",
        "568f8ebf-c14f-4e42-881a-de4f0aabc851": "What is the significance of the numbers 2, 15.1, 16.4, and 0.0 in the context information provided?",
        "25284ecb-942d-4a70-88c4-c64bc57e6aed": "Can you explain the meaning or relevance of the term \"Ro\" in the context information?",
        "6ddc8428-832b-4697-a2e7-36b72bc2b84b": "How do the numbers 16.2, 18.7, 17.9, 23.0, and 37 relate to each other in the context information provided?",
        "dcaee940-6e74-4faf-8325-30f4d5b02544": "What is the average of the numbers provided in the first line of the context information?",
        "6eb8d77d-1acd-41b0-9524-e00919e41974": "What is the range of the numbers in the second line of the context information?",
        "d3f90820-e3ed-44ba-92b9-06e05aa5a562": "How many numbers are there in total in the context information?",
        "59957a32-1985-45f7-867f-f8d805ca0179": "What is the difference between the highest and lowest numbers in the context information?",
        "523dc148-26ae-425c-93dc-061424a7e2c6": "Can you identify any patterns or trends in the numbers provided in the context information?",
        "85a88e10-9b5d-465b-84da-f483b53e9326": "What are the values listed in the first line of the context information?",
        "5cef9d1b-56f7-4a44-b090-4e8dfaedb961": "How many values are listed in the second line of the context information?",
        "5037b6c3-4ede-4aaa-afc9-3e47059295fd": "What is the abbreviation \"Ar\" most likely referring to in the context information?",
        "854de804-2884-41db-9086-0af57068b43a": "Can you identify any patterns or trends in the values listed in the context information?",
        "8d672015-701e-49f7-ad0b-6e5c1b224930": "How would you interpret the presence of the value \"0.0\" in both the first and second lines of the context information?",
        "c6471f07-17dd-4353-838a-abe476f7baf7": "What is the average value of the numbers listed in the first line of the context information?",
        "1df81698-f4be-49c1-acf8-dfc5f2d9e195": "How many numbers are listed in the second line of the context information?",
        "7d3adbc0-9800-4fdb-9b9e-be6a6ba8d75b": "What is the sum of the numbers listed in the third line of the context information?",
        "f17cd43e-a00f-4940-b403-09373ffd45b3": "What is the highest value among the numbers listed in the context information?",
        "934f4cfb-fb76-4d25-b020-28356658928f": "Can you identify any patterns or trends in the numbers listed in the context information?",
        "05e32dca-08b7-4f55-9771-caa7327d6222": "What are the values listed for Ne in the context information?",
        "44b7239a-d42a-4822-8fe4-e520aaf2454a": "How many elements are listed for Si in the context information?",
        "68a1fb97-7fcc-4443-b6a5-ea5679e845ec": "Can you identify the highest value listed for Si in the context information?",
        "b6fd7db0-df25-42ea-bdab-3140ab75f5c8": "What is the average value for Ne in the context information?",
        "f71dd069-4c40-4a4c-83c3-a724f43b547e": "How many elements are listed for each element in the context information?",
        "1e974e6c-b8c3-4c2a-80c0-a6d284eff6b0": "How many numbers are listed in the first set of data?",
        "6b0c2dd3-4a5c-4e0f-b17d-c9e7537e424c": "What is the average of the numbers in the second set of data?",
        "a3909f0b-ebbe-4177-ba5f-4945d1c0f23a": "Can you explain the concept of unsupervised machine translation via language transfer?",
        "468313c5-76ae-463b-98e7-f6c36930f4c3": "How do you think language transfer can be utilized in improving machine translation?",
        "8e86809d-ebc5-49fd-ba95-c2fccf353b68": "What do you think are the potential challenges of implementing unsupervised machine translation?",
        "652600bd-8cdb-4225-b86b-d180587e421a": "How does the model fine-tuned on one language pair perform when directly tested on another language pair in unsupervised machine translation via language transfer?",
        "59c883ec-1b4d-4bd3-8008-32aa5022e07f": "What is the significance of using gray and lightgray colors in Table 11 in the context of language transfer within similar language groups?",
        "647c7baf-d858-48be-a7b6-95e5adb0e5ee": "Can you identify the highest transferring score for each language pair in the table?",
        "b56a299e-4ca6-4313-a7d3-323d1d02cc33": "In the context of transferring scores, what is the significance of bolding the highest transferring score for each pair?",
        "2f972066-de12-44a0-9a16-ffea75f19257": "How does highlighting the highest transferring score help in analyzing data more effectively?",
        "403e3a2f-1ddd-47c8-9933-0059f6aceb49": "Can you explain the importance of identifying the highest transferring score in a pair when analyzing data sets?",
        "4cc67e14-e4bf-4557-88ea-4fd4f5401e72": "What is the highest transferring score for the Ro\u2192En pair in the given table?",
        "dee5bd82-5d89-4a35-bafd-ddc7df82158f": "Which pair has the highest combined transferring score in the table?",
        "772b4fbd-a54a-460e-bf60-0da4866ae0ae": "Compare the transferring scores for the Ne\u2192En and Hi\u2192En pairs. Which pair has a higher score?",
        "54205779-1f4f-437a-ae98-cc5339fdbadf": "How does the transferring score for the Nl\u2192En pair compare to the transferring score for the It\u2192En pair?",
        "1afbcbb7-a244-47f2-a570-5b6db6b7c88b": "Discuss the significance of back-translation in language translation based on the information provided in the table.",
        "e91059ac-55ac-416d-b398-7df01644ef1e": "How does the study discuss the concept of language transfer in the context of unsupervised machine translation?",
        "b284eeb1-5ed8-499d-917c-df3c0250c31c": "Can you explain the significance of transferring scores and language pairs in the study?",
        "47cce76d-159d-4cf0-880f-291ef9b6b2c1": "Provide examples of language transfer between Zh, Ja, and Ko as mentioned in the document.",
        "d8b09e35-d4f1-44f1-927a-8fe3e5dff146": "According to Table 11, when is language transfer considered useful and what are the results shown for each pair?",
        "ac22369f-2161-4448-b5de-04edf59be335": "How does language transfer perform when fine-tuning is conducted within the same language family, particularly between Indic languages?",
        "b27a990a-f6b7-4031-8d44-82d6940fa4f0": "Is significant vocabulary sharing necessary for effective language transfer between languages, according to the information provided in Table 11?",
        "3cacd207-5856-4b6c-b03e-c1d76afe3ad8": "How does the effectiveness of transfer learning relate to vocabulary sharing between languages?",
        "35b269de-0360-4b27-a750-9b20b91b9f13": "Can effective transfer learning occur even when there is low vocabulary overlapping between languages?",
        "88821746-789a-4191-97cb-65ef92a0462c": "Provide an example of languages that achieve the best transfer learning results despite having low vocabulary overlapping.",
        "7894bafd-950d-444f-a4f1-80980ae5aca4": "How does language transfer compare to back-translation in unsupervised machine translation, according to the results presented in Table 12?",
        "de2ca1e0-3a0e-4995-8db6-1753bc97288c": "Under what conditions is language transfer shown to outperform conventional methods with back-translation in machine translation?",
        "19c382fb-ce5c-4e5a-94b1-43ba3416caee": "How do the results of combining transfer learning and back-translation techniques compare to using each technique individually?",
        "735bfa9d-469d-4042-8706-2a51c20efbd2": "What is the approach taken when combining these two techniques, starting from the best transferred model?",
        "d065dcdb-2e18-432c-94ce-400297959a51": "How do the results vary when applying one iteration of back-translation on the same monolingual corpus used in pre-training?",
        "a65f672d-8e2b-4faf-b1d3-b97e87cce602": "Can you explain the improvements seen in all pairs when both techniques are combined?",
        "d3dd32f8-d114-4284-8433-738a5a56d61d": "How does the iterative back-translation process contribute to the overall performance of the models in the study?",
        "c8d38d11-d741-4080-86fb-81ae71eabe52": "How do improvements in text generation occur when both techniques are combined?",
        "7f79c83c-d69c-4f56-8555-c923b5833338": "How does the work on pre-training for text generation build upon the success of self-supervised pre-training for NLP applications?",
        "182accb2-a0ca-40aa-966b-d981b3f00461": "How does denoising pre-training contribute to improving text generation tasks, such as machine translation and dialogue generation?",
        "eafad432-b70f-4bf3-b6b8-5d1509256cdd": "Explain the significance of multilingual translation in the field of machine translation and how it aims to improve translation performance on low-resource languages.",
        "cd199930-1e19-4f2d-a6d8-ace768b575e9": "How does the use of multilingual pre-training models impact document-level translation compared to previous efforts that focused on sentence-level translation?",
        "4bac5f93-3362-4336-8304-3fecd4df90e8": "What are the challenges and approaches involved in unsupervised machine translation, and how does the use of pre-trained models aid in this process?",
        "b1035858-c356-4b76-a4d4-023d079f8a96": "Discuss the findings and implications of the study on the effectiveness of multilingual de-noising pre-training in supervised and unsupervised machine translation tasks.",
        "411929ea-bfb9-4e01-965b-54da7d1081b3": "How are pre-trained models being utilized in various text generation tasks according to the context information?",
        "2151e597-3f5c-4fc1-a1a3-81c01dee8abb": "What is the significance of denoising pre-training in translation applications based on the provided information?",
        "fafa224f-dbdc-449b-b7bb-c32f8df18e78": "How does multilinguality play a role in NLP tasks, as discussed in the context information?",
        "4e9c5abe-85e0-4676-a8b0-e63f4515c097": "What is the concept of multilingual translation and how does it aim to improve translation performance, as mentioned in the text?",
        "eae5c8ad-04ce-4091-82c2-a02e9e23ce4b": "How do cross-lingual models contribute to exploiting shared representations across languages, as highlighted in the context information?",
        "1e5e4e7f-02ff-40a2-95f3-bd371b5a42c5": "How does the approach discussed in the paper differ from traditional multilingual translation models in terms of data requirements and scalability to low-resource languages?",
        "29c54ea7-d667-4138-bcde-d9ad5e9dd968": "How does the use of a multilingual pre-trained model in document-level translation improve results compared to previous efforts that focused on sentence-level translation?",
        "577f05ed-713f-475a-a33c-7a1f39f90a3e": "What are the key applications of the work discussed in the paper, particularly in relation to incorporating document-level contexts into neural machine translation?",
        "6128e7eb-9273-42f8-b6e4-522822e6c13b": "Can you explain the concept of unsupervised machine translation as outlined in the document, and discuss the categories of applications focused on in this work?",
        "dc3683ba-3ea3-421b-a362-410e9551a4c1": "How do the authors address the challenges of learning to translate between languages without a direct parallel corpus, and what techniques are proposed to overcome these challenges?",
        "4ed17cd9-3662-45c0-a2f4-80d7f5689ae3": "How does multilingual de-noising pre-training improve both supervised and unsupervised machine translation according to the text?",
        "c22f728c-faad-486c-ac09-ecc342b03a2e": "Compare and contrast the approaches used in the text for unsupervised translation, specifically mentioning the methods used by Wu et al. (2019b) and Pourdamghani et al. (2019).",
        "cf16dd48-198f-43f9-a10b-6a43be964fd2": "Discuss the significance of transfer learning in the context of multilingual pre-training as mentioned in the text.",
        "f6b41439-ff1b-4c58-8973-5206306cd5da": "How do the authors suggest combining pre-training with other approaches such as back-translation for improved machine translation?",
        "479f971e-d64f-404b-93ce-36fc892896cf": "What are the potential future directions mentioned in the conclusion of the text regarding scaling up the current pre-training methods?",
        "1db45ff5-d7e6-449a-8ff0-73f5e545ee7d": "How have recent advancements in natural language processing technology impacted text generation tasks?",
        "4a09b8aa-91ee-45ac-9b7e-d50c1b0d881b": "Can you name some of the key researchers and studies mentioned in the context related to text generation tasks?",
        "830ec017-b244-4577-919a-8a29b6326365": "What are some of the potential applications of text generation technology mentioned in the context?",
        "afea48f9-38fb-4654-b58c-5861c8211743": "How do researchers evaluate the effectiveness of text generation models in the studies mentioned?",
        "13d20c24-3e93-4562-b72b-6707c94c7709": "What are some of the challenges faced in text generation tasks according to the context information?",
        "f50d953a-f153-49d1-8bf3-8bda7829427f": "What are some examples of self-supervised objectives designed for training big neural models on unlabeled text corpora?",
        "f1a75769-863b-40d4-9289-100b8047e263": "How are pre-trained models typically used in the context of fine-tuning for downstream tasks?",
        "9ab7722a-5850-4366-a9c7-2cc068af598b": "Can you explain the concept of controllable language modeling and its relevance in the field of machine translation?",
        "aabf4001-b521-4769-8b59-d43411076749": "How does this work differ from prior research in natural language processing, specifically in the application of denoising pre-training for translation tasks?",
        "3304b424-12f7-4bbb-8639-bcf6b6e8fbc8": "How is multilinguality relevant to the exploration of denoising pre-training in various translation applications according to the context provided?",
        "e5acdc06-2f9d-4412-b39f-baacad338dfd": "How can multilingual word embeddings be aligned into a universal space according to the given information?",
        "c1a3504b-ded6-48d8-bfad-8276fe0143c8": "What are some techniques mentioned in the context for learning cross-lingual models and exploiting shared representations across languages?",
        "5c5298a5-9079-4ae1-9b3d-b83e90bace4f": "How can shared representations across languages be utilized in machine translation?",
        "e39aaf66-9eb8-4ac2-aec1-2229b46755cd": "What is the most relevant field for machine translation in relation to multilingual translation?",
        "f5685311-4124-4f36-8e7f-148c19f7be2d": "How does the joint training of a translation model for multiple language directions aim to improve translation performance on low-resource languages?",
        "4cb7c25e-7c22-44f0-961c-e656dd7d43f9": "Can you explain the concept of sharing representations in the context of training a translation model for multiple languages simultaneously?",
        "4ea9e695-8ce7-43e4-a4f3-7f3c2deca326": "How does focusing on multilingualism in the pre-training stage benefit the scalability of models to low-resource languages and specific domains?",
        "8b6585fc-d56f-49f5-b6ff-43a21bff1357": "What is the main difference between multilingual translation and the approach discussed in the paper for improving scalability to low-resource languages?",
        "6f67a7f5-99e7-4ff9-bd71-43c95f035aed": "How does fine-tuning the learned model in the standard bilingual scenario contribute to the overall effectiveness of the approach described in the paper?",
        "76af0645-efe5-47ba-bba6-6e18bb2a85d0": "How does multilingual pre-training differ from regular multilingual translation models in terms of potential interference problems between dissimilar languages?",
        "13e9516f-d289-4b43-99c0-df3bc0b5f9d7": "Can multilingual pre-training be a more effective approach for handling multiple languages compared to traditional translation models? Why or why not?",
        "3acd93c5-2aa6-4d9f-a679-acb1b07ec4a9": "How do document-level contexts play a role in neural machine translation according to previous efforts mentioned in the context?",
        "c442b223-0dd5-4d0d-aee1-bf3b8af98ce3": "Can you name some of the researchers who have worked on incorporating document-level contexts into neural machine translation as referenced in the context?",
        "e5e5c353-6143-4673-8215-d5b4a7368da2": "How did Li et al. (2019) utilize pre-trained encoder (BERT) in their work?",
        "fb0afc67-1a4d-4056-beec-22cf68687834": "What is the significance of handling longer context in natural language processing tasks?",
        "8d9b4395-5d2e-4d06-978f-5599b233bc2b": "Why have previous works not shown positive results on pure Seq2Seq models at the document-level?",
        "ab001046-f324-44db-a51d-5da343f517e6": "What are some task-specific techniques that have been used in document-level translation?",
        "30e09d84-1e4e-4598-9a63-47a3531720bf": "How do sentence-level translation and document-level translation differ in terms of context range?",
        "877c8fc5-80e5-4c0d-a665-61f6e12929cf": "How does the multilingual pre-trained model mentioned in the context differ from other existing models?",
        "2f8d7319-8797-4c9c-bd06-ff5e5419cae8": "What type of learning approach was used to achieve improved results on document-level translation in the study?",
        "7eb61441-eca1-4b19-85fa-c2ae215e5d70": "Can you explain the significance of the multilingual pre-trained model in the field of machine translation?",
        "b842b46b-ae18-472d-999d-45300d5c6565": "What are the three categories of unsupervised machine translation mentioned in the context?",
        "9cc2912d-a760-4818-86ac-e59aa748d5d1": "Who are the authors mentioned in the context that worked on translation without a direct parallel corpus?",
        "5277cb6e-a539-4160-8f0e-27991bb5bbfd": "Why does the work in the context focus only on applications to the first and third kinds of unsupervised machine translation?",
        "ebbe2391-96ca-4145-98ae-03adce1e5c78": "How did Artetxe et al. (2017) and Lample et al. (2018a,c) propose to handle the lack of a parallel corpus for translation tasks?",
        "10f1450d-54f5-466c-929d-1af02226364b": "What limitations were mentioned regarding the approach of jointly learning denoising auto-encoder and back-translation from both directions?",
        "e9f889f7-d154-4d2b-a451-c02c872c87ea": "Can you explain the requirement of good initialization for the method proposed by Artetxe et al. (2017) and Lample et al. (2018a,c)?",
        "601bd8e0-0353-442b-b7d0-e4deaecfaf25": "How did the approach of Wu et al. differ from the method proposed by Artetxe et al. and Lample et al. in handling the lack of a parallel corpus for translation tasks?",
        "dac0681e-76ca-4871-a768-2f9daccc97d3": "How did Wu et al. (2019b) solve the problem of back-translation in their approach to machine translation?",
        "726fca23-6f09-441c-a2a2-798a0c373115": "What approach did Lample and Conneau (2019) and Song et al. (2019) take in their pre-trained model initialization step?",
        "9b28c710-73ab-477b-a3e0-0ecb9de27582": "How did Wu et al. (2019b) mine sentences for weakly supervised translation pairs in their research?",
        "b366ddb8-1721-4b95-b1f6-d4996f4e4c86": "What was the main difference between the approaches of Wu et al. (2019b) and Lample and Conneau (2019) in their pre-trained models?",
        "b5c7a8d9-de30-47a5-ab8c-2d311dbf052b": "How did the authors in the context information utilize sentences from target monolingual data in their research?",
        "ac49ef16-9089-470d-a700-7b4ecfa8048c": "How does the approach of unsupervised translation using language transfer differ from traditional translation methods?",
        "0ccc3f4f-812d-4830-b541-4158bd951d9f": "Can you explain the concept of generating translationese of the source language and training a system on high-resource languages to correct intermediate utterances?",
        "3553ae3c-3f37-440a-8638-fee768fcfad4": "How are the methods discussed in Pourdamghani et al. (2019) and Conneau et al. (2018) related to the topic of unsupervised translation using language transfer?",
        "f4944e79-b03f-47a3-9cd0-5131c8fe8687": "How does multilingual de-noising pre-training impact supervised and unsupervised machine translation at both the sentence and document levels?",
        "a12f8121-6ded-4faa-92af-bc56c74a15d1": "In what ways can pre-training be effectively combined with other approaches, such as back-translation, according to the findings in the document?",
        "6e3538f2-0a50-4c12-aa32-857c3800027d": "How do the results demonstrate the transfer learning ability of the learned representations from multilingual pre-training?",
        "d6c13ed5-4f8c-45ec-ba51-acf13c9b41e9": "In what ways do the authors plan to scale-up the current pre-training in future work?",
        "1c5d016b-cce6-48ee-8f2b-8c3f818acdae": "What are some challenges associated with deploying the mBART100 model in production?",
        "ccb736b8-1d01-4906-a98f-41ee6be0629e": "How did the authors acknowledge the contributions of various individuals and organizations in their research?",
        "b437d5cd-b6d3-4f0c-8a8e-280dad91e233": "What are some key references mentioned in the document related to neural machine translation?",
        "4ac42d30-69d2-471f-9be1-5e2013d070d8": "How do unsupervised neural machine translation and cross-lingual transferability play a role in the research discussed?",
        "736269c0-c299-4771-9c42-bfbd708dd2c1": "Can you explain the significance of the BERT model in the context of language understanding and pre-training?",
        "86ad2d59-aa57-454e-b20b-a1f446d3a367": "What are some challenges mentioned in deploying the mBART100 model in production?",
        "4fb70bb1-3da6-44f6-81e8-b77a7ece001c": "Who are some experts mentioned in the acknowledgements section and what expertise did they share?",
        "fb7e11da-ef1a-4cce-bed1-864ddfd1bf92": "What are some key findings and challenges discussed in the paper \"Massively multilingual neural machine translation in the wild\"?",
        "5ffdb99a-6821-4140-84e0-1f6708125689": "What is the topic of the paper \"Unsupervised neural machine translation\" by Mikel Artetxe et al.?",
        "9d1a5daf-643a-4aa9-b8bd-f8ae86fdf714": "What is the significance of the Wit3 dataset mentioned in the references section?",
        "fdcfe074-5677-4ab9-976a-e1fb48250384": "What evaluation campaign was discussed in the paper by Mauro Cettolo et al. in 2015?",
        "1f645005-631b-4409-9173-9a08f78d33ac": "What task was submitted by Facebook AI in the wat19 Myanmar-English translation task?",
        "856b0aef-8625-4950-b752-db701f871313": "What was the focus of the research by Xilun Chen and Claire Cardie in 2018?",
        "a8a34ed1-3f92-4d45-bfe6-05978d6ed205": "How did Yun Chen et al. propose to approach zero-resource neural machine translation?",
        "38a87c47-4f3a-4a71-8821-36c4e8dcf378": "What was the main objective of the research by Alexis Conneau et al. in 2019 on unsupervised cross-lingual representation learning?",
        "adf612f9-9be5-49fe-a8e3-033d7c1bab85": "How does the Xnli paper evaluate cross-lingual sentence representations?",
        "bfcf3a71-8c58-4a76-ac7b-7879ed2e185a": "What is the main contribution of the BERT paper by Devlin et al. in the field of language understanding?",
        "89a1f790-7e83-46cb-9427-964e47186232": "What approach is proposed in the paper by Ding et al. for Burmese (Myanmar) morphological analysis?",
        "49c30f2e-68ca-4023-a449-ec6dbea6deb0": "How does the paper by Ding et al. utilize syllable-based tokenization and part-of-speech tagging in their research?",
        "0f0150e0-553d-4957-aa10-ecacace3daf1": "What is the significance of the ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP) journal in the field of language processing?",
        "d0c45014-b931-4135-a6e3-84439a684cb3": "How does the size of the mBART100 model impact its deployment in production?",
        "8d19c6fb-08ae-4e5a-949b-13dc643b3fa1": "What is the future work plan for addressing the cost of deploying the model in production?",
        "0b53445f-4a94-4f20-b01d-89d9aaffbab9": "How does pre-training more efficient models relate to the challenges of deploying the current model in production?",
        "753a14cd-c546-4024-af31-84bfd5d97d5c": "Who are some of the individuals mentioned in the acknowledgements section for their expertise in low-resource and unsupervised machine translation?",
        "19e0eb04-a876-4966-95c2-1c5fd2c20dc5": "Can you name some of the datasets mentioned in the acknowledgements section, and who provided details about them?",
        "58d20f8d-0607-41c8-8848-7dec1d0dd1e5": "How did colleagues at FAIR and FAIAR contribute to the project mentioned in the acknowledgements section?",
        "68df4dfd-796e-42ca-96c3-b205602e064d": "How did Roee Aharoni, Melvin Johnson, and Orhan Firat contribute to the field of neural machine translation?",
        "1cec7837-c3c6-43b1-a35f-7b7b8e597f71": "What role did FAIR and FAIAR colleagues play in the research mentioned in the document?",
        "c5c23cb3-e716-4f2c-b565-0a91f2a713ef": "What was the topic of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics?",
        "783b15f2-5762-44e4-8361-d6bf28d69770": "Where was the conference held?",
        "c304191a-6164-4862-8320-9b9b1e655fe7": "What was the focus of the paper presented at the conference?",
        "4cf21c40-98d4-4a43-8632-77520eafadb3": "Who organized the conference?",
        "e3931b5d-5482-40a9-b657-1c01d05f78ac": "Can you briefly explain the significance of massively multilingual neural machine translation in the field of computational linguistics?",
        "a4fe542a-c77c-4a24-8bff-46b584396794": "Who are some of the authors listed in the context information for the publication by the Association for Computational Linguistics?",
        "89a9c377-1936-4434-a348-b53080d2df24": "What is the title of the publication mentioned in the context information?",
        "4492f02a-af5c-4c4f-910d-4feb0944bf99": "Can you identify any specific roles or positions held by the individuals mentioned in the context information?",
        "b4162267-4fc7-42c5-a729-6f0ffa44a247": "What year was the publication by the Association for Computational Linguistics released?",
        "d9190e9c-735b-4d28-aba5-7da7807d1409": "How many authors are listed in the context information for the publication?",
        "33ec0786-aceb-4c5b-b630-7bd5a865a925": "What are some of the challenges faced in massively multilingual neural machine translation according to the findings in the document?",
        "9f1a3106-ef82-4a15-8f20-06c8b17dc1e8": "How does the concept of unsupervised neural machine translation differ from traditional machine translation methods, as discussed in the document?",
        "9cf95f91-cde6-48c7-a48d-525806779a4d": "How do Mikel Artetxe, Sebastian Ruder, and Dani Yogatama contribute to the field of cross-lingual transferability of monolingual representations?",
        "b170e925-1db9-442d-8551-46b82b859e14": "What is the significance of the Wit3 dataset created by Mauro Cettolo, Christian Girardi, and Marcello Federico in the context of transcribed and translated talks?",
        "1495e930-fedc-4a32-bae2-fb77b8b44b0b": "What is the title of the conference where the research on transcribed and translated talks was presented in 2012?",
        "138c5c08-4172-4446-b556-547560ebc4a6": "What is the purpose of the Wit3 project mentioned in the context information?",
        "5a2da332-30c2-443c-add7-7dd8f3d9015f": "How many pages did the research on transcribed and translated talks span in the Conference of European Association for Machine Translation in 2012?",
        "eb07569a-2e5e-4d8d-8870-3e7c3e3ba0dd": "What was the purpose of the iwslt 2015 evaluation campaign mentioned in the document?",
        "66963d34-0d2a-4301-a4f2-01e817a058fc": "Who were the authors involved in the Conference of European Association for Machine Translation mentioned in the document?",
        "bbd8baa8-cd3a-4fb9-80b1-c32bf3e23963": "What was the title of the workshop where the research was presented?",
        "600fae38-9db1-4057-9ee1-5b1f47a1ce6c": "Who were the authors of the submission for the Myanmar-English translation task at WAT19?",
        "3dfa7fc6-d25a-4b71-8ab9-425c664d4cea": "What platform was used for the submission of the research?",
        "026fe193-7e49-4c0d-9ee4-cc4372d62ffe": "Can you name one of the authors who contributed to the research on Myanmar-English translation?",
        "aabe89ce-5f2d-483e-8b99-5bb8aafa515d": "What is the publication number for the arXiv preprint of the submission?",
        "9a61529c-8a9c-4b89-89f3-c82a3b44a5ef": "What is the title of the paper mentioned in the arXiv preprint?",
        "2f3e4bfb-4340-4f3a-b0c3-02d79da1e27d": "Who are the authors of the paper on unsupervised multilingual word embeddings?",
        "e8c1e68f-d86d-469d-938e-675de33e9a7d": "In which city was the 2018 Conference on Empirical Methods in Natural Language Processing held?",
        "a9e5780f-7cea-4e42-a324-292e9e9ad8d9": "What organization organized the conference mentioned in the context?",
        "d39c8cad-ab3f-43c0-baeb-ef32dea45960": "Can you name one of the authors of the paper mentioned at the end of the context information?",
        "6d39b841-a9b6-4b17-90e7-4df9a29dcc4a": "What is the title of the paper presented by Yun Chen, Yang Liu, Yong Cheng, and Victor OK Li at the 55th Annual Meeting of the Association for Computational Linguistics?",
        "0a3bf95f-d7c3-4ed4-ae90-0c54145c9dfe": "Can you explain the teacher-student framework proposed in the paper for zero-resource neural machine translation?",
        "fa6697d1-f5fe-405b-874a-7a32bb8ce718": "How did the authors approach cross-lingual representation learning in their study?",
        "5337e778-b15d-4056-8db3-a858ff1fd904": "What is the significance of unsupervised learning in the context of cross-lingual representation?",
        "7d67e93c-3aa7-4bf3-ba61-7c0dd3ac6482": "Who are the authors of the study on unsupervised cross-lingual representation learning at scale?",
        "4bf68fee-e2a0-47e4-bb7a-75966763feb4": "What are some of the key findings or contributions of the research conducted by Conneau et al. in the field of cross-lingual representation learning?",
        "9cac18e6-a9aa-4f06-8869-0ad240897890": "How did the authors scale up their unsupervised cross-lingual representation learning approach in their study?",
        "2c9e9eb6-57f8-47a6-bb70-37cbd5db2b14": "What is the title of the paper mentioned in the context information?",
        "bbe1daac-c2d4-451c-90a3-cb02a4448408": "Who are the authors of the paper on unsupervised cross-lingual representation learning at scale?",
        "ed208b1d-012b-4370-b6bf-66d639b56117": "What is the purpose of the Xnli dataset mentioned in the context information?",
        "6e14aa81-1347-4f21-a101-65c43e608b13": "How do the authors evaluate cross-lingual sentence representations in their work?",
        "047f96be-6762-4fb7-acba-dd0db9bba57c": "Can you briefly explain the significance of cross-lingual representation learning in natural language processing?",
        "93430de5-91e3-40fd-b5a6-eb6fbb117eb9": "How does the Xnli paper evaluate cross-lingual sentence representations?",
        "19917214-af47-4e54-a2f0-8ee8bda36a44": "What is the main focus of the BERT paper by Devlin et al. in terms of pre-training deep bidirectional transformers for language understanding?",
        "ee1d22d5-94d7-42ca-bccd-5d514967b2b3": "What is the title of the paper mentioned in the context information?",
        "24e15fdd-ad10-4070-9c7f-156621662965": "Who are the authors of the paper?",
        "2d5212ea-f39e-4072-a3ef-b16602843f03": "What is the main focus of the research described in the paper?",
        "fd140fab-d8cc-41aa-9c0b-e2983e56051a": "In which conference was the paper presented?",
        "15a08f4b-d77c-4d93-8ead-1f2ccb6be6e0": "Can you briefly explain the significance of pre-training deep bidirectional transformers for language understanding?",
        "97446e7d-895a-4a15-9630-e4a7b676c4c7": "What is the focus of the research discussed in the article \"Towards Burmese (Myanmar) morphological analysis: Syllable-based tokenization and part-of-speech tagging\"?",
        "13b73801-cfee-4655-a046-77410e2a5569": "How does the article contribute to the field of Asian and Low-Resource Language Information Processing?",
        "d8782af3-e3f1-408b-9638-7acfc22e2bd9": "What is the significance of using syllable-based tokenization in Burmese (Myanmar) morphological analysis?",
        "149744ba-90ef-44b3-9588-eb2a03cf3ad5": "How does part-of-speech tagging play a role in the research discussed in the article?",
        "4e669bec-0ade-4760-abce-10e023baa6d8": "What are some potential implications of the findings presented in the article for natural language processing in Burmese (Myanmar)?",
        "911bc345-a477-47f8-8e74-80601e08f868": "What is the main focus of the research presented in the paper \"NOV A: A feasible and flexible annotation system for joint tokenization and part-of-speech tagging\" by Chenchen Ding, Masao Utiyama, and Eiichiro Sumita?",
        "f0129c5c-2132-4105-9340-1e5761a15ef9": "How do pre-trained language model representations contribute to language generation, as discussed in the paper by Sergey Edunov, Alexei Baevski, and Michael Auli?",
        "465ccd61-e08a-43c8-a0f7-519cdfa9f767": "What is the significance of the FLORES evaluation datasets for low-resource machine translation, as described in the paper by Francisco Guzm\u00e1n, Peng-Jen Chen, and others?",
        "1c84d781-7dc7-4c6f-a397-d24baca77dc2": "How does Google's multilingual neural machine translation system enable zero-shot translation, according to the paper by Melvin Johnson, Mike Schuster, and others?",
        "6f4a108a-b8d2-4158-94d2-4c8a362b90e0": "What is the purpose of the IIT Bombay English-Hindi parallel corpus, as mentioned in the paper by Anoop Kunchukuttan, Pratik Mehta, and Pushpak Bhattacharyya?",
        "a77df864-27ab-412a-82f1-9f742bca6368": "What is the main focus of the research presented in the paper by Chenchen Ding, Masao Utiyama, and Eiichiro Sumita?",
        "78990526-f016-4318-87b2-8c8059a4ba83": "How do pre-trained language model representations contribute to language generation, according to Sergey Edunov, Alexei Baevski, and Michael Auli?",
        "12c15db5-3aaa-4e8d-ae6a-d1643ceb6213": "How does the shared attention mechanism in multi-way, multilingual neural machine translation benefit the translation process, as discussed by Orhan Firat, Kyunghyun Cho, and Yoshua Bengio?",
        "085e0c6e-b764-4e07-a0aa-efa5ec6ac315": "What are the key findings or contributions of the research on universal neural machine translation for extremely low resource languages by Jiatao Gu, Hany Hassan, Jacob Devlin, and Victor O.K. Li?",
        "ea32aa59-f56b-4c42-8dcf-940bb2805d56": "How does the approach of ignoring spurious correlations improve zero-shot neural machine translation, as proposed by Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor OK Li?",
        "922ab79e-992f-496e-8354-bdca5f319364": "How does the FLORES evaluation datasets contribute to low-resource machine translation in the context of Nepali-English and Sinhala-English languages?",
        "313f021b-81cd-4887-9764-913dbd6680b8": "What are the key findings or contributions of the Google multilingual neural machine translation system discussed in the document?",
        "1bfaac07-6c8a-49da-805e-aaa818e3e61d": "How does the concept of unsupervised machine translation using monolingual corpora only differ from traditional machine translation approaches?",
        "2546868b-109f-452d-8f7f-ea1288dcdde8": "What is the significance of cross-lingual language model pretraining in the field of natural language processing?",
        "3a85f27a-c063-4882-a3ea-93692e5a8d08": "How does the SentencePiece subword tokenizer and detokenizer contribute to neural text processing, as discussed in the document?",
        "2f76a288-f644-4994-afa3-cce024c84f95": "What is the main focus of the research presented in the paper \"Word translation without parallel data\" by Guillaume Lample, Alexis Conneau, Marc\u2019Aurelio Ranzato, Ludovic Denoyer, and Herv\u00e9 J\u00e9gou?",
        "fd525b99-7fae-48b4-a00b-f34c66e4fc4e": "How does the paper \"Phrase-based & neural unsupervised machine translation\" by Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato contribute to the field of machine translation?",
        "ec6f4056-bbea-401a-a207-6150a836b005": "What is the key contribution of the paper \"Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension\" by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer?",
        "d3b9549f-391a-41a1-8bac-aecd68281057": "How does the NOV A annotation system differ from traditional systems for joint tokenization and part-of-speech tagging?",
        "a587dbe3-dca7-4747-8bca-8ea0cdbf4b1c": "What is the significance of having a feasible and flexible annotation system for language processing tasks?",
        "7e4841db-f1ec-4287-abb3-7a35a2fc741d": "How do Chenchen Ding, Masao Utiyama, and Eiichiro Sumita contribute to the development of the NOV A annotation system?",
        "f9878610-0dcc-4bd2-82c0-19414e3ada3f": "What is the focus of the ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP) journal?",
        "30141654-54d4-4f13-b241-bd546de55b3c": "Can you explain the importance of joint tokenization and part-of-speech tagging in natural language processing?",
        "0231f39d-0c9e-464b-9b4c-f44cc9f4e5ee": "What is the title of the paper mentioned in the context information?",
        "f74b1bdb-c6d9-4c15-afcb-fd1dc3264d9b": "Who are the authors of the paper on unified language model pre-training for natural language understanding and generation?",
        "38479ecd-5e6d-43f0-9b50-f2f943d5dbe5": "What is the publication platform of the paper, as mentioned in the context information?",
        "a7d4196d-784f-49bd-9922-a991d5f40a87": "What is the main focus of the research discussed in the paper?",
        "85fa7698-932d-4e2d-bcbf-5ae173089b5b": "Can you name one of the key contributions mentioned in the context information?",
        "ea434952-1c3d-4246-9cf3-fc2d6795ddda": "How do pre-trained language model representations contribute to language generation, according to the research by Sergey Edunov, Alexei Baevski, and Michael Auli?",
        "ef64f244-3ce7-453a-ac99-d3ef41a580cd": "What is the significance of the research conducted by Orhan Firat, Kyunghyun Cho, and Yoshua Bengio in 2016 in the field of language generation?",
        "a7cd0c72-a70b-4e95-aef0-ddc6a74a004c": "How do pre-trained language model representations differ from traditional language generation techniques, based on the information provided in the arXiv preprints?",
        "4e0cb885-5cb1-4078-8745-e2f4b162c87e": "Can you explain the potential applications of pre-trained language model representations in real-world language generation tasks, as discussed in the context information?",
        "6917ecc9-9416-484e-adc1-8d87a6d829dc": "How do the advancements in pre-trained language model representations impact the future of language generation technology, according to the research mentioned in the arXiv preprints?",
        "77c8b62d-23d9-4f8e-bd04-46d4afe564eb": "How does the shared attention mechanism contribute to multi-way, multilingual neural machine translation?",
        "58fbc138-46ca-43b6-943d-634aefd9bdb6": "What are the key features of universal neural machine translation for extremely low resource languages according to Gu et al. (2018)?",
        "56b0853b-dcc2-4b6a-ae69-df7c0aba531c": "What was the focus of the research presented in the paper \"Universal neural machine translation for extremely low resource languages\"?",
        "5e211c6d-b0d7-4f1e-b82c-dde81870ec53": "Who were the authors of the paper presented at the 2018 Conference of the North American Chapter of the Association for Computational Linguistics?",
        "5ff904a3-d6f9-4b82-850a-67c43cac7b1f": "Where was the conference held where the paper was presented?",
        "4875de5e-cf0c-4ec9-a3f8-29528bfe87b5": "What is the significance of developing universal neural machine translation for extremely low resource languages?",
        "5b95c675-d9e2-48f8-85de-5a6226970663": "How do the authors propose to address the challenges of translating extremely low resource languages in their research?",
        "17ca23df-3d48-4215-b9e1-2e0903233bf7": "How did the authors of the paper improve zero-shot neural machine translation?",
        "f6fb9cfa-46b7-4700-a45b-6ff3263d34eb": "Who are the authors of the paper on improved zero-shot neural machine translation?",
        "c8b64ddb-c54f-40e6-81de-1ed2675f6b9a": "What is the title of the paper and where was it published?",
        "c6846c75-c0e2-4bdf-b197-a8f2f260fd07": "What is the significance of ignoring spurious correlations in neural machine translation?",
        "fa8290a5-f1d5-4812-a691-3c6c3ae6fc26": "How do the authors propose to enhance zero-shot neural machine translation in their paper?",
        "cd44375e-4fca-4115-bb90-2cdafb265db7": "What are the two language pairs included in the FLORES evaluation datasets for low-resource machine translation?",
        "2f2e1629-5fb4-4bda-ac89-ec85a0f76266": "Where was the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing held?",
        "57cbbb9d-9de0-400e-a376-9e810adfc7ec": "What organization is responsible for the publication of the proceedings mentioned in the context information?",
        "ef1188a2-8760-4045-acdb-041f5fc27ecf": "What is the significance of the FLORES evaluation datasets in the field of machine translation?",
        "8d03f6d3-c349-4d95-b4b5-63a66a3af668": "How do the Nepali-English and Sinhala-English language pairs contribute to the study of low-resource machine translation?",
        "39c6f4b3-ae54-47b9-8462-57e00d22721c": "What is the title of the paper mentioned in the context information?",
        "3d1fd3bb-72ad-48cc-863e-03fa51fb54a5": "Who are the authors of the paper on neural machine translation and larger context?",
        "2a1c8dea-9cf3-4e85-9e5f-24c56ba352be": "What is the publication venue of the paper mentioned in the context information?",
        "a1f4b627-49f3-4c74-a272-b7f1c5b77f1f": "What is the main focus of the paper on neural machine translation and larger context?",
        "38ed1d95-ac99-4615-960e-b9a71e9ce6ab": "How do the authors investigate the impact of larger context on neural machine translation in the paper mentioned?",
        "fdbc218f-092e-4a16-ac7b-6a4cd4d3824f": "How does Google's multilingual neural machine translation system enable zero-shot translation?",
        "1309a41c-e22a-4ba9-bebf-7fdd6f5c17fb": "Who are some of the key individuals involved in the development of Google's multilingual neural machine translation system?",
        "e8e58c67-a7ff-4a49-9393-d31b0677529b": "How does Google's multilingual neural machine translation system enable zero-shot translation?",
        "b842bf68-8195-454e-a919-929c7a590e8f": "What is the purpose of SentencePiece, as described by Taku Kudo and John Richardson in their work?",
        "a03cc3b8-117c-460e-a317-d1e032d50e85": "What is the title of the conference where the research was presented?",
        "432aeeb8-3332-4b22-a1d7-57d2fd848626": "Who are the authors of the paper on the IIT Bombay English-Hindi parallel corpus?",
        "45d3fa29-3a02-4677-acf5-aaef4e3beaab": "Where was the conference on Empirical Methods in Natural Language Processing held?",
        "09990c92-5a81-4657-8b9f-dfc7b5b55088": "What is the publication venue of the paper on the IIT Bombay English-Hindi parallel corpus?",
        "fa9c0077-377c-4268-bbd7-013af8e8ce41": "What is the significance of the CoRR identifier abs/1710.02855 in the context of the document?",
        "4a94df6d-6f18-4173-9ebf-5db3fe3a17a2": "What is the title of the paper by Guillaume Lample and Alexis Conneau that discusses cross-lingual language model pretraining?",
        "bfa23b12-8ca7-4b53-bd69-fddeedd3baea": "What is the main focus of the paper by Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato on unsupervised machine translation?",
        "9131c3f3-403f-49ba-ba42-5157369408ee": "How are monolingual corpora utilized in the paper by Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc\u2019Aurelio Ranzato for unsupervised machine translation?",
        "eeb91105-c104-4b27-88d5-43de5c9ad689": "What is the focus of the research mentioned in the context information?",
        "58b5d612-8c60-4a09-8250-351db547fe30": "How does the approach of unsupervised machine translation differ from supervised machine translation?",
        "824dd9e3-b226-43cb-bd8c-a71be211aeef": "Can you explain the significance of using monolingual corpora in machine translation research?",
        "fbf87613-ab44-49b7-b544-5a34e3c65caa": "What is the name of the conference where this research was presented?",
        "592986f4-ce72-4ffb-bf39-97028e01ab8d": "How does the use of monolingual corpora impact the accuracy of machine translation systems?",
        "aa7e7026-9d2d-4d9c-892c-249b720d4bd8": "How did Guillaume Lample and his team approach word translation without parallel data in their research?",
        "6b18e481-3c43-473e-aed1-acd90d7f840c": "What other authors were involved in the research presented at the International Conference on Learning Representations in 2018?",
        "088e8254-bc09-4b31-9299-2a6be0915e2d": "What is the significance of conducting research on word translation without parallel data in the field of machine learning?",
        "9a7f1e7e-3e9d-4c7e-b8dd-83b6af4a403b": "How did the researchers address the challenge of word translation without parallel data in their study?",
        "d0ba8151-9e6f-4726-9836-d4882da2f7ec": "What potential implications could the findings of Guillaume Lample and his team have on the field of natural language processing?",
        "fcf25c33-17d2-4bd9-b6ae-3cbaa3d0cb29": "What is the title of the paper mentioned in the context information?",
        "66704757-bb2a-4d13-a608-63ffe582a9e2": "Who are the authors of the paper on phrase-based and neural unsupervised machine translation?",
        "e1ee0929-0ffc-435f-a9b4-e9ffabb6245f": "What year was the paper on unsupervised machine translation published?",
        "b11bfc3a-cd23-4f6a-9d1a-9c85c4a356d3": "Can you name one of the authors of the paper who worked on neural unsupervised machine translation?",
        "63f158a4-bced-4ab7-bf5e-6dc7c737f2ea": "What is the significance of the research mentioned in the context information?",
        "d98bb21c-d850-4e5b-a7fd-7a259dc3d0ea": "What is the focus of Bart's research as described in the context information?",
        "80d306f2-1ef6-45e0-8f59-9e2703e60a1d": "How does Bart propose to improve natural language generation, translation, and comprehension in their research?",
        "3937f2ab-3006-4cba-9d29-79b33ebb58dd": "What is the significance of denoising sequence-to-sequence pre-training in the context of natural language processing?",
        "9e6c6fa3-2c87-4980-bb4f-e925d1665ab6": "How do pretrained language models contribute to document-level neural machine translation, as discussed in the papers by Liangyou Li, Xin Jiang, and Qun Liu, and Yang Liu and Mirella Lapata?",
        "2ca61430-34e6-4ad3-a3fc-39840c9a06be": "What is the approach proposed in the paper by Yinhan Liu et al. for robustly optimizing BERT pretraining?",
        "d5640bbb-0c9e-46e3-8643-64d5461d0ae7": "How do hierarchical attention networks play a role in document-level neural machine translation, as explored by Lesly Miculicich et al.?",
        "cac9f757-9d40-4316-b4c3-6b595621035c": "What is the significance of BLEU scores in evaluating machine translation, as discussed by Kishore Papineni et al.?",
        "38a4bdc5-f206-440e-aae3-0e3d449020e5": "How do language models contribute to unsupervised learning, as highlighted in the technical reports by Alec Radford et al.?",
        "d73b41e4-281c-45ae-8763-dcf7d14d89e4": "How do pretrained language models contribute to document-level neural machine translation according to Liangyou Li, Xin Jiang, and Qun Liu?",
        "6adce29a-0b9d-4e63-9b5c-26db19cbd830": "What is the key focus of the research conducted by Yinhan Liu et al. on Roberta, a robustly optimized BERT pretraining approach?",
        "c81e8c5c-085f-4d26-be10-8c6bb5dea412": "How do hierarchical attention networks play a role in document-level neural machine translation, as discussed by Lesly Miculicich et al.?",
        "b39acfed-9663-42c5-b2ba-1b89648740cf": "What is the significance of exploiting similarities among languages for machine translation, as mentioned by Tomas Mikolov, Quoc V. Le, and Ilya Sutskever?",
        "3a1d2b28-3731-4dae-9d0a-36104a4cf30d": "How does the FAIRSEQ toolkit contribute to sequence modeling, as described by Myle Ott et al.?",
        "24692404-b6ba-4e63-8b80-d057f22f96d0": "What are some key contributions mentioned in the document regarding deep contextualized word representations?",
        "50aad40f-b587-47c2-918d-b067bfb619ab": "How does the two-step approach to unsupervised machine translation work, as described in the document?",
        "9526f376-eaca-4c92-b961-0664d900923a": "What are some strategies mentioned in the document for improving language understanding with unsupervised learning?",
        "7bee7d51-62fd-41b7-8944-c9b2e0853053": "How do language models function as unsupervised multitask learners, according to the document?",
        "d09bf6fa-e0e8-4561-af8c-290f1f817a1e": "What are some findings discussed in the document regarding the limits of transfer learning with a unified text-to-text transformer?",
        "4c4eb01a-48a0-4fdc-adb8-f9b506a8c333": "How do neural machine translation models benefit from the use of monolingual data, as discussed in the 2016b paper?",
        "c9acad36-8339-4f00-acae-11d247a859df": "What is the main contribution of the Ctrl model, as described in the 2019 paper by Nitish Shirish Keskar et al.?",
        "f5ab47b4-964b-40f5-b3db-901fe5e97872": "How does the MASS model, presented in the 2019 paper by Kaitao Song et al., differ from traditional sequence-to-sequence pre-training methods?",
        "d302f359-87b3-4247-b2a3-9c0528ca342a": "In the 2017 paper by J\u00f6rg Tiedemann and Yves Scherrer, how is neural machine translation improved through the use of extended context?",
        "f8a144e7-adf2-49f7-b7e3-437d4f51771b": "How do pretrained language models contribute to document-level neural machine translation according to Liangyou Li, Xin Jiang, and Qun Liu?",
        "5c050d77-9f73-4c6b-bc01-781e3b7fdb12": "What is the focus of the research conducted by Yang Liu and Mirella Lapata in the field of text summarization?",
        "a3ada4af-4acd-4f8c-bd0c-9fd02cc9d911": "How do pretrained encoders play a role in text summarization, as discussed in the context information?",
        "96df7835-0492-4fa6-b59e-8062c9c7a2cd": "Can you explain the significance of using pretrained language models in the context of neural machine translation?",
        "73612d38-ec9c-4ead-8c69-d3aeed0e1d42": "How do the two research papers mentioned in the context information contribute to advancements in natural language processing?",
        "a7b91af8-0d7d-45f6-be4b-cdf9ff47005f": "How does the Roberta model differ from traditional BERT pretraining approaches?",
        "2ad8f267-9df5-4901-8a4f-a98ddd92cdcf": "What are some key features of the Roberta model as described in the preprint?",
        "2a807c2c-25f2-4733-83d2-6d5e62bbe4d0": "How do the authors of the preprint describe the optimization process for the Roberta model?",
        "ebc1a6f7-37fa-4d0d-93c1-2c5eccfb5159": "What are some potential advantages of using the Roberta model in natural language processing tasks?",
        "742bf95e-304c-48ad-9f8a-ade7d7cc8483": "How do the authors of the preprint suggest that the Roberta model can improve upon existing BERT models?",
        "88fc9c7b-0252-456d-a4ce-02bc0ca90828": "How does the approach described in the paper \"Roberta: A robustly optimized bert pretraining approach\" differ from other bert pretraining approaches?",
        "331b3274-1c08-44a4-9a13-f393417b918f": "What is the focus of the research conducted by Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, and James Henderson in their document-level neural machine translation with hierarchical attention networks study?",
        "ab4b84eb-731c-4b5f-ac89-75184f04286a": "How do hierarchical attention networks contribute to document-level neural machine translation?",
        "a9d9c690-d9c5-4417-b126-a8f07969074d": "What conference was the 2018 paper on document-level neural machine translation presented at?",
        "88e9e4c5-454b-414e-bd13-0861f32d3382": "Who are the authors of the 2013 paper on exploiting similarities among languages for machine translation?",
        "b7a71b29-0e26-4388-a92d-93ac73d64643": "How does the FAIRSEQ toolkit contribute to sequence modeling?",
        "8037537f-0833-4847-83ce-611179ef3141": "What are some of the key authors involved in the research on exploiting similarities among languages for machine translation?",
        "aa239fc2-5bdf-40d1-ae61-a4c534795f5d": "How does the concept of exploiting similarities among languages impact the field of machine translation?",
        "7079bb05-a53c-4085-b986-1a39ebacd803": "Can you explain the significance of the research mentioned in the context information for the development of machine translation technologies?",
        "7139dd1b-c754-42e8-838d-43ef415e74a3": "How does the collaboration between the authors mentioned in the context information contribute to advancements in the field of sequence modeling?",
        "5806110e-cdca-434f-b593-d8f436f949ee": "Explain the significance of the FAIRSEQ toolkit in the field of sequence modeling.",
        "4860a02a-95e9-4ee9-8f20-62dbe5c9a747": "How does the BLEU method proposed by Papineni et al. evaluate machine translation automatically?",
        "2117ca08-51f7-4461-8d98-945507cf3759": "What is Bleu and what is its purpose in the field of machine translation?",
        "8c518111-0ea8-4d8f-87e5-2781d1da71cf": "What is the significance of the 40th annual meeting on association for computational linguistics in relation to Bleu?",
        "c4765881-7e7d-4b84-b400-25f967414f85": "How does Bleu contribute to the automatic evaluation of machine translation?",
        "98a37763-3f9d-4318-96e9-789717f19e13": "Can you explain the role of Association for Computational Linguistics in the development and implementation of Bleu?",
        "ceb94edd-45f3-42ae-8aa8-474a8ae95b4d": "How does Bleu compare to other methods of evaluating machine translation?",
        "314fecd4-4a18-457f-aea5-170deac4acc9": "How do deep contextualized word representations differ from traditional word embeddings?",
        "83958818-ded2-4a3d-8c7d-8562f5fd44e4": "What is the significance of Matt Post's call for clarity in reporting BLEU scores in the field of computational linguistics?",
        "9fc32296-a07d-4aea-8575-5893c9b04a5d": "What is the significance of BLEU scores in machine translation evaluation according to Matt Post's paper?",
        "a8d162ef-a089-4a64-98b3-1be64a85cccd": "How do Nima Pourdamghani, Nada Aldarrab, Marjan Ghazvininejad, Kevin Knight, and Jonathan May contribute to the field of machine translation?",
        "e3e37b08-6ef5-43c0-b207-9912a4f19693": "Can you explain the importance of clarity in reporting BLEU scores as mentioned in Matt Post's paper?",
        "e1e9fdb6-59ee-47cf-a4f4-c86030785ca4": "How do you think the research papers presented at the Third Conference on Machine Translation contribute to the advancement of the field?",
        "e5882c85-9b03-4df0-913e-93915c648385": "What are some potential challenges in accurately reporting and interpreting BLEU scores in machine translation research?",
        "ddcd21f4-3289-4aa1-b7ab-5f26d7a5d89c": "How does the two-step approach to unsupervised machine translation differ from traditional machine translation methods?",
        "f2584d67-ad98-4a45-9d94-8d9f814714c6": "What are some key findings or improvements discussed in the technical report by Alec Radford, Karthik Narasimhan, Time Salimans, and Ilya Sutskever on improving language understanding with unsupervised learning?",
        "3c67cc7c-719b-4dcd-a02c-1d2bd4c5fbdd": "What is the title of the technical report published by OpenAI in 2019?",
        "f0455ebd-d1a6-413e-8edc-b6b21f398720": "Who are the authors of the report on language models being unsupervised multitask learners?",
        "ed1f754b-ebd4-43a4-8ab8-b4003339dd5a": "What is the main focus of the technical report by Colin Raffel et al. on language models?",
        "1d9e0894-7678-4749-b8eb-41f2d271e20c": "How do the authors describe language models in the context of multitask learning?",
        "5bba8f5a-20a5-4b09-9801-db942e0e8be8": "What is the significance of transfer learning in the text-to-text transformer model discussed in the arXiv preprint?",
        "000a4a4d-6a93-47c6-9cea-8c5c60e03e1e": "How do the authors aim to explore the limits of transfer learning in their research?",
        "f1a22ac0-d790-4f3b-956f-d2c5d2587ab2": "Can you explain the role of unsupervised learning in the development of language models according to the authors' findings?",
        "ad59414f-2e5d-45fe-bd0d-fe6c593f570f": "How did the Edinburgh neural machine translation systems perform in the WMT 16 conference?",
        "934641a8-63fc-43e6-8785-2b2b1954bf23": "Who were the authors of the paper presented at the First Conference on Machine Translation in 2016?",
        "96fefd92-3096-44a4-ada6-ffc6ddda21c7": "What was the title of the paper presented by Rico Sennrich, Barry Haddow, and Alexandra Birch at the WMT 16 conference?",
        "4d0c3e35-3360-47f5-ac27-37ef35d6c957": "What was the page range of the paper presented by Rico Sennrich, Barry Haddow, and Alexandra Birch at the First Conference on Machine Translation?",
        "1039439e-44ef-4283-8689-178f348eda0b": "What is the preprint number of the paper by Rico Sennrich, Barry Haddow, and Alexandra Birch on arXiv?",
        "001d4307-4ec7-4764-87ce-ece4ad26d9bc": "How did Sennrich, Haddow, and Birch aim to improve neural machine translation models?",
        "7279946f-e7b0-4ebe-9c3b-ae92a8240a5d": "What type of data did the researchers use to enhance their neural machine translation models?",
        "be1233ed-d81f-4bdf-b2e0-eec0b5363981": "How did the researchers demonstrate the effectiveness of incorporating monolingual data in their study?",
        "0c686a3a-8ef3-4810-8674-0f8d9e3b40bc": "How did the authors of the paper propose to improve neural machine translation models?",
        "aea1cdec-d9a4-46db-8675-4ee8975bed49": "Where was the 54th Annual Meeting of the Association for Computational Linguistics held?",
        "046e98cd-7d49-49de-9b11-17d42d0360d5": "What type of data did the authors suggest using to enhance neural machine translation models?",
        "8fc4ed59-2ed2-42a3-ac66-e8e1f874cdb6": "What is the significance of incorporating monolingual data in neural machine translation models?",
        "92e25078-8abe-4874-abb0-a5417375aa00": "How can the findings of this paper potentially impact the field of computational linguistics?",
        "861c5862-92de-44c2-8374-2f87b28c7c42": "What is the title of the research paper mentioned in the context information?",
        "09575657-2eb6-4431-afd4-840db5d7390b": "Who are the authors of the paper \"Ctrl: A conditional transformer language model for controllable generation\"?",
        "cc4d3e50-0338-4c80-876b-44e3c343e30e": "What is the publication platform for the paper mentioned in the context information?",
        "313a759e-6f43-4757-995c-545461949c54": "Can you briefly explain the main idea or contribution of the research paper mentioned in the context information?",
        "5e9f8f65-fad8-4346-9545-f763a4d4209b": "How many authors are listed for the second research paper mentioned in the context information?",
        "3b821306-295d-4826-a850-80018df3c7e3": "What is the title of the paper presented at the International Conference on Machine Learning in 2019?",
        "b9585c37-3d2f-47b2-92cf-f37c9313c0ea": "Who are the authors of the paper on neural machine translation with extended context from 2017?",
        "b607e83e-6d6e-461d-a1a7-53f87bba26b6": "How are BLEU scores used as an automatic metric to evaluate translation performance in the document?",
        "5c917f2d-5fc4-4da3-92e2-85c2d2bb811e": "What tools are used for tokenization in different languages such as Indic, Japanese, Korean, Arabic, Burmese, Romanian, and Chinese?",
        "55de8272-9545-4ec9-a664-767e273ff86e": "Can you explain the approach taken for computing BLEU scores for languages not listed in the document?",
        "be79df6a-5e41-4367-9191-973287f68264": "How is attention utilized in the neural machine translation system described by Vaswani et al. (2017)?",
        "c7368894-d2cc-4d1c-8541-3dd170082bfb": "What is the significance of learning to remember translation history with a continuous cache, as discussed by Tu et al. (2018)?",
        "576b3434-1b05-485e-bd61-284211eb8f10": "What is the significance of learning to remember translation history with a continuous cache in machine translation?",
        "8461a1c2-eb9d-4932-8596-d556d4d85ef4": "How does the \"Attention is all you need\" approach differ from traditional machine translation methods?",
        "7a184328-d666-4ddf-9120-08281a3b826b": "What are the key features of Google's multilingual neural machine translation system that enable zero-shot translation?",
        "23570530-f722-4b12-832c-1ee1f3b1f35d": "How does unsupervised cross-lingual word embedding by multilingual neural language models contribute to machine translation?",
        "5233ffa7-bb46-46ee-aba8-6819165c1325": "How does exploiting cross-sentence context improve neural machine translation performance?",
        "0c69f20a-0ef2-4e75-b871-3dc3af01218f": "How do the authors evaluate the translation performance in their tasks?",
        "743a808d-eb8e-4bd5-a627-4553aa72bcaf": "What language-wise tokenization methods are used for different languages in the evaluation process?",
        "a22498ee-7883-470f-bbae-5ae6b2de8dac": "Can you explain the significance of using BLEU scores as an automatic metric for evaluating translation performance?",
        "146caf11-a5b1-4b0f-832f-f3db1e0abf9d": "How do the authors handle de-tokenization of raw texts in their evaluation process?",
        "1e1e4c0c-7148-4fef-8340-b39b46c905b2": "What tools are used for segmenting Japanese, Korean, Arabic, and Burmese texts in the evaluation of translation performance?",
        "95650467-b03e-4304-9891-a0d147d1fab3": "How does the use of Moses tokenization and special normalization contribute to the translation process for Romanian texts?",
        "bcd6ac04-bb87-47ed-b806-a48e4d732d04": "What is the significance of using the official sacreBleu Chinese tokenizer for Chinese texts?",
        "8f8ba067-109e-48b7-8553-f819a9d24106": "How are BLEU scores computed for languages that are not listed in the context information?",
        "f054d068-c39f-489c-bff3-d4791820ffc9": "Can you explain the importance of tokenization in the translation process?",
        "c71085ca-afbf-4c6c-9d62-52dffba433e4": "How do the tools and resources mentioned in the context information aid in language processing and translation tasks?",
        "0c68b460-3491-44e9-91a4-1b940e2c2b5f": "What is the title of the workshop where the paper was presented?",
        "3a1a7adf-dfd7-44fe-8727-f0d54ccb7e13": "Who are the authors of the paper \"Learning to remember translation history with a continuous cache\"?",
        "dddf6615-3568-4379-b4f1-9de5496860bd": "What is the publication where the paper \"Learning to remember translation history with a continuous cache\" appeared?",
        "ed4dfccd-a401-4787-9572-184a7daf6071": "What is the page range of the paper in the publication?",
        "1fc667a5-fa55-4c5f-aa6d-ebd492837813": "What is the volume number of the publication where the paper \"Learning to remember translation history with a continuous cache\" appeared?",
        "def38685-5c39-437e-998d-62097d0cfb69": "How does the paper \"Attention is all you need\" contribute to the field of computational linguistics?",
        "fe3f034e-1fcb-4e98-8a5f-873f1def1625": "What are some of the key authors involved in the research presented in the Transactions of the Association for Computational Linguistics?",
        "d9f83b46-bca7-48d2-a3db-a3b5be3fc534": "How does the use of attention mechanisms in neural networks impact natural language processing tasks?",
        "e07e32c6-90ed-4c8a-aa9f-fa3614a0e9d2": "What are some potential applications of the research presented in the Advances in neural information processing systems paper?",
        "103035ef-0f34-4ca7-99ac-fffd0f079fb8": "How do the authors of the two papers mentioned collaborate or build upon each other's work in the field of computational linguistics?",
        "0b963cfe-cac9-4560-abcb-89645517596d": "How does Google's multi-lingual neural machine translation system enable zero-shot translation?",
        "f883ac14-3a1d-4828-be4f-689927836c44": "Who are some of the key individuals involved in the development of Google's neural machine translation system mentioned in the document?",
        "576d8fd1-153e-49cc-8641-1c5ba269c4ac": "How does Google's multi-lingual neural machine translation system enable zero-shot translation?",
        "2d132bc9-b386-4487-989b-0ab7d4b2c129": "What is the focus of the research by Takashi Wada and Tomoharu Iwata on unsupervised cross-lingual word embedding?",
        "a3b7a1d5-7dc0-47ad-85f3-906fd5d9e0c1": "What are some potential applications of the research by Longyue Wang, Zhaopeng Tu, Andy Way, and Qun Liu in the field of language translation?",
        "647ff9fd-133d-4579-a459-aed85456e6ee": "How does the paper \"Exploiting cross-sentence context for neural machine translation\" contribute to the field of natural language processing?",
        "b45bb0b2-3cf7-4dc5-91b7-4885b9fc0535": "What was the location of the 2017 Conference on Empirical Methods in Natural Language Processing?",
        "2c28d095-581a-4ce6-84b2-b8da41e25006": "What organization hosted the conference mentioned in the context?",
        "ef5e6d4f-1827-4959-addb-352a7e9585e5": "What is the significance of considering cross-sentence context in neural machine translation?",
        "44340f91-11f8-4fe1-bb6a-92f0f4e8b7cc": "How do you think the findings presented in the paper could impact future developments in machine translation technology?",
        "89b8c664-27e7-4507-bf65-1f4543b5351c": "What is the title of the paper mentioned in the context information?",
        "74eb2865-c8f4-48c7-ab5a-5a13aabdf45d": "Who are the authors of the paper \"Ccnet: Extracting high quality monolingual datasets from web crawl data\"?",
        "3cdcb0bd-4f9c-4ee7-9528-eccfd14dd2d6": "What is the main focus of the research discussed in the paper?",
        "08243e09-5c74-429a-bc5f-e35ff95f6ba5": "How is the dataset for the research obtained according to the context information?",
        "2a799ec9-d25b-44ec-aea9-474cef72a719": "What is the significance of extracting high quality monolingual datasets from web crawl data in the field of computational linguistics?",
        "e21a4d8d-070b-4074-8a51-45097bb81a41": "Who are the authors of the arXiv preprint with the identifier arXiv:1911.00359?",
        "b03e592e-93d4-4c37-bcba-058ce157fb21": "What is the title of the preprint by Jiawei Wu, Xin Wang, and William Yang Wang in 2019?",
        "a86a5f11-517a-4520-947a-c85a9a07891c": "What is the title of the paper by Jiawei Wu, Xin Wang, and William Yang Wang?",
        "b5dd8499-44f5-4c2b-8ca3-e3ea224194e8": "What is the alternative proposed by the authors for unsupervised neural machine translation?",
        "3a351357-00c6-4dc8-991e-2e4d16fe3074": "Who are the authors of the paper mentioned in the context information?",
        "49b812ab-4d5f-4a41-899d-f5e48ae9005e": "What is the arXiv preprint number for the paper by Jiawei Wu, Xin Wang, and William Yang Wang?",
        "2542ec1c-3223-427e-be46-be6ee62c0aac": "What is the title of the paper by Lijun Wu, Jinhua Zhu, Di He, Fei Gao, Xu Tan, Tao Qin, and Tie-Yan Liu?",
        "4d79b442-d715-47b8-af76-ebd90d202b40": "How does XLNet differ from traditional machine translation methods in terms of training data requirements?",
        "6f9ae28b-1574-4e66-8214-31142ea4ff1b": "What is the main focus of XLNet's pretraining process for language understanding?",
        "6fb035ad-461b-4466-9b13-9e599f68aa68": "How do the authors of the paper propose to address the issue of weakly paired bilingual documents in machine translation?",
        "9660277b-93c5-40a6-8de1-116f80068bc8": "Can you explain the significance of generalized autoregressive pretraining in the context of XLNet?",
        "9419959d-6ca3-4afc-af25-3fdf5e2db882": "How do the authors of the paper suggest that XLNet can improve language understanding compared to other models?",
        "43c2be9a-b76e-4bae-b0c7-06d7d87d9b57": "What is the title of the preprint mentioned in the context information?",
        "465b4e1c-ae1b-42c3-bc7a-13fa1875d465": "Who are the authors of the preprint \"Dialogpt: Large-scale generative pre-training for conversational response generation\"?",
        "337140e5-f572-46da-867a-e3df4c464b5d": "How is the translation performance evaluated in the study?",
        "b95a3619-d5ff-4c22-83d1-4a42eb808953": "What metric is used to evaluate the translation performance?",
        "a07dc4ff-433c-4e69-af9f-ae230020a538": "Can you explain the process of computing BLEU scores in this context?",
        "469e3012-8567-40e7-b3f5-a10fcb34dc47": "How does language-wise tokenization affect the evaluation process?",
        "0692e3ab-847d-41a9-a806-f59ca19a2e56": "How do BLEU scores help in assessing the conversational response generation in Dialogpt?",
        "dc2b0e79-fab6-4abd-9daa-5d1ec591cd83": "How is tokenization handled for Indic languages such as Gu, Ne, Si, and Hi according to the provided instructions?",
        "92933f94-aa3f-4bff-8b85-563a7a93e11b": "What tool is used to segment Japanese texts in the context mentioned above?",
        "52c341f5-1d5e-49c2-8c87-763b273a7c16": "How do we segment Japanese texts in this study?",
        "936fd818-7895-4f3c-b6ab-430b0cb666dc": "What tool and dictionary are used to segment Korean texts?",
        "79a5fd39-0be1-4eee-a0ec-956e41f14420": "How are Arabic texts processed in this research?",
        "1a0c21fa-8db4-441f-bb2b-bd3cd02224d5": "What segmentation tool is utilized for Burmese texts according to the context information?",
        "a0b49971-1329-4e05-8dba-67369b795675": "How does the tokenization and special normalization process for Romanian texts differ from other languages, according to Sennrich et al. (2016a)?",
        "d506980e-7754-4a1b-bb89-35ac6e9252fe": "What Chinese tokenizer is used for processing Chinese texts in the document, and why was it chosen?",
        "1bec1238-f58e-4f27-9fb1-88dc3b586378": "Can you explain the significance of applying Moses tokenization for Burmese texts, as mentioned in the context information?",
        "88755055-dfdd-4399-9783-14388b8fa8b4": "How does the use of the official sacreBleu Chinese tokenizer contribute to the overall text processing in the document?",
        "d7fd7fb5-4685-42d1-a17f-54775d90d57a": "Discuss the importance of following specific tokenization and normalization techniques for different languages, as highlighted in the context information.",
        "30f39978-2491-4f25-a06a-3f4600b9367d": "How are BLEU scores computed for languages that are not listed above?",
        "4744c16f-ad78-46dd-838a-05a48c2005f5": "What tool is used to calculate BLEU scores with DEFAULT tokenization?",
        "1f4fd06e-700e-4466-aed5-dac7d26ea432": "How does sacreBLEU handle tokenization for languages not listed above?",
        "3348523c-3715-4c92-aa35-d2b3ffa4daee": "How can the indic_nlp_library be useful in natural language processing tasks?",
        "20042984-1a89-4c00-a78a-e44826049709": "What is the purpose of the kytea tool mentioned in the context?",
        "cd17ed71-2eec-49db-8855-39de45b91efb": "How can the Konlpy library be installed for use in text processing?",
        "b1f1948f-7130-4b76-9e49-6185b6f2997b": "What is the function of the Arabic normalizer tool mentioned in the context?",
        "c313e0c2-3080-4095-b2b9-cb11b38fab86": "How can the sacreBLEU tool be utilized in language translation tasks?",
        "3dbb5193-7250-4464-8d2c-86f1baefaaf9": "How does the artist view the connection between humans and nature in their work?",
        "a0597241-eb44-4f26-abdf-29aecc47670d": "What was the artist's experience like when they first saw icebergs in Antarctica?",
        "b70160e3-bacd-42dd-8c76-daa68130fa98": "How does the artist approach photographing icebergs and what significance do they hold for them?",
        "3fa5dace-c445-44b9-a76e-28da0782dd91": "Can you describe the process of how icebergs are formed and the different personalities they exhibit?",
        "09df2e45-e6eb-4387-8832-77eaaeb65a70": "What is the significance of the iceberg rolling event witnessed by the artist in Greenland?",
        "cbe6f873-f6d4-4bb4-ad1a-81b8c2fdf8f7": "How does the speaker describe the formation of icebergs and their interaction with the environment around them?",
        "b9c97deb-3b23-4890-a7d6-9f6c1a8de94a": "What is the significance of the icebergs melting according to the speaker's perspective?",
        "0aecbc41-ecc7-4c56-a9e9-6cad1854fb89": "How does the artist in the text emphasize the interconnectedness between human beings and nature through their artwork?",
        "8b18dc2c-a0ba-4dd7-917e-be51fb832b5e": "What was the artist's experience like when they first visited Antarctica and saw mountains for the first time?",
        "331d00c8-119c-470d-9a00-008c6922fe79": "How does the artist describe the personality and interactions of icebergs in the text?",
        "dd4de403-3896-4c94-93d1-9c3bd9518f71": "What significance does the artist attribute to the melting ice and the release of minerals in the text?",
        "dcab5551-1797-4210-bf47-3e6c68150638": "How does the artist's photography capture the uniqueness and fleeting nature of individual ice formations?",
        "f100507b-c548-4e48-97fc-3f24c7fc4be1": "What is the significance of the number 10 mentioned in the document?",
        "ef4d4b50-b862-49bb-b46b-6e190e5ee17a": "Can you identify any patterns or repetitions in the text provided?",
        "aba5763c-8733-433c-bb17-537e1b26e20a": "How many question marks are present in the document?",
        "3cc61a1a-6e28-4a5a-8d63-a5fed11fc757": "What is the purpose of the numbers listed in the text?",
        "5ef1900b-9c1a-4dc4-afce-337409c1bf68": "How many times does the number 200 appear in the document?",
        "e6286a17-55d0-4093-9dc6-9fa2dc6e57d3": "How does the artist in the passage emphasize the importance of connection in their work?",
        "05aa1c11-895c-48a5-819d-820b905a5c64": "What is the artist's message about the interconnectedness of humans and nature?",
        "2a497321-290b-412e-a5d6-26cdb04959c1": "How did the artist's experience in Antarctica influence their perspective on nature?",
        "664d940f-5f77-435e-bd87-f2712bb76dcb": "What was the artist's reaction when they saw their first icebergs in Antarctica?",
        "0e9aa17c-43a6-4e9b-b150-58ee200bf02f": "How does the artist's work reflect their belief that everything is interconnected?",
        "c064c3dd-c2e1-4a2d-8260-4729d70259b9": "How are icebergs formed and what factors contribute to their individual personalities?",
        "4bb6fb8e-a02a-460b-a608-ed7dc824b87a": "What role do icebergs play in nourishing various forms of life as they melt?",
        "bf2df4e3-eba4-420a-ae76-87631c4ba7e0": "How does the photographer approach photographing icebergs, and what significance does he attribute to them in terms of their existence and lifecycle?",
        "12543ede-2d2d-44fc-a0ca-7d178ae22bae": "Describe the age range of the ice in the icebergs that the photographer captures in his photographs.",
        "a2432765-7312-4d0e-8115-242ef034e773": "What unique event did the photographer witness and capture in Greenland, and what details can be observed in the photographs of the rolling iceberg?",
        "3c1df9fc-c749-4c88-8da2-a347b903f9b5": "How does the photographer emphasize the scale of the iceberg in the photographs, and what specific elements help convey its size to the viewer?",
        "520d64dc-6f8b-4e8e-958d-8d5285ca4a43": "In what way does the photographer view the melting of icebergs, and how does he suggest it is not an end but a continuation of their path through the cycle of life?",
        "c339336f-bb78-4fe8-835e-c20c574c90d1": "How does the artist in the video emphasize the importance of connection through their artwork?",
        "93af2951-9201-41d1-bc92-dc1ade321815": "What was the artist's initial reaction upon seeing an iceberg for the first time in Antarctica?",
        "f3d9f0e5-5afb-4948-9596-c21badf8f386": "How do glaciers form and what causes them to break off from glaciers or ice shelves?",
        "9e1c9bb8-ea94-4229-a49b-9652cc667200": "How do icebergs interact with their environment and circumstances, and what unique characteristics do they possess?",
        "7dce0a84-7d41-4187-aa26-0055b6966819": "What is the significance of the statement \"every iceberg has its own unique personality\" in relation to the overall theme of the passage?",
        "1b8aa497-2a3b-4d8e-a6d3-3ba75a8cc092": "How does the melting of a glacier impact the surrounding environment, and what does it release as it melts?",
        "ab66bf89-b67c-4c9e-839a-6f5ad75e75dc": "In what way does the author compare icebergs to human beings in terms of isolation and independence?",
        "27073bf2-bbe5-4146-b45a-f0a01a60d82e": "How does the photographer describe their experience of photographing icebergs in relation to their ancestors?",
        "cdfe3d3f-5adb-4b01-9fc3-3a84ce1c61a2": "What is the significance of witnessing the rolling of an iceberg, as described in the text?",
        "2a520c95-e267-4949-a885-5d094827922e": "How does the artist convey the idea that humans are connected to nature through their artwork?",
        "7d126ec8-4368-4fe3-baa6-658da5b21a6f": "What is the significance of icebergs breaking off from glaciers or ice shelves in the formation process?",
        "8b3425d5-bbdc-4e0f-8c9a-5167a33bea15": "How do icebergs interact with their environment and circumstances, according to the text?",
        "bc924a4e-8c61-4002-9d86-9592604c915b": "Can you explain the different aspects of personality that icebergs exhibit, as mentioned in the passage?",
        "d4c497de-e15d-48ba-95ff-bc25dd7247c1": "What was the artist's initial reaction upon seeing icebergs for the first time in Antarctica?",
        "bdda92d4-d36a-4843-b340-037ba3de6d6b": "How does the melting of icebergs contribute to the environment in terms of releasing fresh water rich in minerals?",
        "42ee6314-5530-4191-8b76-7348156381af": "What is the significance of photographing icebergs in relation to the concept of ancestry and the passage of time?",
        "a47fbd5b-73ee-484c-9624-c7b409046ba2": "How does the shape of the iceberg change as it floats over the surface of the water?",
        "75d1393b-e4ee-49a4-8653-83f1eebbb50a": "What is the average size of an Icelandic iceberg mentioned in the context?",
        "8678f5ae-c519-4aba-9747-516ab43b6d77": "How high above the surface of the water does the average Icelandic iceberg float?",
        "efb22109-0c2d-4a94-aca7-fedaaf38a73a": "What is the significance of the boat moving to the other side as the iceberg starts to roll?",
        "394be7da-4653-43f2-8306-aef5602fa620": "How does the video capture different aspects of the icebergs' personality?",
        "a9120303-243e-4d3f-b4f8-c4b9bfdc9fc1": "How does the artist in the text convey the interconnectedness of human beings and nature through their artwork?",
        "2eebb745-5988-4f15-bb26-f5dd83fdcce7": "What was the artist's experience like when they first saw mountains in Antarctica?",
        "86664d84-44c2-49f5-81f3-c5ea292a65a5": "Can you describe the personality and behavior of icebergs as mentioned in the text?",
        "0db412b0-dcee-4661-82fe-a551217e2f40": "How does the artist use the example of icebergs to illustrate a deeper connection between individuals in society?",
        "76d2424a-8ec4-4e1b-b5c3-4cb26c427140": "What message does the artist aim to communicate through their observations of icebergs in Antarctica?",
        "d0e97e04-2a2c-44b7-b69b-398a9e2e7310": "How does the melting ice release rich minerals and feed 20,000 organisms?",
        "66bf7740-67e1-4390-be68-6644199c6b87": "Can you explain the significance of photographing the ice mountains and ancestors in the context of the text?",
        "bb5354cb-87b1-4019-9457-0d8b789dab96": "How does the speaker describe the average iceberg in Greenland in terms of its height?",
        "c8294095-fd09-446c-be1e-fbf7ac2464bb": "What aspect of the iceberg does the speaker mention focusing on as an artist?",
        "8c9f4c5e-78c4-44d3-ad88-23c992d82491": "What does the speaker mention about the ice in the glacier and its melting process?",
        "25bf54de-6c40-4e45-ba7c-288ba31230cc": "How does the speaker describe the movement of little boats around the iceberg?",
        "674740cb-ef53-44eb-84ea-ddcca0272ae4": "What does the speaker mention about showing pictures related to the ice?",
        "1159bff1-5b23-4481-bec6-e919ed1da1ec": "How does the Doc-MT system differ from the Sent-MT system in terms of producing translations in the example provided?",
        "a5fcf3d6-b630-41a6-9f17-c6c5bbc64ee2": "Why does the Doc-MT system produce more fluent and coherent translations compared to the Sent-MT system in the given example?",
        "f03c0a2b-bf96-408a-a039-0539a0035fa9": "What is the significance of the \"And\" connectors used by the Doc-MT model in the translation example?",
        "8a7d8c5a-2c96-4c90-b2d8-ac6d64d2019e": "How do models with pre-training perform compared to non-pretrained models in terms of translation quality, as mentioned in the context information?",
        "b096c8f1-7c22-4da9-9a63-af5572dc6cee": "Can you explain the impact of global knowledge on the translation output of the Doc-MT system in the example provided?",
        "c2a6167a-0a6e-4237-a61c-e2a7e4c463e6": "What information is missing in the context provided?",
        "64574e73-5cd6-4004-81c0-f01cf36edb84": "How many question marks are present in the document?",
        "13fadca4-a60b-4ad8-a053-f88375ec52a0": "Can you identify any patterns or repetitions in the context information?",
        "27c8b167-81d2-42d6-96ea-bfcd36efca33": "What is the significance of the number 10 in the document?",
        "6a44f812-210e-4133-ac0e-b22c7a0cedc7": "How would you categorize the content of the document based on the limited information given?",
        "7eccd965-ba5c-4236-af44-ec19ba668f06": "What is the significance of the question marks scattered throughout the document?",
        "e5dbb9b8-7a82-4a29-9fe0-aa9b658fe6a0": "Can you identify any patterns or trends in the sequence of question marks?",
        "7e87066c-c886-43aa-9ff7-c65918576c43": "How does the presence of the number \"200\" impact the overall context of the document?",
        "f30cd5b6-adf8-48e5-b568-8851f011a37d": "What do you think the author is trying to convey through the use of question marks and other symbols?",
        "21d9afb4-377d-40d1-8096-49a553bb6ee5": "How might the placement of the question marks affect the reader's interpretation of the text?",
        "6c8b0cb0-74c9-4ca6-aca1-01cdc5a5e82f": "What is the significance of the question marks scattered throughout the document?",
        "b6ee45bc-a8cf-4923-a1d6-48ced1c923c4": "How can the information provided be organized or categorized?",
        "d0680d92-a783-4dae-94a9-88b5e85e367e": "Can you identify any patterns or repetitions in the context information?",
        "0acf23ca-882a-40c4-af9e-fa1cecdde729": "What potential interpretations or meanings can be derived from the context information?",
        "0d930bf2-ff52-4d9d-99af-b602418e1941": "How might the presence of question marks impact the overall understanding of the document?",
        "4b7ea2a3-1034-429c-a053-ad845dca8a4c": "What are the missing elements in the context information provided?",
        "1adf3529-fac7-4743-a2fd-51b74b5708a1": "How many question marks are present in the document?",
        "8754fbb1-a897-4885-8834-7b1b7333c9f4": "Can you identify any patterns or repetitions in the context information?",
        "029b84b0-13f5-4034-8c30-130dcc2cf941": "What is the significance of the question marks in the document?",
        "b4ec98d1-b15b-4714-949b-ced20bba2687": "How would you categorize the information provided in the context?",
        "6ed3a6fe-9b6b-4f86-8a60-73a865fbb8fc": "What is the significance of the question marks scattered throughout the document?",
        "550ca23e-da45-4ee0-ad79-7513bc87bda6": "How does the repetition of question marks create a sense of uncertainty or confusion in the text?",
        "3a5de9fa-b658-43cc-a7ec-fc5dd86f6958": "Can you identify any patterns or sequences in the placement of the question marks?",
        "a096a72e-a581-4985-a70e-2e72520e2d24": "How might the use of question marks relate to the overall theme or message of the document?",
        "289a3498-bacb-4c98-8324-f7550c4a7ddb": "What effect does the lack of clear answers or information have on the reader's understanding of the text?",
        "ef8bc08a-5e20-40e9-8a64-c827ec84bfc5": "What types of information are provided in the context?",
        "c4f5ca5e-8188-4c3f-9d95-75afe3aa9bdc": "How many sections are there in the document?",
        "a1216cb8-48d4-4948-8a01-ff2942ba1b38": "Can you identify any specific patterns or themes in the context?",
        "e05b369a-8ca2-434b-8f31-b540b601c891": "What is the purpose of the document?",
        "ba7555e8-19a8-4bac-8258-f70cc2d0213c": "Are there any specific details or keywords that stand out in the context?",
        "38348547-bf81-4ad4-bc6e-49078f8cb94f": "What is the significance of the question marks scattered throughout the document?",
        "b885d8e7-1d64-4f86-ad09-01b6e5bafaed": "How can the information provided be organized or categorized?",
        "bb8a4f6a-0d73-497d-9d5d-48c579453007": "Can you identify any patterns or themes within the context information?",
        "53dc36c4-a60f-4711-980d-8f0a2479b40f": "What do you think the question marks at the end of some lines indicate?",
        "4947c59b-4119-4fef-af72-bc64b7994131": "How would you interpret the overall tone or mood of the document based on the context information?",
        "97ea5c82-9ac4-4a22-a600-559d876681c9": "What is the significance of the term \"Kekertsuatsiak\" in the context provided?",
        "50aad2c5-8af8-48f9-8f86-cf96a8f1658a": "How many instances of question marks are present in the document?",
        "eb64b1fb-e705-4768-858e-e5708405f8b2": "Can you identify any patterns or repetitions in the text that may be significant?",
        "b113e7c3-32b3-4a7c-8a08-acf41d1c670b": "What do you think the purpose of the repeated question marks is in the document?",
        "b21af34a-730e-4976-8881-b2917b929cfb": "How would you interpret the overall tone or mood of the text based on the use of question marks?",
        "c6ed621e-dca5-4730-adc4-049c692b308c": "What is the significance of the number 15 in the context information provided?",
        "32081bd5-15c8-4963-b87f-6f283ed4d61e": "Can you identify any patterns or repetitions in the data presented?",
        "a82fe042-a443-4f82-be5c-7a385925e400": "How many sections are mentioned in the context information?",
        "0e4feb69-1d09-45d6-88bb-724d8b21e43e": "What can you infer about the structure or format of the document based on the provided context information?",
        "f2c06130-69fc-402a-9e03-1d8b5d634191": "How would you categorize the information presented in the document?",
        "1506be28-3099-4d9b-94c3-62e8a3911bc9": "What is the significance of the number 120 in the context information provided?",
        "a95ec513-151e-45b1-8c0b-7a825b30e577": "How many question marks are present in the document?",
        "59d2808a-eb47-4fcf-af93-eef1d678b2da": "Can you identify any patterns or repetitions in the sequence of question marks?",
        "5615fcc1-b19a-4033-afe8-f477e9561660": "What could be the possible meaning or purpose behind the repeated question marks?",
        "d5b39437-938b-41e0-9a89-9052a5e810a0": "How does the presence of the number 40 relate to the overall context of the document?",
        "3d0f0bfa-a900-4166-a24d-efdd0ae73ab0": "How does the artist in the passage emphasize the importance of connection in their work?",
        "46210930-e1cf-4a4c-8281-89e4290e953a": "How does the artist convey the idea that humans are not separate from nature in their art?",
        "abf5e3ec-c21c-436b-ab86-c525e59a00d5": "What was the author's reaction upon seeing icebergs for the first time in Antarctica almost 10 years ago?",
        "1140dd69-91f7-4295-a164-7a00b118a21d": "What physical reactions did the speaker experience when encountering what stood in front of them?",
        "398241ca-5f15-4369-9211-752ec5ef27bc": "How tall were the icebergs surrounding the speaker?",
        "2765dd6c-1712-4664-bd65-94d81ea8a1df": "What comparison did the speaker make between the icebergs and snowflakes?",
        "7b8004a5-5a8d-4349-8efd-471bcbbef30d": "How are icebergs formed?",
        "d6c6532b-54b7-4f9b-b21a-91e05ae5ee51": "How do icebergs interact with their environment according to the context information?",
        "21bf0ae8-44d3-4675-a3b1-3449451b6831": "How do different individuals react to challenges according to the context information provided?",
        "8d4e6c04-c4ce-45e3-bf21-be94c51fc719": "Can you identify the contrasting responses of individuals in difficult situations as described in the passage?",
        "ef772b3c-9c12-42e2-a9cb-fe52894e88e0": "How does the speaker compare icebergs to humans in terms of isolation and separation?",
        "720924b1-c01f-4a33-9283-aee89938b973": "How does the melting iceberg contribute to the nourishment of various forms of life?",
        "58024763-1b69-4d80-8d00-9db11bf9a69a": "What impact does the melting iceberg have on the atmosphere that is being breathed in?",
        "235126fc-c6f1-4c2e-8f1d-68408494fd93": "How does the photographer approach photographing icebergs, according to the context information provided?",
        "b92c53f0-2665-47e5-9365-1e82859bc1c4": "How does the melting of icebergs relate to the cycle of life?",
        "1c952bdb-42c3-4e15-af50-773cdd40bd94": "Can you explain the age range of the ice in the icebergs that the photographer captures?",
        "7b55cca4-8bea-4b43-8038-99a7a61a90c1": "How old is some of the ice in Greenland, according to the text?",
        "a6245ed1-9e79-4635-83e8-ed0a9fd2d75d": "What is the size of the boat seen on the left side of the iceberg in the given context?",
        "107aaacc-7220-487e-80f1-ef2d8aa4571c": "How does the size of the boat mentioned in the context information compare to the iceberg's shape and position at the waterline?",
        "4a2bbf14-6fce-4c8a-bad0-1a3e5abedff9": "How tall is an average-size Greenlandic iceberg above the water?",
        "d34f1458-662b-471b-9fad-c03b02925f0a": "How does the fact that the video is in real time impact the content being shown?",
        "3feb1652-8e0c-4ff3-9b78-6ea7d0eaa77b": "How does the video being in real time impact the viewer's perception of the iceberg?",
        "29fbfc33-2c0c-4755-bcf3-e575a24cdc7d": "Why does the artist emphasize the importance of connection in their work?",
        "720da86c-cf8c-4856-8c6d-93644e614b51": "How does the artist in the passage emphasize the importance of connection through their artwork?",
        "63c8cd66-0b3e-4199-a259-a2593dd2c8a5": "In what way does the artist convey the idea that humans are not separate from nature in their illustrations?",
        "ca930f2c-f12b-484d-9f70-989d93ad8be0": "Describe the speaker's experience of seeing an iceberg in Antarctica for the first time.",
        "3e587ead-003a-4748-934d-3705391ffde6": "How did the speaker feel in the given situation?",
        "d960d097-a993-4b5f-8543-09562b52beb8": "What physical sensations did the speaker experience while trying to figure out what was going on in front of them?",
        "51cfb640-5df7-4eb0-a744-3ea50994fe9d": "How does the speaker describe the iceberg in relation to its height above the surface of the water?",
        "a87d158b-b189-428f-94ac-7d25458e96ae": "What comparison does the speaker make between the iceberg and snowflakes in the passage?",
        "e24068cb-1690-49aa-8a00-1739f6f2c9cc": "How do glaciers form and what causes them to break off from glaciers or ice shelves?",
        "dfaea2d9-6f57-442c-b0ec-b09ac8185b1c": "In what ways do icebergs interact with their environment and circumstances, according to the passage?",
        "54baeca8-672a-4263-a0d8-4a22f29792ba": "How do the glaciers in the passage demonstrate different responses to the heat of passion?",
        "0892ac9c-cc56-4d6a-9263-791eea7f1e64": "How does the author compare icebergs to the way we sometimes think about ourselves?",
        "d1927d4d-778e-4c4c-bfdf-b1fef892c02e": "How does the melting glacier impact the environment in terms of releasing fresh water and minerals?",
        "92198546-fc74-4365-8cdb-bc24258f2026": "What sensory experience does the speaker have as the glacier melts?",
        "dffe4bd4-a0bc-444e-91ba-ce18be9755fa": "How did the photographer describe their approach to photographing icebergs in relation to their ancestors?",
        "328db0b2-f81b-41c7-a8d6-f9ddd842308a": "How does the melting of glaciers symbolize the continuation of a life-long path rather than the end or death?",
        "ea66a0b8-61e5-4f9b-84fe-9cf9e8127653": "How long has some of the ice been present in the location mentioned in the text?",
        "de393764-db00-417b-b849-e7c1925610e8": "Where was the iceberg photographed by the speaker?",
        "df263050-177c-4f77-a92e-463415daf5aa": "How would you describe the difficulty of witnessing the rolling of an iceberg based on the context information provided?",
        "271ae001-640a-464a-ae54-c44de1960be9": "Can you estimate the size of the boat mentioned in the passage?",
        "20a791f8-31a8-4bf2-bf91-b6a82883957a": "How does the shape of the iceberg change as it moves over the surface?",
        "cd91b56b-7363-4421-ad0c-03a0cf806c85": "What happens to the boat when the iceberg rolls and the man moves to the other side?",
        "759e5741-9ca7-4d6e-80ab-037ab54969cb": "How high above the surface does the average size glacier in Greenland float?",
        "ed876c85-52a6-4588-b232-941ecccb2bb9": "What is the approximate height of the glacier in meters?",
        "392c94bb-6332-4ea4-9005-24e369899d7c": "Is the video of the glacier taken in real time or in slow motion?",
        "939e091f-a852-4358-8d34-96982a30f6e5": "How does the video being taken in real time impact the viewer's perception of the iceberg?",
        "5ed62716-9ce6-446f-bbb4-db08f4559205": "Why does the speaker mention that icebergs show different aspects of their personality?",
        "e2ae48a0-3d20-4fbf-b305-0dd8239d7690": "Why does the artist emphasize the importance of connection in their work?",
        "848d0363-bc99-4129-b746-6b53cd560a3a": "How does the artist convey the idea that humans are connected to nature through their artwork?",
        "5cc3df7c-ce66-47df-9239-39ca13b0da70": "What was the artist's experience when they first saw icebergs in Antarctica 10 years ago?",
        "909318ed-fbcf-499d-8307-459904d360de": "How did the speaker feel when faced with what was in front of them?",
        "9d7a5b7b-9ffd-48d4-9c72-1abc3a5c747e": "How high above the surface of the water were the icebergs floating?",
        "9ab88254-c0db-4949-aa98-01922f457502": "What comparison does the speaker make about the icebergs being like a \"snowflake covering another snowflake\"?",
        "28d6740c-7746-416f-9149-10e83f146275": "How do icebergs form according to the context information provided?",
        "b70c4890-531b-4745-97a5-39583ffb2ec3": "In what ways can icebergs break off from glaciers or ice shelves based on the given information?",
        "870865c8-fb50-4eb1-bd27-c31ab2d93b7c": "How do icebergs interact with the environment around them?",
        "992a5fdb-0020-49ea-bb6b-002c4e565679": "Can you explain how each iceberg has its own unique personality and how it affects their interactions with their surroundings?",
        "c57cb76d-c243-4fb2-98bb-c7fe95a92a6a": "How do some icebergs react to the heat of passion that pours down on them?",
        "082b7ebf-a0c7-4178-a7de-179eb617ebb1": "Why do some icebergs refuse to settle down?",
        "2da08d9d-9abf-43df-9720-0409d3dde74f": "How does the speaker compare icebergs to the way we sometimes think about ourselves?",
        "b92b3cec-b869-4f7b-b22d-f62e57478372": "How does the melting of icebergs impact the environment in terms of releasing fresh water rich in minerals?",
        "167b014b-9fd8-450d-bf42-b18ba76d2907": "How does the speaker compare photographing icebergs to photographing their ancestors?",
        "75772d32-78e9-41ea-a79f-b20e74c30d23": "What is the significance of the speaker learning about the individual moments when icebergs used to exist in a certain way?",
        "c0eef7eb-8a7d-434f-8ed5-74e4836719bf": "How does the melting of icebergs relate to the concept of continuation of a lifetime rather than death or the end?",
        "77ade70f-a791-4ff6-886c-fcff9c0757a1": "Can you explain the significance of the age of the icebergs that have been photographed in relation to their melting process?",
        "f4d2b834-55c0-46ac-8c7d-9fc4e6359e2c": "How old are some of the icebergs mentioned in the text?",
        "d981dd0f-c590-4508-b531-b84fc21bf04e": "Where was the iceberg photographed by the speaker in Greenland?",
        "c85957fb-141f-4634-b1a3-269c7c52dff8": "Describe the significance of witnessing the rolling of an iceberg in the given context.",
        "548f44fd-3203-4bb3-80bb-b25fa1a641d1": "How does the shape of the iceberg change as it floats over the surface of the water?",
        "04684985-f00a-47c1-8638-69dd10bbef9a": "What is happening in the scene described in the context information?",
        "26b8073b-01db-42f6-bbc8-9db251827b25": "How is the size of the iceberg being described in the passage?",
        "395cb73f-a57e-44e8-986f-15995299d2e9": "How tall is an average size Icelandic iceberg above the surface of the water?",
        "7cff876d-5a64-437f-87df-9ca1453e8d74": "How does the height of the iceberg in the video compare to the average size of Icelandic icebergs?",
        "7e4a70cb-f81d-4aca-a168-7fc24b1ee39a": "How does the video being taken in real time impact the viewer's perception of the icebergs?",
        "84f2923c-34d1-4d17-abc4-902404d19d58": "In what ways do the icebergs in the video display different aspects of their personality?",
        "c89c009f-dec6-4417-b7f5-dc7f163be383": "How does the artist in the text emphasize the importance of connection through their artwork?",
        "1a116e44-1386-48ee-9848-5c11477d4d69": "What message does the artist convey about the relationship between human beings and nature in their art?",
        "d16d1915-266e-49fe-8097-715b5a0e2271": "How did the speaker feel when they first saw mountains in Antarctica?",
        "2092afd5-fbdd-4485-b06b-5b5ca38b8f6a": "How deep is the water surrounding the iceberg?",
        "1eaf7417-a89a-455b-8006-3822526bb747": "What is the significance of the snow covering another piece of snow for years?",
        "4d1423b2-0afe-46dc-9e5b-18f72b735ef3": "How do icebergs form and break apart from glaciers or ice shelves?",
        "d7b04364-37aa-48f3-b676-ee6e8a3739b7": "In what way do icebergs interact with their surrounding environment, according to the text?",
        "b2fb4ff2-ec79-4871-ad1a-638565d42eaf": "How do some ice mountains react to compromise?",
        "ca98c8cd-4cc7-4995-bb0c-33cc4cdca4bb": "What happens to the water during a violent ice collapse?",
        "4f6864b3-fb6c-4a07-a444-691de0489e44": "How does the speaker use the metaphor of an iceberg to convey a deeper message about unity and interconnectedness?",
        "792267a8-fa7b-49b3-b1e6-0150aa83163d": "How does the melting ice release rich minerals and feed 20,000 organisms?",
        "a5311387-727a-4005-b6d3-1762c7150440": "What is the significance of breathing in the ancient smell of the melting ice?",
        "a2893555-9306-4522-b7e3-6adddaa6d99b": "How does photographing the mountains of ice contribute to understanding their impact on the environment?",
        "fc355e0c-aba6-4a60-85a4-83f0defbc406": "How does the speaker connect photographing mountains of ice with photographing their ancestors?",
        "c4cbd214-b09e-491a-a8dd-693201ad5608": "How does the melting of something signify a continuation of continuity to life according to the context information provided?",
        "e5ae96fd-35e2-4e29-a58a-4ae2e2a7a28a": "How does the age of the ice in the photographed iceberg vary, ranging from thousands of years to over 100,000 years?",
        "a4379c39-2941-49d1-8898-c84c890f4f31": "Can you describe the significance of the ice made in Greenland that is mentioned in the context information?",
        "bb7759c3-8751-46b8-9ceb-686efff02b84": "How would you describe the difficulty level of the opportunity mentioned in the context?",
        "1c6892fa-ed78-4499-bbec-a3dcb5604b06": "Can you provide details about the size of the boat mentioned on the left side of the hill?",
        "5095fbf8-e2b4-443e-84db-20af6480a8fa": "How long is the ship described in the context information?",
        "62fa032c-4b3c-4a65-af13-dfb26d403c95": "Can you describe the shape of the iceberg in the water as mentioned in the text?",
        "b6a4b49c-c658-471c-a159-38ddf37ce4cf": "How tall is an average iceberg in Greenland, according to the context information provided?",
        "c006c02f-3180-42cd-a328-074aa3290063": "Describe what is happening in the real-time lapse footage of the iceberg in Greenland.",
        "9e38f140-bef7-469a-a577-dc6eab23e051": "How does the author compare the real time lapse to an iceberg in terms of showing different aspects of personality?",
        "924ef69f-b1c1-43b9-8c10-83dd543d8309": "How does the repetition of the phrase \"as an artist\" contribute to the overall message or tone of the text?",
        "d3006a00-d4ac-4bb6-85b2-b3d4690ca5cb": "How does the repetition of the word \"glacier\" in the context suggest a strong emphasis on this natural feature?",
        "ed9bbd8b-160b-493e-b594-97fd3021bd83": "Can you identify any specific details or characteristics of the glacier that are mentioned in the context?",
        "761c6dc9-e170-4985-a3f1-6aefbe619ce2": "How does the repetition of the phrase \"a lot of ice in the ice\" contribute to the overall tone or mood of the text?",
        "255b0f50-0365-454e-a79c-fc8e1d62efe8": "What effect does the abundance of ice have on the setting described in the context?",
        "60ac03dc-e2ac-4866-aa64-34c0de0f0d83": "Can you identify any potential symbolism or metaphorical meaning behind the presence of so much ice in the text?",
        "de286b33-4fe5-473d-b8b9-d0db3c0e56a7": "How does the repetition of the phrase \"a lot of ice in the ice\" impact the rhythm or flow of the writing?",
        "a7765b99-f656-4c8d-9118-571a1aa34eb8": "In what ways does the abundance of ice in the text enhance the reader's understanding of the environment being depicted?",
        "63e09c00-a2af-4407-b1d4-dba1b4f5960b": "How does the ice in the context information change form?",
        "8b6dc6fd-da80-4ebb-bff2-cf6082621ddf": "What is the significance of the repeated mention of melted ice in the text?",
        "492c7e57-c40d-46ec-8ed7-da300978e7ef": "How does the speaker plan to demonstrate the amount of ice to the audience?",
        "0f8f776f-f03d-48de-b1e8-9c02fbf8317a": "What type of visuals will be used to showcase the ice in the presentation?",
        "59acfdd1-2488-4582-bcbf-5ecba8e8216d": "How does the example demonstrate document-level translation from mBART25 Sent-MT and Doc-MT?",
        "932a1c8c-1aed-43b4-b76b-9be52dbee15a": "What is the significance of the example being held out from the test set of TED15 Zh-En?",
        "97cd2cb6-c3dc-4a5b-ae62-31dd7efb5bad": "Can you explain the difference between Sent-MT and Doc-MT in the context of document-level translation?",
        "2eb0c761-eb41-4055-8fab-12272c712470": "How does the example illustrate the movement of the translation to the top of the document?",
        "96b98ae4-0965-4783-b5b5-24f4bbb2a201": "What can be inferred about the effectiveness of mBART25 Sent-MT and Doc-MT based on the example provided?",
        "01175685-2be5-49b4-bfaa-63397a5e0afc": "How does the Doc-MT system differ from the Sent-MT system in terms of producing translations?",
        "e57f6038-e7a3-4407-9e9d-edf0dd9c520c": "Why is it mentioned that the Doc-MT model produces several \"And\" to connect sentences?",
        "7db5dbc8-2eea-491f-92e1-ab16282b568d": "What is the significance of global knowledge in translation models, as discussed in the context?",
        "3b94ccaa-d185-452c-880a-aa16eb2ee39a": "How do models with pre-training compare to models without pre-training in terms of translation output quality?",
        "79c69eeb-0ef1-4b93-9916-9802cde2cffa": "Can you explain why the non-pretrained Doc-MT model failed to produce readable translation output?",
        "119dd2ce-f072-4c49-ac0c-e751994d06a5": "What action is the Chief Medical Officers' Council calling for in response to the government's silence?",
        "8e851787-3cda-4b1b-93cb-4017d732f8fd": "Why is education considered a big event for girls in poor countries, patriarchal societies, and tribal societies?",
        "db0bbe81-ad80-4c89-ab28-2e9a4c491af0": "How does the conventional wisdom suggest achieving higher resolution in a certain field, and what limitations are mentioned in the text?",
        "6a3c0432-157f-4441-9c5d-ae799b1706a3": "What is the significance of the request made by the Board of Primary Doctors to the British Medical Association?",
        "c105d217-6973-4be6-a6f6-17ffe2e6038a": "How does the mBART25 model demonstrate successful unsupervised machine translation between different language pairs in the examples provided?",
        "bd8d946e-1e90-4e9b-8c80-35bc46e88ce3": "What action is the Chief Medical Officers' Council calling for in response to the government's silence?",
        "906b6169-e399-4158-b5d6-4a8bd2ca413f": "Why is education considered a significant event in the lives of girls in poor countries, patriarchal societies, and clan societies?",
        "c387f0a7-a7ad-4526-ada3-721adf9eefe6": "How does the importance of education for girls differ between developed countries like Canada and the United States, and poorer, patriarchal societies?",
        "a6035d59-43ed-4fac-924c-c0126c74db75": "In what types of societies is education seen as a priority for girls, according to the context information provided?",
        "e20d3852-3e2d-4ba0-82d7-12dc8d93f85a": "Why is schooling considered a big deal for girls in patriarchal and tribal societies, as mentioned in the text?",
        "93d7d6e3-565a-4215-b12e-0c0d33f079bb": "How does the perception of education for girls vary between developed countries and countries with patriarchal or tribal societies, based on the information provided?",
        "ea090b42-248d-44c8-9343-20dc1ded8b12": "What is the conventional wisdom regarding achieving higher resolution in the context of magnets?",
        "3a1f4c35-a210-4ef0-9fa4-2f8567bc2551": "How do bigger magnets contribute to resolution improvement according to the text?",
        "c6594448-7daf-4ce6-bf05-30967db3f869": "What is the role of big cushions in the quest for higher resolution as mentioned in the document?",
        "3ab2709f-9793-47a8-8a43-f01a110c90a7": "How are large jellyfish related to the discussion on resolution improvement in the text?",
        "83150b33-c19d-402b-ac91-0850445a81b7": "Can you explain the limitations of relying solely on bigger magnets, cushions, or jellyfish for achieving the desired resolution improvement?",
        "3efa13bf-3ddc-4cc2-91d5-848ef385bcb3": "How does the mBART25 model perform when fine-tuned on different language pairs in terms of translation accuracy?",
        "97b1e330-13ce-4e89-bec5-1e89668faf48": "Can cultural and historical correlations between languages be effectively captured through pre-training in machine translation models?",
        "30df58b5-90f0-4b41-925f-7091c5bb8f44": "Provide an example of a failure case in translation by the supervised model, and explain why it occurred.",
        "826b74a8-4013-419b-937c-41918eda591c": "How does the pre-training stage potentially bias the output distribution of the machine translation model?",
        "58c4bbcf-8337-4c2f-a093-6ec66661fac2": "Discuss the significance of the shared character sets and syntactic structures in the context of machine translation between different languages.",
        "475cb9a6-b698-47ba-a8e9-50c29188b052": "What are the missing elements in the context information provided?",
        "e41cd965-5bd1-4eee-bf13-7a3a18fddc20": "How many unknowns are present in the context information?",
        "f15f9f9f-e66b-44e9-982d-bfd593bc42a6": "Can you identify any patterns or themes in the context information?",
        "5b40cff4-e6fe-4c61-9160-530e65748ca9": "What information can be inferred from the context provided?",
        "30b370f2-d555-485f-8975-71b3c66ea0b4": "How would you summarize the content of the document based on the context information given?",
        "09d60d94-9678-4278-a39d-a337146e1a67": "What is the Chief Medical Officers' Council calling for in response to the government's silence?",
        "e1dc374f-8dae-4860-8888-d3db82e65fe2": "What steps did the JDC exec take in response to the government's silence?",
        "29fd5d6c-98f8-4197-bfcd-1f7604f39828": "What is the purpose of the special meeting requested by the JDC exec?",
        "371cec3e-7b25-4185-960d-9fa7c37f7694": "When is the rolling programme of escalated industrial action set to begin?",
        "94d9d4ce-5cb3-4d02-a822-d28616bb2869": "Who has the authority to authorise the industrial action mentioned in the document?",
        "1e4ce3ea-9406-45c7-a983-2aabccc3b5f7": "How might the government's silence have influenced the decision to request a special meeting for industrial action authorization?",
        "ef0a3bc0-3e3a-4cab-82c7-e455269c89ea": "What action has the Council of Chief Medical Officers formally requested the Royal College of Physicians to approve?",
        "22631ce9-1ae2-4540-b17c-1dcca08f6560": "What action did the Board of Primary Doctors take in response to the government's silence?",
        "d48ac364-c046-4a45-885f-b7338b64c749": "What is the model used for translation in the Zh-En language pair?",
        "dea604bb-ffb8-44d1-97e6-c94af73fd26b": "How many language pairs does the mBART25 model support for translation?",
        "0641b875-4480-48aa-b17c-fe5221538a38": "Can you identify any specific features or characteristics of the mBART25 model based on the context information provided?",
        "36cbeb6c-c25b-4f40-9e3a-f1aa4318c4a2": "What is the significance of the mBART25 model in the field of machine translation?",
        "96d2436e-20e3-4ea7-9a6e-a2734777e6d4": "How does the mBART25 model compare to other translation models in terms of performance and capabilities?",
        "30a27d50-7ac9-4e79-89de-aeb893306c64": "In which countries is it commonplace to see the phenomenon mentioned in the context information?",
        "3798b860-9462-4ab8-b612-e651ad1644cd": "Can you provide examples of other countries where this phenomenon is common?",
        "80f8f362-d40e-495c-bf3b-f1cecf4b9ef9": "How does the prevalence of this phenomenon differ between Canada and the United States?",
        "30439c61-ffd0-4ee6-8787-7058eecf10ed": "What factors may contribute to the widespread occurrence of this phenomenon in certain countries?",
        "f1246010-4ac4-4b77-beae-3421aab4aab2": "How might the presence of this phenomenon impact society in the countries where it is common?",
        "0b5405f2-d7dd-46a5-9fac-1f2f623fcd5f": "How does the prevalence of child marriage vary between different types of societies?",
        "912a8892-cfea-4c63-a6c9-284364009d8d": "Why is education particularly important for girls in patriarchal and clan societies where child marriage is common?",
        "11d39845-9713-4474-bd9b-1ca92efee5bb": "How does the significance of a girl's life event vary between developed countries and poor, patriarchal societies?",
        "024e6bc3-a425-4fb9-a796-b5f0ed505357": "Why is education considered to be very important for girls in poor countries, patriarchal societies, and tribal societies according to the context information provided?",
        "be030726-e3aa-4e67-9b1a-4ecedac95a38": "In which countries is education a priority for girls according to the context information provided?",
        "f4df8bd4-4556-45da-b017-487e6808af21": "How does the prioritization of education for girls vary across different types of societies mentioned in the context information?",
        "050dea33-2460-4eaf-a8d2-ab6589c4acd7": "What is the language pair supported by mBART25 for translation in the Ja-En model?",
        "f1a87b42-a12f-4e16-9934-8bbd8ad5bcea": "How many languages are supported by mBART25 for translation in total?",
        "5af7e0c2-395e-45d8-b337-b3876a920845": "Can you identify the missing language pair for translation in the Zh-En model?",
        "32037b93-f7a9-4a6f-be71-236a5fcee68b": "How many translations can mBART25 generate per query?",
        "8cf07dd3-7318-4ba6-accc-8b196bfdf24f": "What is the significance of the number 1,000 mentioned in the context information?",
        "e38506d3-8d3d-43ab-a6c9-89fcf0a5e250": "What is the significance of the number 1,000 in the context information provided?",
        "1ca4ef6a-c212-43b6-846a-b19b117fcb7b": "Can you identify any patterns or themes present in the document based on the repeated use of question marks and ellipses?",
        "da34bc48-1c25-4b01-8f7f-0ed2ec0c1b11": "How might the use of question marks and ellipses contribute to the overall tone or mood of the text?",
        "b2a9cb6f-5a8c-49ab-8845-d9d2c8b7df06": "What do you think the author is trying to convey through the repetition of question marks and ellipses?",
        "43d99f34-3a5e-414f-be7a-bbf8d859ef2a": "How does the ambiguity created by the use of question marks and ellipses impact the reader's interpretation of the text?",
        "8dec2602-5bea-4853-aabf-c3c9cef9a8eb": "How many numbers are listed in the context information?",
        "c9aba70c-c8e9-467a-8b41-e1d51adffb50": "What is the missing number after 1,000 in the sequence?",
        "52077523-ce4e-424b-9d01-3267b54f5860": "Can you identify any patterns or trends in the numbers provided?",
        "a77e2ab1-c109-45a6-857f-d08d36225c8e": "How many question marks are present in the context information?",
        "bf1d8a64-f314-472d-87c1-ce115e2a102c": "What could be the possible value of the missing numbers in the sequence?",
        "9e3bf3ae-4737-4f7f-bc9c-e96b942a6720": "What is the conventional wisdom regarding achieving higher resolution?",
        "51cd6365-243d-4961-ba78-16d2fcf7fcd4": "Why is it stated that bigger magnets only provide a small improvement in resolution, rather than the significant increase needed?",
        "3fc81b6b-adf5-4454-8446-1877b55b7d07": "How does conventional wisdom suggest that higher resolution can be achieved in this context?",
        "adcdc95e-e463-4c79-900f-07b71b1565c2": "Why are bigger magnets only able to offer incremental resolution improvements according to the text?",
        "8d0f4dd3-341e-490e-8a55-ed47dfa78c67": "How does the use of bigger cushions impact the resolution in the given scenario?",
        "0e30a2d7-0c0a-4a49-88c6-cdbf4c98f4f3": "What is the significance of achieving 1,000 times better resolution in this context?",
        "7621620c-7af0-4db8-a106-145cb4a2063d": "How is higher resolution typically achieved according to conventional wisdom?",
        "dfbb0c21-0082-48b0-aa4e-a288ce455f6e": "What is the limitation of using large jellyfish for obtaining higher resolution?",
        "281134a6-18ad-456e-95a2-297b2ad60d6a": "How does the resolution in the document compare to the amount needed?",
        "92c0cde2-d369-4296-8ace-8a80bb4a2d3a": "How can resolution be improved in the document?",
        "04560412-f6b1-4df1-b4cb-94b1b07b3bbe": "What is the significance of language transfer in unsupervised machine translation?",
        "994fab51-3ccd-4f45-b62f-408b17ead6a1": "Can you explain the concept of mBART25 in machine translation?",
        "e33fbf51-f25b-4a6a-b6fa-15f7e1a54619": "How do examples from Japanese, Korean, and Chinese languages demonstrate unsupervised machine translation to English?",
        "e3d421b5-b77c-402d-87b1-c638007f43bf": "Can you identify the significance of marking supervised settings in red in the document?",
        "cddf15a6-0501-49d4-8912-9eadc0196751": "How does the use of color coding help in highlighting important information in a document?",
        "aa46744a-c0ce-47a7-ad8d-229e4e91d874": "What potential impact could the color red have on the reader's perception of the supervised settings in the document?",
        "866406e2-a69f-44b1-a8af-8f76f08fd753": "How do the character sets of the three languages mentioned in the document differ from each other?",
        "e4793d90-04b9-49c6-8f2f-4161fe9a4961": "How are the syntactic structures of the languages discussed in the document unique from each other?",
        "b7f9382a-15e2-42cc-bb95-b157b699a93f": "How does the cultural and historical correlation between the languages impact the assumption of pre-training in the context of the document?",
        "ae8b4fe9-8a14-4a10-93b0-c807ff227562": "Can you explain how fine-tuning the mBART25 model on one pair of languages allows for successful translation in other language pairs without the need for parallel sentences?",
        "be9e5c65-c26f-4dad-ab42-337f1f9ba904": "What are some potential reasons for the failure cases mentioned in the context information?",
        "4ce80d52-8af6-42a1-b0a7-301093c316b5": "How does the ability of the resulted model to translate well in different language pairs impact the field of machine translation?",
        "cd8f354d-a461-4262-9ca5-a9ee7a3e81b6": "Can you discuss the significance of the mBART25 model in the context of multilingual translation tasks?",
        "529b46f8-1da6-4719-9dd5-5e16b687b1ae": "How might the findings mentioned in the context information contribute to advancements in natural language processing technology?",
        "93462b4f-b99e-4431-b331-dedd3c9c1273": "In the 3rd example mentioned, which model correctly translates the word \"\uc790\uc11d\" into \"magnets\"?",
        "69dc7f15-bcb6-4f66-8866-a713b5605a29": "What were the incorrect translations provided by the Ja-En and Zh-En models for the word \"\uc790\uc11d\"?",
        "c1aaa089-b0af-43a4-9b79-924925b34546": "In the 2nd example, what error did the Ko-En model make in translating the word \"developed\"?",
        "a4eafe29-a8d4-4242-a03d-231d2fe13c2a": "How does the pre-training stage potentially bias the output distribution?",
        "527a8ee7-abab-4a6f-8147-d1ab0dd8fc3f": "Can you explain the relationship between the pre-training stage and the output distribution in machine learning models?"
    },
    "corpus": {
        "36970c66-6851-4c7e-bef9-3a0f62405461": "Multilingual Denoising Pre-training for Neural Machine Translation\nYinhan Liu*, Jiatao Gu*, Naman Goyal*, Xian Li, Sergey Edunov\nMarjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer\nFacebook AI Research\n{yinhanliu,jgu,naman,xianl,edunov\nghazvini,mikelewis,lsz} @fb.com\nAbstract\nThis paper demonstrates that multilingual\ndenoising pre-training produces signi\ufb01cant\nperformance gains across a wide variety of\nmachine translation (MT) tasks. We present\nmBART \u2013 a sequence-to-sequence denois-\ning auto-encoder pre-trained on large-scale\nmonolingual corpora in many languages us-\ning the BART objective (Lewis et al., 2019).\nmBART is the \ufb01rst method for pre-training\na complete sequence-to-sequence model by\ndenoising full texts in multiple languages,\nwhile previous approaches have focused\nonly on the encoder, decoder, or reconstruct-\ning parts of the text. Pre-training a complete\nmodel allows it to be directly \ufb01ne tuned\nfor supervised (both sentence-level and\ndocument-level) and unsupervised machine\ntranslation, with no task-speci\ufb01c modi\ufb01ca-\ntions. We demonstrate that adding mBART\ninitialization produces performance gains in\nall but the highest-resource settings, includ-\ning up to 12 BLEU points for low resource\nMT and over 5 BLEU points for many\ndocument-level and unsupervised models.\nWe also show it also enables new types of\ntransfer to language pairs with no bi-text or\nthat were not in the pre-training corpus, and\npresent extensive analysis of which factors\ncontribute the most to effective pre-training.\n1 Introduction\nDespite its wide adoption for other NLP tasks (De-\nvlin et al., 2019; Liu et al., 2019; Yang et al.,\n2019; Lewis et al., 2019; Raffel et al., 2019), self-\nsupervised pretraining is not yet common prac-\ntice in machine translation (MT). Existing MT\napproaches only pre-train parts of the model, in-\ncluding the encoder (Lample and Conneau, 2019)\nand the decoder (Edunov et al., 2019), or use pre-\ntraining objectives that only reconstruct parts of\ntext (Song et al., 2019), or only focus on English\n*Equal contribution.corpora (Lewis et al., 2019; Raffel et al., 2019). In\nthis paper, we show that signi\ufb01cant performance\ngains are possible by pre-training a complete au-\ntoregressive model with an objective that noises\nand reconstructs full texts across many languages.\nIn this work, we present mBART \u2013 a multilin-\ngual sequence-to-sequence (Seq2Seq) denoising\nauto-encoder. mBART is trained by applying the\nBART (Lewis et al., 2019) to large-scale mono-\nlingual corpora across many languages. The input\ntexts are noised by masking phrases and permut-\ning sentences, and a single Transformer (Vaswani\net al., 2017) model is learned to recover the texts.\nDifferent from other pre-training approaches for\nMT (Lample and Conneau, 2019; Song et al.,\n2019), mBART pre-trains a complete autoregres-\nsive Seq2Seq model. mBART is trained once for\nall languages, providing a set of parameters that\ncan be \ufb01ne-tuned for any of the language pairs in\nboth supervised and unsupervised settings, with-\nout any task-speci\ufb01c or language-speci\ufb01c modi\ufb01-\ncations or initialization schemes.\nExtensive experiments demonstrate that this\nsimple approach works remarkably well. We \ufb01rst\nfocus on existing MT benchmarks. For supervised\nsentence-level MT, mBART initialization leads to\nsigni\ufb01cant gains (up to 12 BLEU points) across\nlow/medium-resource pairs (<10M bi-text pairs),\nwithout sacri\ufb01cing performance in high-resource\nsettings. These results further improve with back-\ntranslation (BT), setting a new state-of-the-art on\nWMT16 English-Romanian and the FloRes test\nsets. For document-level MT, our document-level\npre-training improves results by up to 5.5. For\nthe unsupervised case, we see consistent gains\nand produce the \ufb01rst non-degenerate results for\nless related language pairs (e.g., 9.5 BLEU gain\non Nepali-English). Previous pre-training schemes\nhave only considered subsets of these tasks, but we\ncompare performance where possible and demon-\nstrate that mBART consistently performs the best.arXiv:2001.08210v2  [cs.CL]  23 Jan 2020",
        "d3b0af95-8db3-4244-8b93-0f1951eda2ab": "Multilingual Denoising Pre-training for Neural Machine Translation\nYinhan Liu*, Jiatao Gu*, Naman Goyal*, Xian Li, Sergey Edunov\nMarjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer\nFacebook AI Research\n{yinhanliu,jgu,naman,xianl,edunov\nghazvini,mikelewis,lsz} @fb.com\nAbstract\nThis paper demonstrates that multilingual\ndenoising pre-training produces signi\ufb01cant\nperformance gains across a wide variety of\nmachine translation (MT) tasks. We present\nmBART \u2013 a sequence-to-sequence denois-\ning auto-encoder pre-trained on large-scale\nmonolingual corpora in many languages us-\ning the BART objective (Lewis et al., 2019).\nmBART is the \ufb01rst method for pre-training\na complete sequence-to-sequence model by\ndenoising full texts in multiple languages,\nwhile previous approaches have focused\nonly on the encoder, decoder, or reconstruct-\ning parts of the text. Pre-training a complete\nmodel allows it to be directly \ufb01ne tuned\nfor supervised (both sentence-level and\ndocument-level) and unsupervised machine\ntranslation, with no task-speci\ufb01c modi\ufb01ca-\ntions. We demonstrate that adding mBART\ninitialization produces performance gains in\nall but the highest-resource settings, includ-\ning up to 12 BLEU points for low resource\nMT and over 5 BLEU points for many\ndocument-level and unsupervised models.\nWe also show it also enables new types of\ntransfer to language pairs with no bi-text or\nthat were not in the pre-training corpus, and\npresent extensive analysis of which factors\ncontribute the most to effective pre-training.\n1 Introduction\nDespite its wide adoption for other NLP tasks (De-\nvlin et al., 2019; Liu et al., 2019; Yang et al.,\n2019; Lewis et al., 2019; Raffel et al., 2019), self-\nsupervised pretraining is not yet common prac-\ntice in machine translation (MT).",
        "37caa115-53da-49ba-94f7-12aa12785f08": "Existing MT\napproaches only pre-train parts of the model, in-\ncluding the encoder (Lample and Conneau, 2019)\nand the decoder (Edunov et al., 2019), or use pre-\ntraining objectives that only reconstruct parts of\ntext (Song et al., 2019), or only focus on English\n*Equal contribution.corpora (Lewis et al., 2019; Raffel et al., 2019). In\nthis paper, we show that signi\ufb01cant performance\ngains are possible by pre-training a complete au-\ntoregressive model with an objective that noises\nand reconstructs full texts across many languages.\nIn this work, we present mBART \u2013 a multilin-\ngual sequence-to-sequence (Seq2Seq) denoising\nauto-encoder. mBART is trained by applying the\nBART (Lewis et al., 2019) to large-scale mono-\nlingual corpora across many languages. The input\ntexts are noised by masking phrases and permut-\ning sentences, and a single Transformer (Vaswani\net al., 2017) model is learned to recover the texts.\nDifferent from other pre-training approaches for\nMT (Lample and Conneau, 2019; Song et al.,\n2019), mBART pre-trains a complete autoregres-\nsive Seq2Seq model. mBART is trained once for\nall languages, providing a set of parameters that\ncan be \ufb01ne-tuned for any of the language pairs in\nboth supervised and unsupervised settings, with-\nout any task-speci\ufb01c or language-speci\ufb01c modi\ufb01-\ncations or initialization schemes.\nExtensive experiments demonstrate that this\nsimple approach works remarkably well. We \ufb01rst\nfocus on existing MT benchmarks. For supervised\nsentence-level MT, mBART initialization leads to\nsigni\ufb01cant gains (up to 12 BLEU points) across\nlow/medium-resource pairs (<10M bi-text pairs),\nwithout sacri\ufb01cing performance in high-resource\nsettings.",
        "16944e27-13ba-44d9-bc94-d009f9289adc": "These results further improve with back-\ntranslation (BT), setting a new state-of-the-art on\nWMT16 English-Romanian and the FloRes test\nsets. For document-level MT, our document-level\npre-training improves results by up to 5.5. For\nthe unsupervised case, we see consistent gains\nand produce the \ufb01rst non-degenerate results for\nless related language pairs (e.g., 9.5 BLEU gain\non Nepali-English). Previous pre-training schemes\nhave only considered subsets of these tasks, but we\ncompare performance where possible and demon-\nstrate that mBART consistently performs the best.arXiv:2001.08210v2  [cs.CL]  23 Jan 2020",
        "08965a05-e4e2-4784-943e-7fdca50c13a2": "Multilingual Denoising Pre-training for Neural Machine Translation\nYinhan Liu*, Jiatao Gu*, Naman Goyal*, Xian Li, Sergey Edunov\nMarjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer\nFacebook AI Research\n{yinhanliu,jgu,naman,xianl,edunov\nghazvini,mikelewis,lsz} @fb.",
        "6358ad7c-bb44-4ccb-a709-1a30c74fd381": "edunov\nghazvini,mikelewis,lsz} @fb.com\nAbstract\nThis paper demonstrates that multilingual\ndenoising pre-training produces signi\ufb01cant\nperformance gains across a wide variety of\nmachine translation (MT) tasks.",
        "44fe4138-6141-46aa-abd0-4350d090eb88": "We present\nmBART \u2013 a sequence-to-sequence denois-\ning auto-encoder pre-trained on large-scale\nmonolingual corpora in many languages us-\ning the BART objective (Lewis et al., 2019).",
        "ed0b985d-5828-446f-9d29-0cd5b5b6c6f0": "mBART is the \ufb01rst method for pre-training\na complete sequence-to-sequence model by\ndenoising full texts in multiple languages,\nwhile previous approaches have focused\nonly on the encoder, decoder, or reconstruct-\ning parts of the text.",
        "7c301759-ad60-47d1-9e88-b2abaddcb120": "Pre-training a complete\nmodel allows it to be directly \ufb01ne tuned\nfor supervised (both sentence-level and\ndocument-level) and unsupervised machine\ntranslation, with no task-speci\ufb01c modi\ufb01ca-\ntions.",
        "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f": "We demonstrate that adding mBART\ninitialization produces performance gains in\nall but the highest-resource settings, includ-\ning up to 12 BLEU points for low resource\nMT and over 5 BLEU points for many\ndocument-level and unsupervised models.",
        "0fa584f2-c4a1-4e0a-a79c-a7445448f79f": "We also show it also enables new types of\ntransfer to language pairs with no bi-text or\nthat were not in the pre-training corpus, and\npresent extensive analysis of which factors\ncontribute the most to effective pre-training.",
        "f5289393-61e8-4aa5-a245-c2e0c7dc9dfd": "1 Introduction\nDespite its wide adoption for other NLP tasks (De-\nvlin et al., 2019; Liu et al., 2019; Yang et al.,\n2019; Lewis et al., 2019; Raffel et al., 2019), self-\nsupervised pretraining is not yet common prac-\ntice in machine translation (MT).",
        "07f4f9ca-3739-4f6a-be8f-7dfce558cb02": "Existing MT\napproaches only pre-train parts of the model, in-\ncluding the encoder (Lample and Conneau, 2019)\nand the decoder (Edunov et al., 2019), or use pre-\ntraining objectives that only reconstruct parts of\ntext (Song et al., 2019), or only focus on English\n*Equal contribution.corpora (Lewis et al., 2019; Raffel et al., 2019).",
        "8a4f7be4-4647-4f82-ac2b-5fa65030bf30": "In\nthis paper, we show that signi\ufb01cant performance\ngains are possible by pre-training a complete au-\ntoregressive model with an objective that noises\nand reconstructs full texts across many languages.\nIn this work, we present mBART \u2013 a multilin-\ngual sequence-to-sequence (Seq2Seq) denoising\nauto-encoder.",
        "e1f81839-b518-445d-8292-39e6cf7b5190": "mBART is trained by applying the\nBART (Lewis et al., 2019) to large-scale mono-\nlingual corpora across many languages. The input\ntexts are noised by masking phrases and permut-\ning sentences, and a single Transformer (Vaswani\net al., 2017) model is learned to recover the texts.",
        "f4ff1f01-0e19-48d1-a2df-924ea1d14da2": "Different from other pre-training approaches for\nMT (Lample and Conneau, 2019; Song et al.,\n2019), mBART pre-trains a complete autoregres-\nsive Seq2Seq model.",
        "922d8246-6e75-4196-9cb8-bd44e2a85eb0": "mBART is trained once for\nall languages, providing a set of parameters that\ncan be \ufb01ne-tuned for any of the language pairs in\nboth supervised and unsupervised settings, with-\nout any task-speci\ufb01c or language-speci\ufb01c modi\ufb01-\ncations or initialization schemes.\nExtensive experiments demonstrate that this\nsimple approach works remarkably well. We \ufb01rst\nfocus on existing MT benchmarks.",
        "1415501b-741a-43ce-ae49-7cc6671850cb": "We \ufb01rst\nfocus on existing MT benchmarks. For supervised\nsentence-level MT, mBART initialization leads to\nsigni\ufb01cant gains (up to 12 BLEU points) across\nlow/medium-resource pairs (<10M bi-text pairs),\nwithout sacri\ufb01cing performance in high-resource\nsettings.",
        "e2ec67a6-199a-4298-a244-237500c4f402": "These results further improve with back-\ntranslation (BT), setting a new state-of-the-art on\nWMT16 English-Romanian and the FloRes test\nsets. For document-level MT, our document-level\npre-training improves results by up to 5.5.",
        "8746c6d1-8700-4c32-aec8-049eb631c8da": "For\nthe unsupervised case, we see consistent gains\nand produce the \ufb01rst non-degenerate results for\nless related language pairs (e.g., 9.5 BLEU gain\non Nepali-English).",
        "307bf3f4-bb26-4f93-8e94-fa2585c69599": "Previous pre-training schemes\nhave only considered subsets of these tasks, but we\ncompare performance where possible and demon-\nstrate that mBART consistently performs the best.arXiv:2001.08210v2  [cs.CL]  23 Jan 2020",
        "3b2fd52b-87e8-4a61-b984-e1706504d37d": "We also show that mBART enables new types\nof transfer across language pairs. For example,\n\ufb01ne-tuning on bi-text in one language pair (e.g.,\nKorean-English) creates a model that can trans-\nlate from all other languages in the monolingual\npre-training set (e.g., Italian-English), with no fur-\nther training. We also show that languages not\nin pre-training corpora can bene\ufb01t from mBART,\nstrongly suggesting that the initialization is at least\npartially language universal. Finally, we present a\ndetailed analysis of which factors contribute the\nmost to effective pre-training, including the num-\nber of languages and their overall similarity.\n2 Multilingual Denoising Pre-training\nWe use a large-scale common crawl (CC) corpus\n(\u00a72.1) to pre-train BART models (\u00a72.2). Our ex-\nperiments in the later sections involve \ufb01netuning a\nrange of models pre-trained on different subsets of\nthe CC languages \u00a72.3).\n2.1 Data: CC25 corpus\nDatasets We pre-train on a subset of 25 lan-\nguages \u2013 CC25 \u2013 extracted from the Common\nCrawl (CC) (Wenzek et al., 2019; Conneau et al.,\n2019)1. CC25 includes languages from different\nfamilies and with varied amounts of text (Table 1).\nFollowing Lample and Conneau (2019), we re-\nbalanced the corpus by up/down-sampling text\nfrom each language iwith a ratio\u03bbi:\n\u03bbi=1\npi\u00b7p\u03b1\ni\u2211\nip\u03b1\ni, (1)\nwherepiis the percentage of each language in CC-\n25. We use the smoothing parameter \u03b1= 0.7.\nPre-processing We tokenize with a sentence-\npiece model (SPM, Kudo and Richardson, 2018)\nlearned on the full CC data that includes 250,000\nsubword tokens. While not all of these languages\nare used for pre-training, this tokenization sup-\nports \ufb01ne-tuning on additional languages. We do\nnot apply additional preprocessing, such as true-\ncasing or normalizing punctuation/characters.\n2.2 Model: mBART\nOur models follow the BART (Lewis et al., 2019)\nsequence-to-sequence pre-training scheme, as re-\nviewed in this section. While BART was only pre-\ntrained for English, we systematically study the ef-\nfects of pre-training on different sets of languages.\n1https://commoncrawl.orgCode Language Tokens/M Size/GB\nEn English 55608 300.8\nRu Russian 23408 278.0\nVi Vietnamese 24757 137.3\nJa Japanese 530 (*) 69.3\nDe German 10297 66.6\nRo Romanian 10354 61.4\nFr French 9780 56.8\nFi Finnish 6730 54.3\nKo Korean 5644 54.2\nEs Spanish 9374 53.3\nZh Chinese (Sim) 259 (*) 46.9\nIt Italian 4983 30.2\nNl Dutch 5025 29.3\nAr Arabic 2869 28.0\nTr Turkish 2736 20.9\nHi Hindi 1715 20.2\nCs Czech 2498 16.3\nLt Lithuanian 1835 13.7\nLv Latvian 1198 8.8\nKk Kazakh 476 6.4\nEt Estonian 843 6.1\nNe Nepali 237 3.8\nSi Sinhala 243 3.6\nGu Gujarati 140 1.9\nMy Burmese 56 1.6\nTable 1: Languages and Statistics of the CC25 Cor-\npus. A list of 25 languages ranked with monolingual\ncorpus size. Throughout this paper, we replace the lan-\nguage names with their ISO codes for simplicity. (*)\nChinese and Japanese corpus are not segmented, so the\ntokens counts here are sentences counts\nArchitecture We use a standard sequence-to-\nsequence Transformer architecture (Vaswani et al.,\n2017), with 12layers of encoder and 12layers\nof decoder with model dimension of 1024 on16\nheads (\u223c680M parameters). We include an addi-\ntional layer-normalization layer on top of both the\nencoder and decoder, which we found stabilized\ntraining at FP16 precision.\nLearning Our training data covers Klanguages:\nD={D1,...,DK}where eachDiis a collection\nof monolingual documents in language i. We (1)\nassume access to a noising function g, de\ufb01ned be-\nlow, that corrupts text, and (2) train the model to\npredict the original text Xgiveng(X). More for-\nmally, we aim to maximize L\u03b8:\nL\u03b8=\u2211\nDi\u2208D\u2211\nX\u2208D ilogP(X|g(X);\u03b8),(2)\nwhereXis an instance in language iand the dis-\ntributionPis de\ufb01ned by the Seq2Seq model.",
        "08b00f30-b1a9-4943-81e5-e70580e24592": "We also show that mBART enables new types\nof transfer across language pairs. For example,\n\ufb01ne-tuning on bi-text in one language pair (e.g.,\nKorean-English) creates a model that can trans-\nlate from all other languages in the monolingual\npre-training set (e.g., Italian-English), with no fur-\nther training. We also show that languages not\nin pre-training corpora can bene\ufb01t from mBART,\nstrongly suggesting that the initialization is at least\npartially language universal. Finally, we present a\ndetailed analysis of which factors contribute the\nmost to effective pre-training, including the num-\nber of languages and their overall similarity.\n2 Multilingual Denoising Pre-training\nWe use a large-scale common crawl (CC) corpus\n(\u00a72.1) to pre-train BART models (\u00a72.2). Our ex-\nperiments in the later sections involve \ufb01netuning a\nrange of models pre-trained on different subsets of\nthe CC languages \u00a72.3).\n2.1 Data: CC25 corpus\nDatasets We pre-train on a subset of 25 lan-\nguages \u2013 CC25 \u2013 extracted from the Common\nCrawl (CC) (Wenzek et al., 2019; Conneau et al.,\n2019)1. CC25 includes languages from different\nfamilies and with varied amounts of text (Table 1).\nFollowing Lample and Conneau (2019), we re-\nbalanced the corpus by up/down-sampling text\nfrom each language iwith a ratio\u03bbi:\n\u03bbi=1\npi\u00b7p\u03b1\ni\u2211\nip\u03b1\ni, (1)\nwherepiis the percentage of each language in CC-\n25. We use the smoothing parameter \u03b1= 0.7.\nPre-processing We tokenize with a sentence-\npiece model (SPM, Kudo and Richardson, 2018)\nlearned on the full CC data that includes 250,000\nsubword tokens. While not all of these languages\nare used for pre-training, this tokenization sup-\nports \ufb01ne-tuning on additional languages. We do\nnot apply additional preprocessing, such as true-\ncasing or normalizing punctuation/characters.",
        "f5f80d76-71f0-498a-b09d-b3acabe5c2f3": "2.2 Model: mBART\nOur models follow the BART (Lewis et al., 2019)\nsequence-to-sequence pre-training scheme, as re-\nviewed in this section. While BART was only pre-\ntrained for English, we systematically study the ef-\nfects of pre-training on different sets of languages.\n1https://commoncrawl.orgCode Language Tokens/M Size/GB\nEn English 55608 300.8\nRu Russian 23408 278.0\nVi Vietnamese 24757 137.3\nJa Japanese 530 (*) 69.3\nDe German 10297 66.6\nRo Romanian 10354 61.4\nFr French 9780 56.8\nFi Finnish 6730 54.3\nKo Korean 5644 54.2\nEs Spanish 9374 53.3\nZh Chinese (Sim) 259 (*) 46.9\nIt Italian 4983 30.2\nNl Dutch 5025 29.3\nAr Arabic 2869 28.0\nTr Turkish 2736 20.9\nHi Hindi 1715 20.2\nCs Czech 2498 16.3\nLt Lithuanian 1835 13.7\nLv Latvian 1198 8.8\nKk Kazakh 476 6.4\nEt Estonian 843 6.1\nNe Nepali 237 3.8\nSi Sinhala 243 3.6\nGu Gujarati 140 1.9\nMy Burmese 56 1.6\nTable 1: Languages and Statistics of the CC25 Cor-\npus. A list of 25 languages ranked with monolingual\ncorpus size. Throughout this paper, we replace the lan-\nguage names with their ISO codes for simplicity. (*)\nChinese and Japanese corpus are not segmented, so the\ntokens counts here are sentences counts\nArchitecture We use a standard sequence-to-\nsequence Transformer architecture (Vaswani et al.,\n2017), with 12layers of encoder and 12layers\nof decoder with model dimension of 1024 on16\nheads (\u223c680M parameters).",
        "627c87ed-d4be-4038-8078-7d897175ba24": "We include an addi-\ntional layer-normalization layer on top of both the\nencoder and decoder, which we found stabilized\ntraining at FP16 precision.\nLearning Our training data covers Klanguages:\nD={D1,...,DK}where eachDiis a collection\nof monolingual documents in language i. We (1)\nassume access to a noising function g, de\ufb01ned be-\nlow, that corrupts text, and (2) train the model to\npredict the original text Xgiveng(X). More for-\nmally, we aim to maximize L\u03b8:\nL\u03b8=\u2211\nDi\u2208D\u2211\nX\u2208D ilogP(X|g(X);\u03b8),(2)\nwhereXis an instance in language iand the dis-\ntributionPis de\ufb01ned by the Seq2Seq model.",
        "7626705c-f2f3-4e77-92a0-3d3220ebd1d3": "We also show that mBART enables new types\nof transfer across language pairs. For example,\n\ufb01ne-tuning on bi-text in one language pair (e.g.,\nKorean-English) creates a model that can trans-\nlate from all other languages in the monolingual\npre-training set (e.g., Italian-English), with no fur-\nther training.",
        "9a45b8ab-8ca5-4851-abad-299cddbf8457": "We also show that languages not\nin pre-training corpora can bene\ufb01t from mBART,\nstrongly suggesting that the initialization is at least\npartially language universal. Finally, we present a\ndetailed analysis of which factors contribute the\nmost to effective pre-training, including the num-\nber of languages and their overall similarity.",
        "1fcab080-6615-4c41-bda1-e93ed36ef38d": "2 Multilingual Denoising Pre-training\nWe use a large-scale common crawl (CC) corpus\n(\u00a72.1) to pre-train BART models (\u00a72.2). Our ex-\nperiments in the later sections involve \ufb01netuning a\nrange of models pre-trained on different subsets of\nthe CC languages \u00a72.3).",
        "7e3c4065-831f-4397-b83f-b4e2f280b255": "2.1 Data: CC25 corpus\nDatasets We pre-train on a subset of 25 lan-\nguages \u2013 CC25 \u2013 extracted from the Common\nCrawl (CC) (Wenzek et al., 2019; Conneau et al.,\n2019)1. CC25 includes languages from different\nfamilies and with varied amounts of text (Table 1).",
        "0a781b40-dd2b-4125-8120-f6a4069031db": "CC25 includes languages from different\nfamilies and with varied amounts of text (Table 1).\nFollowing Lample and Conneau (2019), we re-\nbalanced the corpus by up/down-sampling text\nfrom each language iwith a ratio\u03bbi:\n\u03bbi=1\npi\u00b7p\u03b1\ni\u2211\nip\u03b1\ni, (1)\nwherepiis the percentage of each language in CC-\n25.",
        "5774090b-e045-4384-9cc6-adc0c370c115": "We use the smoothing parameter \u03b1= 0.7.\nPre-processing We tokenize with a sentence-\npiece model (SPM, Kudo and Richardson, 2018)\nlearned on the full CC data that includes 250,000\nsubword tokens. While not all of these languages\nare used for pre-training, this tokenization sup-\nports \ufb01ne-tuning on additional languages.",
        "0c84d059-b029-47bf-9885-da5d51e5a817": "We do\nnot apply additional preprocessing, such as true-\ncasing or normalizing punctuation/characters.",
        "4fab5263-2760-44da-a7a8-f5b1e87074d7": "2.2 Model: mBART\nOur models follow the BART (Lewis et al., 2019)\nsequence-to-sequence pre-training scheme, as re-\nviewed in this section. While BART was only pre-\ntrained for English, we systematically study the ef-\nfects of pre-training on different sets of languages.\n1https://commoncrawl.orgCode Language Tokens/M Size/GB\nEn English 55608 300.",
        "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6": "orgCode Language Tokens/M Size/GB\nEn English 55608 300.8\nRu Russian 23408 278.0\nVi Vietnamese 24757 137.3\nJa Japanese 530 (*) 69.3\nDe German 10297 66.6\nRo Romanian 10354 61.4\nFr French 9780 56.8\nFi Finnish 6730 54.3\nKo Korean 5644 54.",
        "f39fe1fe-b0a1-496e-8501-f02dfefbee0e": "3\nKo Korean 5644 54.2\nEs Spanish 9374 53.3\nZh Chinese (Sim) 259 (*) 46.9\nIt Italian 4983 30.2\nNl Dutch 5025 29.3\nAr Arabic 2869 28.0\nTr Turkish 2736 20.9\nHi Hindi 1715 20.2\nCs Czech 2498 16.",
        "2b2cd616-b670-44e2-8116-2989a64392f6": "9\nHi Hindi 1715 20.2\nCs Czech 2498 16.3\nLt Lithuanian 1835 13.7\nLv Latvian 1198 8.8\nKk Kazakh 476 6.4\nEt Estonian 843 6.1\nNe Nepali 237 3.8\nSi Sinhala 243 3.6\nGu Gujarati 140 1.",
        "c5666718-d94d-413b-9d67-79a3adc0020e": "6\nGu Gujarati 140 1.9\nMy Burmese 56 1.6\nTable 1: Languages and Statistics of the CC25 Cor-\npus. A list of 25 languages ranked with monolingual\ncorpus size. Throughout this paper, we replace the lan-\nguage names with their ISO codes for simplicity.",
        "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012": "Throughout this paper, we replace the lan-\nguage names with their ISO codes for simplicity. (*)\nChinese and Japanese corpus are not segmented, so the\ntokens counts here are sentences counts\nArchitecture We use a standard sequence-to-\nsequence Transformer architecture (Vaswani et al.,\n2017), with 12layers of encoder and 12layers\nof decoder with model dimension of 1024 on16\nheads (\u223c680M parameters).",
        "5c1d93a6-df99-4c97-9014-2ca0f0c06927": "We include an addi-\ntional layer-normalization layer on top of both the\nencoder and decoder, which we found stabilized\ntraining at FP16 precision.",
        "6c34551c-572c-4638-9709-f073d8c19f20": "Learning Our training data covers Klanguages:\nD={D1,...,DK}where eachDiis a collection\nof monolingual documents in language i. We (1)\nassume access to a noising function g, de\ufb01ned be-\nlow, that corrupts text, and (2) train the model to\npredict the original text Xgiveng(X).",
        "f60195af-ac97-4a9b-82a2-983fc22a6a5c": "More for-\nmally, we aim to maximize L\u03b8:\nL\u03b8=\u2211\nDi\u2208D\u2211\nX\u2208D ilogP(X|g(X);\u03b8),(2)\nwhereXis an instance in language iand the dis-\ntributionPis de\ufb01ned by the Seq2Seq model.",
        "129ed859-b0ae-4e77-b178-d0b348652ac1": "Where did __ from ? </s> Who __ I __ </s> <En> <En> Who am I ? </s> Where did I come from ? </s> Who am I ? </s> Where did I come from ? </s> <En> \nWho am I ? </s> <En> Transformer EncoderTransformer Decoder\u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> <Ja>\n<Ja> \u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> Transformer EncoderTransformer Decoder\n BB\u0003\u0e01\u0ded\u0003\u0336 </s> \u0373\u03a2\u0003BB\u001f\u0012V!\u0003<Ja> <Ja> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> <Ja> Transformer EncoderTransformer DecoderMultilingual Denoising Pre-Training  (mBART)Fine-tuning on Machine Translation\u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> <Ja> Transformer EncoderTransformer Decoder:HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V! See you tomorrow .</s> <En>\n<En> :HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V! See you tomorrow .</s> Doc-MTSent-MTFigure 1: Framework for our Multilingual Denoising Pre-training (left) and \ufb01ne-tuning on downstream MT tasks\n(right), where we use (1) sentence permutation (2) word-span masking as the injected noise. A special language id\ntoken is added at both the encoder and decoder. One multilingual pre-trained model is used for all tasks.\nNoise function Following Lewis et al. (2019),\nwe use two types of noise in g. We \ufb01rst remove\nspans of text and replace them with a mask to-\nken. We mask 35% of the words in each instance\nby random sampling a span length according to a\nPoisson distribution ( \u03bb= 3.5). We also permute\nthe order of sentences within each instance. The\ndecoder input is the original text with one posi-\ntion offset. A language id symbol <LID> is used\nas the initial token to predict the sentence. It is also\npossible to use other noise types, such as those in\nLample et al. (2018c), but we leave the exploration\nof the optimal noising strategy to future work.\nInstance format For each instance of a batch,\nwe sample a language id symbol <LID>, and\nwe pack as many consecutive sentences as pos-\nsible sampled from the corresponding corpus of\n<LID>, until either it hits the document boundary\nor reaches the 512 max token length. Sentences\nin the instance are separated by the end of sen-\ntence (</S>) token. Then, we append the selected\n<LID> token to represent the end of this instance.\nPre-training at \u201cmulti-sentence\u201d level enables us to\nwork on both sentence and document translation.\nOptimization Our full model (including 25lan-\nguages) is trained on 256 Nvidia V100 GPUs\n(32GB) for 500K steps. The total batch size\nis around 128K tokens per GPU, matching\nBART (Lewis et al., 2019) con\ufb01guration. We use\nthe Adam optimizer ( \u03f5= 1e\u22126,\u03b22= 0.98) and\nlinear learning rate decay scheduling. The total\ntraining time was approximately 2.5 weeks. We\nstarted the training with dropout 0.1and reduced it\nto0.05at 250K steps and 0at 400K steps. All ex-\nperiments are done with Fairseq (Ott et al., 2019).2.3 Pre-trained Models\nTo better measure the effects of different levels\nof multilinguality during pre-training, we built a\nrange of models as follows:\n\u2022mBART25 We pre-train a model on all 25 lan-\nguages, using the setting described in \u00a72.2.\n\u2022mBART06 To explore the effect of pre-training\non related languages, we pretrain a model on a\nsubset of six European languages: Ro, It, Cs, Fr,\nEs and En. For a fair comparison, we use \u223c1/4\nof the mBART25 batch size, which allows our\nmodel to have the same number of updates per\nlanguage during pre-training.\n\u2022mBART02 We pre-train bilingual models, us-\ning English and one other language for four\nlanguage pairs: En-De, En-Ro, En-It. We use a\nbatch size of\u223c1/12of that in the mBART25.\n\u2022BART-En/Ro To help establish baseline per-\nformance levels, we also train monolingual\nBART models on the same En and Ro corpus\nonly.\n\u2022Random As additional baselines, we will also\ninclude a comparison with a model randomly\ninitialized without pre-training for each trans-\nlation task. Since the sizes of different down-\nstream datasets vary, we always grid-search the\nhyper-parameters (architecture, dropout, etc.) to\n\ufb01nd the best non-pretrained con\ufb01guration.\nAll models use the same vocabulary (\u00a72.1). Not\nall tokens will frequently occur in all pre-training\ncorpora, but later experiments show that this large\nvocabulary can improve generalization in multilin-\ngual settings even for unseen languages.",
        "63563aaf-19ec-421e-b6ef-f9f27de694a8": "Where did __ from ? </s> Who __ I __ </s> <En> <En> Who am I ? </s> Where did I come from ? </s> Who am I ? </s> Where did I come from ? </s> <En> \nWho am I ? </s> <En> Transformer EncoderTransformer Decoder\u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> <Ja>\n<Ja> \u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> Transformer EncoderTransformer Decoder\n BB\u0003\u0e01\u0ded\u0003\u0336 </s> \u0373\u03a2\u0003BB\u001f\u0012V!\u0003<Ja> <Ja> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> <Ja> Transformer EncoderTransformer DecoderMultilingual Denoising Pre-Training  (mBART)Fine-tuning on Machine Translation\u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> <Ja> Transformer EncoderTransformer Decoder:HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V! See you tomorrow .</s> <En>\n<En> :HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V! See you tomorrow .</s> Doc-MTSent-MTFigure 1: Framework for our Multilingual Denoising Pre-training (left) and \ufb01ne-tuning on downstream MT tasks\n(right), where we use (1) sentence permutation (2) word-span masking as the injected noise. A special language id\ntoken is added at both the encoder and decoder. One multilingual pre-trained model is used for all tasks.\nNoise function Following Lewis et al. (2019),\nwe use two types of noise in g. We \ufb01rst remove\nspans of text and replace them with a mask to-\nken.",
        "860faaec-9749-47ec-9cab-d3dc78ab07b9": "We mask 35% of the words in each instance\nby random sampling a span length according to a\nPoisson distribution ( \u03bb= 3.5). We also permute\nthe order of sentences within each instance. The\ndecoder input is the original text with one posi-\ntion offset. A language id symbol <LID> is used\nas the initial token to predict the sentence. It is also\npossible to use other noise types, such as those in\nLample et al. (2018c), but we leave the exploration\nof the optimal noising strategy to future work.\nInstance format For each instance of a batch,\nwe sample a language id symbol <LID>, and\nwe pack as many consecutive sentences as pos-\nsible sampled from the corresponding corpus of\n<LID>, until either it hits the document boundary\nor reaches the 512 max token length. Sentences\nin the instance are separated by the end of sen-\ntence (</S>) token. Then, we append the selected\n<LID> token to represent the end of this instance.\nPre-training at \u201cmulti-sentence\u201d level enables us to\nwork on both sentence and document translation.\nOptimization Our full model (including 25lan-\nguages) is trained on 256 Nvidia V100 GPUs\n(32GB) for 500K steps. The total batch size\nis around 128K tokens per GPU, matching\nBART (Lewis et al., 2019) con\ufb01guration. We use\nthe Adam optimizer ( \u03f5= 1e\u22126,\u03b22= 0.98) and\nlinear learning rate decay scheduling. The total\ntraining time was approximately 2.5 weeks. We\nstarted the training with dropout 0.1and reduced it\nto0.05at 250K steps and 0at 400K steps.",
        "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e": "All ex-\nperiments are done with Fairseq (Ott et al., 2019).2.3 Pre-trained Models\nTo better measure the effects of different levels\nof multilinguality during pre-training, we built a\nrange of models as follows:\n\u2022mBART25 We pre-train a model on all 25 lan-\nguages, using the setting described in \u00a72.2.\n\u2022mBART06 To explore the effect of pre-training\non related languages, we pretrain a model on a\nsubset of six European languages: Ro, It, Cs, Fr,\nEs and En. For a fair comparison, we use \u223c1/4\nof the mBART25 batch size, which allows our\nmodel to have the same number of updates per\nlanguage during pre-training.\n\u2022mBART02 We pre-train bilingual models, us-\ning English and one other language for four\nlanguage pairs: En-De, En-Ro, En-It. We use a\nbatch size of\u223c1/12of that in the mBART25.\n\u2022BART-En/Ro To help establish baseline per-\nformance levels, we also train monolingual\nBART models on the same En and Ro corpus\nonly.\n\u2022Random As additional baselines, we will also\ninclude a comparison with a model randomly\ninitialized without pre-training for each trans-\nlation task. Since the sizes of different down-\nstream datasets vary, we always grid-search the\nhyper-parameters (architecture, dropout, etc.) to\n\ufb01nd the best non-pretrained con\ufb01guration.\nAll models use the same vocabulary (\u00a72.1). Not\nall tokens will frequently occur in all pre-training\ncorpora, but later experiments show that this large\nvocabulary can improve generalization in multilin-\ngual settings even for unseen languages.",
        "97eea3ea-b4d2-4f1b-b52b-197ae0fdb55d": "Where did __ from ? </s> Who __ I __ </s> <En> <En> Who am I ? </s> Where did I come from ? </s> Who am I ? </s> Where did I come from ? </s> <En> \nWho am I ? </s> <En> Transformer EncoderTransformer Decoder\u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> <Ja>\n<Ja>",
        "265ec4ca-778b-4942-a5a6-4f5f699d4559": "</s> <Ja>\n<Ja> \u143a\u0003\u0385\u0003\u6291\u0003\u0498 </s> Transformer EncoderTransformer Decoder\n BB\u0003\u0e01\u0ded\u0003\u0336 </s> \u0373\u03a2\u0003BB\u001f\u0012V!\u0003<Ja> <Ja> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s>",
        "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101": "</s> \u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s> <Ja> Transformer EncoderTransformer DecoderMultilingual Denoising Pre-Training  (mBART)Fine-tuning on Machine Translation\u0373\u03a2\u0003\u036e\u0399\u0003\u0358 \u0335\u001f\u0012V!\u0003\u0380\u0375\u0003\u0e01\u0ded\u0003\u0336 </s>",
        "4722aa7e-9971-4e4c-80b9-4dcad378e2ed": "</s> <Ja> Transformer EncoderTransformer Decoder:HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V! See you tomorrow .</s> <En>\n<En> :HOO\u0003WKHQ\u0003\u0011\u0003\u001f\u0012V!",
        "fc8a9558-8135-4c7e-9143-8c8743ca0243": "See you tomorrow .</s> Doc-MTSent-MTFigure 1: Framework for our Multilingual Denoising Pre-training (left) and \ufb01ne-tuning on downstream MT tasks\n(right), where we use (1) sentence permutation (2) word-span masking as the injected noise. A special language id\ntoken is added at both the encoder and decoder. One multilingual pre-trained model is used for all tasks.\nNoise function Following Lewis et al.",
        "e033034e-5a0e-454f-b149-f89ed7ada6aa": "One multilingual pre-trained model is used for all tasks.\nNoise function Following Lewis et al. (2019),\nwe use two types of noise in g. We \ufb01rst remove\nspans of text and replace them with a mask to-\nken.",
        "9603b668-c292-4721-a97c-3d8f34b9d1b9": "We mask 35% of the words in each instance\nby random sampling a span length according to a\nPoisson distribution ( \u03bb= 3.5). We also permute\nthe order of sentences within each instance. The\ndecoder input is the original text with one posi-\ntion offset. A language id symbol <LID> is used\nas the initial token to predict the sentence.",
        "3c2da02b-c1cb-4e40-b401-84a7d13de26a": "It is also\npossible to use other noise types, such as those in\nLample et al. (2018c), but we leave the exploration\nof the optimal noising strategy to future work.",
        "a1344fb0-a0f2-42b9-b6c6-d716057f9517": "Instance format For each instance of a batch,\nwe sample a language id symbol <LID>, and\nwe pack as many consecutive sentences as pos-\nsible sampled from the corresponding corpus of\n<LID>, until either it hits the document boundary\nor reaches the 512 max token length. Sentences\nin the instance are separated by the end of sen-\ntence (</S>) token.",
        "6e0c5c8b-0357-49f3-b32f-45221dceed76": "Then, we append the selected\n<LID> token to represent the end of this instance.\nPre-training at \u201cmulti-sentence\u201d level enables us to\nwork on both sentence and document translation.\nOptimization Our full model (including 25lan-\nguages) is trained on 256 Nvidia V100 GPUs\n(32GB) for 500K steps.",
        "a162a527-dae7-4a16-8397-3514db7c3bfb": "The total batch size\nis around 128K tokens per GPU, matching\nBART (Lewis et al., 2019) con\ufb01guration. We use\nthe Adam optimizer ( \u03f5= 1e\u22126,\u03b22= 0.98) and\nlinear learning rate decay scheduling. The total\ntraining time was approximately 2.5 weeks.",
        "2fe89c5b-3002-42da-98d1-50312fa0c62b": "The total\ntraining time was approximately 2.5 weeks. We\nstarted the training with dropout 0.1and reduced it\nto0.05at 250K steps and 0at 400K steps.",
        "7dd3c318-c49f-4d74-8e68-28fb3b08c9b4": "All ex-\nperiments are done with Fairseq (Ott et al., 2019).2.3 Pre-trained Models\nTo better measure the effects of different levels\nof multilinguality during pre-training, we built a\nrange of models as follows:\n\u2022mBART25 We pre-train a model on all 25 lan-\nguages, using the setting described in \u00a72.2.",
        "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1": "\u2022mBART06 To explore the effect of pre-training\non related languages, we pretrain a model on a\nsubset of six European languages: Ro, It, Cs, Fr,\nEs and En. For a fair comparison, we use \u223c1/4\nof the mBART25 batch size, which allows our\nmodel to have the same number of updates per\nlanguage during pre-training.",
        "0299a496-1c7c-4512-8e8c-69b09b2849a4": "\u2022mBART02 We pre-train bilingual models, us-\ning English and one other language for four\nlanguage pairs: En-De, En-Ro, En-It. We use a\nbatch size of\u223c1/12of that in the mBART25.\n\u2022BART-En/Ro To help establish baseline per-\nformance levels, we also train monolingual\nBART models on the same En and Ro corpus\nonly.",
        "2d3ef750-4597-45af-8ed4-28a3cf223d9e": "\u2022Random As additional baselines, we will also\ninclude a comparison with a model randomly\ninitialized without pre-training for each trans-\nlation task. Since the sizes of different down-\nstream datasets vary, we always grid-search the\nhyper-parameters (architecture, dropout, etc.) to\n\ufb01nd the best non-pretrained con\ufb01guration.\nAll models use the same vocabulary (\u00a72.1).",
        "17b7ef06-16eb-418e-a268-64e76685858e": "All models use the same vocabulary (\u00a72.1). Not\nall tokens will frequently occur in all pre-training\ncorpora, but later experiments show that this large\nvocabulary can improve generalization in multilin-\ngual settings even for unseen languages.",
        "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f": "Languages En-Gu En-Kk En-Vi En-Tr En-Ja En-Ko\nData Source WMT19 WMT19 IWSLT15 WMT17 IWSLT17 IWSLT17\nSize 10K 91K 133K 207K 223K 230K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 0.0 0.0 0.8 0.2 23.6 24.8 12.2 9.5 10.4 12.3 15.3 16.3\nmBART25 0.3 0.1 7.4 2.5 36.1 35.4 22.5 17.8 19.1 19.4 24.6 22.6\nLanguages En-Nl En-Ar En-It En-My En-Ne En-Ro\nData Source IWSLT17 IWSLT17 IWSLT17 WAT19 FLoRes WMT16\nSize 237K 250K 250K 259K 564K 608K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 34.6 29.3 27.5 16.9 31.7 28.0 23.3 34.9 7.6 4.3 34.0 34.3\nmBART25 43.3 34.8 37.6 21.6 39.8 34.0 28.3 36.9 14.5 7.4 37.8 37.7\nLanguages En-Si En-Hi En-Et En-Lt En-Fi En-Lv\nData Source FLoRes ITTB WMT18 WMT19 WMT17 WMT17\nSize 647K 1.56M 1.94M 2.11M 2.66M 4.50M\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 7.2 1.2 10.9 14.2 22.6 17.9 18.1 12.1 21.8 20.2 15.6 12.9\nmBART25 13.7 3.3 23.5 20.8 27.8 21.4 22.4 15.3 28.5 22.4 19.3 15.9\nTable 2: Low/Medium Resource Machine Translation Pre-training consistently improves over a randomly ini-\ntialized baseline, with particularly large gains on low resource language pairs (e.g. Vi-En).\nLanguages Cs Es Zh De Ru Fr\nSize 11M 15M 25M 28M 29M 41M\nRandom 16.5 33.2 35.0 30.9 31.5 41.4\nmBART25 18.0 34.0 33.3 30.5 31.3 41.0\nTable 3: High Resource Machine Translation where\nall the datasets are from their latest WMT competitions.\nWe only evaluate our models on En-X translation.\n3 Sentence-level Machine Translation\nThis section shows that mBART pre-training pro-\nvides consistent performance gains in low to\nmedium resource sentence-level MT settings, in-\ncluding bi-text only and with back translation, and\noutperforms other existing pre-training schemes\n(\u00a73.2). We also present a detailed analysis to un-\nderstand better which factors contribute the most\nto these gains (\u00a73.3), and show that pre-training\ncan even improve performance for languages not\npresent in the pre-training data at all (\u00a73.4).\n3.1 Experimental Settings\nDatasets We gather 24pairs of publicly avail-\nable parallel corpora that cover all the languages\nin CC25 (Table 1). Most pairs are from previous\nWMT (Gu, Kk, Tr, Ro, Et, Lt, Fi, Lv, Cs, Es,\nZh, De, Ru, Fr\u2194En) and IWSLT (Vi, Ja, Ko,\nNl, Ar, It\u2194En) competitions. We also use FLo-\nRes pairs (Guzm\u00e1n et al., 2019, En-Ne and En-\nSi), En-Hi from IITB (Kunchukuttan et al., 2017),and En-My from WAT19 (Ding et al., 2018, 2019).\nWe divide the datasets into three categories \u2013 low\nresource (<1M sentence pairs), medium resource\n(>1M and<10M), and high resource ( >10M).\nFine-tuning & Decoding We \ufb01ne-tune our mul-\ntilingual pre-trained models on a single pair of bi-\ntext data, feeding the source language into the en-\ncoder and decoding the target language. As shown\nin Figure 1, we load the pre-trained weights and\ntrain the MT model on bi-texts with teacher forc-\ning. For all directions, we train with 0.3dropout,\n0.2label smoothing, 2500 warm-up steps, 3e\u22125\nmaximum learning rate. We use a maximum of\n40K training updates for all low and medium re-\nsource pairs and 100K for high resource pairs. The\n\ufb01nal models are selected based on validation like-\nlihood. For decoding, we use beam-search with\nbeam size 5for all directions. The \ufb01nal results\nare reported in BLEU (Papineni et al., 2002) with\nlanguage-speci\ufb01c settings, see appendix A.\n3.2 Main Results\nAs shown in Table 2, initializing with the pre-\ntrained mBART25 weights shows gains on all the\nlow and medium resource pairs when compared\nwith randomly initialized baselines. We observe\ngains of 12+ BLEU on low resource pairs such as\nEn-Vi, En-Tr, and noisily aligned pairs like En-Hi.\nFine-tuning fails in extremely low-resource setting\nsuch as En-Gu, which only have roughly 10k ex-",
        "dff7d8e0-1ff3-4125-9b9b-a87d022938b4": "Languages En-Gu En-Kk En-Vi En-Tr En-Ja En-Ko\nData Source WMT19 WMT19 IWSLT15 WMT17 IWSLT17 IWSLT17\nSize 10K 91K 133K 207K 223K 230K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 0.0 0.0 0.8 0.2 23.6 24.8 12.2 9.5 10.4 12.3 15.3 16.3\nmBART25 0.3 0.1 7.4 2.5 36.1 35.4 22.5 17.8 19.1 19.4 24.6 22.6\nLanguages En-Nl En-Ar En-It En-My En-Ne En-Ro\nData Source IWSLT17 IWSLT17 IWSLT17 WAT19 FLoRes WMT16\nSize 237K 250K 250K 259K 564K 608K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 34.6 29.3 27.5 16.9 31.7 28.0 23.3 34.9 7.6 4.3 34.0 34.3\nmBART25 43.3 34.8 37.6 21.6 39.8 34.0 28.3 36.9 14.5 7.4 37.8 37.7\nLanguages En-Si En-Hi En-Et En-Lt En-Fi En-Lv\nData Source FLoRes ITTB WMT18 WMT19 WMT17 WMT17\nSize 647K 1.56M 1.94M 2.11M 2.66M 4.50M\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 7.2 1.2 10.9 14.2 22.6 17.9 18.1 12.1 21.8 20.",
        "45ca9b40-7aa6-42bf-8f67-9abc7d65171c": "6 17.9 18.1 12.1 21.8 20.2 15.6 12.9\nmBART25 13.7 3.3 23.5 20.8 27.8 21.4 22.4 15.3 28.5 22.4 19.3 15.9\nTable 2: Low/Medium Resource Machine Translation Pre-training consistently improves over a randomly ini-\ntialized baseline, with particularly large gains on low resource language pairs (e.g. Vi-En).\nLanguages Cs Es Zh De Ru Fr\nSize 11M 15M 25M 28M 29M 41M\nRandom 16.5 33.2 35.0 30.9 31.5 41.4\nmBART25 18.0 34.0 33.3 30.5 31.3 41.0\nTable 3: High Resource Machine Translation where\nall the datasets are from their latest WMT competitions.\nWe only evaluate our models on En-X translation.\n3 Sentence-level Machine Translation\nThis section shows that mBART pre-training pro-\nvides consistent performance gains in low to\nmedium resource sentence-level MT settings, in-\ncluding bi-text only and with back translation, and\noutperforms other existing pre-training schemes\n(\u00a73.2). We also present a detailed analysis to un-\nderstand better which factors contribute the most\nto these gains (\u00a73.3), and show that pre-training\ncan even improve performance for languages not\npresent in the pre-training data at all (\u00a73.4).\n3.1 Experimental Settings\nDatasets We gather 24pairs of publicly avail-\nable parallel corpora that cover all the languages\nin CC25 (Table 1). Most pairs are from previous\nWMT (Gu, Kk, Tr, Ro, Et, Lt, Fi, Lv, Cs, Es,\nZh, De, Ru, Fr\u2194En) and IWSLT (Vi, Ja, Ko,\nNl, Ar, It\u2194En) competitions.",
        "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27": "We also use FLo-\nRes pairs (Guzm\u00e1n et al., 2019, En-Ne and En-\nSi), En-Hi from IITB (Kunchukuttan et al., 2017),and En-My from WAT19 (Ding et al., 2018, 2019).\nWe divide the datasets into three categories \u2013 low\nresource (<1M sentence pairs), medium resource\n(>1M and<10M), and high resource ( >10M).\nFine-tuning & Decoding We \ufb01ne-tune our mul-\ntilingual pre-trained models on a single pair of bi-\ntext data, feeding the source language into the en-\ncoder and decoding the target language. As shown\nin Figure 1, we load the pre-trained weights and\ntrain the MT model on bi-texts with teacher forc-\ning. For all directions, we train with 0.3dropout,\n0.2label smoothing, 2500 warm-up steps, 3e\u22125\nmaximum learning rate. We use a maximum of\n40K training updates for all low and medium re-\nsource pairs and 100K for high resource pairs. The\n\ufb01nal models are selected based on validation like-\nlihood. For decoding, we use beam-search with\nbeam size 5for all directions. The \ufb01nal results\nare reported in BLEU (Papineni et al., 2002) with\nlanguage-speci\ufb01c settings, see appendix A.\n3.2 Main Results\nAs shown in Table 2, initializing with the pre-\ntrained mBART25 weights shows gains on all the\nlow and medium resource pairs when compared\nwith randomly initialized baselines. We observe\ngains of 12+ BLEU on low resource pairs such as\nEn-Vi, En-Tr, and noisily aligned pairs like En-Hi.\nFine-tuning fails in extremely low-resource setting\nsuch as En-Gu, which only have roughly 10k ex-",
        "43a314c5-5bb1-4e98-997a-9d80fe399ccc": "Languages En-Gu En-Kk En-Vi En-Tr En-Ja En-Ko\nData Source WMT19 WMT19 IWSLT15 WMT17 IWSLT17 IWSLT17\nSize 10K 91K 133K 207K 223K 230K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 0.0 0.0 0.8 0.2 23.",
        "94b89bc7-6af1-49e2-981c-a13d981e0441": "0 0.0 0.8 0.2 23.6 24.8 12.2 9.5 10.4 12.3 15.3 16.3\nmBART25 0.3 0.1 7.4 2.5 36.1 35.4 22.5 17.8 19.1 19.4 24.6 22.",
        "dc555c9e-a52d-4ea3-b1c5-e213c533e443": "5 17.8 19.1 19.4 24.6 22.6\nLanguages En-Nl En-Ar En-It En-My En-Ne En-Ro\nData Source IWSLT17 IWSLT17 IWSLT17 WAT19 FLoRes WMT16\nSize 237K 250K 250K 259K 564K 608K\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 34.",
        "86163975-231f-471e-8e82-703faac466e9": "6 29.3 27.5 16.9 31.7 28.0 23.3 34.9 7.6 4.3 34.0 34.3\nmBART25 43.3 34.8 37.6 21.6 39.8 34.0 28.3 36.9 14.5 7.4 37.8 37.",
        "40ba310b-d549-407d-9c03-93fd01d2199a": "3 36.9 14.5 7.4 37.8 37.7\nLanguages En-Si En-Hi En-Et En-Lt En-Fi En-Lv\nData Source FLoRes ITTB WMT18 WMT19 WMT17 WMT17\nSize 647K 1.56M 1.94M 2.11M 2.66M 4.",
        "8dd05b68-c22c-451f-aae3-7895f0e43502": "56M 1.94M 2.11M 2.66M 4.50M\nDirection\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 7.2 1.2 10.9 14.2 22.6 17.9 18.1 12.1 21.8 20.",
        "c6296cfa-9003-45dd-b079-2496789e2689": "6 17.9 18.1 12.1 21.8 20.2 15.6 12.9\nmBART25 13.7 3.3 23.5 20.8 27.8 21.4 22.4 15.3 28.5 22.4 19.3 15.",
        "557a5f88-548a-4357-9ec1-e808708d0743": "4 15.3 28.5 22.4 19.3 15.9\nTable 2: Low/Medium Resource Machine Translation Pre-training consistently improves over a randomly ini-\ntialized baseline, with particularly large gains on low resource language pairs (e.g. Vi-En).\nLanguages Cs Es Zh De Ru Fr\nSize 11M 15M 25M 28M 29M 41M\nRandom 16.5 33.",
        "5e557e8c-6b50-4dde-bc71-5ce92840bb13": "5 33.2 35.0 30.9 31.5 41.4\nmBART25 18.0 34.0 33.3 30.5 31.3 41.0\nTable 3: High Resource Machine Translation where\nall the datasets are from their latest WMT competitions.\nWe only evaluate our models on En-X translation.",
        "5b00f618-97b6-44b2-879b-953a9ac45d1e": "We only evaluate our models on En-X translation.\n3 Sentence-level Machine Translation\nThis section shows that mBART pre-training pro-\nvides consistent performance gains in low to\nmedium resource sentence-level MT settings, in-\ncluding bi-text only and with back translation, and\noutperforms other existing pre-training schemes\n(\u00a73.2).",
        "fc986e0c-1fbb-42b8-8fb7-b55583c48d9e": "We also present a detailed analysis to un-\nderstand better which factors contribute the most\nto these gains (\u00a73.3), and show that pre-training\ncan even improve performance for languages not\npresent in the pre-training data at all (\u00a73.4).\n3.1 Experimental Settings\nDatasets We gather 24pairs of publicly avail-\nable parallel corpora that cover all the languages\nin CC25 (Table 1).",
        "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90": "Most pairs are from previous\nWMT (Gu, Kk, Tr, Ro, Et, Lt, Fi, Lv, Cs, Es,\nZh, De, Ru, Fr\u2194En) and IWSLT (Vi, Ja, Ko,\nNl, Ar, It\u2194En) competitions.",
        "2c9ebd87-9851-4ca2-b805-22f59b650244": "We also use FLo-\nRes pairs (Guzm\u00e1n et al., 2019, En-Ne and En-\nSi), En-Hi from IITB (Kunchukuttan et al., 2017),and En-My from WAT19 (Ding et al., 2018, 2019).",
        "87f44cf4-ec69-4f61-80ba-420865b22cad": "We divide the datasets into three categories \u2013 low\nresource (<1M sentence pairs), medium resource\n(>1M and<10M), and high resource ( >10M).\nFine-tuning & Decoding We \ufb01ne-tune our mul-\ntilingual pre-trained models on a single pair of bi-\ntext data, feeding the source language into the en-\ncoder and decoding the target language.",
        "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008": "As shown\nin Figure 1, we load the pre-trained weights and\ntrain the MT model on bi-texts with teacher forc-\ning. For all directions, we train with 0.3dropout,\n0.2label smoothing, 2500 warm-up steps, 3e\u22125\nmaximum learning rate. We use a maximum of\n40K training updates for all low and medium re-\nsource pairs and 100K for high resource pairs.",
        "69220555-9f3b-445d-9721-a931d531cc11": "The\n\ufb01nal models are selected based on validation like-\nlihood. For decoding, we use beam-search with\nbeam size 5for all directions. The \ufb01nal results\nare reported in BLEU (Papineni et al., 2002) with\nlanguage-speci\ufb01c settings, see appendix A.",
        "e2d137d8-3d2c-4e11-9d38-df694a09dcdc": "3.2 Main Results\nAs shown in Table 2, initializing with the pre-\ntrained mBART25 weights shows gains on all the\nlow and medium resource pairs when compared\nwith randomly initialized baselines. We observe\ngains of 12+ BLEU on low resource pairs such as\nEn-Vi, En-Tr, and noisily aligned pairs like En-Hi.",
        "adc9c7e3-bfd5-45b0-9f49-a9769705b806": "Fine-tuning fails in extremely low-resource setting\nsuch as En-Gu, which only have roughly 10k ex-",
        "183d6d60-4edf-4737-b474-74ad60375c6b": "0 1 2\n+BT iterations6810Finetuning BLEU\n4.36.8 6.87.48.69.6En-Ne\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.612.715.114.519.421.3Ne-En\nRandom\nmBART25\n0 1 2\n+BT iterations0246810\n1.25.26.5\n3.37.99.3En-Si\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.212.115.1\n13.718.620.2Si-En\nRandom\nmBART25Figure 2: Pre-training + Back Translation on FLoRes with two iterations of BT.\nPre-training Fine-tuning\nModel Data En\u2192Ro Ro\u2192En +BT\nRandom None 34.3 34.0 36.8\nXLM (2019) En Ro - 35.6 38.5\nMASS (2019) En Ro - - 39.1\nBART (2019) En - - 38.0\nXLM-R (2019) CC100 35.6 35.8 -\nBART-En En 36.0 35.8 37.4\nBART-Ro Ro 37.6 36.8 38.1\nmBART02 En Ro 38.5 38.5 39.9\nmBART25 CC25 37.7 37.8 38.8\nTable 4: Comparison with Other Pre-training Ap-\nproaches on WMT16 Ro-En.\namples for tuning. In these settings, unsupervised\ntranslation is more appropriate, see \u00a75.2.\nFor high resource cases (Table 3), we do not\nobserve consistent gains, and pre-training slightly\nhurts performance when >25M parallel sentence\nare available. When a signi\ufb01cant amount of bi-text\ndata is given, we suspect that supervised training\nwashes out the pre-trained weights completely.\n+ Back Translation Back-translation (BT, Sen-\nnrich et al., 2016b) is a standard approach to aug-\nment bi-text with target side monolingual data. We\ncombine our pre-training with BT and test it on\nlow resource language pairs \u2013 En-Si and En-Ne \u2013\nusing the FLoRes dataset (Guzm\u00e1n et al., 2019).\nFor a fair comparison, we use the same mono-\nlingual data as (Guzm\u00e1n et al., 2019) to gener-\nate BT data. Figure 2 shows that initializing the\nmodel with our mBART25 pre-trained parameters\nimproves BLEU scores at each iteration of back\ntranslation, resulting in new state-of-the-art results\nin all four translation directions.\nv.s. Other Pre-training Approaches We also\ncompare our pre-trained models with recent self-\nsupervised pre-training methods, as shown in Ta-\nble 4. We consider En-Ro translation, the only\npair with established results. Our mBART modeloutperforms all the other pre-trained models, both\nwith and without BT augmentation. We also show\ncomparisons with the conventional BART model\ntrained on the same En and Ro data only. Both\nhave improvements over baselines, while worse\nthan mBART results, indicating pre-training in a\nmultilingual setting is essential. Moreover, com-\nbining BT leads to additional gains, resulting in a\nnew state-of-the-art for Ro-En translation.\n3.3 Analysis\nWe also present additional analysis, to better quan-\ntify when our pre-training helps.\nHow many languages should you pre-train on?\nWe investigate when it is helpful for pre-training\nto include languages other than the targeted lan-\nguage pair that will be used during \ufb01ne tuning. Ta-\nble 5 shows performance on four X-En pairs. Pre-\ntraining on more languages helps most when the\ntarget language monolingual data is limited (e.g.\nEn-My, the size of My is around 0.5%of En).\nIn contrast, when monolingual data is plenti-\nful (De, Ro), pre-training on multiple languages\nslightly hurts the \ufb01nal results (< 1BLEU). In these\ncases, additional languages may reduce the ca-\npacity available for each test language. Addition-\nally, the fact that mBART06 performs similar to\nmBART02 on Ro-En suggests that pre-training\nwith similar languages is particularly helpful.\nHow many pre-training steps are needed? We\nplot Ro-En BLEU score v.s. Pre-training steps in\nFigure 3, where we take the saved checkpoints (ev-\nery 25K steps) and apply the same \ufb01ne-tuning pro-\ncess described in \u00a73.1. Without any pre-training,\nour model over\ufb01ts and performs much worse than\nthe baseline. However, after just 25K steps (5% of\ntraining), both models outperform the best base-\nline. The models keep improving by over 3BLEU\nfor the rest of steps and have not fully con-\nverged after 500K steps. mBART25 is consistently",
        "aae6a10d-66b1-4095-8d1b-85279734d1bc": "0 1 2\n+BT iterations6810Finetuning BLEU\n4.36.8 6.87.48.69.6En-Ne\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.612.715.114.519.421.3Ne-En\nRandom\nmBART25\n0 1 2\n+BT iterations0246810\n1.25.26.5\n3.37.99.3En-Si\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.212.115.1\n13.718.620.2Si-En\nRandom\nmBART25Figure 2: Pre-training + Back Translation on FLoRes with two iterations of BT.\nPre-training Fine-tuning\nModel Data En\u2192Ro Ro\u2192En +BT\nRandom None 34.3 34.0 36.8\nXLM (2019) En Ro - 35.6 38.5\nMASS (2019) En Ro - - 39.1\nBART (2019) En - - 38.0\nXLM-R (2019) CC100 35.6 35.8 -\nBART-En En 36.0 35.8 37.4\nBART-Ro Ro 37.6 36.8 38.1\nmBART02 En Ro 38.5 38.5 39.9\nmBART25 CC25 37.7 37.8 38.8\nTable 4: Comparison with Other Pre-training Ap-\nproaches on WMT16 Ro-En.\namples for tuning. In these settings, unsupervised\ntranslation is more appropriate, see \u00a75.2.\nFor high resource cases (Table 3), we do not\nobserve consistent gains, and pre-training slightly\nhurts performance when >25M parallel sentence\nare available. When a signi\ufb01cant amount of bi-text\ndata is given, we suspect that supervised training\nwashes out the pre-trained weights completely.",
        "86c366bd-d571-4368-a5fa-d178e7f25026": "+ Back Translation Back-translation (BT, Sen-\nnrich et al., 2016b) is a standard approach to aug-\nment bi-text with target side monolingual data. We\ncombine our pre-training with BT and test it on\nlow resource language pairs \u2013 En-Si and En-Ne \u2013\nusing the FLoRes dataset (Guzm\u00e1n et al., 2019).\nFor a fair comparison, we use the same mono-\nlingual data as (Guzm\u00e1n et al., 2019) to gener-\nate BT data. Figure 2 shows that initializing the\nmodel with our mBART25 pre-trained parameters\nimproves BLEU scores at each iteration of back\ntranslation, resulting in new state-of-the-art results\nin all four translation directions.\nv.s. Other Pre-training Approaches We also\ncompare our pre-trained models with recent self-\nsupervised pre-training methods, as shown in Ta-\nble 4. We consider En-Ro translation, the only\npair with established results. Our mBART modeloutperforms all the other pre-trained models, both\nwith and without BT augmentation. We also show\ncomparisons with the conventional BART model\ntrained on the same En and Ro data only. Both\nhave improvements over baselines, while worse\nthan mBART results, indicating pre-training in a\nmultilingual setting is essential. Moreover, com-\nbining BT leads to additional gains, resulting in a\nnew state-of-the-art for Ro-En translation.\n3.3 Analysis\nWe also present additional analysis, to better quan-\ntify when our pre-training helps.\nHow many languages should you pre-train on?\nWe investigate when it is helpful for pre-training\nto include languages other than the targeted lan-\nguage pair that will be used during \ufb01ne tuning. Ta-\nble 5 shows performance on four X-En pairs. Pre-\ntraining on more languages helps most when the\ntarget language monolingual data is limited (e.g.\nEn-My, the size of My is around 0.5%of En).",
        "22099506-9d51-4f92-b600-fd72a5039db0": "En-My, the size of My is around 0.5%of En).\nIn contrast, when monolingual data is plenti-\nful (De, Ro), pre-training on multiple languages\nslightly hurts the \ufb01nal results (< 1BLEU). In these\ncases, additional languages may reduce the ca-\npacity available for each test language. Addition-\nally, the fact that mBART06 performs similar to\nmBART02 on Ro-En suggests that pre-training\nwith similar languages is particularly helpful.\nHow many pre-training steps are needed? We\nplot Ro-En BLEU score v.s. Pre-training steps in\nFigure 3, where we take the saved checkpoints (ev-\nery 25K steps) and apply the same \ufb01ne-tuning pro-\ncess described in \u00a73.1. Without any pre-training,\nour model over\ufb01ts and performs much worse than\nthe baseline. However, after just 25K steps (5% of\ntraining), both models outperform the best base-\nline. The models keep improving by over 3BLEU\nfor the rest of steps and have not fully con-\nverged after 500K steps. mBART25 is consistently",
        "2acdb36f-6941-43bc-a94c-808f00fe7cc2": "0 1 2\n+BT iterations6810Finetuning BLEU\n4.36.8 6.87.48.69.6En-Ne\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.612.715.114.519.421.3Ne-En\nRandom\nmBART25\n0 1 2\n+BT iterations0246810\n1.25.26.",
        "e66a3366-ab88-4caf-8ff5-200d82e9eaa7": "25.26.5\n3.37.99.3En-Si\nRandom\nmBART25\n0 1 2\n+BT iterations101520\n7.212.115.1\n13.718.620.2Si-En\nRandom\nmBART25Figure 2: Pre-training + Back Translation on FLoRes with two iterations of BT.",
        "99ac9b18-811d-499c-b94f-a55012ac2c47": "Pre-training Fine-tuning\nModel Data En\u2192Ro Ro\u2192En +BT\nRandom None 34.3 34.0 36.8\nXLM (2019) En Ro - 35.6 38.5\nMASS (2019) En Ro - - 39.1\nBART (2019) En - - 38.0\nXLM-R (2019) CC100 35.6 35.",
        "4e5ae620-3616-4817-9dec-46ebb620359c": "0\nXLM-R (2019) CC100 35.6 35.8 -\nBART-En En 36.0 35.8 37.4\nBART-Ro Ro 37.6 36.8 38.1\nmBART02 En Ro 38.5 38.5 39.9\nmBART25 CC25 37.7 37.8 38.",
        "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251": "9\nmBART25 CC25 37.7 37.8 38.8\nTable 4: Comparison with Other Pre-training Ap-\nproaches on WMT16 Ro-En.\namples for tuning. In these settings, unsupervised\ntranslation is more appropriate, see \u00a75.2.",
        "b85218a9-cc38-4662-affb-d26f4ac0ec92": "In these settings, unsupervised\ntranslation is more appropriate, see \u00a75.2.\nFor high resource cases (Table 3), we do not\nobserve consistent gains, and pre-training slightly\nhurts performance when >25M parallel sentence\nare available. When a signi\ufb01cant amount of bi-text\ndata is given, we suspect that supervised training\nwashes out the pre-trained weights completely.",
        "b75f87cd-5dbc-4061-aa74-16ae328b754b": "+ Back Translation Back-translation (BT, Sen-\nnrich et al., 2016b) is a standard approach to aug-\nment bi-text with target side monolingual data. We\ncombine our pre-training with BT and test it on\nlow resource language pairs \u2013 En-Si and En-Ne \u2013\nusing the FLoRes dataset (Guzm\u00e1n et al., 2019).",
        "5124075c-8aa4-4617-8be8-b6fc9d88993b": "For a fair comparison, we use the same mono-\nlingual data as (Guzm\u00e1n et al., 2019) to gener-\nate BT data. Figure 2 shows that initializing the\nmodel with our mBART25 pre-trained parameters\nimproves BLEU scores at each iteration of back\ntranslation, resulting in new state-of-the-art results\nin all four translation directions.\nv.s.",
        "ef04511c-24a6-491b-a237-af425f7a60ef": "v.s. Other Pre-training Approaches We also\ncompare our pre-trained models with recent self-\nsupervised pre-training methods, as shown in Ta-\nble 4. We consider En-Ro translation, the only\npair with established results. Our mBART modeloutperforms all the other pre-trained models, both\nwith and without BT augmentation.",
        "4a5872b3-8202-4028-8b7b-573f8d0c0fec": "We also show\ncomparisons with the conventional BART model\ntrained on the same En and Ro data only. Both\nhave improvements over baselines, while worse\nthan mBART results, indicating pre-training in a\nmultilingual setting is essential. Moreover, com-\nbining BT leads to additional gains, resulting in a\nnew state-of-the-art for Ro-En translation.",
        "ac9410c1-a1bf-460a-8389-87af13a62fb9": "3.3 Analysis\nWe also present additional analysis, to better quan-\ntify when our pre-training helps.\nHow many languages should you pre-train on?\nWe investigate when it is helpful for pre-training\nto include languages other than the targeted lan-\nguage pair that will be used during \ufb01ne tuning. Ta-\nble 5 shows performance on four X-En pairs.",
        "2451027a-456b-4b67-8d85-340eb5ca2878": "Ta-\nble 5 shows performance on four X-En pairs. Pre-\ntraining on more languages helps most when the\ntarget language monolingual data is limited (e.g.\nEn-My, the size of My is around 0.5%of En).",
        "392cdbf6-cad4-4d9a-b6ed-7008bfe6d77f": "En-My, the size of My is around 0.5%of En).\nIn contrast, when monolingual data is plenti-\nful (De, Ro), pre-training on multiple languages\nslightly hurts the \ufb01nal results (< 1BLEU). In these\ncases, additional languages may reduce the ca-\npacity available for each test language.",
        "497d872d-cc12-4d96-a92e-9384cf47e421": "Addition-\nally, the fact that mBART06 performs similar to\nmBART02 on Ro-En suggests that pre-training\nwith similar languages is particularly helpful.\nHow many pre-training steps are needed? We\nplot Ro-En BLEU score v.s.",
        "16dbd297-f1d2-4648-9bfc-dc1665869dbc": "We\nplot Ro-En BLEU score v.s. Pre-training steps in\nFigure 3, where we take the saved checkpoints (ev-\nery 25K steps) and apply the same \ufb01ne-tuning pro-\ncess described in \u00a73.1. Without any pre-training,\nour model over\ufb01ts and performs much worse than\nthe baseline.",
        "9f42ba3f-8e68-4a11-82c2-211a8df9b99f": "However, after just 25K steps (5% of\ntraining), both models outperform the best base-\nline. The models keep improving by over 3BLEU\nfor the rest of steps and have not fully con-\nverged after 500K steps. mBART25 is consistently",
        "d81d0b97-1536-41bd-84b9-bb8df5dfeca7": "Languages De Ro It My En\nSize/GB 66.6 61.4 30.2 1.6 300.8\nmBART02 31.3 38.5 39.7 36.5\nmBART06 - 38.5 39.3 -\nmBART25 30.5 37.7 39.8 36.9\nTable 5: Pretraining Languages on En-X translation.\nThe size refers to the size of monolingual data for X.\nThe size of En is shown as reference. All the pretrained\nmodels were controlled to see the same number of En-\nglish instances during training.\nModelsEn-My Training Cost\n\u2190 \u2192 GPU hours\nRandom (2019) 23.3 34.9 5\n+ BT 32.0 37.7 5 + 300 + 350\nmBART02 29.1 37.8 300\u223c3000 + 40\n+ BT 34.9 39.2 -\nTable 6: Comparison with Back-Translation on My-En\ntranslation using same mono-lingual data. We also esti-\nmate the computational costs for both pre-training and\nback-translation based on Nvidia V100 GPUs.\nslightly worse than mBART02.\nHow does the size of bitexts inference the gain\nfrom pre-training? Tables 2 and 3 show that\npre-training consistently improves for low and\nmedium resource language pairs. To verify this\ntrend, we plot performance for differing sized sub-\nsets of the En-De dataset. More precisely, we take\nthe full En-De corpus ( 28M pairs) and randomly\nsample 10K, 50K, 100K, 500K, 1M, 5M, 10M\ndatasets. We compare performance without pre-\ntraining to the mBART02 results, as shown in Fig-\nure 4. The pre-trained model is able to achieve\nover 20 BLEU with only 10K training examples,\nwhile the baseline system scores 0. Unsurpris-\ningly, increasing the size of bi-text corpus im-\nproves both models. Our pre-trained model con-\nsistently outperforms the baseline models, but the\ngap reduces with increasing amounts of bi-text, es-\npecially after 10M sentence pairs. This result con-\n\ufb01rms our observation in \u00a73.2 that our pre-training\ndoes not help translation in high-resource pairs.\nIs pre-training complementary to BT? Fig-\nure 2 presents that our pre-trained models can\nbe combined with iterative back-translation (BT)\non additional data, however, it is still not a fair\ncomparison. Table 6 shows the results when using\n0 100 200 300 400 500\npretraining steps (K)3435363738Finetuning BLEU\nmBART25\nmBART02\nRandomFigure 3: Fine-tuning curves for Ro-En along with\nPre-training steps . Both mBART25 and mBART02\noutperform the best baseline system after 25K steps.\n104105106107\nBi-text Size (# of sentence pairs)051015202530Finetuning BLEU\n0.04.49.214.722.426.527.430.9\n20.724.224.926.9 27.229.130.231.3\nRandom\nmBART02\nFigure 4: Fine-tuning curves for En-De along with\nsize of bitext. The x-axis is on a log scale.\nsame monolingual data where we use 79M En and\n29M My sentences following Chen et al. (2019).\nWith the same amount of monolingual corpus,\nmBART pre-training achieves the same perfor-\nmance on En\u2192My as BT, while still 3BLEU\nworse on My\u2192En. We suspect BT bene\ufb01ts from\nbigger monolingual data (En). Moreover, combin-\ning mBART02 model with BT, we see further\ngains even with same monolingual data. Besides,\nwe also provide estimated training costs where BT\nhas a longer pipeline involving training a baseline\nsystem (5h), translating monolingual data (300h)\nand formal training (350h). Instead, most of train-\ning costs of mBART lies in the pre-training part\nand can be easily adjusted to be more ef\ufb01cient.\n3.4 Generalization to Languages NOT in\nPre-training\nIn this section, we show that mBART can im-\nprove performance even with \ufb01ne tuning for lan-\nguages that did not appear in the pre-training cor-\npora, suggesting that the pre-training has language\nuniversal aspects, especially within the parameters\nlearned at the Transformer layers.",
        "678c751d-9b82-497b-b06d-4a8043c898ab": "Languages De Ro It My En\nSize/GB 66.6 61.4 30.2 1.6 300.8\nmBART02 31.3 38.5 39.7 36.5\nmBART06 - 38.5 39.3 -\nmBART25 30.5 37.7 39.8 36.9\nTable 5: Pretraining Languages on En-X translation.\nThe size refers to the size of monolingual data for X.\nThe size of En is shown as reference. All the pretrained\nmodels were controlled to see the same number of En-\nglish instances during training.\nModelsEn-My Training Cost\n\u2190 \u2192 GPU hours\nRandom (2019) 23.3 34.9 5\n+ BT 32.0 37.7 5 + 300 + 350\nmBART02 29.1 37.8 300\u223c3000 + 40\n+ BT 34.9 39.2 -\nTable 6: Comparison with Back-Translation on My-En\ntranslation using same mono-lingual data. We also esti-\nmate the computational costs for both pre-training and\nback-translation based on Nvidia V100 GPUs.\nslightly worse than mBART02.\nHow does the size of bitexts inference the gain\nfrom pre-training? Tables 2 and 3 show that\npre-training consistently improves for low and\nmedium resource language pairs. To verify this\ntrend, we plot performance for differing sized sub-\nsets of the En-De dataset. More precisely, we take\nthe full En-De corpus ( 28M pairs) and randomly\nsample 10K, 50K, 100K, 500K, 1M, 5M, 10M\ndatasets. We compare performance without pre-\ntraining to the mBART02 results, as shown in Fig-\nure 4. The pre-trained model is able to achieve\nover 20 BLEU with only 10K training examples,\nwhile the baseline system scores 0. Unsurpris-\ningly, increasing the size of bi-text corpus im-\nproves both models.",
        "b269883b-4761-4009-b399-24b72e80790c": "Our pre-trained model con-\nsistently outperforms the baseline models, but the\ngap reduces with increasing amounts of bi-text, es-\npecially after 10M sentence pairs. This result con-\n\ufb01rms our observation in \u00a73.2 that our pre-training\ndoes not help translation in high-resource pairs.\nIs pre-training complementary to BT? Fig-\nure 2 presents that our pre-trained models can\nbe combined with iterative back-translation (BT)\non additional data, however, it is still not a fair\ncomparison. Table 6 shows the results when using\n0 100 200 300 400 500\npretraining steps (K)3435363738Finetuning BLEU\nmBART25\nmBART02\nRandomFigure 3: Fine-tuning curves for Ro-En along with\nPre-training steps . Both mBART25 and mBART02\noutperform the best baseline system after 25K steps.\n104105106107\nBi-text Size (# of sentence pairs)051015202530Finetuning BLEU\n0.04.49.214.722.426.527.430.9\n20.724.224.926.9 27.229.130.231.3\nRandom\nmBART02\nFigure 4: Fine-tuning curves for En-De along with\nsize of bitext. The x-axis is on a log scale.\nsame monolingual data where we use 79M En and\n29M My sentences following Chen et al. (2019).\nWith the same amount of monolingual corpus,\nmBART pre-training achieves the same perfor-\nmance on En\u2192My as BT, while still 3BLEU\nworse on My\u2192En. We suspect BT bene\ufb01ts from\nbigger monolingual data (En). Moreover, combin-\ning mBART02 model with BT, we see further\ngains even with same monolingual data. Besides,\nwe also provide estimated training costs where BT\nhas a longer pipeline involving training a baseline\nsystem (5h), translating monolingual data (300h)\nand formal training (350h).",
        "29370a68-265d-4090-8014-b3c989190c12": "Instead, most of train-\ning costs of mBART lies in the pre-training part\nand can be easily adjusted to be more ef\ufb01cient.\n3.4 Generalization to Languages NOT in\nPre-training\nIn this section, we show that mBART can im-\nprove performance even with \ufb01ne tuning for lan-\nguages that did not appear in the pre-training cor-\npora, suggesting that the pre-training has language\nuniversal aspects, especially within the parameters\nlearned at the Transformer layers.",
        "315471c9-4e32-4823-a5bd-978ef710f82c": "Languages De Ro It My En\nSize/GB 66.6 61.4 30.2 1.6 300.8\nmBART02 31.3 38.5 39.7 36.5\nmBART06 - 38.5 39.3 -\nmBART25 30.5 37.7 39.8 36.9\nTable 5: Pretraining Languages on En-X translation.",
        "459efc1c-bc8e-4bf3-a493-7b98644e9bcc": "The size refers to the size of monolingual data for X.\nThe size of En is shown as reference. All the pretrained\nmodels were controlled to see the same number of En-\nglish instances during training.\nModelsEn-My Training Cost\n\u2190 \u2192 GPU hours\nRandom (2019) 23.3 34.9 5\n+ BT 32.0 37.7 5 + 300 + 350\nmBART02 29.",
        "f699a84d-4d6a-43c6-9658-d7c528597797": "7 5 + 300 + 350\nmBART02 29.1 37.8 300\u223c3000 + 40\n+ BT 34.9 39.2 -\nTable 6: Comparison with Back-Translation on My-En\ntranslation using same mono-lingual data. We also esti-\nmate the computational costs for both pre-training and\nback-translation based on Nvidia V100 GPUs.",
        "b3850b77-2a76-4afc-84cd-97b8271a3581": "slightly worse than mBART02.\nHow does the size of bitexts inference the gain\nfrom pre-training? Tables 2 and 3 show that\npre-training consistently improves for low and\nmedium resource language pairs. To verify this\ntrend, we plot performance for differing sized sub-\nsets of the En-De dataset.",
        "76fde090-43ec-4dc9-98c4-c6738c3c09ed": "More precisely, we take\nthe full En-De corpus ( 28M pairs) and randomly\nsample 10K, 50K, 100K, 500K, 1M, 5M, 10M\ndatasets. We compare performance without pre-\ntraining to the mBART02 results, as shown in Fig-\nure 4.",
        "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98": "The pre-trained model is able to achieve\nover 20 BLEU with only 10K training examples,\nwhile the baseline system scores 0. Unsurpris-\ningly, increasing the size of bi-text corpus im-\nproves both models.",
        "d6d98e26-1b03-426c-b9d3-265988b7d534": "Our pre-trained model con-\nsistently outperforms the baseline models, but the\ngap reduces with increasing amounts of bi-text, es-\npecially after 10M sentence pairs. This result con-\n\ufb01rms our observation in \u00a73.2 that our pre-training\ndoes not help translation in high-resource pairs.\nIs pre-training complementary to BT?",
        "14591a5c-68b6-471b-94d3-3c1d835fd73d": "Is pre-training complementary to BT? Fig-\nure 2 presents that our pre-trained models can\nbe combined with iterative back-translation (BT)\non additional data, however, it is still not a fair\ncomparison.",
        "26863519-3ca9-44a4-b4aa-e68af3be5a7a": "Table 6 shows the results when using\n0 100 200 300 400 500\npretraining steps (K)3435363738Finetuning BLEU\nmBART25\nmBART02\nRandomFigure 3: Fine-tuning curves for Ro-En along with\nPre-training steps . Both mBART25 and mBART02\noutperform the best baseline system after 25K steps.",
        "9e249fba-0770-41d1-95f7-d97d5b64945d": "104105106107\nBi-text Size (# of sentence pairs)051015202530Finetuning BLEU\n0.04.49.214.722.426.527.430.9\n20.724.224.926.9 27.229.130.231.3\nRandom\nmBART02\nFigure 4: Fine-tuning curves for En-De along with\nsize of bitext. The x-axis is on a log scale.",
        "7b71e183-6d43-4aa6-8c35-a71635ffe38e": "The x-axis is on a log scale.\nsame monolingual data where we use 79M En and\n29M My sentences following Chen et al. (2019).\nWith the same amount of monolingual corpus,\nmBART pre-training achieves the same perfor-\nmance on En\u2192My as BT, while still 3BLEU\nworse on My\u2192En. We suspect BT bene\ufb01ts from\nbigger monolingual data (En).",
        "25530425-2315-42cf-8c01-0f22e924e79b": "We suspect BT bene\ufb01ts from\nbigger monolingual data (En). Moreover, combin-\ning mBART02 model with BT, we see further\ngains even with same monolingual data. Besides,\nwe also provide estimated training costs where BT\nhas a longer pipeline involving training a baseline\nsystem (5h), translating monolingual data (300h)\nand formal training (350h).",
        "ce006e9f-386f-41ca-93dd-037bf3cb2122": "Instead, most of train-\ning costs of mBART lies in the pre-training part\nand can be easily adjusted to be more ef\ufb01cient.",
        "d9d4a246-4091-42c2-ad28-7d68117a6644": "3.4 Generalization to Languages NOT in\nPre-training\nIn this section, we show that mBART can im-\nprove performance even with \ufb01ne tuning for lan-\nguages that did not appear in the pre-training cor-\npora, suggesting that the pre-training has language\nuniversal aspects, especially within the parameters\nlearned at the Transformer layers.",
        "5a056a36-8d46-4c2d-82a5-a496f87d2da2": "Monolingual Nl-En En-Nl Ar-En En-Ar Nl-De De-Nl\nRandom None 34.6 (-8.7) 29.3 (-5.5) 27.5 (-10.1) 16.9 (-4.7) 21.3 (-6.4) 20.9 (-5.2)\nmBART02 En Ro 41.4 (-2.9) 34.5 (-0.3) 34.9 (-2.7) 21.2 (-0.4) 26.1 (-1.6) 25.4 (-0.7)\nmBART06 En Ro Cs It Fr Es 43.1 (-0.2) 34.6 (-0.2) 37.3 (-0.3) 21.1 (-0.5) 26.4 (-1.3) 25.3 (-0.8)\nmBART25 All 43.3 34.8 37.6 21.6 27.7 26.1\nTable 7: Generalization to Unseen Languages Language transfer results, \ufb01ne-tuning on language-pairs without\npre-training on them. mBART25 uses all languages during pre-training, while other settings contain at least one\nunseen language pair. For each model, we also show the gap to mBART25 results.\nExperimental Settings We analyze the results\nof three pairs: Nl-En, Ar-En and De-Nl using the\npre-trained mBART25, mBART06 and mBART02\n(EnRo) models. During pre-training, mBART06\nand EnRo Bilingual do not contain Arabic (Ar),\nGerman (De) or Dutch (Nl) data, but all languages\nare in mBART25. Both De and Nl are European\nlanguages and are related to En, Ro and other the\nlanguages in mBART06 pre-training data.\nResults mBART25 uses all languages during\npre-training, but other settings contain at least one\nunseen language. We \ufb01nd large gains from pre-\ntraining on English-Romanian, even when trans-\nlating a distantly related unseen language (Arabic)\nand two unseen languages (German and Dutch).\nThe best results are achieved when pre-training in-\ncludes both test languages, however pre-training\non other languages is surprisingly competitive.\nUnseen Vocabularies Arabic is distantly related\nto the languages in mBART02 and mBART06, and\nits use of a disjoint character set means that it word\nembeddings will be largely untrained. However,\nwe obtain similar improvements on Ar-En pairs to\nthose on Nl-En. This result suggests that the pre-\ntrained Transformer layers learn universal prop-\nerties of language that generalize well even with\nminimal lexical overlap.\nUnseen Source or Target Languages Table 7\nshows different performance when the unseen lan-\nguages are on the source side, target side, or both\nsides. If both sides are unseen, the performance\n(in terms of difference from mBART25) is worse\nthan where at least one language is seen dur-\ning pre-training. Furthermore, although the En-X\npairs perform similarly, mBART06 outperforms\nmBART02 by a margin on X-En pairs. Fine-tuning\nunseen languages on source side is more dif\ufb01cult,\ndeserving more extensive future study.Datasets # Docs # Insts # Sents\nWMT19 En-De 77K 171K 3.7M\nTED15 Zh-En 1.7K 6.5K 0.2M\nTable 8: Statistics for the Document-level Corpus of\nWMT19 En-De and TED15 Zh-En. # of instances is\nthe # of training examples in document model.\n4 Document-level Machine Translation\nWe evaluate mBART on document-level machine\ntranslation tasks, where the goal is to translate seg-\nments of text that contain more than one sentence\n(up to an entire document). During pre-training,\nwe use document fragments of up to 512 tokens,\nallowing the models to learn dependencies be-\ntween sentences. We show that this pre-training\nsigni\ufb01cantly improves document-level translation.\n4.1 Experimental Settings\nDatasets We evaluate performance on two com-\nmon document-level MT datasets: WMT19 En-De\nand TED15 Zh-En (statistics in Table 8). For En-\nDe, we use the document data from WMT19 to\ntrain our model, without any additional sentence-\nlevel data; Zh-En dataset is from the IWSLT 2014\nand 2015 evaluation campaigns (Cettolo et al.,\n2012, 2015). Following Miculicich et al. (2018),\nwe use 2010-2013 TED as the test set.\nPre-processing We use the same pre-processing\nas that in pre-training. For each block, sentences\nare separated by end of sentence symbols (</S>)\nand the entire instance is ended with the speci\ufb01c\nlanguage id (<LID>). The numbers of segmented\ninstances are also shown in Table 8 where on av-\nerage, every document is split into 2-4 instances.\nFine-tuning & Decoding We use the same \ufb01ne-\ntuning scheme as for sentence-level translation\n(\u00a73.1), without using any task-speci\ufb01c techniques\ndeveloped by previous work (Miculicich et al.,",
        "605bdd85-aa56-4408-aebe-2733f9324422": "Monolingual Nl-En En-Nl Ar-En En-Ar Nl-De De-Nl\nRandom None 34.6 (-8.7) 29.3 (-5.5) 27.5 (-10.1) 16.9 (-4.7) 21.3 (-6.4) 20.9 (-5.2)\nmBART02 En Ro 41.4 (-2.9) 34.5 (-0.3) 34.9 (-2.7) 21.2 (-0.4) 26.1 (-1.6) 25.4 (-0.7)\nmBART06 En Ro Cs It Fr Es 43.1 (-0.2) 34.6 (-0.2) 37.3 (-0.3) 21.1 (-0.5) 26.4 (-1.3) 25.3 (-0.8)\nmBART25 All 43.3 34.8 37.6 21.6 27.7 26.1\nTable 7: Generalization to Unseen Languages Language transfer results, \ufb01ne-tuning on language-pairs without\npre-training on them. mBART25 uses all languages during pre-training, while other settings contain at least one\nunseen language pair. For each model, we also show the gap to mBART25 results.\nExperimental Settings We analyze the results\nof three pairs: Nl-En, Ar-En and De-Nl using the\npre-trained mBART25, mBART06 and mBART02\n(EnRo) models. During pre-training, mBART06\nand EnRo Bilingual do not contain Arabic (Ar),\nGerman (De) or Dutch (Nl) data, but all languages\nare in mBART25. Both De and Nl are European\nlanguages and are related to En, Ro and other the\nlanguages in mBART06 pre-training data.\nResults mBART25 uses all languages during\npre-training, but other settings contain at least one\nunseen language.",
        "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3": "We \ufb01nd large gains from pre-\ntraining on English-Romanian, even when trans-\nlating a distantly related unseen language (Arabic)\nand two unseen languages (German and Dutch).\nThe best results are achieved when pre-training in-\ncludes both test languages, however pre-training\non other languages is surprisingly competitive.\nUnseen Vocabularies Arabic is distantly related\nto the languages in mBART02 and mBART06, and\nits use of a disjoint character set means that it word\nembeddings will be largely untrained. However,\nwe obtain similar improvements on Ar-En pairs to\nthose on Nl-En. This result suggests that the pre-\ntrained Transformer layers learn universal prop-\nerties of language that generalize well even with\nminimal lexical overlap.\nUnseen Source or Target Languages Table 7\nshows different performance when the unseen lan-\nguages are on the source side, target side, or both\nsides. If both sides are unseen, the performance\n(in terms of difference from mBART25) is worse\nthan where at least one language is seen dur-\ning pre-training. Furthermore, although the En-X\npairs perform similarly, mBART06 outperforms\nmBART02 by a margin on X-En pairs. Fine-tuning\nunseen languages on source side is more dif\ufb01cult,\ndeserving more extensive future study.Datasets # Docs # Insts # Sents\nWMT19 En-De 77K 171K 3.7M\nTED15 Zh-En 1.7K 6.5K 0.2M\nTable 8: Statistics for the Document-level Corpus of\nWMT19 En-De and TED15 Zh-En. # of instances is\nthe # of training examples in document model.\n4 Document-level Machine Translation\nWe evaluate mBART on document-level machine\ntranslation tasks, where the goal is to translate seg-\nments of text that contain more than one sentence\n(up to an entire document). During pre-training,\nwe use document fragments of up to 512 tokens,\nallowing the models to learn dependencies be-\ntween sentences. We show that this pre-training\nsigni\ufb01cantly improves document-level translation.",
        "35c49909-93eb-4800-95a1-42885e625575": "We show that this pre-training\nsigni\ufb01cantly improves document-level translation.\n4.1 Experimental Settings\nDatasets We evaluate performance on two com-\nmon document-level MT datasets: WMT19 En-De\nand TED15 Zh-En (statistics in Table 8). For En-\nDe, we use the document data from WMT19 to\ntrain our model, without any additional sentence-\nlevel data; Zh-En dataset is from the IWSLT 2014\nand 2015 evaluation campaigns (Cettolo et al.,\n2012, 2015). Following Miculicich et al. (2018),\nwe use 2010-2013 TED as the test set.\nPre-processing We use the same pre-processing\nas that in pre-training. For each block, sentences\nare separated by end of sentence symbols (</S>)\nand the entire instance is ended with the speci\ufb01c\nlanguage id (<LID>). The numbers of segmented\ninstances are also shown in Table 8 where on av-\nerage, every document is split into 2-4 instances.\nFine-tuning & Decoding We use the same \ufb01ne-\ntuning scheme as for sentence-level translation\n(\u00a73.1), without using any task-speci\ufb01c techniques\ndeveloped by previous work (Miculicich et al.,",
        "7ff2cbe3-765f-4340-a882-114b743e38e5": "Monolingual Nl-En En-Nl Ar-En En-Ar Nl-De De-Nl\nRandom None 34.6 (-8.7) 29.3 (-5.5) 27.5 (-10.1) 16.9 (-4.7) 21.3 (-6.4) 20.9 (-5.2)\nmBART02 En Ro 41.4 (-2.9) 34.",
        "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4": "2)\nmBART02 En Ro 41.4 (-2.9) 34.5 (-0.3) 34.9 (-2.7) 21.2 (-0.4) 26.1 (-1.6) 25.4 (-0.7)\nmBART06 En Ro Cs It Fr Es 43.1 (-0.2) 34.6 (-0.2) 37.3 (-0.",
        "73742d1b-b8a6-4294-ab4a-d4b528675576": "2) 34.6 (-0.2) 37.3 (-0.3) 21.1 (-0.5) 26.4 (-1.3) 25.3 (-0.8)\nmBART25 All 43.3 34.8 37.6 21.6 27.7 26.1\nTable 7: Generalization to Unseen Languages Language transfer results,",
        "9497da6f-772f-4249-9c89-7d2c4bb08977": "7 26.1\nTable 7: Generalization to Unseen Languages Language transfer results, \ufb01ne-tuning on language-pairs without\npre-training on them. mBART25 uses all languages during pre-training, while other settings contain at least one\nunseen language pair. For each model, we also show the gap to mBART25 results.",
        "3f64143a-3245-423b-a626-e94005fc3ef0": "For each model, we also show the gap to mBART25 results.\nExperimental Settings We analyze the results\nof three pairs: Nl-En, Ar-En and De-Nl using the\npre-trained mBART25, mBART06 and mBART02\n(EnRo) models.",
        "f457f437-5780-4380-9834-4d04bbe9242b": "During pre-training, mBART06\nand EnRo Bilingual do not contain Arabic (Ar),\nGerman (De) or Dutch (Nl) data, but all languages\nare in mBART25. Both De and Nl are European\nlanguages and are related to En, Ro and other the\nlanguages in mBART06 pre-training data.\nResults mBART25 uses all languages during\npre-training, but other settings contain at least one\nunseen language.",
        "ada7a6ce-8f09-4a8a-ab3c-c0d0aa3d6cba": "We \ufb01nd large gains from pre-\ntraining on English-Romanian, even when trans-\nlating a distantly related unseen language (Arabic)\nand two unseen languages (German and Dutch).\nThe best results are achieved when pre-training in-\ncludes both test languages, however pre-training\non other languages is surprisingly competitive.",
        "a5466468-1762-4e22-a233-cbd82d7eb77d": "Unseen Vocabularies Arabic is distantly related\nto the languages in mBART02 and mBART06, and\nits use of a disjoint character set means that it word\nembeddings will be largely untrained. However,\nwe obtain similar improvements on Ar-En pairs to\nthose on Nl-En. This result suggests that the pre-\ntrained Transformer layers learn universal prop-\nerties of language that generalize well even with\nminimal lexical overlap.",
        "1a7fb1be-bd49-4b0d-ad9c-86beed902bcd": "Unseen Source or Target Languages Table 7\nshows different performance when the unseen lan-\nguages are on the source side, target side, or both\nsides. If both sides are unseen, the performance\n(in terms of difference from mBART25) is worse\nthan where at least one language is seen dur-\ning pre-training.",
        "c9211a67-866e-490d-8e0d-8d51ab4241a6": "Furthermore, although the En-X\npairs perform similarly, mBART06 outperforms\nmBART02 by a margin on X-En pairs.",
        "460c0b61-1c48-4b45-b2f9-0ffb19161952": "Fine-tuning\nunseen languages on source side is more dif\ufb01cult,\ndeserving more extensive future study.Datasets # Docs # Insts # Sents\nWMT19 En-De 77K 171K 3.7M\nTED15 Zh-En 1.7K 6.5K 0.2M\nTable 8: Statistics for the Document-level Corpus of\nWMT19 En-De and TED15 Zh-En.",
        "ed6ec4f2-f7de-40cf-a92a-1249badb0dd2": "# of instances is\nthe # of training examples in document model.\n4 Document-level Machine Translation\nWe evaluate mBART on document-level machine\ntranslation tasks, where the goal is to translate seg-\nments of text that contain more than one sentence\n(up to an entire document). During pre-training,\nwe use document fragments of up to 512 tokens,\nallowing the models to learn dependencies be-\ntween sentences.",
        "731114e7-d6ff-43a1-b64c-f1f0547e411b": "We show that this pre-training\nsigni\ufb01cantly improves document-level translation.",
        "1c3dd3c5-5f5d-4d9c-8dee-724cb8f586f2": "We show that this pre-training\nsigni\ufb01cantly improves document-level translation.\n4.1 Experimental Settings\nDatasets We evaluate performance on two com-\nmon document-level MT datasets: WMT19 En-De\nand TED15 Zh-En (statistics in Table 8).",
        "e0d214e7-c05c-4452-80ff-79382eece746": "For En-\nDe, we use the document data from WMT19 to\ntrain our model, without any additional sentence-\nlevel data; Zh-En dataset is from the IWSLT 2014\nand 2015 evaluation campaigns (Cettolo et al.,\n2012, 2015). Following Miculicich et al. (2018),\nwe use 2010-2013 TED as the test set.",
        "6ceb7709-fc92-4c21-b126-15f5e622c83b": "(2018),\nwe use 2010-2013 TED as the test set.\nPre-processing We use the same pre-processing\nas that in pre-training. For each block, sentences\nare separated by end of sentence symbols (</S>)\nand the entire instance is ended with the speci\ufb01c\nlanguage id (<LID>).",
        "5c3c5e4c-ccb8-4915-af80-adc7a667daf4": "The numbers of segmented\ninstances are also shown in Table 8 where on av-\nerage, every document is split into 2-4 instances.\nFine-tuning & Decoding We use the same \ufb01ne-\ntuning scheme as for sentence-level translation\n(\u00a73.1), without using any task-speci\ufb01c techniques\ndeveloped by previous work (Miculicich et al.,",
        "54901690-7e9f-4112-9582-bebb286bc44d": "(a) Sentence- and Document-level BLEU scores on En-De\nModelRandom mBART25\ns-BLEU d-BLEU s-BLEU d-BLEU\nSent-MT 34.5 35.9 36.4 38.0\nDoc-MT\u00d7 7.7 37.1 38.5(b) Document-level BLEU scores on Zh-En\nModelRandom mBART25 HAN (2018)\nd-BLEU d-BLEU d-BLEU\nSent-MT 22.0 28.4 -\nDoc-MT 3.2 29.6 24.0\nTable 9: Document-Level Machine Translation on En-De and Zh-En. ( \u00d7) The randomly initialized Doc-MT\nmodel cannot produce translations aligned to the original sentences, so only document evaluation is possible.\n2018; Li et al., 2019), such as constrained con-\ntexts or restricted attention. For decoding, we sim-\nply pack the source sentences into blocks, and\ntranslate each instance block autoregressively. The\nmodel does not know how many sentences to gen-\nerate in advance and decoding stops when <LID>\nis predicted. We use beam size 5 by default.\nBaselines & Evaluation We train 4 models: a\ndocument-level (Doc-) MT model (\u00a74.1) and a\ncorresponded sentence-level (Sent-) MT model\n(\u00a73.1) as the baseline, both with and without pre-\ntraining. We use mBART25 as the common pre-\ntrained model for En-De and Zh-En. For En-De,\neven though our mBART25 Doc-MT model de-\ncodes multiple sentences together, the translated\nsentences can be aligned to the source sentences,\nwhich allows us to evaluate BLEU scores both on\nsentence-level (s-BLEU) and document-level (d-\nBLEU)2. For Zh-En, however, we cannot produce\nthe same number of translated sentences as the ref-\nerence due to alignment errors in the test data. We\nonly provide the d-BLEU scores on this direction.\nWe also compare our models with Hierarchi-\ncal Attention Networks (HAN, Miculicich et al.,\n2018) on Zh-En, which is the state-of-the-art non-\npretraining approach for document-level transla-\ntion for this pair. They combine two layers of at-\ntention \u2013 \ufb01rst within and then across sentences.\n4.2 Main Results\nWe show the main results for both En-De and Zh-\nEn are presented in Table 9.\nRandom v.s. Pre-trained The MT models ini-\ntialized with pre-trained weights outperform ran-\ndomly initialized models by large margins, for\nboth sentence-level and document-level training.\nOur mBART25 models (both Sent-MT and Doc-\nMT) also outperform HAN (Miculicich et al.,\n2Standard BLEU scores match n-grams at sentence-level.\nWe also consider document-level where we match n-grams\nover the whole document resulting in a slightly higher score.2018)3, despite the fact that they are not cus-\ntomized for document-level MT in any way.\nSent-MT v.s. Doc-MT For cases (En-De, En-\nZh), the mBART25 Doc-MT models outperform\nthemselves \ufb01ne-tuned at sentence-level by a mar-\ngin, which is completely opposite for models with-\nout pre-training. For both datasets, randomly ini-\ntialized Doc-MT fail to work, resulting in much\nworse results than the sentence-level models. Such\nlarge performance gaps indicate that pre-training\niscritical for document level performance. It is in\ngeneral dif\ufb01cult to collect high quality document-\nlevel data in large quantities, suggesting that pre-\ntraining may be a strong strategy for future work.\nWe also include a sampled example in appendix B.\n5 Unsupervised Machine Translation\nIn addition to supervised machine translation, we\nalso evaluate our model on tasks where no bi-text\nis available for the target language pair. We de\ufb01ne\nthree types of unsupervised translation:\n1. No bi-text of any kind is given. A common so-\nlution is to learn from back-translation (BT)\n(Artetxe et al., 2017; Lample et al., 2018c). We\nshow that mBART provides a simple and effec-\ntive initialize scheme for these methods.\n2. No bi-text for the target pair is available, but\nthe target languages both appear in bi-text cor-\npora for other language pairs. Previous work\nhas shown that zero-shot transfer is possible via\nmassively multi-lingual MT (Johnson et al.,\n2017; Gu et al., 2019) or distillation through\npivoting (Chen et al., 2017). We limit our fo-\ncus to building MT models for single language\npairs, and leave multi-lingual pre-training for\nmulti-lingual MT to future work.\n3. No bi-text for the target pair is available, but\nthere is bi-text for translating from some other\n3d-BLEU is recomputed from the provided system output.",
        "43f1b3b9-3661-456a-81fc-fd9728a19e53": "(a) Sentence- and Document-level BLEU scores on En-De\nModelRandom mBART25\ns-BLEU d-BLEU s-BLEU d-BLEU\nSent-MT 34.5 35.9 36.4 38.0\nDoc-MT\u00d7 7.7 37.1 38.5(b) Document-level BLEU scores on Zh-En\nModelRandom mBART25 HAN (2018)\nd-BLEU d-BLEU d-BLEU\nSent-MT 22.0 28.4 -\nDoc-MT 3.2 29.6 24.0\nTable 9: Document-Level Machine Translation on En-De and Zh-En. ( \u00d7) The randomly initialized Doc-MT\nmodel cannot produce translations aligned to the original sentences, so only document evaluation is possible.\n2018; Li et al., 2019), such as constrained con-\ntexts or restricted attention. For decoding, we sim-\nply pack the source sentences into blocks, and\ntranslate each instance block autoregressively. The\nmodel does not know how many sentences to gen-\nerate in advance and decoding stops when <LID>\nis predicted. We use beam size 5 by default.\nBaselines & Evaluation We train 4 models: a\ndocument-level (Doc-) MT model (\u00a74.1) and a\ncorresponded sentence-level (Sent-) MT model\n(\u00a73.1) as the baseline, both with and without pre-\ntraining. We use mBART25 as the common pre-\ntrained model for En-De and Zh-En. For En-De,\neven though our mBART25 Doc-MT model de-\ncodes multiple sentences together, the translated\nsentences can be aligned to the source sentences,\nwhich allows us to evaluate BLEU scores both on\nsentence-level (s-BLEU) and document-level (d-\nBLEU)2. For Zh-En, however, we cannot produce\nthe same number of translated sentences as the ref-\nerence due to alignment errors in the test data. We\nonly provide the d-BLEU scores on this direction.",
        "877425de-0e10-4378-9488-d4df19756fe1": "We\nonly provide the d-BLEU scores on this direction.\nWe also compare our models with Hierarchi-\ncal Attention Networks (HAN, Miculicich et al.,\n2018) on Zh-En, which is the state-of-the-art non-\npretraining approach for document-level transla-\ntion for this pair. They combine two layers of at-\ntention \u2013 \ufb01rst within and then across sentences.\n4.2 Main Results\nWe show the main results for both En-De and Zh-\nEn are presented in Table 9.\nRandom v.s. Pre-trained The MT models ini-\ntialized with pre-trained weights outperform ran-\ndomly initialized models by large margins, for\nboth sentence-level and document-level training.\nOur mBART25 models (both Sent-MT and Doc-\nMT) also outperform HAN (Miculicich et al.,\n2Standard BLEU scores match n-grams at sentence-level.\nWe also consider document-level where we match n-grams\nover the whole document resulting in a slightly higher score.2018)3, despite the fact that they are not cus-\ntomized for document-level MT in any way.\nSent-MT v.s. Doc-MT For cases (En-De, En-\nZh), the mBART25 Doc-MT models outperform\nthemselves \ufb01ne-tuned at sentence-level by a mar-\ngin, which is completely opposite for models with-\nout pre-training. For both datasets, randomly ini-\ntialized Doc-MT fail to work, resulting in much\nworse results than the sentence-level models. Such\nlarge performance gaps indicate that pre-training\niscritical for document level performance. It is in\ngeneral dif\ufb01cult to collect high quality document-\nlevel data in large quantities, suggesting that pre-\ntraining may be a strong strategy for future work.\nWe also include a sampled example in appendix B.\n5 Unsupervised Machine Translation\nIn addition to supervised machine translation, we\nalso evaluate our model on tasks where no bi-text\nis available for the target language pair. We de\ufb01ne\nthree types of unsupervised translation:\n1. No bi-text of any kind is given.",
        "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5": "No bi-text of any kind is given. A common so-\nlution is to learn from back-translation (BT)\n(Artetxe et al., 2017; Lample et al., 2018c). We\nshow that mBART provides a simple and effec-\ntive initialize scheme for these methods.\n2. No bi-text for the target pair is available, but\nthe target languages both appear in bi-text cor-\npora for other language pairs. Previous work\nhas shown that zero-shot transfer is possible via\nmassively multi-lingual MT (Johnson et al.,\n2017; Gu et al., 2019) or distillation through\npivoting (Chen et al., 2017). We limit our fo-\ncus to building MT models for single language\npairs, and leave multi-lingual pre-training for\nmulti-lingual MT to future work.\n3. No bi-text for the target pair is available, but\nthere is bi-text for translating from some other\n3d-BLEU is recomputed from the provided system output.",
        "48249f21-c82b-4151-a1f3-24778c309a3b": "(a) Sentence- and Document-level BLEU scores on En-De\nModelRandom mBART25\ns-BLEU d-BLEU s-BLEU d-BLEU\nSent-MT 34.5 35.9 36.4 38.0\nDoc-MT\u00d7 7.7 37.1 38.",
        "0842dfc8-98cc-4063-ae45-903d4237329a": "0\nDoc-MT\u00d7 7.7 37.1 38.5(b) Document-level BLEU scores on Zh-En\nModelRandom mBART25 HAN (2018)\nd-BLEU d-BLEU d-BLEU\nSent-MT 22.0 28.4 -\nDoc-MT 3.2 29.6 24.0\nTable 9: Document-Level Machine Translation on En-De and Zh-En.",
        "a3ba1560-813e-4666-8321-e5f07b0aa551": "0\nTable 9: Document-Level Machine Translation on En-De and Zh-En. ( \u00d7) The randomly initialized Doc-MT\nmodel cannot produce translations aligned to the original sentences, so only document evaluation is possible.\n2018; Li et al., 2019), such as constrained con-\ntexts or restricted attention. For decoding, we sim-\nply pack the source sentences into blocks, and\ntranslate each instance block autoregressively.",
        "080e7fa7-7959-4061-9955-8f27948863a9": "The\nmodel does not know how many sentences to gen-\nerate in advance and decoding stops when <LID>\nis predicted. We use beam size 5 by default.\nBaselines & Evaluation We train 4 models: a\ndocument-level (Doc-) MT model (\u00a74.1) and a\ncorresponded sentence-level (Sent-) MT model\n(\u00a73.1) as the baseline, both with and without pre-\ntraining.",
        "8429c806-222c-4bd2-b6dc-0e46b00cdd3b": "We use mBART25 as the common pre-\ntrained model for En-De and Zh-En. For En-De,\neven though our mBART25 Doc-MT model de-\ncodes multiple sentences together, the translated\nsentences can be aligned to the source sentences,\nwhich allows us to evaluate BLEU scores both on\nsentence-level (s-BLEU) and document-level (d-\nBLEU)2.",
        "ba5b35f6-e3c5-4d08-aefa-711db9dd8ef9": "For Zh-En, however, we cannot produce\nthe same number of translated sentences as the ref-\nerence due to alignment errors in the test data. We\nonly provide the d-BLEU scores on this direction.",
        "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd": "We\nonly provide the d-BLEU scores on this direction.\nWe also compare our models with Hierarchi-\ncal Attention Networks (HAN, Miculicich et al.,\n2018) on Zh-En, which is the state-of-the-art non-\npretraining approach for document-level transla-\ntion for this pair. They combine two layers of at-\ntention \u2013 \ufb01rst within and then across sentences.",
        "59bcb2c1-bdb2-4631-9e28-f5fc9610e9b6": "They combine two layers of at-\ntention \u2013 \ufb01rst within and then across sentences.\n4.2 Main Results\nWe show the main results for both En-De and Zh-\nEn are presented in Table 9.\nRandom v.s. Pre-trained The MT models ini-\ntialized with pre-trained weights outperform ran-\ndomly initialized models by large margins, for\nboth sentence-level and document-level training.",
        "229c72e8-adee-40b1-a1c9-d4270155a1ad": "Our mBART25 models (both Sent-MT and Doc-\nMT) also outperform HAN (Miculicich et al.,\n2Standard BLEU scores match n-grams at sentence-level.\nWe also consider document-level where we match n-grams\nover the whole document resulting in a slightly higher score.2018)3, despite the fact that they are not cus-\ntomized for document-level MT in any way.\nSent-MT v.s.",
        "e0fc2709-1cf5-4b4f-8497-4d68b11ae008": "Sent-MT v.s. Doc-MT For cases (En-De, En-\nZh), the mBART25 Doc-MT models outperform\nthemselves \ufb01ne-tuned at sentence-level by a mar-\ngin, which is completely opposite for models with-\nout pre-training. For both datasets, randomly ini-\ntialized Doc-MT fail to work, resulting in much\nworse results than the sentence-level models.",
        "edb6ee27-4900-409c-82c0-b6ad447712c6": "Such\nlarge performance gaps indicate that pre-training\niscritical for document level performance. It is in\ngeneral dif\ufb01cult to collect high quality document-\nlevel data in large quantities, suggesting that pre-\ntraining may be a strong strategy for future work.\nWe also include a sampled example in appendix B.\n5 Unsupervised Machine Translation\nIn addition to supervised machine translation, we\nalso evaluate our model on tasks where no bi-text\nis available for the target language pair.",
        "5d96f0bf-4d4d-4b81-846b-7453a83b7554": "We de\ufb01ne\nthree types of unsupervised translation:\n1. No bi-text of any kind is given.",
        "3cbe1897-367d-47d3-9291-1bedf70366a1": "No bi-text of any kind is given. A common so-\nlution is to learn from back-translation (BT)\n(Artetxe et al., 2017; Lample et al., 2018c). We\nshow that mBART provides a simple and effec-\ntive initialize scheme for these methods.\n2.",
        "ebf0b555-e717-43e5-88fe-96f92de8d76f": "2. No bi-text for the target pair is available, but\nthe target languages both appear in bi-text cor-\npora for other language pairs. Previous work\nhas shown that zero-shot transfer is possible via\nmassively multi-lingual MT (Johnson et al.,\n2017; Gu et al., 2019) or distillation through\npivoting (Chen et al., 2017).",
        "bc4b70f6-1b9c-4340-83c3-03360f5e3d89": "We limit our fo-\ncus to building MT models for single language\npairs, and leave multi-lingual pre-training for\nmulti-lingual MT to future work.\n3. No bi-text for the target pair is available, but\nthere is bi-text for translating from some other\n3d-BLEU is recomputed from the provided system output.",
        "ca277acd-f083-4c2b-931d-e01f804f048a": "mBARTGenerated En TextMonolingual Ne TextmBARTDecodeMLE lossInputInputmBARTGenerated Ne TextMonolingual En TextmBARTDecodeMLE lossInputInputmBARTParallel Hi TextParallel En TextmBARTDecodeMLE lossInputTransfer (no train)Ne TextInputGenerated En Text\n(a)(b)Figure 5: Illustrated frameworks for unsupervised machine translation via (a) back-translation (b) language transfer\nwhere Ne-En is used as an example. For both cases, we initialize from multilingual pre-training (e.g. mBART25).\nlanguage into the target language. This is a new\nevaluation regime, where we will show that\nmBART supports effective transfer, even if the\nsource language has no bi-text of any form.\nIn this section, we demonstrate the effectiveness\nof multilingual pre-training in unsupervised ma-\nchine translation via (1) back-translation ( \u00a75.1)\nand (3) language transfer (\u00a75.2). An illustration of\nboth approaches are presented in Figure 5.\n5.1 Unsupervised Machine Translation via\nBack-Translation\nDatasets We evaluate our pre-trained models on\nboth similar (En-De, En-Ro) and dissimilar pairs\n(En-Ne, En-Si), which are determined by measur-\ning the subword units that are shared between the\nsource and target languages. We use the same test\nsets as the supervised benchmarks \u00a73.1, and di-\nrectly use the pre-training data (CC25) for back-\ntranslation to avoid introducing new information.\nLearning Following the same procedure de-\nscribed in Lample et al. (2018c); Lample and\nConneau (2019), we \ufb01rst initialize the transla-\ntion model with the pre-trained weights, and then\nlearn to predict the monolingual sentences condi-\ntioned on source sentences generated by on-the-\n\ufb02y back-translation (BT). Lample and Conneau\n(2019) only pre-train an encoder, so perform addi-\ntional de-noising training to learn a seq2seq model\n\u2013 a step which is unnecessary for mBART\u2019s pre-\ntrained seq2seq model. However, we do constrain\nmBART to only generating tokens in target lan-\nguage4for the \ufb01rst 1000 steps of on-the-\ufb02y BT, to\navoid it simply copying the source text.\nResults Table 10 shows the unsupervised trans-\nlation results compared with non-pretrained mod-\n4We mask out the output probability of predicting tokens\nwhich appear less than 1%in the target monolingual corpus.els, as well as models with existing pre-training\nmethods. Our models achieve large gains over\nnon-pretrained models for all directions, and out-\nperform XLM signi\ufb01cantly for dissimilar pairs\n(En-Ne, En-Si) where the existing approaches\ncompletely fail. For similar pairs, our model also\nperforms well against XLM and MASS, with the\nbest numbers for En-X pairs.\n5.2 Unsupervised Machine Translation via\nLanguage Transfer\nThe second case of unsupervised machine transla-\ntion assumes the target language appears in a bi-\ntext corpus with some other source language.\nDatasets We only consider X \u2192En translation,\nand choose the bitexts of 12 language pairs from\n\u00a73.1, covering Indic languages (Ne, Hi, Si, Gu),\nEuropean languages (Ro, It, Cs, Nl), East Asian\nlanguages (Zh, Ja, Ko) and Arabic languages (Ar).\nResults As illustrated in Figure 5 (b), we take\nthe pre-trained mBART25 model and \ufb01netune on\neach language pair, and then directly apply them\nto the rest of pairs, as seen in Table 11. We also\npresent the direct \ufb01ne-tuning performance (\u00a73) on\nthe diagonal, for reference. We can always ob-\ntain reasonable transferring scores at all pairs over\ndifferent \ufb01ne-tuned models except from Gu-En\nwhere the supervised model completely fails ( 0.3\nBLEU). In some cases, we can achieve similar\n(Cs-En) or even much better (Ne-En, Gu-En) re-\nsults compared to the supervised results.\nAs a comparison, we also apply the same proce-\ndure on randomly initialized models without pre-\ntraining, which always ends up with \u22480BLEU.\nThis indicates that multilingual pre-training is\nessential and produces universal representations\nacross languages, so that once the model learns\nto translate one language to En, it learns to trans-",
        "ecbbc79c-ae02-49d4-ae93-13650c0458bf": "mBARTGenerated En TextMonolingual Ne TextmBARTDecodeMLE lossInputInputmBARTGenerated Ne TextMonolingual En TextmBARTDecodeMLE lossInputInputmBARTParallel Hi TextParallel En TextmBARTDecodeMLE lossInputTransfer (no train)Ne TextInputGenerated En Text\n(a)(b)Figure 5: Illustrated frameworks for unsupervised machine translation via (a) back-translation (b) language transfer\nwhere Ne-En is used as an example. For both cases, we initialize from multilingual pre-training (e.g. mBART25).\nlanguage into the target language. This is a new\nevaluation regime, where we will show that\nmBART supports effective transfer, even if the\nsource language has no bi-text of any form.\nIn this section, we demonstrate the effectiveness\nof multilingual pre-training in unsupervised ma-\nchine translation via (1) back-translation ( \u00a75.1)\nand (3) language transfer (\u00a75.2). An illustration of\nboth approaches are presented in Figure 5.\n5.1 Unsupervised Machine Translation via\nBack-Translation\nDatasets We evaluate our pre-trained models on\nboth similar (En-De, En-Ro) and dissimilar pairs\n(En-Ne, En-Si), which are determined by measur-\ning the subword units that are shared between the\nsource and target languages. We use the same test\nsets as the supervised benchmarks \u00a73.1, and di-\nrectly use the pre-training data (CC25) for back-\ntranslation to avoid introducing new information.\nLearning Following the same procedure de-\nscribed in Lample et al. (2018c); Lample and\nConneau (2019), we \ufb01rst initialize the transla-\ntion model with the pre-trained weights, and then\nlearn to predict the monolingual sentences condi-\ntioned on source sentences generated by on-the-\n\ufb02y back-translation (BT). Lample and Conneau\n(2019) only pre-train an encoder, so perform addi-\ntional de-noising training to learn a seq2seq model\n\u2013 a step which is unnecessary for mBART\u2019s pre-\ntrained seq2seq model.",
        "ee2660c9-d070-4c13-9f4b-c6c371c407d0": "However, we do constrain\nmBART to only generating tokens in target lan-\nguage4for the \ufb01rst 1000 steps of on-the-\ufb02y BT, to\navoid it simply copying the source text.\nResults Table 10 shows the unsupervised trans-\nlation results compared with non-pretrained mod-\n4We mask out the output probability of predicting tokens\nwhich appear less than 1%in the target monolingual corpus.els, as well as models with existing pre-training\nmethods. Our models achieve large gains over\nnon-pretrained models for all directions, and out-\nperform XLM signi\ufb01cantly for dissimilar pairs\n(En-Ne, En-Si) where the existing approaches\ncompletely fail. For similar pairs, our model also\nperforms well against XLM and MASS, with the\nbest numbers for En-X pairs.\n5.2 Unsupervised Machine Translation via\nLanguage Transfer\nThe second case of unsupervised machine transla-\ntion assumes the target language appears in a bi-\ntext corpus with some other source language.\nDatasets We only consider X \u2192En translation,\nand choose the bitexts of 12 language pairs from\n\u00a73.1, covering Indic languages (Ne, Hi, Si, Gu),\nEuropean languages (Ro, It, Cs, Nl), East Asian\nlanguages (Zh, Ja, Ko) and Arabic languages (Ar).\nResults As illustrated in Figure 5 (b), we take\nthe pre-trained mBART25 model and \ufb01netune on\neach language pair, and then directly apply them\nto the rest of pairs, as seen in Table 11. We also\npresent the direct \ufb01ne-tuning performance (\u00a73) on\nthe diagonal, for reference. We can always ob-\ntain reasonable transferring scores at all pairs over\ndifferent \ufb01ne-tuned models except from Gu-En\nwhere the supervised model completely fails ( 0.3\nBLEU). In some cases, we can achieve similar\n(Cs-En) or even much better (Ne-En, Gu-En) re-\nsults compared to the supervised results.",
        "90c185c8-41e2-4642-a8ae-830fa3809fac": "As a comparison, we also apply the same proce-\ndure on randomly initialized models without pre-\ntraining, which always ends up with \u22480BLEU.\nThis indicates that multilingual pre-training is\nessential and produces universal representations\nacross languages, so that once the model learns\nto translate one language to En, it learns to trans-",
        "62811350-736e-4f5f-ba5c-e9b3d767ec7a": "mBARTGenerated En TextMonolingual Ne TextmBARTDecodeMLE lossInputInputmBARTGenerated Ne TextMonolingual En TextmBARTDecodeMLE lossInputInputmBARTParallel Hi TextParallel En TextmBARTDecodeMLE lossInputTransfer (no train)Ne TextInputGenerated En Text\n(a)(b)Figure 5: Illustrated frameworks for unsupervised machine translation via (a) back-translation (b) language transfer\nwhere Ne-En is used",
        "4748cc60-ab41-413a-be1b-fe5abfed0acf": "translation via (a) back-translation (b) language transfer\nwhere Ne-En is used as an example. For both cases, we initialize from multilingual pre-training (e.g. mBART25).\nlanguage into the target language. This is a new\nevaluation regime, where we will show that\nmBART supports effective transfer, even if the\nsource language has no bi-text of any form.",
        "27e84570-b7f7-43f4-86ed-582d09b3e250": "In this section, we demonstrate the effectiveness\nof multilingual pre-training in unsupervised ma-\nchine translation via (1) back-translation ( \u00a75.1)\nand (3) language transfer (\u00a75.2). An illustration of\nboth approaches are presented in Figure 5.",
        "806e94f3-ef63-4ca5-8e9c-256ab0a731f2": "An illustration of\nboth approaches are presented in Figure 5.\n5.1 Unsupervised Machine Translation via\nBack-Translation\nDatasets We evaluate our pre-trained models on\nboth similar (En-De, En-Ro) and dissimilar pairs\n(En-Ne, En-Si), which are determined by measur-\ning the subword units that are shared between the\nsource and target languages.",
        "f245eb97-4360-4adb-a1ad-4d9bfff540c9": "We use the same test\nsets as the supervised benchmarks \u00a73.1, and di-\nrectly use the pre-training data (CC25) for back-\ntranslation to avoid introducing new information.\nLearning Following the same procedure de-\nscribed in Lample et al.",
        "18c65a55-8d90-44b8-88b5-09a500b7a64c": "Learning Following the same procedure de-\nscribed in Lample et al. (2018c); Lample and\nConneau (2019), we \ufb01rst initialize the transla-\ntion model with the pre-trained weights, and then\nlearn to predict the monolingual sentences condi-\ntioned on source sentences generated by on-the-\n\ufb02y back-translation (BT).",
        "6e5046ac-6386-428b-9a41-b2669372fc0f": "Lample and Conneau\n(2019) only pre-train an encoder, so perform addi-\ntional de-noising training to learn a seq2seq model\n\u2013 a step which is unnecessary for mBART\u2019s pre-\ntrained seq2seq model.",
        "0ec49777-138b-472e-909c-ea918d632b5f": "However, we do constrain\nmBART to only generating tokens in target lan-\nguage4for the \ufb01rst 1000 steps of on-the-\ufb02y BT, to\navoid it simply copying the source text.",
        "8daca4a3-d167-49f3-990b-cbd448d96d81": "Results Table 10 shows the unsupervised trans-\nlation results compared with non-pretrained mod-\n4We mask out the output probability of predicting tokens\nwhich appear less than 1%in the target monolingual corpus.els, as well as models with existing pre-training\nmethods.",
        "79dc952e-2935-49ce-93ec-0421ec411ddd": "Our models achieve large gains over\nnon-pretrained models for all directions, and out-\nperform XLM signi\ufb01cantly for dissimilar pairs\n(En-Ne, En-Si) where the existing approaches\ncompletely fail. For similar pairs, our model also\nperforms well against XLM and MASS, with the\nbest numbers for En-X pairs.",
        "e4ac8d47-17f0-4b14-996e-4a19f728fe8b": "5.2 Unsupervised Machine Translation via\nLanguage Transfer\nThe second case of unsupervised machine transla-\ntion assumes the target language appears in a bi-\ntext corpus with some other source language.",
        "391f4c2a-f856-481f-8dcb-ff29ee963881": "Datasets We only consider X \u2192En translation,\nand choose the bitexts of 12 language pairs from\n\u00a73.1, covering Indic languages (Ne, Hi, Si, Gu),\nEuropean languages (Ro, It, Cs, Nl), East Asian\nlanguages (Zh, Ja, Ko) and Arabic languages (Ar).",
        "e3d5006e-0145-4a79-9131-a3028d80af64": "Results As illustrated in Figure 5 (b), we take\nthe pre-trained mBART25 model and \ufb01netune on\neach language pair, and then directly apply them\nto the rest of pairs, as seen in Table 11. We also\npresent the direct \ufb01ne-tuning performance (\u00a73) on\nthe diagonal, for reference.",
        "be78bb13-3e46-4c1d-abef-f131a40cf72f": "We can always ob-\ntain reasonable transferring scores at all pairs over\ndifferent \ufb01ne-tuned models except from Gu-En\nwhere the supervised model completely fails ( 0.3\nBLEU). In some cases, we can achieve similar\n(Cs-En) or even much better (Ne-En, Gu-En) re-\nsults compared to the supervised results.",
        "46062741-82a7-445f-87c1-f08910f7c8fd": "As a comparison, we also apply the same proce-\ndure on randomly initialized models without pre-\ntraining, which always ends up with \u22480BLEU.\nThis indicates that multilingual pre-training is\nessential and produces universal representations\nacross languages, so that once the model learns\nto translate one language to En, it learns to trans-",
        "b7d634c9-4b9c-4a51-aab6-5ff697a05248": "ModelSimilar Pairs Dissimilar Pairs\nEn-De En-Ro En-Ne En-Si\n\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 21.0 17.2 19.4 21.2 0.0 0.0 0.0 0.0\nXLM (2019) 34.3 26.4 31.8 33.3 0.5 0.1 0.1 0.1\nMASS (2019) 35.2 28.3 33.1 35.2 - - - -\nmBART 34.0 29.8 30.5 35.0 10.0 4.4 8.2 3.9\nTable 10: Unsupervised MT via Back-Translation . En-De, En-Ro are initialized by mBART02, while En-Ne,\nEn-Si are initialized by mBART25. Our models are trained on monolingual data used in pre-training.\nFine-tuning Languages\nZh Ja Ko Cs Ro Nl It Ar Hi Ne Si Gu\nDomain News TED TED News News TED TED TED News Wiki Wiki WikiTesting LanguagesZh 23.7 8.8 9.2 2.8 7.8 7.0 6.8 6.2 7.2 4.2 5.9 0.0\nJa 9.9 19.1 12.2 0.9 4.8 6.4 5.1 5.6 4.7 4.2 6.5 0.0\nKo 5.8 16.9 24.6 5.7 8.5 9.5 9.1 8.7 9.6 8.8 11.1 0.0\nCs 9.3 15.1 17.2 21.6 19.5 17.0 16.7 16.9 13.2 15.1 16.4 0.0\nRo 16.2 18.7 17.9 23.0 37.8 22.3 21.6 22.6 16.4 18.5 22.1 0.0\nNl 14.4 30.4 32.3 21.2 27.0 43.3 34.1 31.0 24.6 23.3 27.3 0.0\nIt 16.9 25.8 27.8 17.1 23.4 30.2 39.8 30.6 20.1 18.5 23.2 0.0\nAr 5.8 15.5 12.8 12.7 12.0 14.7 14.7 37.6 11.6 13.0 16.7 0.0\nHi 3.2 10.1 9.9 5.8 6.7 6.1 5.0 7.6 23.5 14.5 13.0 0.0\nNe 2.1 6.7 6.5 5.0 4.3 3.0 2.2 5.2 17.9 14.5 10.8 0.0\nSi 5.0 5.7 3.8 3.8 1.3 0.9 0.5 3.5 8.1 8.9 13.7 0.0\nGu 8.2 8.5 4.7 5.4 3.5 2.1 0.0 6.2 13.8 13.5 12.8 0.3\nTable 11: Unsupervised MT via Language Transfer on X-En translations. The model \ufb01ne-tuned on one language\npair is directly tested on another. We use gray color to show the direct \ufb01ne-tuning results, and lightgray color to\nshow language transfer within similar language groups. We bold the highest transferring score for each pair.\nPairs BT Transfer Combined\nRo\u2192En 30.5 Cs\u2192En 23.0 33.9\nNe\u2192En 10.0 Hi\u2192En 18.9 22.1\nZh\u2192En 11.3 Ko\u2192En 9.2 15.0\nNl\u2192En 28.5 It\u2192En 34.1 35.4\nTable 12: Back-Translation v.s. Language Transfer\nfor Unsupervised MT . We present the best transfer-\nring scores together with the pairs transferred from.\nlate all languages with similar representations. We\nalso present three examples of language transfer-\nring between Zh, Ja and Ko in appendix B.\nWhen is language transfer useful? Table 11\nalso shows mixed results at each pair. First, for\nmost pairs, language transfer works better when\n\ufb01ne-tuning is also conducted in the same language\nfamily, especially between Indic languages (Hi,\nNe, Gu). However, signi\ufb01cant vocabulary sharing\nis not required for effective transfer. For instance,\nZh-En and It-En achieve the best transfer learning\nresults on Ko-En and Ar-En, respectively. How-ever, the vocabulary overlapping (even character\noverlapping) between Zh and Ko, It and Ar is low.\nw/ Back-Translation We also present the com-\nparison on 4 pairs of unsupervised MT with back-\ntranslation (BT) v.s. language transfer in Table 12.\nThe results are also mixed. If there exists high\nquality (similar languages) bi-text data, or trans-\nlating between dissimilar pairs, language transfer\nis able to beat the conventional methods with BT.\nFurthermore, we also show promising results for\ncombining these two techniques. In such cases, we\nstart from the best transferred model and apply (it-\nerative) BT on the same monolingual corpus used\nin pre-training. Table 12 presents the results with 1\niteration of BT. For all pairs, we see improvements\nby combining both techniques.\n6 Related Work\nPre-training for Text Generation This work\ninherits from the recent success brought by self-\nsupervised pre-training for NLP applications (Pe-",
        "1673c6ec-906e-4d25-852c-cacee830590b": "ModelSimilar Pairs Dissimilar Pairs\nEn-De En-Ro En-Ne En-Si\n\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 21.0 17.2 19.4 21.2 0.0 0.0 0.0 0.0\nXLM (2019) 34.3 26.4 31.8 33.3 0.5 0.1 0.1 0.1\nMASS (2019) 35.2 28.3 33.1 35.2 - - - -\nmBART 34.0 29.8 30.5 35.0 10.0 4.4 8.2 3.9\nTable 10: Unsupervised MT via Back-Translation . En-De, En-Ro are initialized by mBART02, while En-Ne,\nEn-Si are initialized by mBART25. Our models are trained on monolingual data used in pre-training.\nFine-tuning Languages\nZh Ja Ko Cs Ro Nl It Ar Hi Ne Si Gu\nDomain News TED TED News News TED TED TED News Wiki Wiki WikiTesting LanguagesZh 23.7 8.8 9.2 2.8 7.8 7.0 6.8 6.2 7.2 4.2 5.9 0.0\nJa 9.9 19.1 12.2 0.9 4.8 6.4 5.1 5.6 4.7 4.2 6.5 0.0\nKo 5.8 16.9 24.6 5.7 8.5 9.5 9.1 8.7 9.6 8.8 11.1 0.0\nCs 9.3 15.1 17.2 21.6 19.5 17.0 16.7 16.9 13.2 15.1 16.4 0.0\nRo 16.2 18.7 17.9 23.0 37.",
        "c41136fd-5d65-435c-bf51-9600fa340b34": "2 18.7 17.9 23.0 37.8 22.3 21.6 22.6 16.4 18.5 22.1 0.0\nNl 14.4 30.4 32.3 21.2 27.0 43.3 34.1 31.0 24.6 23.3 27.3 0.0\nIt 16.9 25.8 27.8 17.1 23.4 30.2 39.8 30.6 20.1 18.5 23.2 0.0\nAr 5.8 15.5 12.8 12.7 12.0 14.7 14.7 37.6 11.6 13.0 16.7 0.0\nHi 3.2 10.1 9.9 5.8 6.7 6.1 5.0 7.6 23.5 14.5 13.0 0.0\nNe 2.1 6.7 6.5 5.0 4.3 3.0 2.2 5.2 17.9 14.5 10.8 0.0\nSi 5.0 5.7 3.8 3.8 1.3 0.9 0.5 3.5 8.1 8.9 13.7 0.0\nGu 8.2 8.5 4.7 5.4 3.5 2.1 0.0 6.2 13.8 13.5 12.8 0.3\nTable 11: Unsupervised MT via Language Transfer on X-En translations. The model \ufb01ne-tuned on one language\npair is directly tested on another. We use gray color to show the direct \ufb01ne-tuning results, and lightgray color to\nshow language transfer within similar language groups. We bold the highest transferring score for each pair.",
        "678858bf-682f-4d01-a6ba-128cb42331f0": "We bold the highest transferring score for each pair.\nPairs BT Transfer Combined\nRo\u2192En 30.5 Cs\u2192En 23.0 33.9\nNe\u2192En 10.0 Hi\u2192En 18.9 22.1\nZh\u2192En 11.3 Ko\u2192En 9.2 15.0\nNl\u2192En 28.5 It\u2192En 34.1 35.4\nTable 12: Back-Translation v.s. Language Transfer\nfor Unsupervised MT . We present the best transfer-\nring scores together with the pairs transferred from.\nlate all languages with similar representations. We\nalso present three examples of language transfer-\nring between Zh, Ja and Ko in appendix B.\nWhen is language transfer useful? Table 11\nalso shows mixed results at each pair. First, for\nmost pairs, language transfer works better when\n\ufb01ne-tuning is also conducted in the same language\nfamily, especially between Indic languages (Hi,\nNe, Gu). However, signi\ufb01cant vocabulary sharing\nis not required for effective transfer. For instance,\nZh-En and It-En achieve the best transfer learning\nresults on Ko-En and Ar-En, respectively. How-ever, the vocabulary overlapping (even character\noverlapping) between Zh and Ko, It and Ar is low.\nw/ Back-Translation We also present the com-\nparison on 4 pairs of unsupervised MT with back-\ntranslation (BT) v.s. language transfer in Table 12.\nThe results are also mixed. If there exists high\nquality (similar languages) bi-text data, or trans-\nlating between dissimilar pairs, language transfer\nis able to beat the conventional methods with BT.\nFurthermore, we also show promising results for\ncombining these two techniques. In such cases, we\nstart from the best transferred model and apply (it-\nerative) BT on the same monolingual corpus used\nin pre-training. Table 12 presents the results with 1\niteration of BT. For all pairs, we see improvements\nby combining both techniques.\n6 Related Work\nPre-training for Text Generation This work\ninherits from the recent success brought by self-\nsupervised pre-training for NLP applications (Pe-",
        "b16095d9-1386-4fb7-9917-e443c6f175bb": "ModelSimilar Pairs Dissimilar Pairs\nEn-De En-Ro En-Ne En-Si\n\u2190 \u2192 \u2190 \u2192 \u2190 \u2192 \u2190 \u2192\nRandom 21.0 17.2 19.4 21.2 0.0 0.0 0.0 0.0\nXLM (2019) 34.3 26.4 31.8 33.3 0.5 0.1 0.",
        "c5930ee0-f3e3-474b-8d8b-28afbd5895dc": "4 31.8 33.3 0.5 0.1 0.1 0.1\nMASS (2019) 35.2 28.3 33.1 35.2 - - - -\nmBART 34.0 29.8 30.5 35.0 10.0 4.4 8.2 3.",
        "377d9b81-8efe-4ab4-8b48-ba715772bef1": "5 35.0 10.0 4.4 8.2 3.9\nTable 10: Unsupervised MT via Back-Translation . En-De, En-Ro are initialized by mBART02, while En-Ne,\nEn-Si are initialized by mBART25. Our models are trained on monolingual data used in pre-training.",
        "87ee4951-cb10-4844-905e-29f77a4d53f8": "Our models are trained on monolingual data used in pre-training.\nFine-tuning Languages\nZh Ja Ko Cs Ro Nl It Ar Hi Ne Si Gu\nDomain News TED TED News News TED TED TED News Wiki Wiki WikiTesting LanguagesZh 23.7 8.8 9.2 2.8 7.8 7.0 6.8 6.2 7.2 4.2 5.9 0.",
        "667f9665-2cd2-49d2-9853-cd2c5b18f213": "8 6.2 7.2 4.2 5.9 0.0\nJa 9.9 19.1 12.2 0.9 4.8 6.4 5.1 5.6 4.7 4.2 6.5 0.0\nKo 5.8 16.9 24.6 5.7 8.5 9.",
        "7f799c73-ab01-47a2-98bc-20ca737c634c": "8 16.9 24.6 5.7 8.5 9.5 9.1 8.7 9.6 8.8 11.1 0.0\nCs 9.3 15.1 17.2 21.6 19.5 17.0 16.7 16.9 13.2 15.1 16.4 0.0\nRo 16.",
        "e5716ee1-4d40-4a9d-b764-55fdf6293b80": "2 15.1 16.4 0.0\nRo 16.2 18.7 17.9 23.0 37.",
        "031229cd-d9d4-4ea4-bdba-cb8ebf85d680": "2 18.7 17.9 23.0 37.8 22.3 21.6 22.6 16.4 18.5 22.1 0.0\nNl 14.4 30.4 32.3 21.2 27.0 43.3 34.1 31.0 24.6 23.3 27.3 0.",
        "2da75a84-be69-4a55-8c06-438399f38946": "1 31.0 24.6 23.3 27.3 0.0\nIt 16.9 25.8 27.8 17.1 23.4 30.2 39.8 30.6 20.1 18.5 23.2 0.0\nAr 5.8 15.5 12.8 12.7 12.0 14.7 14.",
        "7917381b-d1b4-4396-848e-213504390975": "5 12.8 12.7 12.0 14.7 14.7 37.6 11.6 13.0 16.7 0.0\nHi 3.2 10.1 9.9 5.8 6.7 6.1 5.0 7.6 23.5 14.5 13.0 0.0\nNe 2.1 6.",
        "dfc07fc5-0319-41c2-9347-47c02c95ef69": "5 13.0 0.0\nNe 2.1 6.7 6.5 5.0 4.3 3.0 2.2 5.2 17.9 14.5 10.8 0.0\nSi 5.0 5.7 3.8 3.8 1.3 0.9 0.5 3.5 8.1 8.",
        "25f8accc-3d44-4335-b5d1-20bb1642e36e": "3 0.9 0.5 3.5 8.1 8.9 13.7 0.0\nGu 8.2 8.5 4.7 5.4 3.5 2.1 0.0 6.2 13.8 13.5 12.8 0.3\nTable 11: Unsupervised MT via Language Transfer on X-En translations.",
        "23292280-a560-46ee-a164-a4fe71d1ccd8": "3\nTable 11: Unsupervised MT via Language Transfer on X-En translations. The model \ufb01ne-tuned on one language\npair is directly tested on another. We use gray color to show the direct \ufb01ne-tuning results, and lightgray color to\nshow language transfer within similar language groups. We bold the highest transferring score for each pair.",
        "c461cb46-c4e8-4c9e-b50f-2831d02d1bc7": "We bold the highest transferring score for each pair.",
        "89cd255c-76f6-4fa4-91af-06f16a8213b5": "We bold the highest transferring score for each pair.\nPairs BT Transfer Combined\nRo\u2192En 30.5 Cs\u2192En 23.0 33.9\nNe\u2192En 10.0 Hi\u2192En 18.9 22.1\nZh\u2192En 11.3 Ko\u2192En 9.2 15.0\nNl\u2192En 28.5 It\u2192En 34.1 35.4\nTable 12: Back-Translation v.s.",
        "9c92bd0e-84cc-4c7f-8a50-1840da7c25a9": "Language Transfer\nfor Unsupervised MT . We present the best transfer-\nring scores together with the pairs transferred from.\nlate all languages with similar representations. We\nalso present three examples of language transfer-\nring between Zh, Ja and Ko in appendix B.\nWhen is language transfer useful? Table 11\nalso shows mixed results at each pair.",
        "69e7cc46-78c5-4b9c-918d-16f7ea04b5f0": "Table 11\nalso shows mixed results at each pair. First, for\nmost pairs, language transfer works better when\n\ufb01ne-tuning is also conducted in the same language\nfamily, especially between Indic languages (Hi,\nNe, Gu). However, signi\ufb01cant vocabulary sharing\nis not required for effective transfer.",
        "a4d6bfd8-0bb2-4069-bcae-03754be015e5": "However, signi\ufb01cant vocabulary sharing\nis not required for effective transfer. For instance,\nZh-En and It-En achieve the best transfer learning\nresults on Ko-En and Ar-En, respectively. How-ever, the vocabulary overlapping (even character\noverlapping) between Zh and Ko, It and Ar is low.",
        "c5aaba65-4e41-4486-a254-62f08f50674c": "w/ Back-Translation We also present the com-\nparison on 4 pairs of unsupervised MT with back-\ntranslation (BT) v.s. language transfer in Table 12.\nThe results are also mixed. If there exists high\nquality (similar languages) bi-text data, or trans-\nlating between dissimilar pairs, language transfer\nis able to beat the conventional methods with BT.\nFurthermore, we also show promising results for\ncombining these two techniques.",
        "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb": "Furthermore, we also show promising results for\ncombining these two techniques. In such cases, we\nstart from the best transferred model and apply (it-\nerative) BT on the same monolingual corpus used\nin pre-training. Table 12 presents the results with 1\niteration of BT. For all pairs, we see improvements\nby combining both techniques.",
        "3a533c6a-f294-4e80-b83a-b702a6792b59": "For all pairs, we see improvements\nby combining both techniques.\n6 Related Work\nPre-training for Text Generation This work\ninherits from the recent success brought by self-\nsupervised pre-training for NLP applications (Pe-",
        "1cd81b3e-4937-49f4-9067-aa1d7669398d": "ters et al., 2018; Radford et al., 2018; Devlin et al.,\n2019; Yang et al., 2019; Liu et al., 2019), espe-\ncially for text generation tasks (Radford et al.,\n2019; Song et al., 2019; Dong et al., 2019; Raf-\nfel et al., 2019; Lewis et al., 2019) where dif-\nferent self-supervised objectives are designed for\ntraining big neural models on enormous unlabeled\ntext corpora The pre-trained models are usually\nused as the initialization for \ufb01ne-tuning variant\ndownstream tasks such as controllable language\nmodeling (Shirish Keskar et al., 2019), machine\ntranslation (Song et al., 2019), summarization (Liu\nand Lapata, 2019) and dialogue generation (Zhang\net al., 2019). In contrast to most prior work, we\nfocus on a deep exploration of applying denoising\npre-training for various translation applications.\nMultilinguality in NLP tasks This work is also\nrelated to the continual trend of multilingual lan-\nguage learning, including aligning multilingual\nword embeddings (Mikolov et al., 2013; Chen and\nCardie, 2018; Lample et al., 2018b) into universal\nspace, and learning cross-lingual models (Wada\nand Iwata, 2018; Lample and Conneau, 2019;\nConneau et al., 2019) to exploit shared represen-\ntations across languages.\nFor machine translation, the most relevant \ufb01eld\nismultilingual translation (Firat et al., 2016;\nVi\u00e9gas et al., 2016; Aharoni et al., 2019; Arivazha-\ngan et al., 2019) where the ultimate goal is to\njointly train one translation model that translates\nmultiple language directions at the same time, and\nshares representations to improve the translation\nperformance on low-resource languages (Gu et al.,\n2018). In this paper, we mainly focus on multilin-\ngualism in the pre-training stage and \ufb01ne-tune the\nlearned model in the standard bi-lingual scenario.\nCompared to multilingual translation, we do not\nrequire parallel data across multiple languages but\nthe targeted direction, which potentially improves\nthe scalability to low-resource languages and spe-\nci\ufb01c domains. Moreover, multilingual pre-training\nis unlikely to suffer the interference problems be-\ntween dissimilar languages, which is typical for\nregular multilingual translation models.\nDocument Translation As one of the key appli-\ncations, this work also links to previous efforts for\nincorporating document-level contexts into neu-\nral machine translation (Wang et al., 2017; Jean\net al., 2017; Tiedemann and Scherrer, 2017; Mi-\nculicich et al., 2018; Tu et al., 2018). Li et al.(2019) is the most relevant work which also uti-\nlized pre-trained encoder (BERT) for handling\nlonger context. However, none of these works had\nshown positive results on pure Seq2Seq models\nat document-level, which involved task-speci\ufb01c\ntechniques, and usually only worked on sentence-\nlevel translation with a constrained range of con-\ntext. To the extent of our knowledge, our mul-\ntilingual pre-trained model is the \ufb01rst-of-its-kind\nwork that shows improved results on document-\nlevel translation with standard Seq2Seq learning.\nUnsupervised Translation This work also sum-\nmarizes the previous efforts of learning to translate\nbetween languages without a direct parallel cor-\npus, and re-de\ufb01nes them as unsupervised machine\ntranslation with three categories where in this\nwork, we only focus on applications to the \ufb01rst and\nthe third kinds (\u00a75). When no parallel corpus of\nany kind is available, Artetxe et al. (2017); Lample\net al. (2018a,c) proposed to jointly learn denois-\ning auto-encoder and back-translation from both\ndirections, which, however, required good initial-\nization and only worked well on similar language\npairs; Wu et al. (2019a) replaced back-translation\nwith retrieved similar sentences from target mono-\nlingual data; Wu et al. (2019b) solves the problem\nby mining sentences from Wikipedia and use them\nas weakly supervised translation pairs. Similar to\nLample and Conneau (2019); Song et al. (2019),\nwe follow the \ufb01rst approach and treat our pre-\ntrained model as the initialization step. Besides,\nwe investigate unsupervised translation using lan-\nguage transfer, which is similar to Pourdamghani\net al. (2019) where the authors generate transla-\ntionese of the source language and train a sys-\ntem on high-resource languages to correct these\nintermediate utterances. It is also closely related\nto Conneau et al. (2018); Artetxe et al. (2019) for\ncross-lingual representation learning.\n7 Conclusion\nWe demonstrate that multilingual de-noising pre-\ntraining is able to signi\ufb01cantly improve both su-\npervised and unsupervised machine translation at\nboth the sentence level and document level. We\nanalyze when and how pre-training is most effec-\ntive and can be combined with other approaches\nsuch as back-translation. Our results also show the\ntransfer learning ability of the learned representa-\ntions from multilingual pre-training.\nIn future work, we will scale-up the current pre-",
        "3d32efb8-59aa-4a7d-8d50-b5052aa597b5": "ters et al., 2018; Radford et al., 2018; Devlin et al.,\n2019; Yang et al., 2019; Liu et al., 2019), espe-\ncially for text generation tasks (Radford et al.,\n2019; Song et al., 2019; Dong et al., 2019; Raf-\nfel et al., 2019; Lewis et al., 2019) where dif-\nferent self-supervised objectives are designed for\ntraining big neural models on enormous unlabeled\ntext corpora The pre-trained models are usually\nused as the initialization for \ufb01ne-tuning variant\ndownstream tasks such as controllable language\nmodeling (Shirish Keskar et al., 2019), machine\ntranslation (Song et al., 2019), summarization (Liu\nand Lapata, 2019) and dialogue generation (Zhang\net al., 2019). In contrast to most prior work, we\nfocus on a deep exploration of applying denoising\npre-training for various translation applications.\nMultilinguality in NLP tasks This work is also\nrelated to the continual trend of multilingual lan-\nguage learning, including aligning multilingual\nword embeddings (Mikolov et al., 2013; Chen and\nCardie, 2018; Lample et al., 2018b) into universal\nspace, and learning cross-lingual models (Wada\nand Iwata, 2018; Lample and Conneau, 2019;\nConneau et al., 2019) to exploit shared represen-\ntations across languages.\nFor machine translation, the most relevant \ufb01eld\nismultilingual translation (Firat et al., 2016;\nVi\u00e9gas et al., 2016; Aharoni et al., 2019; Arivazha-\ngan et al., 2019) where the ultimate goal is to\njointly train one translation model that translates\nmultiple language directions at the same time, and\nshares representations to improve the translation\nperformance on low-resource languages (Gu et al.,\n2018).",
        "7dcbc37d-0c94-4c01-8a93-26edd9020474": "In this paper, we mainly focus on multilin-\ngualism in the pre-training stage and \ufb01ne-tune the\nlearned model in the standard bi-lingual scenario.\nCompared to multilingual translation, we do not\nrequire parallel data across multiple languages but\nthe targeted direction, which potentially improves\nthe scalability to low-resource languages and spe-\nci\ufb01c domains. Moreover, multilingual pre-training\nis unlikely to suffer the interference problems be-\ntween dissimilar languages, which is typical for\nregular multilingual translation models.\nDocument Translation As one of the key appli-\ncations, this work also links to previous efforts for\nincorporating document-level contexts into neu-\nral machine translation (Wang et al., 2017; Jean\net al., 2017; Tiedemann and Scherrer, 2017; Mi-\nculicich et al., 2018; Tu et al., 2018). Li et al.(2019) is the most relevant work which also uti-\nlized pre-trained encoder (BERT) for handling\nlonger context. However, none of these works had\nshown positive results on pure Seq2Seq models\nat document-level, which involved task-speci\ufb01c\ntechniques, and usually only worked on sentence-\nlevel translation with a constrained range of con-\ntext. To the extent of our knowledge, our mul-\ntilingual pre-trained model is the \ufb01rst-of-its-kind\nwork that shows improved results on document-\nlevel translation with standard Seq2Seq learning.\nUnsupervised Translation This work also sum-\nmarizes the previous efforts of learning to translate\nbetween languages without a direct parallel cor-\npus, and re-de\ufb01nes them as unsupervised machine\ntranslation with three categories where in this\nwork, we only focus on applications to the \ufb01rst and\nthe third kinds (\u00a75). When no parallel corpus of\nany kind is available, Artetxe et al. (2017); Lample\net al. (2018a,c) proposed to jointly learn denois-\ning auto-encoder and back-translation from both\ndirections, which, however, required good initial-\nization and only worked well on similar language\npairs; Wu et al.",
        "e8f06d09-39f8-4250-a2d2-59c452085922": "(2019a) replaced back-translation\nwith retrieved similar sentences from target mono-\nlingual data; Wu et al. (2019b) solves the problem\nby mining sentences from Wikipedia and use them\nas weakly supervised translation pairs. Similar to\nLample and Conneau (2019); Song et al. (2019),\nwe follow the \ufb01rst approach and treat our pre-\ntrained model as the initialization step. Besides,\nwe investigate unsupervised translation using lan-\nguage transfer, which is similar to Pourdamghani\net al. (2019) where the authors generate transla-\ntionese of the source language and train a sys-\ntem on high-resource languages to correct these\nintermediate utterances. It is also closely related\nto Conneau et al. (2018); Artetxe et al. (2019) for\ncross-lingual representation learning.\n7 Conclusion\nWe demonstrate that multilingual de-noising pre-\ntraining is able to signi\ufb01cantly improve both su-\npervised and unsupervised machine translation at\nboth the sentence level and document level. We\nanalyze when and how pre-training is most effec-\ntive and can be combined with other approaches\nsuch as back-translation. Our results also show the\ntransfer learning ability of the learned representa-\ntions from multilingual pre-training.\nIn future work, we will scale-up the current pre-",
        "9466031c-5dde-41ec-bf34-3d0cc9065329": "ters et al. 2018; Radford et al. 2018; Devlin et al.\n2019; Yang et al. 2019; Liu et al. 2019), espe-\ncially for text generation tasks (Radford et al.\n2019; Song et al. 2019; Dong et al. 2019; Raf-\nfel et al. 2019; Lewis et al.",
        "6563f83e-5b12-42fd-9cf5-dbe5f9dc035d": "2019; Raf-\nfel et al. 2019; Lewis et al. 2019) where dif-\nferent self-supervised objectives are designed for\ntraining big neural models on enormous unlabeled\ntext corpora The pre-trained models are usually\nused as the initialization for \ufb01ne-tuning variant\ndownstream tasks such as controllable language\nmodeling (Shirish Keskar et al. 2019), machine\ntranslation (Song et al.",
        "1ecfcd7f-e8c0-41b3-9782-d1b9983166bc": "2019), machine\ntranslation (Song et al. 2019), summarization (Liu\nand Lapata, 2019) and dialogue generation (Zhang\net al. 2019). In contrast to most prior work, we\nfocus on a deep exploration of applying denoising\npre-training for various translation applications.\nMultilinguality in NLP tasks This work is also\nrelated to the continual trend of multilingual lan-\nguage learning,",
        "b0894c37-378e-4b0d-9709-aa440ab8aaa5": "including aligning multilingual\nword embeddings (Mikolov et al. 2013; Chen and\nCardie, 2018; Lample et al. 2018b) into universal\nspace, and learning cross-lingual models (Wada\nand Iwata, 2018; Lample and Conneau, 2019;\nConneau et al. 2019) to exploit shared represen-\ntations across languages.",
        "42eff7a7-3c97-406f-a6e1-6dbb83a9706b": "2019) to exploit shared represen-\ntations across languages.\nFor machine translation, the most relevant \ufb01eld\nismultilingual translation (Firat et al. 2016;\nVi\u00e9gas et al. 2016; Aharoni et al. 2019; Arivazha-\ngan et al.",
        "672574b1-6370-488b-b79f-6e41c3eedc07": "Aharoni et al. 2019; Arivazha-\ngan et al. 2019) where the ultimate goal is to\njointly train one translation model that translates\nmultiple language directions at the same time, and\nshares representations to improve the translation\nperformance on low-resource languages (Gu et al.\n2018).",
        "d0951a55-9953-4323-8fcb-2db5e812f5d8": "In this paper, we mainly focus on multilin-\ngualism in the pre-training stage and \ufb01ne-tune the\nlearned model in the standard bi-lingual scenario.\nCompared to multilingual translation, we do not\nrequire parallel data across multiple languages but\nthe targeted direction, which potentially improves\nthe scalability to low-resource languages and spe-\nci\ufb01c domains.",
        "712001d9-0dd1-48ff-92f5-d304365dc855": "Moreover, multilingual pre-training\nis unlikely to suffer the interference problems be-\ntween dissimilar languages, which is typical for\nregular multilingual translation models.",
        "03cf226c-20af-498b-91d8-3828ed3d4832": "Document Translation As one of the key appli-\ncations, this work also links to previous efforts for\nincorporating document-level contexts into neu-\nral machine translation (Wang et al., 2017; Jean\net al., 2017; Tiedemann and Scherrer, 2017; Mi-\nculicich et al., 2018; Tu et al., 2018). Li et al.",
        "93c4cdca-8bc8-4c11-ba3a-88f030e150cd": "Li et al.(2019) is the most relevant work which also uti-\nlized pre-trained encoder (BERT) for handling\nlonger context. However, none of these works had\nshown positive results on pure Seq2Seq models\nat document-level, which involved task-speci\ufb01c\ntechniques, and usually only worked on sentence-\nlevel translation with a constrained range of con-\ntext.",
        "331c7fce-9520-451c-b215-b114c698a45b": "To the extent of our knowledge, our mul-\ntilingual pre-trained model is the \ufb01rst-of-its-kind\nwork that shows improved results on document-\nlevel translation with standard Seq2Seq learning.",
        "1ff2df31-95cf-487a-b44a-83b21b1f2647": "Unsupervised Translation This work also sum-\nmarizes the previous efforts of learning to translate\nbetween languages without a direct parallel cor-\npus, and re-de\ufb01nes them as unsupervised machine\ntranslation with three categories where in this\nwork, we only focus on applications to the \ufb01rst and\nthe third kinds (\u00a75). When no parallel corpus of\nany kind is available, Artetxe et al.",
        "44f29973-cc07-42c6-b3d1-29518a044620": "When no parallel corpus of\nany kind is available, Artetxe et al. (2017); Lample\net al. (2018a,c) proposed to jointly learn denois-\ning auto-encoder and back-translation from both\ndirections, which, however, required good initial-\nization and only worked well on similar language\npairs; Wu et al.",
        "e1ca0619-8065-49cf-afe8-df1d5aabf2a3": "(2019a) replaced back-translation\nwith retrieved similar sentences from target mono-\nlingual data; Wu et al. (2019b) solves the problem\nby mining sentences from Wikipedia and use them\nas weakly supervised translation pairs. Similar to\nLample and Conneau (2019); Song et al. (2019),\nwe follow the \ufb01rst approach and treat our pre-\ntrained model as the initialization step.",
        "610698d8-3f47-4e39-99ea-208edb87f351": "Besides,\nwe investigate unsupervised translation using lan-\nguage transfer, which is similar to Pourdamghani\net al. (2019) where the authors generate transla-\ntionese of the source language and train a sys-\ntem on high-resource languages to correct these\nintermediate utterances. It is also closely related\nto Conneau et al. (2018); Artetxe et al.",
        "cc538936-855b-4561-a382-96926d69b783": "(2018); Artetxe et al. (2019) for\ncross-lingual representation learning.\n7 Conclusion\nWe demonstrate that multilingual de-noising pre-\ntraining is able to signi\ufb01cantly improve both su-\npervised and unsupervised machine translation at\nboth the sentence level and document level. We\nanalyze when and how pre-training is most effec-\ntive and can be combined with other approaches\nsuch as back-translation.",
        "afd5dca0-0e82-4a6a-88fb-63a3aa26b9b3": "Our results also show the\ntransfer learning ability of the learned representa-\ntions from multilingual pre-training.\nIn future work, we will scale-up the current pre-",
        "274561f3-500a-4650-9c03-709dc3394b65": "training to more languages, e.g., an mBART100\nmodel. The size of our model makes it expensive\nto deploy in production \u2013 future work will explore\npre-training more ef\ufb01cient models.\n8 Acknowledgements\nWe thank Marc\u2019Aurelio Ranzato, Guillaume Lam-\nple, Alexis Conneau, and Michael Auli for shar-\ning their expertise on low-resource and unsuper-\nvised machine translation, Peng-Jen Chen, Jiajun\nShen for details about FloRes and WAT datasets.\nWe also thank our colleagues at FAIR and FAIAR\nfor valuable feedback.\nReferences\nRoee Aharoni, Melvin Johnson, and Orhan Firat.\n2019. Massively multilingual neural machine\ntranslation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the\nAssociation for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long\nand Short Papers) , pages 3874\u20133884, Min-\nneapolis, Minnesota. Association for Computa-\ntional Linguistics.\nNaveen Arivazhagan, Ankur Bapna, Orhan Fi-\nrat, Dmitry Lepikhin, Melvin Johnson, Maxim\nKrikun, Mia Xu Chen, Yuan Cao, George\nFoster, Colin Cherry, Wolfgang Macherey,\nZhifeng Chen, and Yonghui Wu. 2019. Mas-\nsively multilingual neural machine translation\nin the wild: Findings and challenges. CoRR ,\nabs/1907.05019.\nMikel Artetxe, Gorka Labaka, Eneko Agirre,\nand Kyunghyun Cho. 2017. Unsupervised\nneural machine translation. arXiv preprint\narXiv:1710.11041 .\nMikel Artetxe, Sebastian Ruder, and Dani Yo-\ngatama. 2019. On the cross-lingual transferabil-\nity of monolingual representations.\nMauro Cettolo, Christian Girardi, and Marcello\nFederico. 2012. Wit3: Web inventory of tran-\nscribed and translated talks. In Conference of\nEuropean Association for Machine Translation ,\npages 261\u2013268.\nMauro Cettolo, Niehues Jan, St\u00fcker Sebastian,\nLuisa Bentivogli, Roldano Cattoni, and Mar-\ncello Federico. 2015. The iwslt 2015 evalua-tion campaign. In International Workshop on\nSpoken Language Translation .\nPeng-Jen Chen, Jiajun Shen, Matt Le, Vishrav\nChaudhary, Ahmed El-Kishky, Guillaume Wen-\nzek, Myle Ott, and Marc\u2019Aurelio Ranzato.\n2019. Facebook ai\u2019s wat19 myanmar-english\ntranslation task submission. arXiv preprint\narXiv:1910.06848 .\nXilun Chen and Claire Cardie. 2018. Unsuper-\nvised multilingual word embeddings. In Pro-\nceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 261\u2013270, Brussels, Belgium. Association\nfor Computational Linguistics.\nYun Chen, Yang Liu, Yong Cheng, and Victor OK\nLi. 2017. A teacher-student framework for\nzero-resource neural machine translation. In\nProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1925\u20131935.\nAlexis Conneau, Kartikay Khandelwal, Naman\nGoyal, Vishrav Chaudhary, Guillaume Wen-\nzek, Francisco Guzm\u00e1n, Edouard Grave, Myle\nOtt, Luke Zettlemoyer, and Veselin Stoyanov.\n2019. Unsupervised cross-lingual represen-\ntation learning at scale. arXiv preprint\narXiv:1911.02116 .\nAlexis Conneau, Ruty Rinott, Guillaume Lample,\nAdina Williams, Samuel R. Bowman, Holger\nSchwenk, and Veselin Stoyanov. 2018. Xnli:\nEvaluating cross-lingual sentence representa-\ntions. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language\nProcessing . Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding. In North American Association\nfor Computational Linguistics (NAACL) .\nChenchen Ding, Hnin Thu Zar Aye, Win Pa Pa,\nKhin Thandar Nwet, Khin Mar Soe, Masao\nUtiyama, and Eiichiro Sumita. 2019. Towards\nBurmese (Myanmar) morphological analysis:\nSyllable-based tokenization and part-of-speech\ntagging. ACM Transactions on Asian and\nLow-Resource Language Information Process-\ning (TALLIP) , 19(1):5.",
        "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4": "training to more languages, e.g., an mBART100\nmodel. The size of our model makes it expensive\nto deploy in production \u2013 future work will explore\npre-training more ef\ufb01cient models.\n8 Acknowledgements\nWe thank Marc\u2019Aurelio Ranzato, Guillaume Lam-\nple, Alexis Conneau, and Michael Auli for shar-\ning their expertise on low-resource and unsuper-\nvised machine translation, Peng-Jen Chen, Jiajun\nShen for details about FloRes and WAT datasets.\nWe also thank our colleagues at FAIR and FAIAR\nfor valuable feedback.\nReferences\nRoee Aharoni, Melvin Johnson, and Orhan Firat.\n2019. Massively multilingual neural machine\ntranslation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the\nAssociation for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long\nand Short Papers) , pages 3874\u20133884, Min-\nneapolis, Minnesota. Association for Computa-\ntional Linguistics.\nNaveen Arivazhagan, Ankur Bapna, Orhan Fi-\nrat, Dmitry Lepikhin, Melvin Johnson, Maxim\nKrikun, Mia Xu Chen, Yuan Cao, George\nFoster, Colin Cherry, Wolfgang Macherey,\nZhifeng Chen, and Yonghui Wu. 2019. Mas-\nsively multilingual neural machine translation\nin the wild: Findings and challenges. CoRR ,\nabs/1907.05019.\nMikel Artetxe, Gorka Labaka, Eneko Agirre,\nand Kyunghyun Cho. 2017. Unsupervised\nneural machine translation. arXiv preprint\narXiv:1710.11041 .\nMikel Artetxe, Sebastian Ruder, and Dani Yo-\ngatama. 2019. On the cross-lingual transferabil-\nity of monolingual representations.\nMauro Cettolo, Christian Girardi, and Marcello\nFederico. 2012. Wit3: Web inventory of tran-\nscribed and translated talks. In Conference of\nEuropean Association for Machine Translation ,\npages 261\u2013268.",
        "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc": "In Conference of\nEuropean Association for Machine Translation ,\npages 261\u2013268.\nMauro Cettolo, Niehues Jan, St\u00fcker Sebastian,\nLuisa Bentivogli, Roldano Cattoni, and Mar-\ncello Federico. 2015. The iwslt 2015 evalua-tion campaign. In International Workshop on\nSpoken Language Translation .\nPeng-Jen Chen, Jiajun Shen, Matt Le, Vishrav\nChaudhary, Ahmed El-Kishky, Guillaume Wen-\nzek, Myle Ott, and Marc\u2019Aurelio Ranzato.\n2019. Facebook ai\u2019s wat19 myanmar-english\ntranslation task submission. arXiv preprint\narXiv:1910.06848 .\nXilun Chen and Claire Cardie. 2018. Unsuper-\nvised multilingual word embeddings. In Pro-\nceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 261\u2013270, Brussels, Belgium. Association\nfor Computational Linguistics.\nYun Chen, Yang Liu, Yong Cheng, and Victor OK\nLi. 2017. A teacher-student framework for\nzero-resource neural machine translation. In\nProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1925\u20131935.\nAlexis Conneau, Kartikay Khandelwal, Naman\nGoyal, Vishrav Chaudhary, Guillaume Wen-\nzek, Francisco Guzm\u00e1n, Edouard Grave, Myle\nOtt, Luke Zettlemoyer, and Veselin Stoyanov.\n2019. Unsupervised cross-lingual represen-\ntation learning at scale. arXiv preprint\narXiv:1911.02116 .\nAlexis Conneau, Ruty Rinott, Guillaume Lample,\nAdina Williams, Samuel R. Bowman, Holger\nSchwenk, and Veselin Stoyanov. 2018. Xnli:\nEvaluating cross-lingual sentence representa-\ntions.",
        "2a71fb63-90dd-49d9-8b04-553b03098168": "Xnli:\nEvaluating cross-lingual sentence representa-\ntions. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language\nProcessing . Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding. In North American Association\nfor Computational Linguistics (NAACL) .\nChenchen Ding, Hnin Thu Zar Aye, Win Pa Pa,\nKhin Thandar Nwet, Khin Mar Soe, Masao\nUtiyama, and Eiichiro Sumita. 2019. Towards\nBurmese (Myanmar) morphological analysis:\nSyllable-based tokenization and part-of-speech\ntagging. ACM Transactions on Asian and\nLow-Resource Language Information Process-\ning (TALLIP) , 19(1):5.",
        "e5e90176-83c9-40bc-886d-886ef16004c7": "training to more languages, e.g., an mBART100\nmodel. The size of our model makes it expensive\nto deploy in production \u2013 future work will explore\npre-training more ef\ufb01cient models.",
        "b933ee97-825f-4512-8227-bdf59686af7b": "8 Acknowledgements\nWe thank Marc\u2019Aurelio Ranzato, Guillaume Lam-\nple, Alexis Conneau, and Michael Auli for shar-\ning their expertise on low-resource and unsuper-\nvised machine translation, Peng-Jen Chen, Jiajun\nShen for details about FloRes and WAT datasets.\nWe also thank our colleagues at FAIR and FAIAR\nfor valuable feedback.",
        "d892da6e-f46f-49b3-824d-f3a5032695e4": "We also thank our colleagues at FAIR and FAIAR\nfor valuable feedback.\nReferences\nRoee Aharoni, Melvin Johnson, and Orhan Firat.\n2019. Massively multilingual neural machine\ntranslation.",
        "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e": "2019. Massively multilingual neural machine\ntranslation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the\nAssociation for Computational Linguistics: Hu-\nman Language Technologies, Volume 1 (Long\nand Short Papers) , pages 3874\u20133884, Min-\nneapolis, Minnesota. Association for Computa-\ntional Linguistics.",
        "f094f6af-059f-46d7-80b8-bd614650ab99": "Association for Computa-\ntional Linguistics.\nNaveen Arivazhagan, Ankur Bapna, Orhan Fi-\nrat, Dmitry Lepikhin, Melvin Johnson, Maxim\nKrikun, Mia Xu Chen, Yuan Cao, George\nFoster, Colin Cherry, Wolfgang Macherey,\nZhifeng Chen, and Yonghui Wu. 2019.",
        "df3372be-ebf5-4591-9a61-20f3d143fd71": "2019. Mas-\nsively multilingual neural machine translation\nin the wild: Findings and challenges. CoRR ,\nabs/1907.05019.\nMikel Artetxe, Gorka Labaka, Eneko Agirre,\nand Kyunghyun Cho. 2017. Unsupervised\nneural machine translation. arXiv preprint\narXiv:1710.11041 .",
        "4cd4cf05-ada0-4361-932d-244968ea5f4b": "arXiv preprint\narXiv:1710.11041 .\nMikel Artetxe, Sebastian Ruder, and Dani Yo-\ngatama. 2019. On the cross-lingual transferabil-\nity of monolingual representations.\nMauro Cettolo, Christian Girardi, and Marcello\nFederico. 2012. Wit3: Web inventory of tran-\nscribed and translated talks.",
        "5c823895-429c-4d6c-acf1-1e2ad7a727bc": "2012. Wit3: Web inventory of tran-\nscribed and translated talks. In Conference of\nEuropean Association for Machine Translation ,\npages 261\u2013268.",
        "0c2ec292-cb09-4fb8-9c29-82a387221bba": "In Conference of\nEuropean Association for Machine Translation ,\npages 261\u2013268.\nMauro Cettolo, Niehues Jan, St\u00fcker Sebastian,\nLuisa Bentivogli, Roldano Cattoni, and Mar-\ncello Federico. 2015. The iwslt 2015 evalua-tion campaign. In International Workshop on\nSpoken Language Translation .",
        "25e2c3ce-52b9-43b8-9422-c3c088c8379c": "In International Workshop on\nSpoken Language Translation .\nPeng-Jen Chen, Jiajun Shen, Matt Le, Vishrav\nChaudhary, Ahmed El-Kishky, Guillaume Wen-\nzek, Myle Ott, and Marc\u2019Aurelio Ranzato.\n2019. Facebook ai\u2019s wat19 myanmar-english\ntranslation task submission. arXiv preprint\narXiv:1910.06848 .",
        "fe4e0050-9a7a-4428-bc5b-70a39332f076": "arXiv preprint\narXiv:1910.06848 .\nXilun Chen and Claire Cardie. 2018. Unsuper-\nvised multilingual word embeddings. In Pro-\nceedings of the 2018 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 261\u2013270, Brussels, Belgium. Association\nfor Computational Linguistics.\nYun Chen, Yang Liu, Yong Cheng, and Victor OK\nLi.",
        "0e9c223b-bc53-4626-9922-87fe2dd4d5b6": "Yun Chen, Yang Liu, Yong Cheng, and Victor OK\nLi. 2017. A teacher-student framework for\nzero-resource neural machine translation. In\nProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1925\u20131935.",
        "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889": "Alexis Conneau, Kartikay Khandelwal, Naman\nGoyal, Vishrav Chaudhary, Guillaume Wen-\nzek, Francisco Guzm\u00e1n, Edouard Grave, Myle\nOtt, Luke Zettlemoyer, and Veselin Stoyanov.\n2019. Unsupervised cross-lingual represen-\ntation learning at scale.",
        "6914ce46-288e-4505-afd5-837c6aae1d56": "Unsupervised cross-lingual represen-\ntation learning at scale. arXiv preprint\narXiv:1911.02116 .\nAlexis Conneau, Ruty Rinott, Guillaume Lample,\nAdina Williams, Samuel R. Bowman, Holger\nSchwenk, and Veselin Stoyanov. 2018. Xnli:\nEvaluating cross-lingual sentence representa-\ntions.",
        "8eacf552-96dc-4ffe-b843-2db4d1b6b396": "Xnli:\nEvaluating cross-lingual sentence representa-\ntions. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language\nProcessing . Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding.",
        "50df9315-bd20-421a-bc4c-331c72ab1875": "BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding. In North American Association\nfor Computational Linguistics (NAACL) .\nChenchen Ding, Hnin Thu Zar Aye, Win Pa Pa,\nKhin Thandar Nwet, Khin Mar Soe, Masao\nUtiyama, and Eiichiro Sumita. 2019.",
        "e74506c9-54f8-4b17-b72c-8123182e5a74": "2019. Towards\nBurmese (Myanmar) morphological analysis:\nSyllable-based tokenization and part-of-speech\ntagging. ACM Transactions on Asian and\nLow-Resource Language Information Process-\ning (TALLIP) , 19(1):5.",
        "98a121be-14b1-4ba9-bf05-c75218e957c9": "Chenchen Ding, Masao Utiyama, and Eiichiro\nSumita. 2018. NOV A: A feasible and \ufb02exi-\nble annotation system for joint tokenization and\npart-of-speech tagging. ACM Transactions on\nAsian and Low-Resource Language Informa-\ntion Processing (TALLIP) , 18(2):17.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei,\nXiaodong Liu, Yu Wang, Jianfeng Gao, Ming\nZhou, and Hsiao-Wuen Hon. 2019. Uni\ufb01ed lan-\nguage model pre-training for natural language\nunderstanding and generation. arXiv preprint\narXiv:1905.03197 .\nSergey Edunov, Alexei Baevski, and Michael Auli.\n2019. Pre-trained language model representa-\ntions for language generation. arXiv preprint\narXiv:1903.09722 .\nOrhan Firat, Kyunghyun Cho, and Yoshua Bengio.\n2016. Multi-way, multilingual neural machine\ntranslation with a shared attention mechanism.\nInNAACL .\nJiatao Gu, Hany Hassan, Jacob Devlin, and Vic-\ntor O.K. Li. 2018. Universal neural machine\ntranslation for extremely low resource lan-\nguages. In Proceedings of the 2018 Conference\nof the North American Chapter of the Asso-\nciation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Pa-\npers) , pages 344\u2013354, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Vic-\ntor OK Li. 2019. Improved zero-shot neural\nmachine translation via ignoring spurious cor-\nrelations. arXiv preprint arXiv:1906.01181 .\nFrancisco Guzm\u00e1n, Peng-Jen Chen, Myle Ott,\nJuan Pino, Guillaume Lample, Philipp Koehn,\nVishrav Chaudhary, and Marc\u2019Aurelio Ran-\nzato. 2019. The FLORES evaluation datasets\nfor low-resource machine translation: Nepali\u2013\nEnglish and Sinhala\u2013English. In Proceedings\nof the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the\n9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) ,\npages 6097\u20136110, Hong Kong, China. Associ-\nation for Computational Linguistics.\nS\u00e9bastien Jean, Stanislas Lauly, Orhan Firat, and\nKyunghyun Cho. 2017. Does neural machinetranslation bene\ufb01t from larger context? CoRR ,\nabs/1704.05135.\nMelvin Johnson, Mike Schuster, Quoc V Le,\nMaxim Krikun, Yonghui Wu, Zhifeng Chen,\nNikhil Thorat, Fernanda Vi\u00e9gas, Martin Wat-\ntenberg, Greg Corrado, et al. 2017. Google\u2019s\nmultilingual neural machine translation system:\nEnabling zero-shot translation. Transactions of\nthe Association for Computational Linguistics ,\n5:339\u2013351.\nTaku Kudo and John Richardson. 2018. Senten-\ncePiece: A simple and language independent\nsubword tokenizer and detokenizer for neural\ntext processing. In Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations ,\npages 66\u201371, Brussels, Belgium. Association\nfor Computational Linguistics.\nAnoop Kunchukuttan, Pratik Mehta, and Pushpak\nBhattacharyya. 2017. The IIT bombay english-\nhindi parallel corpus. CoRR , abs/1710.02855.\nGuillaume Lample and Alexis Conneau. 2019.\nCross-lingual language model pretraining.\narXiv preprint arXiv:1901.07291 .\nGuillaume Lample, Alexis Conneau, Ludovic De-\nnoyer, and Marc\u2019Aurelio Ranzato. 2018a. Un-\nsupervised machine translation using monolin-\ngual corpora only. In International Conference\non Learning Representations .\nGuillaume Lample, Alexis Conneau,\nMarc\u2019Aurelio Ranzato, Ludovic Denoyer,\nand Herv\u00e9 J\u00e9gou. 2018b. Word transla-\ntion without parallel data. In International\nConference on Learning Representations .\nGuillaume Lample, Myle Ott, Alexis Conneau,\nLudovic Denoyer, and Marc\u2019Aurelio Ranzato.\n2018c. Phrase-based & neural unsuper-\nvised machine translation. arXiv preprint\narXiv:1804.07755 .\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2019. Bart: Denoising sequence-to-sequence\npre-training for natural language generation,\ntranslation, and comprehension. arXiv preprint\narXiv:1910.13461 .",
        "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b": "Chenchen Ding, Masao Utiyama, and Eiichiro\nSumita. 2018. NOV A: A feasible and \ufb02exi-\nble annotation system for joint tokenization and\npart-of-speech tagging. ACM Transactions on\nAsian and Low-Resource Language Informa-\ntion Processing (TALLIP) , 18(2):17.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei,\nXiaodong Liu, Yu Wang, Jianfeng Gao, Ming\nZhou, and Hsiao-Wuen Hon. 2019. Uni\ufb01ed lan-\nguage model pre-training for natural language\nunderstanding and generation. arXiv preprint\narXiv:1905.03197 .\nSergey Edunov, Alexei Baevski, and Michael Auli.\n2019. Pre-trained language model representa-\ntions for language generation. arXiv preprint\narXiv:1903.09722 .\nOrhan Firat, Kyunghyun Cho, and Yoshua Bengio.\n2016. Multi-way, multilingual neural machine\ntranslation with a shared attention mechanism.\nInNAACL .\nJiatao Gu, Hany Hassan, Jacob Devlin, and Vic-\ntor O.K. Li. 2018. Universal neural machine\ntranslation for extremely low resource lan-\nguages. In Proceedings of the 2018 Conference\nof the North American Chapter of the Asso-\nciation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Pa-\npers) , pages 344\u2013354, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Vic-\ntor OK Li. 2019. Improved zero-shot neural\nmachine translation via ignoring spurious cor-\nrelations. arXiv preprint arXiv:1906.01181 .\nFrancisco Guzm\u00e1n, Peng-Jen Chen, Myle Ott,\nJuan Pino, Guillaume Lample, Philipp Koehn,\nVishrav Chaudhary, and Marc\u2019Aurelio Ran-\nzato. 2019.",
        "cf511d8c-69d2-4a76-9f4a-b938f797b405": "2019. The FLORES evaluation datasets\nfor low-resource machine translation: Nepali\u2013\nEnglish and Sinhala\u2013English. In Proceedings\nof the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the\n9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) ,\npages 6097\u20136110, Hong Kong, China. Associ-\nation for Computational Linguistics.\nS\u00e9bastien Jean, Stanislas Lauly, Orhan Firat, and\nKyunghyun Cho. 2017. Does neural machinetranslation bene\ufb01t from larger context? CoRR ,\nabs/1704.05135.\nMelvin Johnson, Mike Schuster, Quoc V Le,\nMaxim Krikun, Yonghui Wu, Zhifeng Chen,\nNikhil Thorat, Fernanda Vi\u00e9gas, Martin Wat-\ntenberg, Greg Corrado, et al. 2017. Google\u2019s\nmultilingual neural machine translation system:\nEnabling zero-shot translation. Transactions of\nthe Association for Computational Linguistics ,\n5:339\u2013351.\nTaku Kudo and John Richardson. 2018. Senten-\ncePiece: A simple and language independent\nsubword tokenizer and detokenizer for neural\ntext processing. In Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations ,\npages 66\u201371, Brussels, Belgium. Association\nfor Computational Linguistics.\nAnoop Kunchukuttan, Pratik Mehta, and Pushpak\nBhattacharyya. 2017. The IIT bombay english-\nhindi parallel corpus. CoRR , abs/1710.02855.\nGuillaume Lample and Alexis Conneau. 2019.\nCross-lingual language model pretraining.\narXiv preprint arXiv:1901.07291 .\nGuillaume Lample, Alexis Conneau, Ludovic De-\nnoyer, and Marc\u2019Aurelio Ranzato. 2018a. Un-\nsupervised machine translation using monolin-\ngual corpora only. In International Conference\non Learning Representations .",
        "44d0c323-8fce-4b2a-85df-9db648d9d202": "In International Conference\non Learning Representations .\nGuillaume Lample, Alexis Conneau,\nMarc\u2019Aurelio Ranzato, Ludovic Denoyer,\nand Herv\u00e9 J\u00e9gou. 2018b. Word transla-\ntion without parallel data. In International\nConference on Learning Representations .\nGuillaume Lample, Myle Ott, Alexis Conneau,\nLudovic Denoyer, and Marc\u2019Aurelio Ranzato.\n2018c. Phrase-based & neural unsuper-\nvised machine translation. arXiv preprint\narXiv:1804.07755 .\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2019. Bart: Denoising sequence-to-sequence\npre-training for natural language generation,\ntranslation, and comprehension. arXiv preprint\narXiv:1910.13461 .",
        "6d610ff2-80d5-4d0b-8bd2-53005bab6dea": "Chenchen Ding, Masao Utiyama, and Eiichiro\nSumita. 2018. NOV A: A feasible and \ufb02exi-\nble annotation system for joint tokenization and\npart-of-speech tagging. ACM Transactions on\nAsian and Low-Resource Language Informa-\ntion Processing (TALLIP) , 18(2):17.",
        "7c001067-3f0d-45a5-a148-de7840007abb": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei,\nXiaodong Liu, Yu Wang, Jianfeng Gao, Ming\nZhou, and Hsiao-Wuen Hon. 2019. Uni\ufb01ed lan-\nguage model pre-training for natural language\nunderstanding and generation. arXiv preprint\narXiv:1905.03197 .",
        "185cd77d-c865-42a0-a7e8-3677bcb99e72": "arXiv preprint\narXiv:1905.03197 .\nSergey Edunov, Alexei Baevski, and Michael Auli.\n2019. Pre-trained language model representa-\ntions for language generation. arXiv preprint\narXiv:1903.09722 .\nOrhan Firat, Kyunghyun Cho, and Yoshua Bengio.\n2016.",
        "1a802d3f-bbe1-43cf-b884-44d305542192": "2016. Multi-way, multilingual neural machine\ntranslation with a shared attention mechanism.\nInNAACL .\nJiatao Gu, Hany Hassan, Jacob Devlin, and Vic-\ntor O.K. Li. 2018. Universal neural machine\ntranslation for extremely low resource lan-\nguages.",
        "a80ff16b-89c9-49c2-a9b0-d58d4b539e68": "2018. Universal neural machine\ntranslation for extremely low resource lan-\nguages. In Proceedings of the 2018 Conference\nof the North American Chapter of the Asso-\nciation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Pa-\npers) , pages 344\u2013354, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Vic-\ntor OK Li.",
        "6a60caca-b559-43eb-9d41-445ca2cf4cd2": "2019. Improved zero-shot neural\nmachine translation via ignoring spurious cor-\nrelations. arXiv preprint arXiv:1906.01181 .\nFrancisco Guzm\u00e1n, Peng-Jen Chen, Myle Ott,\nJuan Pino, Guillaume Lample, Philipp Koehn,\nVishrav Chaudhary, and Marc\u2019Aurelio Ran-\nzato. 2019.",
        "a5bbc50f-1da0-452c-b35f-8225945de20e": "2019. The FLORES evaluation datasets\nfor low-resource machine translation: Nepali\u2013\nEnglish and Sinhala\u2013English. In Proceedings\nof the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the\n9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) ,\npages 6097\u20136110, Hong Kong, China. Associ-\nation for Computational Linguistics.",
        "ace7a56d-f862-4b93-bd81-720163fcf947": "Associ-\nation for Computational Linguistics.\nS\u00e9bastien Jean, Stanislas Lauly, Orhan Firat, and\nKyunghyun Cho. 2017. Does neural machinetranslation bene\ufb01t from larger context? CoRR ,\nabs/1704.05135.",
        "fe793593-c220-433a-8518-818aa6c39007": "CoRR ,\nabs/1704.05135.\nMelvin Johnson, Mike Schuster, Quoc V Le,\nMaxim Krikun, Yonghui Wu, Zhifeng Chen,\nNikhil Thorat, Fernanda Vi\u00e9gas, Martin Wat-\ntenberg, Greg Corrado, et al. 2017. Google\u2019s\nmultilingual neural machine translation system:\nEnabling zero-shot translation.",
        "bfe5ccc1-3df0-41d9-a0d6-b1ac017a0fd1": "Google\u2019s\nmultilingual neural machine translation system:\nEnabling zero-shot translation. Transactions of\nthe Association for Computational Linguistics ,\n5:339\u2013351.\nTaku Kudo and John Richardson. 2018. Senten-\ncePiece: A simple and language independent\nsubword tokenizer and detokenizer for neural\ntext processing.",
        "56dad008-3878-4100-9128-1429c4a52b70": "In Proceedings of the 2018\nConference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations ,\npages 66\u201371, Brussels, Belgium. Association\nfor Computational Linguistics.\nAnoop Kunchukuttan, Pratik Mehta, and Pushpak\nBhattacharyya. 2017. The IIT bombay english-\nhindi parallel corpus. CoRR , abs/1710.02855.",
        "556270c0-4bac-4ae8-95e1-a4844787c889": "CoRR , abs/1710.02855.\nGuillaume Lample and Alexis Conneau. 2019.\nCross-lingual language model pretraining.\narXiv preprint arXiv:1901.07291 .\nGuillaume Lample, Alexis Conneau, Ludovic De-\nnoyer, and Marc\u2019Aurelio Ranzato. 2018a. Un-\nsupervised machine translation using monolin-\ngual corpora only.",
        "9f8fe4fe-131d-491f-b2be-ab5b692ddf87": "Un-\nsupervised machine translation using monolin-\ngual corpora only. In International Conference\non Learning Representations .",
        "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f": "In International Conference\non Learning Representations .\nGuillaume Lample, Alexis Conneau,\nMarc\u2019Aurelio Ranzato, Ludovic Denoyer,\nand Herv\u00e9 J\u00e9gou. 2018b. Word transla-\ntion without parallel data. In International\nConference on Learning Representations .\nGuillaume Lample, Myle Ott, Alexis Conneau,\nLudovic Denoyer, and Marc\u2019Aurelio Ranzato.\n2018c.",
        "0e2c9060-409f-4afc-9f18-87bbb298200e": "2018c. Phrase-based & neural unsuper-\nvised machine translation. arXiv preprint\narXiv:1804.07755 .\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2019.",
        "c53957a8-9bab-430c-a3b5-b548ce35b7fa": "2019. Bart: Denoising sequence-to-sequence\npre-training for natural language generation,\ntranslation, and comprehension. arXiv preprint\narXiv:1910.13461 .",
        "5fd8151c-1c5f-4053-ad99-14f7a52394cc": "Liangyou Li, Xin Jiang, and Qun Liu. 2019.\nPretrained language models for document-level\nneural machine translation. arXiv preprint\narXiv:1911.03110 .\nYang Liu and Mirella Lapata. 2019. Text sum-\nmarization with pretrained encoders. arXiv\npreprint arXiv:1908.08345 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei\nDu, Mandar Joshi, Danqi Chen, Omer Levy,\nMike Lewis, Luke Zettlemoyer, and Veselin\nStoyanov. 2019. Roberta: A robustly opti-\nmized bert pretraining approach. arXiv preprint\narXiv:1907.11692 .\nLesly Miculicich, Dhananjay Ram, Nikolaos Pap-\npas, and James Henderson. 2018. Document-\nlevel neural machine translation with hierarchi-\ncal attention networks. In Proceedings of the\n2018 Conference on Empirical Methods in Nat-\nural Language Processing , pages 2947\u20132954,\nBrussels, Belgium. Association for Computa-\ntional Linguistics.\nTomas Mikolov, Quoc V . Le, and Ilya Sutskever.\n2013. Exploiting similarities among languages\nfor machine translation. CoRR , abs/1309.4168.\nMyle Ott, Sergey Edunov, Alexei Baevski, An-\ngela Fan, Sam Gross, Nathan Ng, David Grang-\nier, and Michael Auli. 2019. FAIRSEQ : A fast,\nextensible toolkit for sequence modeling. In\nNorth American Association for Computational\nLinguistics (NAACL): System Demonstrations .\nKishore Papineni, Salim Roukos, Todd Ward, and\nWei-Jing Zhu. 2002. Bleu: a method for au-\ntomatic evaluation of machine translation. In\nProceedings of the 40th annual meeting on as-\nsociation for computational linguistics , pages\n311\u2013318. Association for Computational Lin-\nguistics.\nMatthew Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee,\nand Luke Zettlemoyer. 2018. Deep contextu-\nalized word representations. In North Ameri-\ncan Association for Computational Linguistics\n(NAACL) .\nMatt Post. 2018. A call for clarity in reporting\nBLEU scores. In Proceedings of the Third Con-\nference on Machine Translation: Research Pa-pers, pages 186\u2013191, Belgium, Brussels. Asso-\nciation for Computational Linguistics.\nNima Pourdamghani, Nada Aldarrab, Marjan\nGhazvininejad, Kevin Knight, and Jonathan\nMay. 2019. Translating translationese: A two-\nstep approach to unsupervised machine transla-\ntion. In ACL.\nAlec Radford, Karthik Narasimhan, Time Sali-\nmans, and Ilya Sutskever. 2018. Improving lan-\nguage understanding with unsupervised learn-\ning. Technical report, OpenAI.\nAlec Radford, Jeffrey Wu, Rewon Child, David\nLuan, Dario Amodei, and Ilya Sutskever. 2019.\nLanguage models are unsupervised multitask\nlearners. Technical report, OpenAI.\nColin Raffel, Noam Shazeer, Adam Roberts,\nKatherine Lee, Sharan Narang, Michael\nMatena, Yanqi Zhou, Wei Li, and Peter J Liu.\n2019. Exploring the limits of transfer learning\nwith a uni\ufb01ed text-to-text transformer. arXiv\npreprint arXiv:1910.10683 .\nRico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016a. Edinburgh neural machine trans-\nlation systems for wmt 16. In Proceedings of\nthe First Conference on Machine Translation:\nVolume 2, Shared Task Papers , pages 371\u2013376.\nRico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016b. Improving neural machine trans-\nlation models with monolingual data. In Pro-\nceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 86\u201396, Berlin, Ger-\nmany. Association for Computational Linguis-\ntics.\nNitish Shirish Keskar, Bryan McCann, Lav R\nVarshney, Caiming Xiong, and Richard Socher.\n2019. Ctrl: A conditional transformer lan-\nguage model for controllable generation. arXiv\npreprint arXiv:1909.05858 .\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and\nTie-Yan Liu. 2019. MASS: Masked sequence\nto sequence pre-training for language genera-\ntion. In International Conference on Machine\nLearning (ICML) .\nJ\u00f6rg Tiedemann and Yves Scherrer. 2017. Neu-\nral machine translation with extended context.",
        "0adea7ee-e226-4d2e-934b-61380dec9205": "Liangyou Li, Xin Jiang, and Qun Liu. 2019.\nPretrained language models for document-level\nneural machine translation. arXiv preprint\narXiv:1911.03110 .\nYang Liu and Mirella Lapata. 2019. Text sum-\nmarization with pretrained encoders. arXiv\npreprint arXiv:1908.08345 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei\nDu, Mandar Joshi, Danqi Chen, Omer Levy,\nMike Lewis, Luke Zettlemoyer, and Veselin\nStoyanov. 2019. Roberta: A robustly opti-\nmized bert pretraining approach. arXiv preprint\narXiv:1907.11692 .\nLesly Miculicich, Dhananjay Ram, Nikolaos Pap-\npas, and James Henderson. 2018. Document-\nlevel neural machine translation with hierarchi-\ncal attention networks. In Proceedings of the\n2018 Conference on Empirical Methods in Nat-\nural Language Processing , pages 2947\u20132954,\nBrussels, Belgium. Association for Computa-\ntional Linguistics.\nTomas Mikolov, Quoc V . Le, and Ilya Sutskever.\n2013. Exploiting similarities among languages\nfor machine translation. CoRR , abs/1309.4168.\nMyle Ott, Sergey Edunov, Alexei Baevski, An-\ngela Fan, Sam Gross, Nathan Ng, David Grang-\nier, and Michael Auli. 2019. FAIRSEQ : A fast,\nextensible toolkit for sequence modeling. In\nNorth American Association for Computational\nLinguistics (NAACL): System Demonstrations .\nKishore Papineni, Salim Roukos, Todd Ward, and\nWei-Jing Zhu. 2002. Bleu: a method for au-\ntomatic evaluation of machine translation. In\nProceedings of the 40th annual meeting on as-\nsociation for computational linguistics , pages\n311\u2013318. Association for Computational Lin-\nguistics.",
        "fc362cd3-fc2e-42af-ae6a-326b94bd888a": "Association for Computational Lin-\nguistics.\nMatthew Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee,\nand Luke Zettlemoyer. 2018. Deep contextu-\nalized word representations. In North Ameri-\ncan Association for Computational Linguistics\n(NAACL) .\nMatt Post. 2018. A call for clarity in reporting\nBLEU scores. In Proceedings of the Third Con-\nference on Machine Translation: Research Pa-pers, pages 186\u2013191, Belgium, Brussels. Asso-\nciation for Computational Linguistics.\nNima Pourdamghani, Nada Aldarrab, Marjan\nGhazvininejad, Kevin Knight, and Jonathan\nMay. 2019. Translating translationese: A two-\nstep approach to unsupervised machine transla-\ntion. In ACL.\nAlec Radford, Karthik Narasimhan, Time Sali-\nmans, and Ilya Sutskever. 2018. Improving lan-\nguage understanding with unsupervised learn-\ning. Technical report, OpenAI.\nAlec Radford, Jeffrey Wu, Rewon Child, David\nLuan, Dario Amodei, and Ilya Sutskever. 2019.\nLanguage models are unsupervised multitask\nlearners. Technical report, OpenAI.\nColin Raffel, Noam Shazeer, Adam Roberts,\nKatherine Lee, Sharan Narang, Michael\nMatena, Yanqi Zhou, Wei Li, and Peter J Liu.\n2019. Exploring the limits of transfer learning\nwith a uni\ufb01ed text-to-text transformer. arXiv\npreprint arXiv:1910.10683 .\nRico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016a. Edinburgh neural machine trans-\nlation systems for wmt 16. In Proceedings of\nthe First Conference on Machine Translation:\nVolume 2, Shared Task Papers , pages 371\u2013376.\nRico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016b. Improving neural machine trans-\nlation models with monolingual data.",
        "896960c2-3e17-4bc6-8956-63b40c9d7d2e": "2016b. Improving neural machine trans-\nlation models with monolingual data. In Pro-\nceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 86\u201396, Berlin, Ger-\nmany. Association for Computational Linguis-\ntics.\nNitish Shirish Keskar, Bryan McCann, Lav R\nVarshney, Caiming Xiong, and Richard Socher.\n2019. Ctrl: A conditional transformer lan-\nguage model for controllable generation. arXiv\npreprint arXiv:1909.05858 .\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and\nTie-Yan Liu. 2019. MASS: Masked sequence\nto sequence pre-training for language genera-\ntion. In International Conference on Machine\nLearning (ICML) .\nJ\u00f6rg Tiedemann and Yves Scherrer. 2017. Neu-\nral machine translation with extended context.",
        "bb763235-9793-45ad-91b6-e05855a7e8bf": "Liangyou Li, Xin Jiang, and Qun Liu. 2019.\nPretrained language models for document-level\nneural machine translation. arXiv preprint\narXiv:1911.03110 .\nYang Liu and Mirella Lapata. 2019. Text sum-\nmarization with pretrained encoders. arXiv\npreprint arXiv:1908.08345 .",
        "a76e3f81-4575-43b6-9888-660022c1f8c9": "arXiv\npreprint arXiv:1908.08345 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei\nDu, Mandar Joshi, Danqi Chen, Omer Levy,\nMike Lewis, Luke Zettlemoyer, and Veselin\nStoyanov. 2019. Roberta: A robustly opti-\nmized bert pretraining approach.",
        "b3ce1d16-79cb-431e-b1a1-585d6b26c8ce": "Roberta: A robustly opti-\nmized bert pretraining approach. arXiv preprint\narXiv:1907.11692 .\nLesly Miculicich, Dhananjay Ram, Nikolaos Pap-\npas, and James Henderson. 2018. Document-\nlevel neural machine translation with hierarchi-\ncal attention networks.",
        "75460117-65d6-4d3d-a003-4dc019cffed0": "2018. Document-\nlevel neural machine translation with hierarchi-\ncal attention networks. In Proceedings of the\n2018 Conference on Empirical Methods in Nat-\nural Language Processing , pages 2947\u20132954,\nBrussels, Belgium. Association for Computa-\ntional Linguistics.\nTomas Mikolov, Quoc V . Le, and Ilya Sutskever.\n2013. Exploiting similarities among languages\nfor machine translation.",
        "42369608-687f-4633-86b7-2704427759a1": "2013. Exploiting similarities among languages\nfor machine translation. CoRR , abs/1309.4168.\nMyle Ott, Sergey Edunov, Alexei Baevski, An-\ngela Fan, Sam Gross, Nathan Ng, David Grang-\nier, and Michael Auli. 2019. FAIRSEQ : A fast,\nextensible toolkit for sequence modeling.",
        "544e7103-8d62-4115-b0b8-f0341dab95a3": "2019. FAIRSEQ : A fast,\nextensible toolkit for sequence modeling. In\nNorth American Association for Computational\nLinguistics (NAACL): System Demonstrations .\nKishore Papineni, Salim Roukos, Todd Ward, and\nWei-Jing Zhu. 2002. Bleu: a method for au-\ntomatic evaluation of machine translation.",
        "3ea893d6-93fe-404c-9b9d-d02baec3e5c5": "Bleu: a method for au-\ntomatic evaluation of machine translation. In\nProceedings of the 40th annual meeting on as-\nsociation for computational linguistics , pages\n311\u2013318. Association for Computational Lin-\nguistics.",
        "4ed8955a-4e2f-4b5e-8447-ad8719f369f9": "Association for Computational Lin-\nguistics.\nMatthew Peters, Mark Neumann, Mohit Iyyer,\nMatt Gardner, Christopher Clark, Kenton Lee,\nand Luke Zettlemoyer. 2018. Deep contextu-\nalized word representations. In North Ameri-\ncan Association for Computational Linguistics\n(NAACL) .\nMatt Post. 2018. A call for clarity in reporting\nBLEU scores.",
        "b13cd79e-4df0-4a9f-a1e6-3547370e0899": "Matt Post. 2018. A call for clarity in reporting\nBLEU scores. In Proceedings of the Third Con-\nference on Machine Translation: Research Pa-pers, pages 186\u2013191, Belgium, Brussels. Asso-\nciation for Computational Linguistics.\nNima Pourdamghani, Nada Aldarrab, Marjan\nGhazvininejad, Kevin Knight, and Jonathan\nMay. 2019.",
        "0b26fe19-d8ba-4a6d-baa0-40cbe0e3a39d": "2019. Translating translationese: A two-\nstep approach to unsupervised machine transla-\ntion. In ACL.\nAlec Radford, Karthik Narasimhan, Time Sali-\nmans, and Ilya Sutskever. 2018. Improving lan-\nguage understanding with unsupervised learn-\ning. Technical report, OpenAI.",
        "84d29e0e-25f7-4f5c-a066-b3c5621144a6": "Technical report, OpenAI.\nAlec Radford, Jeffrey Wu, Rewon Child, David\nLuan, Dario Amodei, and Ilya Sutskever. 2019.\nLanguage models are unsupervised multitask\nlearners. Technical report, OpenAI.",
        "10681c4c-8a95-4475-8dda-367b52031752": "Language models are unsupervised multitask\nlearners. Technical report, OpenAI.\nColin Raffel, Noam Shazeer, Adam Roberts,\nKatherine Lee, Sharan Narang, Michael\nMatena, Yanqi Zhou, Wei Li, and Peter J Liu.\n2019. Exploring the limits of transfer learning\nwith a uni\ufb01ed text-to-text transformer. arXiv\npreprint arXiv:1910.10683 .",
        "ec3152b8-a408-4e9a-aec0-92d6e21918bc": "arXiv\npreprint arXiv:1910.10683 .\nRico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016a. Edinburgh neural machine trans-\nlation systems for wmt 16. In Proceedings of\nthe First Conference on Machine Translation:\nVolume 2, Shared Task Papers , pages 371\u2013376.\nRico Sennrich, Barry Haddow, and Alexandra\nBirch.",
        "7586021c-06cb-4bbf-af31-207827f5464d": "Rico Sennrich, Barry Haddow, and Alexandra\nBirch. 2016b. Improving neural machine trans-\nlation models with monolingual data.",
        "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d": "2016b. Improving neural machine trans-\nlation models with monolingual data. In Pro-\nceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 86\u201396, Berlin, Ger-\nmany. Association for Computational Linguis-\ntics.",
        "68d1e877-772d-42e2-924a-a7272eb774b7": "Association for Computational Linguis-\ntics.\nNitish Shirish Keskar, Bryan McCann, Lav R\nVarshney, Caiming Xiong, and Richard Socher.\n2019. Ctrl: A conditional transformer lan-\nguage model for controllable generation. arXiv\npreprint arXiv:1909.05858 .\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and\nTie-Yan Liu.",
        "186f5b60-9c0f-46fa-b723-6832c450f2ec": "2019. MASS: Masked sequence\nto sequence pre-training for language genera-\ntion. In International Conference on Machine\nLearning (ICML) .\nJ\u00f6rg Tiedemann and Yves Scherrer. 2017. Neu-\nral machine translation with extended context.",
        "c54124f5-331c-40dc-8829-ba419a9326ac": "InProceedings of the Third Workshop on Dis-\ncourse in Machine Translation , pages 82\u201392,\nCopenhagen, Denmark. Association for Com-\nputational Linguistics.\nZhaopeng Tu, Yang Liu, Shuming Shi, and Tong\nZhang. 2018. Learning to remember translation\nhistory with a continuous cache. Transactions\nof the Association for Computational Linguis-\ntics, 6:407\u2013420.\nAshish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. 2017. At-\ntention is all you need. In Advances in neural\ninformation processing systems .\nFernanda Vi\u00e9gas, Greg Corrado, Jeffrey Dean,\nMacduff Hughes, Martin Wattenberg, Maxim\nKrikun, Melvin Johnson, Mike Schuster, Nikhil\nThorat, Quoc V Le, et al. 2016. Google\u2019s multi-\nlingual neural machine translation system: En-\nabling zero-shot translation.\nTakashi Wada and Tomoharu Iwata. 2018. Un-\nsupervised cross-lingual word embedding by\nmultilingual neural language models. CoRR ,\nabs/1809.02306.\nLongyue Wang, Zhaopeng Tu, Andy Way, and\nQun Liu. 2017. Exploiting cross-sentence con-\ntext for neural machine translation. In Pro-\nceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 2826\u20132831, Copenhagen, Denmark. As-\nsociation for Computational Linguistics.\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis\nConneau, Vishrav Chaudhary, Francisco Guz-\nman, Armand Joulin, and Edouard Grave. 2019.\nCcnet: Extracting high quality monolingual\ndatasets from web crawl data. arXiv preprint\narXiv:1911.00359 .\nJiawei Wu, Xin Wang, and William Yang Wang.\n2019a. Extract and edit: An alternative to back-\ntranslation for unsupervised neural machine\ntranslation. arXiv preprint arXiv:1904.02331 .\nLijun Wu, Jinhua Zhu, Di He, Fei Gao, Xu Tan,\nTao Qin, and Tie-Yan Liu. 2019b. Machine\ntranslation with weakly paired bilingual docu-\nments.Zhilin Yang, Zihang Dai, Yiming Yang, Jaime\nCarbonell, Ruslan Salakhutdinov, and Quoc V\nLe. 2019. Xlnet: Generalized autoregressive\npretraining for language understanding. arXiv\npreprint arXiv:1906.08237 .\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun\nChen, Chris Brockett, Xiang Gao, Jianfeng\nGao, Jingjing Liu, and Bill Dolan. 2019. Di-\nalogpt: Large-scale generative pre-training for\nconversational response generation.\nA Evaluation Details\nFor all our tasks, we use BLEU scores (Papineni\net al., 2002) as the automatic metric to evaluate\nthe translation performance. Normally, we com-\npute the BLEU scores over tokenized text for both\nsystem outputs and the references, and we apply\nlanguage-wise tokenization after over the trans-\nlation. Note that, since we directly work on raw\ntexts, we automatically get de-tokenized output af-\nter recovering sentence-piece subwords. Follow-\ning the literature, the instructions of language-wise\ntokenization are as follows:\n\u2022Gu, Ne, Si, Hi : We use Indic-NLP Library5to\ntokenize the Indic language outputs.\n\u2022Ja: We use KyTea6to segment Japanese texts.\n\u2022Ko: We use Mecab-Ko7and its default dictio-\nnary to segment the Korean texts\n\u2022Ar: We apply QCRI Arabic Normalizer8over\nthe Arabic texts.\n\u2022My: We use the of\ufb01cial segmentation tool pro-\nvided by Ding et al. (2019) for Burmese.\n\u2022Ro: Following Sennrich et al. (2016a), we ap-\nply Moses tokenization and special normaliza-\ntion for Romanian texts9.\n\u2022Zh: We use the of\ufb01cial sacreBleu (Post, 2018)10\nChinese tokenizer (\u2013tok zh).\nFor other languages that are not listed above, we\ncompute BLEU scores with sacreBLEU with DE-\nFAULT tokenization.\nB Translation Examples\n5https://anoopkunchukuttan.github.io/indic_nlp_library/\n6http://www.phontron.com/kytea/\n7http://konlpy.org/en/v0.3.0/install/\n8http://alt.qcri.org/tools/arabic-normalizer/\n9https://github.com/rsennrich/wmt16-script\n10https://github.com/mjpost/sacreBLEU",
        "500abd46-fdd9-4866-9a62-4caf6c532212": "InProceedings of the Third Workshop on Dis-\ncourse in Machine Translation , pages 82\u201392,\nCopenhagen, Denmark. Association for Com-\nputational Linguistics.\nZhaopeng Tu, Yang Liu, Shuming Shi, and Tong\nZhang. 2018. Learning to remember translation\nhistory with a continuous cache. Transactions\nof the Association for Computational Linguis-\ntics, 6:407\u2013420.\nAshish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. 2017. At-\ntention is all you need. In Advances in neural\ninformation processing systems .\nFernanda Vi\u00e9gas, Greg Corrado, Jeffrey Dean,\nMacduff Hughes, Martin Wattenberg, Maxim\nKrikun, Melvin Johnson, Mike Schuster, Nikhil\nThorat, Quoc V Le, et al. 2016. Google\u2019s multi-\nlingual neural machine translation system: En-\nabling zero-shot translation.\nTakashi Wada and Tomoharu Iwata. 2018. Un-\nsupervised cross-lingual word embedding by\nmultilingual neural language models. CoRR ,\nabs/1809.02306.\nLongyue Wang, Zhaopeng Tu, Andy Way, and\nQun Liu. 2017. Exploiting cross-sentence con-\ntext for neural machine translation. In Pro-\nceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 2826\u20132831, Copenhagen, Denmark. As-\nsociation for Computational Linguistics.\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis\nConneau, Vishrav Chaudhary, Francisco Guz-\nman, Armand Joulin, and Edouard Grave. 2019.\nCcnet: Extracting high quality monolingual\ndatasets from web crawl data. arXiv preprint\narXiv:1911.00359 .\nJiawei Wu, Xin Wang, and William Yang Wang.\n2019a.",
        "6058fa69-a58a-41c2-8b06-eeb4066a321e": "Jiawei Wu, Xin Wang, and William Yang Wang.\n2019a. Extract and edit: An alternative to back-\ntranslation for unsupervised neural machine\ntranslation. arXiv preprint arXiv:1904.02331 .\nLijun Wu, Jinhua Zhu, Di He, Fei Gao, Xu Tan,\nTao Qin, and Tie-Yan Liu. 2019b. Machine\ntranslation with weakly paired bilingual docu-\nments.Zhilin Yang, Zihang Dai, Yiming Yang, Jaime\nCarbonell, Ruslan Salakhutdinov, and Quoc V\nLe. 2019. Xlnet: Generalized autoregressive\npretraining for language understanding. arXiv\npreprint arXiv:1906.08237 .\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun\nChen, Chris Brockett, Xiang Gao, Jianfeng\nGao, Jingjing Liu, and Bill Dolan. 2019. Di-\nalogpt: Large-scale generative pre-training for\nconversational response generation.\nA Evaluation Details\nFor all our tasks, we use BLEU scores (Papineni\net al., 2002) as the automatic metric to evaluate\nthe translation performance. Normally, we com-\npute the BLEU scores over tokenized text for both\nsystem outputs and the references, and we apply\nlanguage-wise tokenization after over the trans-\nlation. Note that, since we directly work on raw\ntexts, we automatically get de-tokenized output af-\nter recovering sentence-piece subwords. Follow-\ning the literature, the instructions of language-wise\ntokenization are as follows:\n\u2022Gu, Ne, Si, Hi : We use Indic-NLP Library5to\ntokenize the Indic language outputs.\n\u2022Ja: We use KyTea6to segment Japanese texts.\n\u2022Ko: We use Mecab-Ko7and its default dictio-\nnary to segment the Korean texts\n\u2022Ar: We apply QCRI Arabic Normalizer8over\nthe Arabic texts.\n\u2022My: We use the of\ufb01cial segmentation tool pro-\nvided by Ding et al. (2019) for Burmese.",
        "84dcf72d-a76d-4451-af49-f489f1b1a761": "(2019) for Burmese.\n\u2022Ro: Following Sennrich et al. (2016a), we ap-\nply Moses tokenization and special normaliza-\ntion for Romanian texts9.\n\u2022Zh: We use the of\ufb01cial sacreBleu (Post, 2018)10\nChinese tokenizer (\u2013tok zh).\nFor other languages that are not listed above, we\ncompute BLEU scores with sacreBLEU with DE-\nFAULT tokenization.\nB Translation Examples\n5https://anoopkunchukuttan.github.io/indic_nlp_library/\n6http://www.phontron.com/kytea/\n7http://konlpy.org/en/v0.3.0/install/\n8http://alt.qcri.org/tools/arabic-normalizer/\n9https://github.com/rsennrich/wmt16-script\n10https://github.com/mjpost/sacreBLEU",
        "ac1189ed-6f00-414c-ab32-ff09d75b087f": "InProceedings of the Third Workshop on Dis-\ncourse in Machine Translation , pages 82\u201392,\nCopenhagen, Denmark. Association for Com-\nputational Linguistics.\nZhaopeng Tu, Yang Liu, Shuming Shi, and Tong\nZhang. 2018. Learning to remember translation\nhistory with a continuous cache. Transactions\nof the Association for Computational Linguis-\ntics, 6:407\u2013420.",
        "3144735b-8daa-472e-a7c7-6ee81ad37e49": "Transactions\nof the Association for Computational Linguis-\ntics, 6:407\u2013420.\nAshish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin. 2017. At-\ntention is all you need. In Advances in neural\ninformation processing systems .",
        "846db9d3-4b4b-4ea2-a5c2-b802928ec4e5": "At-\ntention is all you need. In Advances in neural\ninformation processing systems .\nFernanda Vi\u00e9gas, Greg Corrado, Jeffrey Dean,\nMacduff Hughes, Martin Wattenberg, Maxim\nKrikun, Melvin Johnson, Mike Schuster, Nikhil\nThorat, Quoc V Le, et al. 2016. Google\u2019s multi-\nlingual neural machine translation system: En-\nabling zero-shot translation.",
        "9f5a416b-dc7f-4299-ab82-9a1c23790cb9": "Google\u2019s multi-\nlingual neural machine translation system: En-\nabling zero-shot translation.\nTakashi Wada and Tomoharu Iwata. 2018. Un-\nsupervised cross-lingual word embedding by\nmultilingual neural language models. CoRR ,\nabs/1809.02306.\nLongyue Wang, Zhaopeng Tu, Andy Way, and\nQun Liu. 2017.",
        "6d595caf-8bbd-45e0-a887-a9475b421a5a": "2017. Exploiting cross-sentence con-\ntext for neural machine translation. In Pro-\nceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing ,\npages 2826\u20132831, Copenhagen, Denmark. As-\nsociation for Computational Linguistics.",
        "cbe21760-9a27-462a-bdf4-4be4f9c53a29": "As-\nsociation for Computational Linguistics.\nGuillaume Wenzek, Marie-Anne Lachaux, Alexis\nConneau, Vishrav Chaudhary, Francisco Guz-\nman, Armand Joulin, and Edouard Grave. 2019.\nCcnet: Extracting high quality monolingual\ndatasets from web crawl data. arXiv preprint\narXiv:1911.00359 .",
        "ada94f87-b83a-42d7-b9fc-6003d8f72825": "arXiv preprint\narXiv:1911.00359 .\nJiawei Wu, Xin Wang, and William Yang Wang.\n2019a.",
        "a642f6dc-1149-4c5e-bd5f-87be054b6d05": "Jiawei Wu, Xin Wang, and William Yang Wang.\n2019a. Extract and edit: An alternative to back-\ntranslation for unsupervised neural machine\ntranslation. arXiv preprint arXiv:1904.02331 .\nLijun Wu, Jinhua Zhu, Di He, Fei Gao, Xu Tan,\nTao Qin, and Tie-Yan Liu. 2019b.",
        "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb": "2019b. Machine\ntranslation with weakly paired bilingual docu-\nments.Zhilin Yang, Zihang Dai, Yiming Yang, Jaime\nCarbonell, Ruslan Salakhutdinov, and Quoc V\nLe. 2019. Xlnet: Generalized autoregressive\npretraining for language understanding. arXiv\npreprint arXiv:1906.08237 .",
        "4c831f5a-c4ae-47e4-a05f-64cf3f3c4853": "arXiv\npreprint arXiv:1906.08237 .\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun\nChen, Chris Brockett, Xiang Gao, Jianfeng\nGao, Jingjing Liu, and Bill Dolan. 2019. Di-\nalogpt: Large-scale generative pre-training for\nconversational response generation.",
        "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771": "Di-\nalogpt: Large-scale generative pre-training for\nconversational response generation.\nA Evaluation Details\nFor all our tasks, we use BLEU scores (Papineni\net al., 2002) as the automatic metric to evaluate\nthe translation performance. Normally, we com-\npute the BLEU scores over tokenized text for both\nsystem outputs and the references, and we apply\nlanguage-wise tokenization after over the trans-\nlation.",
        "7acbe339-ca92-45fc-9b39-8b7c259d945a": "Note that, since we directly work on raw\ntexts, we automatically get de-tokenized output af-\nter recovering sentence-piece subwords. Follow-\ning the literature, the instructions of language-wise\ntokenization are as follows:\n\u2022Gu, Ne, Si, Hi : We use Indic-NLP Library5to\ntokenize the Indic language outputs.\n\u2022Ja: We use KyTea6to segment Japanese texts.",
        "42ec581e-7aa8-4796-bb20-b5c7b6811056": "\u2022Ja: We use KyTea6to segment Japanese texts.\n\u2022Ko: We use Mecab-Ko7and its default dictio-\nnary to segment the Korean texts\n\u2022Ar: We apply QCRI Arabic Normalizer8over\nthe Arabic texts.\n\u2022My: We use the of\ufb01cial segmentation tool pro-\nvided by Ding et al. (2019) for Burmese.",
        "2f7ec96a-5c87-4eec-9115-12314e10d4f2": "(2019) for Burmese.\n\u2022Ro: Following Sennrich et al. (2016a), we ap-\nply Moses tokenization and special normaliza-\ntion for Romanian texts9.\n\u2022Zh: We use the of\ufb01cial sacreBleu (Post, 2018)10\nChinese tokenizer (\u2013tok zh).",
        "476c68ee-bd93-497f-bbb9-0572dbc356ce": "For other languages that are not listed above, we\ncompute BLEU scores with sacreBLEU with DE-\nFAULT tokenization.",
        "e18c239b-c919-4b7f-928d-45fb3e157308": "B Translation Examples\n5https://anoopkunchukuttan.github.io/indic_nlp_library/\n6http://www.phontron.com/kytea/\n7http://konlpy.org/en/v0.3.0/install/\n8http://alt.qcri.org/tools/arabic-normalizer/\n9https://github.com/rsennrich/wmt16-script\n10https://github.com/mjpost/sacreBLEU",
        "5d096cfc-2076-422d-8155-799e85f9e4af": "?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?10\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?200\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?-- \n?\n?\n?\n?\n?? \n?\n?\n? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n? \nKekertsuatsiak\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?15\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?120\n?\n?\n? \n?\n?40\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n??\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nThrough \nmy \nwork \nI'm \ntrying \nto \narticulate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature \nand \nthat \neverything \nis \ninterconnected. \nI \nfirst \nwent \nto \nAntarctica \nalmost \n10 \nyears \nago, \nwhere \nI \nsaw \nmy \nfirst \nicebergs. \nI \nwas \nin \nawe. \nMy \nheart \nbeat \nfast, \nmy \nhead \nwas \ndizzy, \ntrying \nto \ncomprehend \nwhat \nit \nwas \nthat \nstood \nin \nfront \nof \nme. \nThe \nicebergs \naround \nme \nwere \nalmost \n200 \nfeet \nout \nof \nthe \nwater, \nand \nI \ncould \nonly \nhelp \nbut \nwonder \nthat \nthis \nwas \none \nsnowflake \non \ntop \nof \nanother \nsnowflake, \nyear \nafter \nyear. \nIcebergs \nare \nborn \nwhen \nthey \ncalve \noff \nof \nglaciers \nor \nbreak \noff \nof \nice \nshelves. \nEach \niceberg \nhas \nits \nown \nindividual \npersonality. \nThey \nhave \na \ndistinct \nway \nof \ninteracting \nwith \ntheir \nenvironment \nand \ntheir \nexperiences. \nSome \nrefuse \nto \ngive \nup \nand \nhold \non \nto \nthe \nbitter \nend, \nwhile \nothers \ncan't \ntake \nit \nanymore \nand \ncrumble \nin \na \nfit \nof \ndramatic \npassion. \nIt's \neasy \nto \nthink, \nwhen \nyou \nlook \nat \nan \niceberg, \nthat \nthey're \nisolated, \nthat \nthey're \nseparate \nand \nalone, \nmuch \nlike \nwe \nas \nhumans \nsometimes \nview \nourselves. \nBut \nthe \nreality \nis \nfar \nfrom \nit. \nAs \nan \niceberg \nmelts, \nI \nam \nbreathing \nin \nits \nancient \natmosphere. \nAs \nthe \niceberg \nmelts, \nit \nis \nreleasing \nmineral-rich \nfresh \nwater \nthat \nnourishes \nmany \nforms \nof \nlife. \nI \napproach \nphotographing \nthese \nicebergs \nas \nif \nI'm \nmaking \nportraits \nof \nmy \nancestors, \nknowing \nthat \nin \nthese \nindividual \nmoments \nthey \nexist \nin \nthat \nway \nand \nwill \nnever \nexist \nthat \nway \nagain. \nIt \nis \nnot \na \ndeath \nwhen \nthey \nmelt; \nit \nis \nnot \nan \nend, \nbut \na \ncontinuation \nof \ntheir \npath \nthrough \nthe \ncycle \nof \nlife. \nSome \nof \nthe \nice \nin \nthe \nicebergs \nthat \nI \nphotograph \nis \nvery \nyoung \n-- \na \ncouple \nthousand \nyears \nold. \nAnd \nsome \nof \nthe \nice \nis \nover \n100,000 \nyears \nold. \nThe \nlast \npictures \nI'd \nlike \nto \nshow \nyou \nare \nof \nan \niceberg \nthat \nI \nphotographed \nin \nQeqetarsuaq, \nGreenland. \nIt's \na \nvery \nrare \noccasion \nthat \nyou \nget \nto \nactually \nwitness \nan \niceberg \nrolling. \nSo \nhere \nit \nis. \nYou \ncan \nsee \non \nthe \nleft \nside \na \nsmall \nboat. \nThat's \nabout \na \n15-foot \nboat. \nAnd \nI'd \nlike \nyou \nto \npay \nattention \nto \nthe \nshape \nof \nthe \niceberg \nand \nwhere \nit \nis \nat \nthe \nwaterline. \nYou \ncan \nsee \nhere, \nit \nbegins \nto \nroll, \nand \nthe \nboat \nhas \nmoved \nto \nthe \nother \nside, \nand \nthe \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage-size \nGreenlandic \niceberg. \nIt's \nabout \n120 \nfeet \nabove \nthe \nwater, \nor \n40 \nmeters. \nAnd \nthis \nvideo \nis \nreal \ntime. \nAnd \njust \nlike \nthat, \nthe \niceberg \nshows \nyou \na \ndifferent \nside \nof \nits \npersonality. \nThank \nyou.\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nAnd \nthrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother. \nI \nwent \nto \nAntarctica \nfor \nthe \nfirst \ntime \nabout \n10 \nyears \nago, \nand \nI \nsaw \nthe \niceberg \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe. \nAnd \nmy \nheart \nwas \npounding, \nmy \nhead \nwas \npounding, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme.",
        "771b2917-040e-4891-a157-1f1d04250b99": "And \nthe \niceberg \nthat \nwas \nright \nnext \nto \nme \nwas \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \njust \ncouldn't \nhelp \nbut \nfeel \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nand \nover \nagain. \nThe \nformation \nof \nglaciers \nis \nwhen \nthey \nbreak \noff \nfrom \nglaciers, \nor \nbreak \noff \nfrom \nice \nshelves. \nEvery \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \naround \nthem. \nSome \nglaciers \nrefused \nto \ncompromise \nand \ninsisted, \nand \nsome \nglaciers \ncouldn't \nstand \nthe \nheat \nof \npassion \nas \nit \npoured \ndown \nthe \nice. \nWhen \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nseparate, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAnd \nas \nthe \nglacier \nmelts, \nI \nbreathe \nin \nits \nancient \nsmell. \nAnd \nas \nthe \nglacier \nmelts, \nit \nreleases \nfresh \nwater \nof \nminerals \nthat \nnourish \neverything. \nI \nstarted \nphotographing \nthese \nicebergs \nlike \nI \nwas \nphotographing \nmy \nancestors, \nand \nI \nlearned \nthat \nin \nthese \nindividual \nmoments, \nthe \nicebergs \nexisted \nin \nthat \nway, \nbut \nthey \nnever \nexisted \nlike \nthat \nagain. \nWhen \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nit's \nabout \nthe \ncontinuation \nof \na \nlife-long \npath. \nI \nphotographed \nglaciers, \nand \nsome \nof \nthem \nwere \nvery \nyoung \n-- \nthousands \nof \nyears \nold. \nSome \nof \nthe \nice \nhas \nbeen \nthere \nfor \nmore \nthan \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \nan \niceberg \nthat \nI \nphotographed \nin \nKekertsuatsiak \non \nthe \nisland \nof \nGreenland. \nIt's \na \nvery \ndifficult \nopportunity \nto \nactually \nwitness \nthe \nrolling \nof \nan \niceberg. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nYou \ncan \nsee \na \nlittle \nboat \non \nthe \nleft. \nThis \nis \na \n15-foot \nboat. \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nmoves \nover \nthe \nsurface. \nAnd \nhere \nyou \nsee \nit \nrolling, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage \nsize \nglacier \nin \nGreenland. \nIt \nfloats \nabout \n120 \nfeet \nup \nor \n40 \nmeters \nabove \nthe \nsurface. \nThis \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd \nlike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.\nAnd \nas \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nThrough \nmy \nartwork, \nI \ntry \nto \nconvey \nthe \nidea \nthat \nhumans \nare \nnot \nseparated \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother. \nWhen \nI \nfirst \nwent \nto \nAntarctica \nabout \n10 \nyears \nago, \nI \nsaw \nfor \nthe \nfirst \ntime \nicebergs. \nAnd\n \nI \nfelt \nawe. \nMy \nheart \nwas \nshaking, \nmy \nhead \nwas \nshaking, \ntrying \nto \nunderstand \nwhat \nwas \nin \nfront \nof \nme. \nThe \nicebergs \naround \nme \nwere \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \ncould \nonly \nfeel \nhow \nstrange \nit \nwas \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nagain \nover \nand \nover \nagain. \nAnd\n \nicebergs \nform \nwhen \nthey \nbreak \noff \nfrom \nglaciers \nor \nwhen \nthey \nbreak \noff \nfrom \nice \nshelves.\n \nAnd\n \neach \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \nin \nwhich \nthey're \nlocated. \nSome \nicebergs \nrefuse \nto \nsettle \ndown, \nand \nsome \nicebergs \ncan't \nstand \nthe \nheat \nof \npassion \nthat \npours \ndown \nand \nbreaks \nice. \nAnd\n \nwhen \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nindividual, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAs \nthe \nicebergs \nmelt, \nI \nbreathe \nin \nthe \nsmell \nof \nits \nancient \npast. \nAs \nthe \nicebergs \nmelt, \nthey \nrelease \nfresh \nwater \nthat \nis \nrich \nin \nminerals \nthat \nfeed \neverything. \nAnd\n \nI'm \nphotographing \nthese \nicebergs \nlike \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \nlearning \nthat \nin \nthese \nindividual \nmoments, \nicebergs \nused \nto \nexist \nin \nthat \nway \nand \nwill \nnever \nbe \nthe \nsame \nagain. \nWhen \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nbut \nit's \nabout \na \ncontinuation \nof \na \nlifetime. \nAnd\n \nthe \nicebergs \nI've \nphotographed, \nsome \nof \nthem \nare \nvery \nyoung \n-- \nthousands \nof \nyears \nold. \nAnd\n \nsome \nof \nthem \nare \nmore \nthan \n100,000 \nyears \nold. \nAnd\n \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \na \niceberg \nthat \nI \nphotographed \non \nKekertsuatsiak \nin \nGreenland.\n \nAnd\n \nit's \na \nvery \ndifficult \nopportunity \nfor \nyou \nto \nactually \nwitness \nthe \nrolling \nof \na \niceberg. \nSo \nhere \nit \nis. \nOn \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nIt's \na \nlittle \nboat \nabout \n15 \nfeet \nlong. \nAnd\n \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nfloats \nover \nthe \nsurface \nof \nthe \nwater. \nAnd\n \nhere \nyou \nsee \nit \nstart \nto \nroll, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nAnd\n \nthis \nis \nan \naverage \nsize \nIcelandic \niceberg. \nAnd\n \nit \nfloats \nabout \n120 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nor \n40 \nmeters. \nAnd\n \nthis \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd\n \nlike \nthese \nicebergs, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.",
        "7d9cb1b2-5399-421e-a5aa-1119b0989ff9": "Thank \nyou.\nSOURCE\nTARGET\nmBART25 \nSENT-MT\nmBART25 \nDOC-MT\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nfor \nme. \nThrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhuman \nbeings \nare \nnot \nseparated \nfrom \nnature, \nbut \neach \none \nof \nthem \nis \ninterconnected. \nAbout \n10 \nyears \nago, \nI \nfirst \nwent \nto \nAntarctica, \nand \nI \nsaw \nmountains \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe. \nMy \nheart \nwas \nrapidly \nwiped \nout, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme. \nThe \niceberg \nthat \nfloats \naround \nme \nalmost \n200 \nfeet \nof \nwater, \nand \nI \ncan \nonly \nfeel \nstrange \nthat \nthis \nsnow \ncovers \nanother \npiece \nof \nsnow \nfor \na \nyear \nand \nyears. \nThe \nform \nof \nthe \niceberg \nis \nthat \nwhen \nthey \nbreak \napart \nfrom \nthe \nglacier \nor \nbreaking \noff \nthe \nshelves \nof \nice. \nEvery \niceberg \nhas \ntheir \nown \npersonality. \nThey're \ninteracting \nwith \ntheir \nsurrounding \nenvironment \nin \na \nvery \ndifferent \nway. \nSome \nof \nthe \nice \nmountains \nrefused \nto \ncompromise, \nand \nsome \nother \nmountains \nof \nice \ncan't \nendure, \nand \nthe \nwater \ncollapses \nduring \na \nviolent \nice. \nAnd \nwhen \nyou \nlook \nat \nthe \niceberg, \nit's \neasy \nto \nthink \nthat \nthey're \nall \nisolated, \nand \nthey're \nindependent, \nthey're \nunited \nalone, \nand \nsometimes \nwe \nthink \nabout \nourselves. \nBut \nit's \nmore \nthan \nthat. \nAs \nthe \nice \nmelts, \nI \nbreathe \nit, \nancient \nsmell. \nAnd \nas \nthe \nice \nmelts, \nit \nreleases \nthe \nrich \nminerals \nand \nit \nfeeds \n20,000. \nI'm \nphotographing \nthese \nmountains \nof \nice, \nand \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \ntaking \npictures \nof \nmy \nancestors, \nand \nI've \nlearned \nthat \nin \nthese \nindividual \nmoments \nof \nice \nis \nthere \nin \na \nway \nthat's \nthere, \nbut \nit's \nnever \ngoing \nto \nexist \nagain. \nWhen \nthey \nmelt, \nit's \nnot \ndead; \nit's \nnot \nthe \nend; \nit's \nthe \nend, \nit's \na \ncontinuation \nof \ncontinuity \nto \nlife. \nThe \niceberg \nthat \nI \nphotographed, \nsome \nof \nthe \nice \nis \nvery \nyoung \n-- \nthe \nage \nof \nthousands \nof \nyears. \nSome \nof \nthem \nare \nice \nover \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \none \nof \nthe \nices \nI \nmade \nin \nGreenland. \nIt's \na \nvery \ndifficult \nopportunity, \nand \nyou \ncan \nactually \nsee \na \nhill \nrolling. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nAnd \non \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nThis \nis \na \nship \nabout \n15 \nfeet. \nAnd \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nis \nshaped \nin \nthe \nwater. \nAnd \nhere \nyou \nsee \nit \nstarts \nrolling, \nlittle \nboats \nmoving \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage \niceberg \nin \nGreenland. \nIt's \nabout \n120 \nfeet \ntall, \nor \n40 \nmeters. \nThis \nis \na \nreal \ntime \nlapse. \nLike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.\nAs \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist. \nI'm \ngoing \nto \nfocus \non \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier. \nThere's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice. \nIt's \na \nice \nthat's \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat \nI've \nlost. \nThere's \na \nlot \nof \nice \nthat \nI'm \ngoing \nto \nshow \nyou \nsome \npictures \nthat \nI'm \ngoing \nto \nshow \nyou. \nAnd \nyou \ncan \nsee \nthat \nit's \nmoving \nto \nthe \ntop \nof \nit, \nand \nit's \nmoving \nto \nthe \ntop \nof \nit.\nRandom \nSENT-MT\nRandom \nDOC-MTFigure 6: An Example of Document-level translation from mBART25 Sent-MT and Doc-MT , held out from\nthe test set of TED15 Zh-En. The Doc-MT system produces much \ufb02uent and coherent translation which is closer\nto the reference translation. For instance, Doc-MT model produces several \u201cAnd \u201d to connect sentences to make it\nreads better, while the Sent-MT model does not contain global knowledge and produce sentences independently.\nBesides, both systems produce much better translations than models without pre-training where the non-pretrained\nDoc-MT model completely fails to produce readable translation output.",
        "323e2233-3581-460e-b3d2-45c7c5612328": "?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?10\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?200\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?",
        "dc5a7e3d-aae4-4c76-9bdd-4d860c701852": "?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?-- \n?\n?\n?\n?\n?? \n?\n?\n? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n? \nKekertsuatsiak\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?15\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?120\n?\n?\n? \n?\n?40\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n??\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nThrough \nmy \nwork \nI'm \ntrying \nto \narticulate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature \nand \nthat \neverything \nis \ninterconnected. \nI \nfirst \nwent \nto \nAntarctica \nalmost \n10 \nyears \nago, \nwhere \nI \nsaw \nmy \nfirst \nicebergs. \nI \nwas \nin \nawe.",
        "547e3605-5337-421e-89bd-1e48481e0ee4": "I \nwas \nin \nawe. \nMy \nheart \nbeat \nfast, \nmy \nhead \nwas \ndizzy, \ntrying \nto \ncomprehend \nwhat \nit \nwas \nthat \nstood \nin \nfront \nof \nme. \nThe \nicebergs \naround \nme \nwere \nalmost \n200 \nfeet \nout \nof \nthe \nwater, \nand \nI \ncould \nonly \nhelp \nbut \nwonder \nthat \nthis \nwas \none \nsnowflake \non \ntop \nof \nanother \nsnowflake, \nyear \nafter \nyear. \nIcebergs \nare \nborn \nwhen \nthey \ncalve \noff \nof \nglaciers \nor \nbreak \noff \nof \nice \nshelves. \nEach \niceberg \nhas \nits \nown \nindividual \npersonality. \nThey \nhave \na \ndistinct \nway \nof \ninteracting \nwith \ntheir \nenvironment \nand \ntheir \nexperiences. \nSome \nrefuse \nto \ngive \nup \nand \nhold \non \nto \nthe \nbitter \nend, \nwhile \nothers \ncan't \ntake \nit \nanymore \nand \ncrumble \nin \na \nfit \nof \ndramatic \npassion. \nIt's \neasy \nto \nthink, \nwhen \nyou \nlook \nat \nan \niceberg, \nthat \nthey're \nisolated, \nthat \nthey're \nseparate \nand \nalone, \nmuch \nlike \nwe \nas \nhumans \nsometimes \nview \nourselves. \nBut \nthe \nreality \nis \nfar \nfrom \nit. \nAs \nan \niceberg \nmelts, \nI \nam \nbreathing \nin \nits \nancient \natmosphere. \nAs \nthe \niceberg \nmelts, \nit \nis \nreleasing \nmineral-rich \nfresh \nwater \nthat \nnourishes \nmany \nforms \nof \nlife.",
        "11b4de39-24f7-4b1f-903e-a31f63d8149f": "I \napproach \nphotographing \nthese \nicebergs \nas \nif \nI'm \nmaking \nportraits \nof \nmy \nancestors, \nknowing \nthat \nin \nthese \nindividual \nmoments \nthey \nexist \nin \nthat \nway \nand \nwill \nnever \nexist \nthat \nway \nagain. \nIt \nis \nnot \na \ndeath \nwhen \nthey \nmelt; \nit \nis \nnot \nan \nend, \nbut \na \ncontinuation \nof \ntheir \npath \nthrough \nthe \ncycle \nof \nlife. \nSome \nof \nthe \nice \nin \nthe \nicebergs \nthat \nI \nphotograph \nis \nvery \nyoung \n-- \na \ncouple \nthousand \nyears \nold. \nAnd \nsome \nof \nthe \nice \nis \nover \n100,000 \nyears \nold. \nThe \nlast \npictures \nI'd \nlike \nto \nshow \nyou \nare \nof \nan \niceberg \nthat \nI \nphotographed \nin \nQeqetarsuaq, \nGreenland. \nIt's \na \nvery \nrare \noccasion \nthat \nyou \nget \nto \nactually \nwitness \nan \niceberg \nrolling. \nSo \nhere \nit \nis. \nYou \ncan \nsee \non \nthe \nleft \nside \na \nsmall \nboat. \nThat's \nabout \na \n15-foot \nboat. \nAnd \nI'd \nlike \nyou \nto \npay \nattention \nto \nthe \nshape \nof \nthe \niceberg \nand \nwhere \nit \nis \nat \nthe \nwaterline. \nYou \ncan \nsee \nhere, \nit \nbegins \nto \nroll, \nand \nthe \nboat \nhas \nmoved \nto \nthe \nother \nside, \nand \nthe \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage-size \nGreenlandic \niceberg. \nIt's \nabout \n120 \nfeet \nabove \nthe \nwater, \nor \n40 \nmeters. \nAnd \nthis \nvideo \nis \nreal \ntime.",
        "76220002-3d46-4e44-a303-4125ef2a623b": "And \nthis \nvideo \nis \nreal \ntime. \nAnd \njust \nlike \nthat, \nthe \niceberg \nshows \nyou \na \ndifferent \nside \nof \nits \npersonality. \nThank \nyou.\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nAnd \nthrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother. \nI \nwent \nto \nAntarctica \nfor \nthe \nfirst \ntime \nabout \n10 \nyears \nago, \nand \nI \nsaw \nthe \niceberg \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe. \nAnd \nmy \nheart \nwas \npounding, \nmy \nhead \nwas \npounding, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme.",
        "0a391e09-68d8-4ac5-bcf6-7d38ef088f35": "And \nthe \niceberg \nthat \nwas \nright \nnext \nto \nme \nwas \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \njust \ncouldn't \nhelp \nbut \nfeel \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nand \nover \nagain. \nThe \nformation \nof \nglaciers \nis \nwhen \nthey \nbreak \noff \nfrom \nglaciers, \nor \nbreak \noff \nfrom \nice \nshelves. \nEvery \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \naround \nthem. \nSome \nglaciers \nrefused \nto \ncompromise \nand \ninsisted, \nand \nsome \nglaciers \ncouldn't \nstand \nthe \nheat \nof \npassion \nas \nit \npoured \ndown \nthe \nice. \nWhen \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nseparate, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAnd \nas \nthe \nglacier \nmelts, \nI \nbreathe \nin \nits \nancient \nsmell. \nAnd \nas \nthe \nglacier \nmelts, \nit \nreleases \nfresh \nwater \nof \nminerals \nthat \nnourish \neverything.",
        "77f97faa-0cef-406c-99bf-665955ef8e62": "I \nstarted \nphotographing \nthese \nicebergs \nlike \nI \nwas \nphotographing \nmy \nancestors, \nand \nI \nlearned \nthat \nin \nthese \nindividual \nmoments, \nthe \nicebergs \nexisted \nin \nthat \nway, \nbut \nthey \nnever \nexisted \nlike \nthat \nagain. \nWhen \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nit's \nabout \nthe \ncontinuation \nof \na \nlife-long \npath. \nI \nphotographed \nglaciers, \nand \nsome \nof \nthem \nwere \nvery \nyoung \n-- \nthousands \nof \nyears \nold. \nSome \nof \nthe \nice \nhas \nbeen \nthere \nfor \nmore \nthan \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \nan \niceberg \nthat \nI \nphotographed \nin \nKekertsuatsiak \non \nthe \nisland \nof \nGreenland. \nIt's \na \nvery \ndifficult \nopportunity \nto \nactually \nwitness \nthe \nrolling \nof \nan \niceberg. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nYou \ncan \nsee \na \nlittle \nboat \non \nthe \nleft. \nThis \nis \na \n15-foot \nboat. \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nmoves \nover \nthe \nsurface. \nAnd \nhere \nyou \nsee \nit \nrolling, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage \nsize \nglacier \nin \nGreenland. \nIt \nfloats \nabout \n120 \nfeet \nup \nor \n40 \nmeters \nabove \nthe \nsurface. \nThis \nvideo \nwas \ntaken \nin \nreal \ntime.",
        "545b41da-4b45-4637-b972-70577e5acc6a": "This \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd \nlike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.\nAnd \nas \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nThrough \nmy \nartwork, \nI \ntry \nto \nconvey \nthe \nidea \nthat \nhumans \nare \nnot \nseparated \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother. \nWhen \nI \nfirst \nwent \nto \nAntarctica \nabout \n10 \nyears \nago, \nI \nsaw \nfor \nthe \nfirst \ntime \nicebergs. \nAnd\n \nI \nfelt \nawe. \nMy \nheart \nwas \nshaking, \nmy \nhead \nwas \nshaking, \ntrying \nto \nunderstand \nwhat \nwas \nin \nfront \nof \nme. \nThe \nicebergs \naround \nme \nwere \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \ncould \nonly \nfeel \nhow \nstrange \nit \nwas \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nagain \nover \nand \nover \nagain. \nAnd\n \nicebergs \nform \nwhen \nthey \nbreak \noff \nfrom \nglaciers \nor \nwhen \nthey \nbreak \noff \nfrom \nice \nshelves.\n \nAnd\n \neach \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \nin \nwhich \nthey're \nlocated. \nSome \nicebergs \nrefuse \nto \nsettle \ndown, \nand \nsome \nicebergs \ncan't \nstand \nthe \nheat \nof \npassion \nthat \npours \ndown \nand \nbreaks \nice.",
        "fcc654c6-ce14-4f55-85eb-5096089d3fa3": "And\n \nwhen \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nindividual, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAs \nthe \nicebergs \nmelt, \nI \nbreathe \nin \nthe \nsmell \nof \nits \nancient \npast. \nAs \nthe \nicebergs \nmelt, \nthey \nrelease \nfresh \nwater \nthat \nis \nrich \nin \nminerals \nthat \nfeed \neverything. \nAnd\n \nI'm \nphotographing \nthese \nicebergs \nlike \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \nlearning \nthat \nin \nthese \nindividual \nmoments, \nicebergs \nused \nto \nexist \nin \nthat \nway \nand \nwill \nnever \nbe \nthe \nsame \nagain. \nWhen \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nbut \nit's \nabout \na \ncontinuation \nof \na \nlifetime. \nAnd\n \nthe \nicebergs \nI've \nphotographed, \nsome \nof \nthem \nare \nvery \nyoung \n-- \nthousands \nof \nyears \nold. \nAnd\n \nsome \nof \nthem \nare \nmore \nthan \n100,000 \nyears \nold. \nAnd\n \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \na \niceberg \nthat \nI \nphotographed \non \nKekertsuatsiak \nin \nGreenland.\n \nAnd\n \nit's \na \nvery \ndifficult \nopportunity \nfor \nyou \nto \nactually \nwitness \nthe \nrolling \nof \na \niceberg. \nSo \nhere \nit \nis. \nOn \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat.",
        "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d": "On \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nIt's \na \nlittle \nboat \nabout \n15 \nfeet \nlong. \nAnd\n \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nfloats \nover \nthe \nsurface \nof \nthe \nwater. \nAnd\n \nhere \nyou \nsee \nit \nstart \nto \nroll, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nAnd\n \nthis \nis \nan \naverage \nsize \nIcelandic \niceberg. \nAnd\n \nit \nfloats \nabout \n120 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nor \n40 \nmeters. \nAnd\n \nthis \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd\n \nlike \nthese \nicebergs, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.",
        "90337e69-77f0-49dd-86c0-dea2e4aee6a6": "Thank \nyou.\nSOURCE\nTARGET\nmBART25 \nSENT-MT\nmBART25 \nDOC-MT\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nfor \nme. \nThrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhuman \nbeings \nare \nnot \nseparated \nfrom \nnature, \nbut \neach \none \nof \nthem \nis \ninterconnected. \nAbout \n10 \nyears \nago, \nI \nfirst \nwent \nto \nAntarctica, \nand \nI \nsaw \nmountains \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe. \nMy \nheart \nwas \nrapidly \nwiped \nout, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme. \nThe \niceberg \nthat \nfloats \naround \nme \nalmost \n200 \nfeet \nof \nwater, \nand \nI \ncan \nonly \nfeel \nstrange \nthat \nthis \nsnow \ncovers \nanother \npiece \nof \nsnow \nfor \na \nyear \nand \nyears. \nThe \nform \nof \nthe \niceberg \nis \nthat \nwhen \nthey \nbreak \napart \nfrom \nthe \nglacier \nor \nbreaking \noff \nthe \nshelves \nof \nice. \nEvery \niceberg \nhas \ntheir \nown \npersonality. \nThey're \ninteracting \nwith \ntheir \nsurrounding \nenvironment \nin \na \nvery \ndifferent \nway. \nSome \nof \nthe \nice \nmountains \nrefused \nto \ncompromise, \nand \nsome \nother \nmountains \nof \nice \ncan't \nendure, \nand \nthe \nwater \ncollapses \nduring \na \nviolent \nice. \nAnd \nwhen \nyou \nlook \nat \nthe \niceberg, \nit's \neasy \nto \nthink \nthat \nthey're \nall \nisolated, \nand \nthey're \nindependent, \nthey're \nunited \nalone, \nand \nsometimes \nwe \nthink \nabout \nourselves. \nBut \nit's \nmore \nthan \nthat.",
        "4525a9c8-d56f-4322-8868-958f652368f9": "But \nit's \nmore \nthan \nthat. \nAs \nthe \nice \nmelts, \nI \nbreathe \nit, \nancient \nsmell. \nAnd \nas \nthe \nice \nmelts, \nit \nreleases \nthe \nrich \nminerals \nand \nit \nfeeds \n20,000. \nI'm \nphotographing \nthese \nmountains \nof \nice, \nand \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \ntaking \npictures \nof \nmy \nancestors, \nand \nI've \nlearned \nthat \nin \nthese \nindividual \nmoments \nof \nice \nis \nthere \nin \na \nway \nthat's \nthere, \nbut \nit's \nnever \ngoing \nto \nexist \nagain. \nWhen \nthey \nmelt, \nit's \nnot \ndead; \nit's \nnot \nthe \nend; \nit's \nthe \nend, \nit's \na \ncontinuation \nof \ncontinuity \nto \nlife. \nThe \niceberg \nthat \nI \nphotographed, \nsome \nof \nthe \nice \nis \nvery \nyoung \n-- \nthe \nage \nof \nthousands \nof \nyears. \nSome \nof \nthem \nare \nice \nover \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \none \nof \nthe \nices \nI \nmade \nin \nGreenland. \nIt's \na \nvery \ndifficult \nopportunity, \nand \nyou \ncan \nactually \nsee \na \nhill \nrolling. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nAnd \non \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nThis \nis \na \nship \nabout \n15 \nfeet. \nAnd \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nis \nshaped \nin \nthe \nwater.",
        "7ae0e732-82de-463c-b429-b06b07022e66": "And \nhere \nyou \nsee \nit \nstarts \nrolling, \nlittle \nboats \nmoving \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage \niceberg \nin \nGreenland. \nIt's \nabout \n120 \nfeet \ntall, \nor \n40 \nmeters. \nThis \nis \na \nreal \ntime \nlapse. \nLike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.\nAs \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist. \nI'm \ngoing \nto \nfocus \non \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier. \nThere's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice. \nIt's \na \nice \nthat's \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat \nI've \nlost. \nThere's \na \nlot \nof \nice \nthat \nI'm \ngoing \nto \nshow \nyou \nsome \npictures \nthat \nI'm \ngoing \nto \nshow \nyou.",
        "19f38fa9-6e93-4fe7-bdca-73e930c0b318": "And \nyou \ncan \nsee \nthat \nit's \nmoving \nto \nthe \ntop \nof \nit, \nand \nit's \nmoving \nto \nthe \ntop \nof \nit.\nRandom \nSENT-MT\nRandom \nDOC-MTFigure 6: An Example of Document-level translation from mBART25 Sent-MT and Doc-MT , held out from\nthe test set of TED15 Zh-En. The Doc-MT system produces much \ufb02uent and coherent translation which is closer\nto the reference translation. For instance, Doc-MT model produces several \u201cAnd \u201d to connect sentences to make it\nreads better, while the Sent-MT model does not contain global knowledge and produce sentences independently.\nBesides, both systems produce much better translations than models without pre-training where the non-pretrained\nDoc-MT model completely fails to produce readable translation output.",
        "47cb5e54-120b-47ea-88e2-e536da8f555f": "?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?10\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n??",
        "a3328510-bcd4-453b-b3cb-0e28d818e8d4": "?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?200\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?",
        "13b9c2c3-e3c5-4170-b91e-733340579a5f": "?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?",
        "14710cca-f23a-4f7f-8744-cced0d97eae2": "?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?",
        "75d1e09d-ef01-44c2-8555-e0141e9970b4": "?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?",
        "2c93147d-617f-492d-ac36-12c3daccb17f": "?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?",
        "5bd14723-1535-4bd0-b479-585845013fe0": "?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?-- \n?\n?\n?\n?\n?? \n?\n?\n? \n?\n?\n?\n?\n?? \n?\n?",
        "1f39c964-f137-4782-8f76-6fdde4e7b0dc": "?\n?\n?\n?? \n?\n?\n? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n? \nKekertsuatsiak\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?",
        "621223d9-d564-4317-8676-a775a9448a97": "?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?15\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?",
        "f5d377f1-e270-4dcf-859e-aab5e10dbb0d": "?\n?\n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?120\n?\n?\n? \n?\n?40\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n??",
        "1316c9df-42ce-41ad-9a46-e04a04ec59fd": "?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?? \n?\n??\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nThrough \nmy \nwork \nI'm \ntrying \nto \narticulate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature \nand \nthat \neverything \nis \ninterconnected.",
        "b6ffe80f-563f-46c6-860e-a33f81abd002": "I \nfirst \nwent \nto \nAntarctica \nalmost \n10 \nyears \nago, \nwhere \nI \nsaw \nmy \nfirst \nicebergs. \nI \nwas \nin \nawe.",
        "7fac2d94-c6a4-4753-b3ea-9141fe971896": "I \nwas \nin \nawe. \nMy \nheart \nbeat \nfast, \nmy \nhead \nwas \ndizzy, \ntrying \nto \ncomprehend \nwhat \nit \nwas \nthat \nstood \nin \nfront \nof \nme.",
        "4d6dbbc0-3bcb-4d02-b537-d84ca011f451": "The \nicebergs \naround \nme \nwere \nalmost \n200 \nfeet \nout \nof \nthe \nwater, \nand \nI \ncould \nonly \nhelp \nbut \nwonder \nthat \nthis \nwas \none \nsnowflake \non \ntop \nof \nanother \nsnowflake, \nyear \nafter \nyear.",
        "6b9bd6a2-3aae-44ff-bc32-7eb20d6595f9": "Icebergs \nare \nborn \nwhen \nthey \ncalve \noff \nof \nglaciers \nor \nbreak \noff \nof \nice \nshelves. \nEach \niceberg \nhas \nits \nown \nindividual \npersonality. \nThey \nhave \na \ndistinct \nway \nof \ninteracting \nwith \ntheir \nenvironment \nand \ntheir \nexperiences.",
        "7b25cf46-d2e1-42a2-90d3-c3032f8582a0": "Some \nrefuse \nto \ngive \nup \nand \nhold \non \nto \nthe \nbitter \nend, \nwhile \nothers \ncan't \ntake \nit \nanymore \nand \ncrumble \nin \na \nfit \nof \ndramatic \npassion.",
        "5f1e741f-82ce-4d4a-a8c8-1c8c6008901a": "It's \neasy \nto \nthink, \nwhen \nyou \nlook \nat \nan \niceberg, \nthat \nthey're \nisolated, \nthat \nthey're \nseparate \nand \nalone, \nmuch \nlike \nwe \nas \nhumans \nsometimes \nview \nourselves. \nBut \nthe \nreality \nis \nfar \nfrom \nit.",
        "0862ecb0-802e-4500-b4a7-1960afe03651": "But \nthe \nreality \nis \nfar \nfrom \nit. \nAs \nan \niceberg \nmelts, \nI \nam \nbreathing \nin \nits \nancient \natmosphere. \nAs \nthe \niceberg \nmelts, \nit \nis \nreleasing \nmineral-rich \nfresh \nwater \nthat \nnourishes \nmany \nforms \nof \nlife.",
        "d0c828a1-3f9b-4864-9d6f-33c75ce008e5": "I \napproach \nphotographing \nthese \nicebergs \nas \nif \nI'm \nmaking \nportraits \nof \nmy \nancestors, \nknowing \nthat \nin \nthese \nindividual \nmoments \nthey \nexist \nin \nthat \nway \nand \nwill \nnever \nexist \nthat \nway \nagain.",
        "51efc490-0c31-41f2-b299-2af80e5d6a89": "It \nis \nnot \na \ndeath \nwhen \nthey \nmelt; \nit \nis \nnot \nan \nend, \nbut \na \ncontinuation \nof \ntheir \npath \nthrough \nthe \ncycle \nof \nlife. \nSome \nof \nthe \nice \nin \nthe \nicebergs \nthat \nI \nphotograph \nis \nvery \nyoung \n-- \na \ncouple \nthousand \nyears \nold.",
        "303652fd-a1b9-4f4c-81d3-1837f74f93e3": "And \nsome \nof \nthe \nice \nis \nover \n100,000 \nyears \nold. \nThe \nlast \npictures \nI'd \nlike \nto \nshow \nyou \nare \nof \nan \niceberg \nthat \nI \nphotographed \nin \nQeqetarsuaq, \nGreenland.",
        "7303b680-feae-44d0-87c0-f68bb282488e": "It's \na \nvery \nrare \noccasion \nthat \nyou \nget \nto \nactually \nwitness \nan \niceberg \nrolling. \nSo \nhere \nit \nis. \nYou \ncan \nsee \non \nthe \nleft \nside \na \nsmall \nboat. \nThat's \nabout \na \n15-foot \nboat.",
        "29d849c7-9e70-4849-b4e2-0758fb264e9f": "That's \nabout \na \n15-foot \nboat. \nAnd \nI'd \nlike \nyou \nto \npay \nattention \nto \nthe \nshape \nof \nthe \niceberg \nand \nwhere \nit \nis \nat \nthe \nwaterline.",
        "7fa11f66-941f-44e2-9a4d-1b612b3f6249": "You \ncan \nsee \nhere, \nit \nbegins \nto \nroll, \nand \nthe \nboat \nhas \nmoved \nto \nthe \nother \nside, \nand \nthe \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage-size \nGreenlandic \niceberg. \nIt's \nabout \n120 \nfeet \nabove \nthe \nwater, \nor \n40 \nmeters.",
        "ba571bc4-6ceb-46b3-befa-feecc1ff773d": "And \nthis \nvideo \nis \nreal \ntime.",
        "6192f3e7-204f-42f1-bab0-60aeb1ce9443": "And \nthis \nvideo \nis \nreal \ntime. \nAnd \njust \nlike \nthat, \nthe \niceberg \nshows \nyou \na \ndifferent \nside \nof \nits \npersonality. \nThank \nyou.\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme.",
        "d94164a7-e021-4ed0-8d8e-e364fc8bc34a": "As \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme. \nAnd \nthrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhumans \nare \nnot \nseparate \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother.",
        "4bf7d494-b7ee-46a2-92fa-089d7be46494": "I \nwent \nto \nAntarctica \nfor \nthe \nfirst \ntime \nabout \n10 \nyears \nago, \nand \nI \nsaw \nthe \niceberg \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe.",
        "68d3b212-4740-4b35-b82b-9232c06551c9": "I \nfelt \nawe. \nAnd \nmy \nheart \nwas \npounding, \nmy \nhead \nwas \npounding, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme.",
        "5f0d7cf2-3144-487f-b1e4-d2ca121a6c82": "And \nthe \niceberg \nthat \nwas \nright \nnext \nto \nme \nwas \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \njust \ncouldn't \nhelp \nbut \nfeel \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nand \nover \nagain.",
        "96ac833e-7830-4283-b27e-3b214399bd7f": "The \nformation \nof \nglaciers \nis \nwhen \nthey \nbreak \noff \nfrom \nglaciers, \nor \nbreak \noff \nfrom \nice \nshelves. \nEvery \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \naround \nthem.",
        "cb7a05cc-56ac-4595-9b10-acceb86172b2": "Some \nglaciers \nrefused \nto \ncompromise \nand \ninsisted, \nand \nsome \nglaciers \ncouldn't \nstand \nthe \nheat \nof \npassion \nas \nit \npoured \ndown \nthe \nice.",
        "1c8a7bb2-65e6-4e96-a83d-7df4cdcacd73": "When \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nseparate, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat.",
        "e0c75985-3ff1-4c23-abbe-c08b68ea7180": "But \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAnd \nas \nthe \nglacier \nmelts, \nI \nbreathe \nin \nits \nancient \nsmell. \nAnd \nas \nthe \nglacier \nmelts, \nit \nreleases \nfresh \nwater \nof \nminerals \nthat \nnourish \neverything.",
        "ff25b706-4d86-4d9a-b097-5edd904b9a33": "I \nstarted \nphotographing \nthese \nicebergs \nlike \nI \nwas \nphotographing \nmy \nancestors, \nand \nI \nlearned \nthat \nin \nthese \nindividual \nmoments, \nthe \nicebergs \nexisted \nin \nthat \nway, \nbut \nthey \nnever \nexisted \nlike \nthat \nagain.",
        "539f6a55-c8db-45a1-bf6e-b9433438cf16": "When \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nit's \nabout \nthe \ncontinuation \nof \na \nlife-long \npath. \nI \nphotographed \nglaciers, \nand \nsome \nof \nthem \nwere \nvery \nyoung \n-- \nthousands \nof \nyears \nold.",
        "4b3fb072-fb3b-47d5-b12d-978959072f06": "Some \nof \nthe \nice \nhas \nbeen \nthere \nfor \nmore \nthan \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \nan \niceberg \nthat \nI \nphotographed \nin \nKekertsuatsiak \non \nthe \nisland \nof \nGreenland.",
        "f73a0f25-b31a-490b-bf7e-01347b63749a": "It's \na \nvery \ndifficult \nopportunity \nto \nactually \nwitness \nthe \nrolling \nof \nan \niceberg. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nYou \ncan \nsee \na \nlittle \nboat \non \nthe \nleft. \nThis \nis \na \n15-foot \nboat.",
        "79f6e067-baed-475f-987d-f1bacb6e2dba": "This \nis \na \n15-foot \nboat. \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nmoves \nover \nthe \nsurface. \nAnd \nhere \nyou \nsee \nit \nrolling, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere.",
        "e6082d15-af36-44e6-8146-80ecf28dc653": "This \nis \nan \naverage \nsize \nglacier \nin \nGreenland. \nIt \nfloats \nabout \n120 \nfeet \nup \nor \n40 \nmeters \nabove \nthe \nsurface. \nThis \nvideo \nwas \ntaken \nin \nreal \ntime.",
        "ba3a5e1c-1129-4201-b2ed-90364696616d": "This \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd \nlike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.\nAnd \nas \nan \nartist, \nconnection \nis \nvery \nimportant \nto \nme.",
        "107485df-b507-4ba1-a34a-097acacd324a": "Through \nmy \nartwork, \nI \ntry \nto \nconvey \nthe \nidea \nthat \nhumans \nare \nnot \nseparated \nfrom \nnature, \nbut \nthat \neverything \nis \nconnected \nto \neach \nother. \nWhen \nI \nfirst \nwent \nto \nAntarctica \nabout \n10 \nyears \nago, \nI \nsaw \nfor \nthe \nfirst \ntime \nicebergs.",
        "b48abc17-bae5-4f12-bdce-a224348abd6d": "And\n \nI \nfelt \nawe. \nMy \nheart \nwas \nshaking, \nmy \nhead \nwas \nshaking, \ntrying \nto \nunderstand \nwhat \nwas \nin \nfront \nof \nme.",
        "6d59231d-30a1-4b15-b1a9-30c7d23699d9": "The \nicebergs \naround \nme \nwere \nfloating \nalmost \n200 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nand \nI \ncould \nonly \nfeel \nhow \nstrange \nit \nwas \nthat \nthis \nwas \na \nsnowflake \ncovering \nanother \nsnowflake, \nforming \nover \nand \nover \nagain \nover \nand \nover \nagain.",
        "981a1b11-2631-4149-b1a9-0b8efa11e9b8": "And\n \nicebergs \nform \nwhen \nthey \nbreak \noff \nfrom \nglaciers \nor \nwhen \nthey \nbreak \noff \nfrom \nice \nshelves.\n \nAnd\n \neach \niceberg \nhas \nits \nown \nunique \npersonality.",
        "8e516b8e-0854-4102-abf0-39b19d4f3360": "And\n \neach \niceberg \nhas \nits \nown \nunique \npersonality. \nThey \ninteract \nin \na \nvery \ndistinctive \nway \nwith \nthe \nenvironment \naround \nthem \nand \nwith \nthe \ncircumstances \nin \nwhich \nthey're \nlocated.",
        "e743f6b9-8ecd-47e0-aead-880c9de1a0ec": "Some \nicebergs \nrefuse \nto \nsettle \ndown, \nand \nsome \nicebergs \ncan't \nstand \nthe \nheat \nof \npassion \nthat \npours \ndown \nand \nbreaks \nice.",
        "2fc8607c-a98b-4e36-ab52-a869b98cd08c": "And\n \nwhen \nyou \nlook \nat \nicebergs, \nit's \neasy \nto \nthink \nthat \nthey're \nisolated, \nthat \nthey're \nindependent, \nthat \nthey're \nindividual, \nthat \nthey're \nmore \nlike \nthe \nway \nwe \nthink \nabout \nourselves \nsometimes. \nBut \nthe \nreality \nis \nmuch \nmore \nthan \nthat.",
        "f2af29e0-e1e8-4c7f-85ae-f17e2ed757b1": "But \nthe \nreality \nis \nmuch \nmore \nthan \nthat. \nAs \nthe \nicebergs \nmelt, \nI \nbreathe \nin \nthe \nsmell \nof \nits \nancient \npast. \nAs \nthe \nicebergs \nmelt, \nthey \nrelease \nfresh \nwater \nthat \nis \nrich \nin \nminerals \nthat \nfeed \neverything.",
        "120aaf13-3d31-4efd-8299-20efc8f78e19": "And\n \nI'm \nphotographing \nthese \nicebergs \nlike \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \nlearning \nthat \nin \nthese \nindividual \nmoments, \nicebergs \nused \nto \nexist \nin \nthat \nway \nand \nwill \nnever \nbe \nthe \nsame \nagain.",
        "5cf18ea9-c0a0-4851-80f9-94d3b5a59116": "When \nthey \nmelt, \nit's \nnot \nabout \ndeath; \nit's \nnot \nabout \nthe \nend, \nbut \nit's \nabout \na \ncontinuation \nof \na \nlifetime. \nAnd\n \nthe \nicebergs \nI've \nphotographed, \nsome \nof \nthem \nare \nvery \nyoung \n-- \nthousands \nof \nyears \nold.",
        "7b7e6cb8-a4e7-4860-b4e3-a582f2ed813f": "And\n \nsome \nof \nthem \nare \nmore \nthan \n100,000 \nyears \nold. \nAnd\n \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \na \niceberg \nthat \nI \nphotographed \non \nKekertsuatsiak \nin \nGreenland.",
        "220dd70f-7c9d-4080-a1d7-d9560d1c91ea": "And\n \nit's \na \nvery \ndifficult \nopportunity \nfor \nyou \nto \nactually \nwitness \nthe \nrolling \nof \na \niceberg. \nSo \nhere \nit \nis. \nOn \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat.",
        "5d3a99e5-dea9-4879-bcbc-2180b007b2ba": "On \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nIt's \na \nlittle \nboat \nabout \n15 \nfeet \nlong. \nAnd\n \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nchanges \nas \nit \nfloats \nover \nthe \nsurface \nof \nthe \nwater.",
        "b61443e9-2f9d-4dfc-8548-0117f4be4b23": "And\n \nhere \nyou \nsee \nit \nstart \nto \nroll, \nand \nthe \nboat \nmoves \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nAnd\n \nthis \nis \nan \naverage \nsize \nIcelandic \niceberg.",
        "050d8316-6c64-4c86-a8c7-406c63d09cf3": "And\n \nthis \nis \nan \naverage \nsize \nIcelandic \niceberg. \nAnd\n \nit \nfloats \nabout \n120 \nfeet \nabove \nthe \nsurface \nof \nthe \nwater, \nor \n40 \nmeters. \nAnd\n \nthis \nvideo \nwas \ntaken \nin \nreal \ntime.",
        "ba7dd23b-b780-48f0-b805-766b6fd25873": "And\n \nthis \nvideo \nwas \ntaken \nin \nreal \ntime. \nAnd\n \nlike \nthese \nicebergs, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.",
        "60c25781-b327-4fa2-be57-185a8baf6545": "Thank \nyou.\nSOURCE\nTARGET\nmBART25 \nSENT-MT\nmBART25 \nDOC-MT\nAs \nan \nartist, \nconnection \nis \nvery \nimportant \nfor \nme. \nThrough \nmy \nartwork, \nI \ntry \nto \nillustrate \nthat \nhuman \nbeings \nare \nnot \nseparated \nfrom \nnature, \nbut \neach \none \nof \nthem \nis \ninterconnected.",
        "c187f805-57e9-4c48-8e5c-c0de2b453c1b": "About \n10 \nyears \nago, \nI \nfirst \nwent \nto \nAntarctica, \nand \nI \nsaw \nmountains \nfor \nthe \nfirst \ntime. \nI \nfelt \nawe. \nMy \nheart \nwas \nrapidly \nwiped \nout, \ntrying \nto \nfigure \nout \nwhat \nwas \ngoing \non \nin \nfront \nof \nme.",
        "e655b8ef-c41a-4596-9156-274d151bf055": "The \niceberg \nthat \nfloats \naround \nme \nalmost \n200 \nfeet \nof \nwater, \nand \nI \ncan \nonly \nfeel \nstrange \nthat \nthis \nsnow \ncovers \nanother \npiece \nof \nsnow \nfor \na \nyear \nand \nyears.",
        "b26d4a03-5fa5-4ea9-b513-27c83357a3b2": "The \nform \nof \nthe \niceberg \nis \nthat \nwhen \nthey \nbreak \napart \nfrom \nthe \nglacier \nor \nbreaking \noff \nthe \nshelves \nof \nice. \nEvery \niceberg \nhas \ntheir \nown \npersonality. \nThey're \ninteracting \nwith \ntheir \nsurrounding \nenvironment \nin \na \nvery \ndifferent \nway.",
        "62cf9597-3ebc-4113-9166-c23f992df1bf": "Some \nof \nthe \nice \nmountains \nrefused \nto \ncompromise, \nand \nsome \nother \nmountains \nof \nice \ncan't \nendure, \nand \nthe \nwater \ncollapses \nduring \na \nviolent \nice.",
        "9aa8043e-005a-4b9a-915a-4985fcfb466c": "And \nwhen \nyou \nlook \nat \nthe \niceberg, \nit's \neasy \nto \nthink \nthat \nthey're \nall \nisolated, \nand \nthey're \nindependent, \nthey're \nunited \nalone, \nand \nsometimes \nwe \nthink \nabout \nourselves. \nBut \nit's \nmore \nthan \nthat.",
        "8fcf9fe0-c222-4b61-bb2e-eb99b50e8c68": "But \nit's \nmore \nthan \nthat. \nAs \nthe \nice \nmelts, \nI \nbreathe \nit, \nancient \nsmell. \nAnd \nas \nthe \nice \nmelts, \nit \nreleases \nthe \nrich \nminerals \nand \nit \nfeeds \n20,000. \nI'm \nphotographing \nthese \nmountains \nof \nice,",
        "52c4ce34-e0a1-46a4-a350-ffabd91e9c7e": "I'm \nphotographing \nthese \nmountains \nof \nice, \nand \nI'm \nphotographing \nmy \nancestors, \nand \nI'm \ntaking \npictures \nof \nmy \nancestors, \nand \nI've \nlearned \nthat \nin \nthese \nindividual \nmoments \nof \nice \nis \nthere \nin \na \nway \nthat's \nthere,",
        "f398a719-ed97-4da4-9116-06e1706aea47": "but \nit's \nnever \ngoing \nto \nexist \nagain. \nWhen \nthey \nmelt, \nit's \nnot \ndead; \nit's \nnot \nthe \nend; \nit's \nthe \nend, \nit's \na \ncontinuation \nof \ncontinuity \nto \nlife.",
        "1436dc47-e876-460a-917b-db6bf153e5e8": "The \niceberg \nthat \nI \nphotographed, \nsome \nof \nthe \nice \nis \nvery \nyoung \n-- \nthe \nage \nof \nthousands \nof \nyears. \nSome \nof \nthem \nare \nice \nover \n100,000 \nyears. \nAnd \nthe \nlast \npicture \nI \nwant \nto \nshow \nyou \nis \none \nof \nthe \nices \nI \nmade \nin \nGreenland.",
        "456fe4d6-ef37-4ca5-9784-267a9a156017": "It's \na \nvery \ndifficult \nopportunity, \nand \nyou \ncan \nactually \nsee \na \nhill \nrolling. \nSo \nthis \nis \nwhat \nit \nlooks \nlike. \nAnd \non \nthe \nleft \nyou \ncan \nsee \na \nlittle \nboat. \nThis \nis \na \nship \nabout \n15 \nfeet.",
        "b729c360-d497-4581-a88d-068d1cf27ff2": "This \nis \na \nship \nabout \n15 \nfeet. \nAnd \nI \nwant \nyou \nto \nnotice \nthat \nthe \nshape \nof \nthe \niceberg \nis \nshaped \nin \nthe \nwater.",
        "95a712b6-9891-43a9-9994-8a0587057407": "And \nhere \nyou \nsee \nit \nstarts \nrolling, \nlittle \nboats \nmoving \nto \nthe \nother \nside, \nand \na \nman \nis \nstanding \nthere. \nThis \nis \nan \naverage \niceberg \nin \nGreenland. \nIt's \nabout \n120 \nfeet \ntall, \nor \n40 \nmeters. \nThis \nis \na \nreal \ntime \nlapse.",
        "00850a17-8e00-481d-aa04-32b1ac9f2771": "This \nis \na \nreal \ntime \nlapse. \nLike \nthis \niceberg, \nthey \nshow \nyou \ndifferent \naspects \nof \ntheir \npersonality. \nThank \nyou.",
        "0bc2c3e8-94d8-43ef-befc-136b7ae08eb7": "Thank \nyou.\nAs \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist, \nas \nan \nartist.",
        "18f6542e-8638-4eee-9d51-c94e37d7a7ae": "I'm \ngoing \nto \nfocus \non \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier \nand \nthe \nglacier.",
        "690367d5-07a0-456b-a36c-4e5693f4bc7e": "There's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice, \nand \nthere's \na \nlot \nof \nice \nin \nthe \nice \nin \nthe \nice.",
        "566e76bc-9e10-4952-8cd9-843a60a3ed40": "It's \na \nice \nthat's \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat's \nmelted \nfrom \nthe \nice \nof \nthe \nice \nthat \nI've \nlost.",
        "40d6c4a3-7e9d-45c4-b82e-cfe0db95d046": "There's \na \nlot \nof \nice \nthat \nI'm \ngoing \nto \nshow \nyou \nsome \npictures \nthat \nI'm \ngoing \nto \nshow \nyou.",
        "03b47759-2bbd-4033-815e-0098429cb1ce": "And \nyou \ncan \nsee \nthat \nit's \nmoving \nto \nthe \ntop \nof \nit, \nand \nit's \nmoving \nto \nthe \ntop \nof \nit.\nRandom \nSENT-MT\nRandom \nDOC-MTFigure 6: An Example of Document-level translation from mBART25 Sent-MT and Doc-MT , held out from\nthe test set of TED15 Zh-En.",
        "87f3ed11-746d-4765-bbca-bf9ad82999ed": "The Doc-MT system produces much \ufb02uent and coherent translation which is closer\nto the reference translation. For instance, Doc-MT model produces several \u201cAnd \u201d to connect sentences to make it\nreads better, while the Sent-MT model does not contain global knowledge and produce sentences independently.\nBesides, both systems produce much better translations than models without pre-training where the non-pretrained\nDoc-MT model completely fails to produce readable translation output.",
        "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8": "?\n?\n?\n?\n?\n?\n?\n?\n?,\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n??\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nChief \nMedical \nOfficers' \nCouncil \nis \ncalling \ntoday \nfor \na \nspecial \nsession \nat \nthe \nCouncil \nof \nthe \nBritish \nMedical \nAssociation\n, \nwhich \nis \na \nlong-term \ninitiative \nto \nupgrade \nlabor \nfrom \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nJDC \nexec \nhas \ntoday \nmade \na \nformal \nrequest \nfor \na \nspecial \nmeeting \nof \nBMA \nCouncil\n \nto \nauthorise \na \nrolling \nprogramme \nof \nescalated \nindustrial \naction\n \nbeginning \nin \nearly \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nCouncil \nof \nChief \nMedical \nOfficers\n \nhas \nformally \nrequested \ntoday \nthe \nRoyal \nCollege \nof \nPhysicians\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term\n \nworkforce \naction\n \nthat \nstarts \nin \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nBoard \nof \nPrimary \nDoctors\n \nhas \ntoday \nformally \nasked \nthe \nBritish \nMedical \nAssociation\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term \nplan \nthat \nstarts \nin \nthe \nbeginning \nof \nSeptember.\nSOURCE\nZh\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n??\n? \n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\nIt's \ncommonplace \nin \ncountries \nlike \nCanada \nand \nthe \nUnited \nStates \nand \nmany \nother\n?\n? \ncountries\n, \nbut \nit's \nnot \ncommonplace \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nclan \nsocieties\n, \nwhere \nschooling\n \nis \na \nbig \ndeal \nfor \ngirls.\nIt \nmay \nbe \ntaken \nfor \ngranted \nin \nCanada, \nin \nAmerica, \nin \nmany \ndeveloped \ncountries, \nbut \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \ntribal \nsocieties, \nit's \na \nbig \nevent \nfor \nthe \nlife \nof \ngirl.\nIn \nCanada, \nin \nthe \nUnited \nStates, \nand \nmany \nother \ndeveloped \ncountries, \nit's \ntaken \nfor \ngranted \nthat \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin\n \ntribal \nsocieties\n, \neducation\n \nis \nvery \nimportant \nfor \ngirls.\nIt's \ncommonplace \nin \nCanada, \nin \nthe \nU.S., \nand \nin \nmany \nother \ncountries \nin \nthe \nworld, \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nethnic \nsocieties, \nthat \neducation\n \nis \na \npriority \nfor \ngirls.\nSOURCE\nJa\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n??? \n???, \n? \n?? \n???? \n?? \n?? \n??? \n??? \n?? \n?????. \n??? \n? \n???? \n? \n? \n??? \n??? \n??? \n?? \n1,000 \n?? \n?? \n??? \n??? \n??? \n??? \n??? \n???? \n????.\nThe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets\n, \nbut \nat \nthis \npoint, \nbigger \nmagnets \nonly \ngive \nus \na \nlittle \nbit \nof \nresolution \nimprovement, \nnot \n1,000 \ntimes \nas \nmuch \nas \nwe \nneed.\nConventional \nwisdom \nsays \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets, \nbut \nat \nthis \npoint \nbigger \nmagnets \nonly \noffer \nincremental \nresolution \nimprovements, \nnot \nthe \nthousandfold \nwe \nneed\nIn \nthe \nconventional \nwisdom, \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nthe \nbig \ncushions\n, \nbut \nat \nthis \npoint, \nthe \nbigger \ncushions \ngive \nus \njust \na \nlittle \nbit \nmore \nresolution \nthan \nwe \nneed \nto \nget \n1,000 \ntimes \nbetter.\nAnd \nthe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \na \nhigher \nresolution \nis \nwith \nlarge \njellyfish\n, \nbut \nat \nthis \npoint \nin \ntime, \nbig \njellyfish \nis \nonly \ngoing \nto \nprovide \nus \nwith \n1,000 \ntimes \nas \nmuch \nresolution \nas \nwe \nneed \nwith \njust \na \nlittle \nbit \nof \nresolution \nimprovement.\nSOURCE\nKo\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-EnFigure 7: Examples of Unsupervised MT via Language Transfer between Ja,Ko,Zh\u2192En. We mark the su-\npervised settings in red. All three languages have quite different character sets (Ja and Zh shares part of the Chinese\ncharacters) and syntactic structures. However, they are still culturally and historically correlated, which we assume\ncan be captured through pre-training. For all cases, if we \ufb01ne-tune the mBART25 model on any pair, the resulted\nmodel directly translates well in the other two pairs without seeing any corresponded parallel sentences. We also\nsee failure cases. For instance (the 3rd example), only the supervised model translates \u201c \uc790\uc11d\u201d into \u201cmagents\u201d cor-\nrectly, while the Ja-En and Zh-En guess with irreverent words \u201ccushions\u201d and \u201cjelly\ufb01sh\u201d, respectively. Also, in the\n2nd example, the Ko-En model fails to translate \u201cdeveloped\u201d and copies the source tokens. We suspect it is because\nthe pre-training stage biases the output distribution.",
        "b0627309-95f0-42fc-9a91-3f7cfce2b5b4": "?\n?\n?\n?\n?\n?\n?\n?\n?,\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n??\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nChief \nMedical \nOfficers' \nCouncil \nis \ncalling \ntoday \nfor \na \nspecial \nsession \nat \nthe \nCouncil \nof \nthe \nBritish \nMedical \nAssociation\n, \nwhich \nis \na \nlong-term \ninitiative \nto \nupgrade \nlabor \nfrom \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nJDC \nexec \nhas \ntoday \nmade \na \nformal \nrequest \nfor \na \nspecial \nmeeting \nof \nBMA \nCouncil\n \nto \nauthorise \na \nrolling \nprogramme \nof \nescalated \nindustrial \naction\n \nbeginning \nin \nearly \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nCouncil \nof \nChief \nMedical \nOfficers\n \nhas \nformally \nrequested \ntoday \nthe \nRoyal \nCollege \nof \nPhysicians\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term\n \nworkforce \naction\n \nthat \nstarts \nin \nSeptember.\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nBoard \nof \nPrimary \nDoctors\n \nhas \ntoday \nformally \nasked \nthe \nBritish \nMedical \nAssociation\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term \nplan \nthat \nstarts \nin \nthe \nbeginning \nof \nSeptember.\nSOURCE\nZh\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n??\n? \n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?",
        "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b": "?\n? \n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\nIt's \ncommonplace \nin \ncountries \nlike \nCanada \nand \nthe \nUnited \nStates \nand \nmany \nother\n?\n? \ncountries\n, \nbut \nit's \nnot \ncommonplace \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nclan \nsocieties\n, \nwhere \nschooling\n \nis \na \nbig \ndeal \nfor \ngirls.\nIt \nmay \nbe \ntaken \nfor \ngranted \nin \nCanada, \nin \nAmerica, \nin \nmany \ndeveloped \ncountries, \nbut \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \ntribal \nsocieties, \nit's \na \nbig \nevent \nfor \nthe \nlife \nof \ngirl.\nIn \nCanada, \nin \nthe \nUnited \nStates, \nand \nmany \nother \ndeveloped \ncountries, \nit's \ntaken \nfor \ngranted \nthat \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin\n \ntribal \nsocieties\n, \neducation\n \nis \nvery \nimportant \nfor \ngirls.\nIt's \ncommonplace \nin \nCanada, \nin \nthe \nU.S., \nand \nin \nmany \nother \ncountries \nin \nthe \nworld, \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nethnic \nsocieties, \nthat \neducation\n \nis \na \npriority \nfor \ngirls.\nSOURCE\nJa\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n??? \n???, \n? \n?? \n???? \n?? \n?? \n??? \n??? \n?? \n?????. \n??? \n? \n???? \n? \n? \n??? \n??? \n??? \n?? \n1,000 \n?? \n?? \n??? \n??? \n??? \n?",
        "15eefdc1-4605-4ff9-928c-d0eedacb6aa5": "1,000 \n?? \n?? \n??? \n??? \n??? \n??? \n??? \n???? \n????.\nThe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets\n, \nbut \nat \nthis \npoint, \nbigger \nmagnets \nonly \ngive \nus \na \nlittle \nbit \nof \nresolution \nimprovement, \nnot \n1,000 \ntimes \nas \nmuch \nas \nwe \nneed.\nConventional \nwisdom \nsays \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets, \nbut \nat \nthis \npoint \nbigger \nmagnets \nonly \noffer \nincremental \nresolution \nimprovements, \nnot \nthe \nthousandfold \nwe \nneed\nIn \nthe \nconventional \nwisdom, \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nthe \nbig \ncushions\n, \nbut \nat \nthis \npoint, \nthe \nbigger \ncushions \ngive \nus \njust \na \nlittle \nbit \nmore \nresolution \nthan \nwe \nneed \nto \nget \n1,000 \ntimes \nbetter.\nAnd \nthe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \na \nhigher \nresolution \nis \nwith \nlarge \njellyfish\n, \nbut \nat \nthis \npoint \nin \ntime, \nbig \njellyfish \nis \nonly \ngoing \nto \nprovide \nus \nwith \n1,000 \ntimes \nas \nmuch \nresolution \nas \nwe \nneed \nwith \njust \na \nlittle \nbit \nof \nresolution \nimprovement.\nSOURCE\nKo\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-EnFigure 7: Examples of Unsupervised MT via Language Transfer between Ja,Ko,Zh\u2192En. We mark the su-\npervised settings in red.",
        "7b2c028c-533e-4528-a28e-532818bbb4a8": "We mark the su-\npervised settings in red. All three languages have quite different character sets (Ja and Zh shares part of the Chinese\ncharacters) and syntactic structures. However, they are still culturally and historically correlated, which we assume\ncan be captured through pre-training. For all cases, if we \ufb01ne-tune the mBART25 model on any pair, the resulted\nmodel directly translates well in the other two pairs without seeing any corresponded parallel sentences. We also\nsee failure cases. For instance (the 3rd example), only the supervised model translates \u201c \uc790\uc11d\u201d into \u201cmagents\u201d cor-\nrectly, while the Ja-En and Zh-En guess with irreverent words \u201ccushions\u201d and \u201cjelly\ufb01sh\u201d, respectively. Also, in the\n2nd example, the Ko-En model fails to translate \u201cdeveloped\u201d and copies the source tokens. We suspect it is because\nthe pre-training stage biases the output distribution.",
        "4377b038-ed8a-4415-8e56-7bd8210e6fee": "?\n?\n?\n?\n?\n?\n?\n?\n?,\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n??",
        "02a8b02d-f6e2-4504-a515-e7778e4e01d5": "?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n??\nIn \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nChief \nMedical \nOfficers' \nCouncil \nis \ncalling \ntoday \nfor \na \nspecial \nsession \nat \nthe \nCouncil \nof \nthe \nBritish \nMedical \nAssociation\n, \nwhich \nis \na \nlong-term \ninitiative \nto \nupgrade \nlabor \nfrom \nSeptember.",
        "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed": "In \nresponse \nto \nthe \ngovernment's \nsilence, \nJDC \nexec \nhas \ntoday \nmade \na \nformal \nrequest \nfor \na \nspecial \nmeeting \nof \nBMA \nCouncil\n \nto \nauthorise \na \nrolling \nprogramme \nof \nescalated \nindustrial \naction\n \nbeginning \nin \nearly \nSeptember.",
        "9b7ca718-35b2-4613-be2a-d7dac02f6b7f": "In \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nCouncil \nof \nChief \nMedical \nOfficers\n \nhas \nformally \nrequested \ntoday \nthe \nRoyal \nCollege \nof \nPhysicians\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term\n \nworkforce \naction\n \nthat \nstarts \nin \nSeptember.",
        "bba5d4b1-baab-4996-9f27-e22a53afa40d": "In \nresponse \nto \nthe \ngovernment's \nsilence, \nthe \nBoard \nof \nPrimary \nDoctors\n \nhas \ntoday \nformally \nasked \nthe \nBritish \nMedical \nAssociation\n \nto \nhold \na \nspecial \nmeeting \nto \napprove \na \nlong-term \nplan \nthat \nstarts \nin \nthe \nbeginning \nof \nSeptember.",
        "bf0d3075-21ba-4f2b-8b03-4739b5bde415": "SOURCE\nZh\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n??\n? \n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?",
        "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4": "?\n? \n?\n?\n?\n?\n??\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\n?\n?\n?\n?\n?\n? \n?\n?\n?\n?\n?\nIt's \ncommonplace \nin \ncountries \nlike \nCanada \nand \nthe \nUnited \nStates \nand \nmany \nother\n?\n?",
        "d870d02b-d9ed-41df-b207-daa6435cc24c": "? \ncountries\n, \nbut \nit's \nnot \ncommonplace \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nclan \nsocieties\n, \nwhere \nschooling\n \nis \na \nbig \ndeal \nfor \ngirls.",
        "5ed9f213-841d-4176-bccf-fe27c2c0ca1d": "It \nmay \nbe \ntaken \nfor \ngranted \nin \nCanada, \nin \nAmerica, \nin \nmany \ndeveloped \ncountries, \nbut \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \ntribal \nsocieties, \nit's \na \nbig \nevent \nfor \nthe \nlife \nof \ngirl.",
        "89de1df1-68ad-4d4a-9afb-1fedb2cab839": "In \nCanada, \nin \nthe \nUnited \nStates, \nand \nmany \nother \ndeveloped \ncountries, \nit's \ntaken \nfor \ngranted \nthat \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin\n \ntribal \nsocieties\n, \neducation\n \nis \nvery \nimportant \nfor \ngirls.",
        "1a147719-08e4-4f5d-9fca-62c5e040241f": "It's \ncommonplace \nin \nCanada, \nin \nthe \nU.S., \nand \nin \nmany \nother \ncountries \nin \nthe \nworld, \nin \npoor \ncountries, \nin \npatriarchal \nsocieties, \nin \nethnic \nsocieties, \nthat \neducation\n \nis \na \npriority \nfor \ngirls.",
        "8b3b3bdb-3a4f-480f-9f4e-111b93c136af": "SOURCE\nJa\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-En\n??? \n???, \n? \n?? \n???? \n?? \n?? \n??? \n??? \n?? \n?????. \n??? \n? \n???? \n? \n? \n??? \n??? \n??? \n?? \n1,000 \n?",
        "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343": "? \n??? \n??? \n??? \n?? \n1,000 \n?? \n?? \n??? \n??? \n??? \n?",
        "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9": "1,000 \n?? \n?? \n??? \n??? \n??? \n??? \n??? \n???? \n????.",
        "627b11ca-8bde-4dfc-b1ea-bb0f4c6f2e12": "?? \n??? \n??? \n??? \n??? \n???? \n????.\nThe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets\n, \nbut \nat \nthis \npoint, \nbigger \nmagnets \nonly \ngive \nus \na \nlittle \nbit \nof \nresolution \nimprovement, \nnot \n1,000 \ntimes \nas \nmuch \nas \nwe \nneed.",
        "242c74bd-dbb2-4312-aa1b-51818c0a02cb": "Conventional \nwisdom \nsays \nthe \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nbigger \nmagnets, \nbut \nat \nthis \npoint \nbigger \nmagnets \nonly \noffer \nincremental \nresolution \nimprovements, \nnot \nthe \nthousandfold \nwe \nneed\nIn \nthe \nconventional \nwisdom,",
        "2f5613ef-ef71-47cb-a232-b7f427f294f4": "the \nonly \nway \nto \nget \nhigher \nresolution \nis \nwith \nthe \nbig \ncushions\n, \nbut \nat \nthis \npoint, \nthe \nbigger \ncushions \ngive \nus \njust \na \nlittle \nbit \nmore \nresolution \nthan \nwe \nneed \nto \nget \n1,000 \ntimes \nbetter.",
        "6f16f638-86ff-4dc3-af58-0683faaa7235": "000 \ntimes \nbetter.\nAnd \nthe \nconventional \nwisdom \nis \nthat \nthe \nonly \nway \nto \nget \na \nhigher \nresolution \nis \nwith \nlarge \njellyfish\n, \nbut \nat \nthis \npoint \nin \ntime, \nbig \njellyfish \nis \nonly \ngoing \nto \nprovide \nus \nwith \n1,",
        "1783f958-e54b-487a-b553-37a674e58dc7": "000 \ntimes \nas \nmuch \nresolution \nas \nwe \nneed \nwith \njust \na \nlittle \nbit \nof \nresolution \nimprovement.\nSOURCE\nKo\nTARGET\nEn\nmBART25 \nJa-En\nmBART25 \nKo-En\nmBART25 \nZh-EnFigure 7: Examples of Unsupervised MT via Language Transfer between Ja,Ko,Zh\u2192En.",
        "18e7d1ef-398c-4757-b5bb-e68a125f0046": "We mark the su-\npervised settings in red.",
        "60fe6772-d507-4875-a61e-c28cdb119c84": "We mark the su-\npervised settings in red. All three languages have quite different character sets (Ja and Zh shares part of the Chinese\ncharacters) and syntactic structures. However, they are still culturally and historically correlated, which we assume\ncan be captured through pre-training.",
        "a74aca60-1490-498f-8a8f-33a3fd9fb48c": "For all cases, if we \ufb01ne-tune the mBART25 model on any pair, the resulted\nmodel directly translates well in the other two pairs without seeing any corresponded parallel sentences. We also\nsee failure cases.",
        "9937a5f7-caee-49f6-9a3f-c5aa775425ca": "We also\nsee failure cases. For instance (the 3rd example), only the supervised model translates \u201c \uc790\uc11d\u201d into \u201cmagents\u201d cor-\nrectly, while the Ja-En and Zh-En guess with irreverent words \u201ccushions\u201d and \u201cjelly\ufb01sh\u201d, respectively. Also, in the\n2nd example, the Ko-En model fails to translate \u201cdeveloped\u201d and copies the source tokens.",
        "0e5b497a-c67f-4527-bcbe-67bc369d3467": "We suspect it is because\nthe pre-training stage biases the output distribution."
    },
    "relevant_docs": {
        "f75238a7-2b43-44db-8689-822d51cacfad": [
            "36970c66-6851-4c7e-bef9-3a0f62405461"
        ],
        "a352edb8-cfc9-4922-ae2c-3e6ccb1a080f": [
            "36970c66-6851-4c7e-bef9-3a0f62405461"
        ],
        "f3d986cd-d22a-4de5-9127-6bcee1d344e6": [
            "36970c66-6851-4c7e-bef9-3a0f62405461"
        ],
        "5f2bc3c4-a846-4469-ba64-9f35e6e2bb75": [
            "36970c66-6851-4c7e-bef9-3a0f62405461"
        ],
        "a4c695cb-4e0f-4348-9305-bd5fbb78e517": [
            "36970c66-6851-4c7e-bef9-3a0f62405461"
        ],
        "84137b2e-502b-4f07-b3f3-06e3888ff932": [
            "d3b0af95-8db3-4244-8b93-0f1951eda2ab"
        ],
        "23d6cfa0-00e0-4385-bfef-8405f02e2e24": [
            "d3b0af95-8db3-4244-8b93-0f1951eda2ab"
        ],
        "44c9ed66-7839-4c17-b051-b3e5f51d4604": [
            "d3b0af95-8db3-4244-8b93-0f1951eda2ab"
        ],
        "becbc11b-55e4-49b2-bb42-a171d8b8b37d": [
            "d3b0af95-8db3-4244-8b93-0f1951eda2ab"
        ],
        "0a397257-ff20-4d22-9be4-a1ca3bfa0d69": [
            "d3b0af95-8db3-4244-8b93-0f1951eda2ab"
        ],
        "446518b5-5d85-4463-8367-dc514602b4c8": [
            "37caa115-53da-49ba-94f7-12aa12785f08"
        ],
        "317393e4-7029-4899-9143-a057703910e4": [
            "37caa115-53da-49ba-94f7-12aa12785f08"
        ],
        "3f264fa8-b819-4232-a1d1-78edc0d7a487": [
            "37caa115-53da-49ba-94f7-12aa12785f08"
        ],
        "faf37889-0b41-488d-b0ea-459760cc8f15": [
            "37caa115-53da-49ba-94f7-12aa12785f08"
        ],
        "5ac93628-63e6-451d-b4a4-04e7b3c2994d": [
            "37caa115-53da-49ba-94f7-12aa12785f08"
        ],
        "b43b75d4-4f88-427b-9144-af733e73f81d": [
            "16944e27-13ba-44d9-bc94-d009f9289adc"
        ],
        "9cc289d5-05c3-4568-adcb-f883e49d5df3": [
            "16944e27-13ba-44d9-bc94-d009f9289adc"
        ],
        "5bfd9076-9732-404d-8592-b58a9c60adfa": [
            "16944e27-13ba-44d9-bc94-d009f9289adc"
        ],
        "1b094e4b-df51-441c-a12e-ba787376e971": [
            "08965a05-e4e2-4784-943e-7fdca50c13a2"
        ],
        "cc0611af-c7d1-4a7f-a5f7-7080e60a2daf": [
            "08965a05-e4e2-4784-943e-7fdca50c13a2"
        ],
        "5ae7158e-e0e8-49ac-bd14-bdd5f2787bfc": [
            "08965a05-e4e2-4784-943e-7fdca50c13a2"
        ],
        "29bdd8b0-2245-49d3-9250-40a2fc193051": [
            "08965a05-e4e2-4784-943e-7fdca50c13a2"
        ],
        "e0ba67bd-a7a6-4aa3-81f1-416dc8bc8351": [
            "08965a05-e4e2-4784-943e-7fdca50c13a2"
        ],
        "e4c7af1e-38af-4d4b-bead-d3f1f6db6fc9": [
            "6358ad7c-bb44-4ccb-a709-1a30c74fd381"
        ],
        "b5843d7f-5001-4a90-ad33-9aa4303b0013": [
            "6358ad7c-bb44-4ccb-a709-1a30c74fd381"
        ],
        "4f31525c-7cd6-4ae9-b0d8-b649dee864d7": [
            "44fe4138-6141-46aa-abd0-4350d090eb88"
        ],
        "8165ea22-8e72-4ec6-8106-582bb011749d": [
            "44fe4138-6141-46aa-abd0-4350d090eb88"
        ],
        "e6dd59b2-0b5f-4d6f-85c5-4586bf64b284": [
            "44fe4138-6141-46aa-abd0-4350d090eb88"
        ],
        "4e1abfa8-bf81-4402-baf3-e30e2cbcb835": [
            "44fe4138-6141-46aa-abd0-4350d090eb88"
        ],
        "e46d4941-c09d-4950-b243-f775edf16ec7": [
            "44fe4138-6141-46aa-abd0-4350d090eb88"
        ],
        "91738561-6a99-4b12-afa0-ac913cff7491": [
            "ed0b985d-5828-446f-9d29-0cd5b5b6c6f0"
        ],
        "016698d2-dd19-4b6a-842a-978b236111d5": [
            "ed0b985d-5828-446f-9d29-0cd5b5b6c6f0"
        ],
        "0656a652-6c91-49a1-adb1-57265602bb54": [
            "ed0b985d-5828-446f-9d29-0cd5b5b6c6f0"
        ],
        "582de25f-0b72-4ebd-b1a6-8933d59905f2": [
            "7c301759-ad60-47d1-9e88-b2abaddcb120"
        ],
        "c7069e1a-0ec3-42f6-b8e3-92f40cf9c686": [
            "7c301759-ad60-47d1-9e88-b2abaddcb120"
        ],
        "368d35e3-08fb-4db2-ba64-934804cffb3f": [
            "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f"
        ],
        "201f8424-3445-4c89-93b5-b815f807ed9a": [
            "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f"
        ],
        "b92c6cdd-81fa-4bd4-8ae7-8cc06b67dc89": [
            "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f"
        ],
        "b2f74080-04b4-44bd-9536-786832b1d0ae": [
            "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f"
        ],
        "32456d11-97c6-40a6-ba33-5a70f72b852e": [
            "4249b403-b61d-4e5c-bb6c-c7d6893e7a4f"
        ],
        "92b585b8-b835-4805-a331-6e3a5a0e61f4": [
            "0fa584f2-c4a1-4e0a-a79c-a7445448f79f"
        ],
        "bd6f6046-f50d-4e61-96bc-4e818086ed2a": [
            "0fa584f2-c4a1-4e0a-a79c-a7445448f79f"
        ],
        "8664bff5-3d3c-4be0-853a-d93f81d288ca": [
            "f5289393-61e8-4aa5-a245-c2e0c7dc9dfd"
        ],
        "b9404e3a-f435-4928-8ca9-ad7e2107bec9": [
            "f5289393-61e8-4aa5-a245-c2e0c7dc9dfd"
        ],
        "19cb0d40-7179-4de8-9629-53cdc044f44b": [
            "07f4f9ca-3739-4f6a-be8f-7dfce558cb02"
        ],
        "d70715df-24a7-451d-941c-af431b40417c": [
            "07f4f9ca-3739-4f6a-be8f-7dfce558cb02"
        ],
        "5c9007d2-d4a4-4785-8af8-944f97d6286c": [
            "07f4f9ca-3739-4f6a-be8f-7dfce558cb02"
        ],
        "d2e1c246-e479-4b90-bdce-2a9362026050": [
            "07f4f9ca-3739-4f6a-be8f-7dfce558cb02"
        ],
        "b02ff23e-56da-48f9-94d7-a485184de48a": [
            "07f4f9ca-3739-4f6a-be8f-7dfce558cb02"
        ],
        "cd515677-0f66-47f4-bb50-3dc2e41ea340": [
            "8a4f7be4-4647-4f82-ac2b-5fa65030bf30"
        ],
        "742c8cd0-8730-4f47-abc5-81a52af63387": [
            "8a4f7be4-4647-4f82-ac2b-5fa65030bf30"
        ],
        "ae571592-e64f-4b49-97ee-2b07d16523d5": [
            "e1f81839-b518-445d-8292-39e6cf7b5190"
        ],
        "c5c5c17a-f5ce-4816-a97c-efe56c0426dc": [
            "e1f81839-b518-445d-8292-39e6cf7b5190"
        ],
        "9c936446-d0c5-4ca3-a7b1-e2c26f5b7400": [
            "e1f81839-b518-445d-8292-39e6cf7b5190"
        ],
        "ea80b72d-f691-480c-8434-d65d27fb6d9f": [
            "e1f81839-b518-445d-8292-39e6cf7b5190"
        ],
        "c8ae474a-f7de-4048-8d44-7b801851bdf1": [
            "f4ff1f01-0e19-48d1-a2df-924ea1d14da2"
        ],
        "a7fc691a-d500-4e6f-a783-3280e6c35849": [
            "f4ff1f01-0e19-48d1-a2df-924ea1d14da2"
        ],
        "e643fac1-128b-426d-b403-f394dc507fee": [
            "f4ff1f01-0e19-48d1-a2df-924ea1d14da2"
        ],
        "6c60d775-71fa-411d-8260-ef849eebd801": [
            "922d8246-6e75-4196-9cb8-bd44e2a85eb0"
        ],
        "1e9a58e3-7034-4b6a-a514-1364055b7ce6": [
            "922d8246-6e75-4196-9cb8-bd44e2a85eb0"
        ],
        "e0bb9b15-9e27-485e-9420-bcbab7a4ce4c": [
            "922d8246-6e75-4196-9cb8-bd44e2a85eb0"
        ],
        "92ef1255-92b1-4e65-8b8d-1e65e11269d0": [
            "922d8246-6e75-4196-9cb8-bd44e2a85eb0"
        ],
        "82c1968a-7e5c-4c3c-a0d5-8e262e743cad": [
            "922d8246-6e75-4196-9cb8-bd44e2a85eb0"
        ],
        "b05d9afa-bd91-4e42-9f2f-efa7b492a7ec": [
            "1415501b-741a-43ce-ae49-7cc6671850cb"
        ],
        "8829f39d-8083-4106-b910-da243a3c1321": [
            "1415501b-741a-43ce-ae49-7cc6671850cb"
        ],
        "62358ea4-22d1-468c-a2b4-cf46831ae66a": [
            "1415501b-741a-43ce-ae49-7cc6671850cb"
        ],
        "d8cc7226-1057-457c-a54f-3844b361dc9a": [
            "e2ec67a6-199a-4298-a244-237500c4f402"
        ],
        "8cdc8632-19c1-4abd-b480-40958d41d20d": [
            "e2ec67a6-199a-4298-a244-237500c4f402"
        ],
        "f707eb12-11d9-4ec8-b8e0-bd6106a55020": [
            "e2ec67a6-199a-4298-a244-237500c4f402"
        ],
        "5240532d-904f-461b-b03f-0491196a73d2": [
            "8746c6d1-8700-4c32-aec8-049eb631c8da"
        ],
        "550b7df6-3369-4c8f-98ca-c743a126af90": [
            "8746c6d1-8700-4c32-aec8-049eb631c8da"
        ],
        "82baba5c-f9f5-4bf1-b39c-56f71bc848e7": [
            "8746c6d1-8700-4c32-aec8-049eb631c8da"
        ],
        "08cb9684-90f6-42ca-8b09-252de56b727a": [
            "307bf3f4-bb26-4f93-8e94-fa2585c69599"
        ],
        "7fe52b36-56ff-454c-ba58-a172e8e91a02": [
            "307bf3f4-bb26-4f93-8e94-fa2585c69599"
        ],
        "1975bf2a-5f66-48e5-810f-4582185953b0": [
            "307bf3f4-bb26-4f93-8e94-fa2585c69599"
        ],
        "2e98f615-92dd-42f2-a379-9054ac65f1cf": [
            "3b2fd52b-87e8-4a61-b984-e1706504d37d"
        ],
        "46f824cb-3727-49a3-9ee2-4fdf88016b34": [
            "3b2fd52b-87e8-4a61-b984-e1706504d37d"
        ],
        "cb6218f7-6c23-41f1-99bc-57c6abc38510": [
            "3b2fd52b-87e8-4a61-b984-e1706504d37d"
        ],
        "8bda4bf3-bfbf-46d5-bb55-9317d86f875d": [
            "3b2fd52b-87e8-4a61-b984-e1706504d37d"
        ],
        "77ee9c10-09e8-4204-b429-c138ce3c0e97": [
            "3b2fd52b-87e8-4a61-b984-e1706504d37d"
        ],
        "1f79a636-e414-4292-b7b2-5c38bb9e76d2": [
            "08b00f30-b1a9-4943-81e5-e70580e24592"
        ],
        "ee2c6a6a-a414-42b1-8936-320714ce5247": [
            "08b00f30-b1a9-4943-81e5-e70580e24592"
        ],
        "c674578b-04f3-4f6c-911f-83f9c39cb46a": [
            "08b00f30-b1a9-4943-81e5-e70580e24592"
        ],
        "d798af8a-ef80-43f5-ab69-7ae061f89ed7": [
            "08b00f30-b1a9-4943-81e5-e70580e24592"
        ],
        "eb73a532-8d00-4507-899e-65323145533f": [
            "08b00f30-b1a9-4943-81e5-e70580e24592"
        ],
        "f16c2131-a46c-4225-af5f-8abc1cbe41e1": [
            "f5f80d76-71f0-498a-b09d-b3acabe5c2f3"
        ],
        "ab2b41ec-ebc7-446e-b0f6-3af2ec1f5785": [
            "f5f80d76-71f0-498a-b09d-b3acabe5c2f3"
        ],
        "9f00379a-806c-4030-9585-b50c5ce8cf5f": [
            "f5f80d76-71f0-498a-b09d-b3acabe5c2f3"
        ],
        "85d8a5ef-5fc1-411d-8768-79bd8e099668": [
            "f5f80d76-71f0-498a-b09d-b3acabe5c2f3"
        ],
        "dbbbc094-5b6e-4e44-af51-fb9c6acf40cf": [
            "f5f80d76-71f0-498a-b09d-b3acabe5c2f3"
        ],
        "2463312e-f328-4a60-b806-38f8f0e6c79d": [
            "627c87ed-d4be-4038-8078-7d897175ba24"
        ],
        "123fc80a-c638-4a61-9e8f-860d2861767e": [
            "627c87ed-d4be-4038-8078-7d897175ba24"
        ],
        "42ddc1cf-fa83-44e1-b3c1-201b3e05e105": [
            "627c87ed-d4be-4038-8078-7d897175ba24"
        ],
        "16a6692b-c01a-4c64-8282-73f699a05c16": [
            "627c87ed-d4be-4038-8078-7d897175ba24"
        ],
        "3739df82-d348-4c52-a058-bf44dc74a349": [
            "627c87ed-d4be-4038-8078-7d897175ba24"
        ],
        "b69b0de0-0de5-4136-864b-bd715d6e4ec7": [
            "7626705c-f2f3-4e77-92a0-3d3220ebd1d3"
        ],
        "299643b1-32f9-4080-aec5-cb842c7f6294": [
            "7626705c-f2f3-4e77-92a0-3d3220ebd1d3"
        ],
        "81d49b34-d0c2-4669-95e4-67cda5709a91": [
            "9a45b8ab-8ca5-4851-abad-299cddbf8457"
        ],
        "39435fca-9661-4024-b988-672b383fd828": [
            "9a45b8ab-8ca5-4851-abad-299cddbf8457"
        ],
        "064e0c75-a1d8-436f-9fb7-8d8af2f09d85": [
            "1fcab080-6615-4c41-bda1-e93ed36ef38d"
        ],
        "c73c10a3-510c-479c-89b2-c5516a4c8fe6": [
            "1fcab080-6615-4c41-bda1-e93ed36ef38d"
        ],
        "5d4f2d62-bca7-4099-a2e6-b2d00d019d2f": [
            "7e3c4065-831f-4397-b83f-b4e2f280b255"
        ],
        "5c56d0f5-e305-431e-94d7-7d91c11a9417": [
            "7e3c4065-831f-4397-b83f-b4e2f280b255"
        ],
        "4449e7b7-e522-4677-a8ea-53057b88f975": [
            "7e3c4065-831f-4397-b83f-b4e2f280b255"
        ],
        "9cc9ce1f-eb09-40ae-b239-82e074199265": [
            "7e3c4065-831f-4397-b83f-b4e2f280b255"
        ],
        "f1525c22-e235-4f7f-9b35-b7b91749186f": [
            "7e3c4065-831f-4397-b83f-b4e2f280b255"
        ],
        "d14a7ff9-93b3-4b4d-9ece-bb1dd83832ca": [
            "0a781b40-dd2b-4125-8120-f6a4069031db"
        ],
        "5678fde9-02c2-40e8-b412-1da5c1a01225": [
            "0a781b40-dd2b-4125-8120-f6a4069031db"
        ],
        "b0b1c86b-0fa6-4f71-a081-8cb403ac90ae": [
            "0a781b40-dd2b-4125-8120-f6a4069031db"
        ],
        "3d77dba4-96ea-46f7-9915-a327fa1537a9": [
            "5774090b-e045-4384-9cc6-adc0c370c115"
        ],
        "d13ee044-1b46-40f3-a9fa-6349d5ce2467": [
            "5774090b-e045-4384-9cc6-adc0c370c115"
        ],
        "0c463a76-d9d9-4f48-b164-a696c80eee01": [
            "5774090b-e045-4384-9cc6-adc0c370c115"
        ],
        "6b4ebf7f-94f6-479c-a861-c6f143cfcb72": [
            "5774090b-e045-4384-9cc6-adc0c370c115"
        ],
        "6e95bb1e-3ff6-47cf-8935-ee4084db95cf": [
            "5774090b-e045-4384-9cc6-adc0c370c115"
        ],
        "1c61c6b8-c4dc-4f48-87d7-a651b8f51127": [
            "0c84d059-b029-47bf-9885-da5d51e5a817"
        ],
        "5b9cdfe2-4d2d-4ef3-9b50-83d61e6d1c02": [
            "0c84d059-b029-47bf-9885-da5d51e5a817"
        ],
        "6d268f3d-5b9a-41e3-ab8f-7a6f163737c0": [
            "4fab5263-2760-44da-a7a8-f5b1e87074d7"
        ],
        "b46c9278-a976-45e2-95bd-ede63dd7a0d3": [
            "4fab5263-2760-44da-a7a8-f5b1e87074d7"
        ],
        "095171af-72b2-4ef9-b3ec-de487ef05d56": [
            "4fab5263-2760-44da-a7a8-f5b1e87074d7"
        ],
        "3417c863-39ce-43da-b5c2-cbcccb016c01": [
            "4fab5263-2760-44da-a7a8-f5b1e87074d7"
        ],
        "dc22fffc-ace5-436c-96bd-23124576578f": [
            "4fab5263-2760-44da-a7a8-f5b1e87074d7"
        ],
        "705cc4e0-a937-460a-a312-9e56f6662542": [
            "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6"
        ],
        "b8c38055-98cb-4ed5-8f28-c98f89a83050": [
            "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6"
        ],
        "2022ff32-f8bc-458f-8090-e3da78a22ea2": [
            "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6"
        ],
        "a9a867c7-df3b-4d54-923a-bca22212d3d0": [
            "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6"
        ],
        "b0d4127d-072f-4dfb-90fb-bfd05096d1f1": [
            "1d8483e9-6a64-4b76-b1a4-78b36d19d3f6"
        ],
        "b8884b2a-14bd-4edb-acd5-ea52c3760293": [
            "f39fe1fe-b0a1-496e-8501-f02dfefbee0e"
        ],
        "f05936cd-99b2-42be-a044-ee52882856fe": [
            "f39fe1fe-b0a1-496e-8501-f02dfefbee0e"
        ],
        "4977e8f2-70a5-4cad-b6c8-d95b5505c3f3": [
            "f39fe1fe-b0a1-496e-8501-f02dfefbee0e"
        ],
        "dc826c66-326e-4891-97fa-a9d9d886b3e6": [
            "f39fe1fe-b0a1-496e-8501-f02dfefbee0e"
        ],
        "d115061f-9708-4200-8e2c-d8e51acf5339": [
            "f39fe1fe-b0a1-496e-8501-f02dfefbee0e"
        ],
        "91b67297-e646-4644-af5a-d874bb076597": [
            "2b2cd616-b670-44e2-8116-2989a64392f6"
        ],
        "2c218fdf-24fc-4b99-8f54-0d50c05dca7e": [
            "2b2cd616-b670-44e2-8116-2989a64392f6"
        ],
        "0925a6c6-ecb1-4763-b3c9-d0b800e7b4c8": [
            "2b2cd616-b670-44e2-8116-2989a64392f6"
        ],
        "8351a8f4-59cc-4892-afc2-399e2cc7c524": [
            "2b2cd616-b670-44e2-8116-2989a64392f6"
        ],
        "796d3c8f-ab21-459d-b551-0d01f030709f": [
            "2b2cd616-b670-44e2-8116-2989a64392f6"
        ],
        "32494132-23e7-44ed-a8ea-f24c7e0e2887": [
            "c5666718-d94d-413b-9d67-79a3adc0020e"
        ],
        "b176cbc1-8633-4f97-84ce-27c65d9f9d69": [
            "c5666718-d94d-413b-9d67-79a3adc0020e"
        ],
        "269739c1-1882-4ed4-ba27-0c5000a96a41": [
            "c5666718-d94d-413b-9d67-79a3adc0020e"
        ],
        "695c84a5-c953-4fc8-9317-245b92a619b1": [
            "c5666718-d94d-413b-9d67-79a3adc0020e"
        ],
        "fd3074ae-7484-40ea-91c7-06d2c623b205": [
            "c5666718-d94d-413b-9d67-79a3adc0020e"
        ],
        "2b275762-dc73-4cf0-9ef5-af2a12c1b003": [
            "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012"
        ],
        "2a91366e-3ff8-4b65-9a0a-16a135468297": [
            "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012"
        ],
        "306c3b51-0cf5-4232-9dba-2a90af0d9450": [
            "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012"
        ],
        "6d8f53ad-46d2-46cc-b70a-63bbbaf43b07": [
            "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012"
        ],
        "4bd48fd7-66bc-40bb-8b11-6195e2bd5efc": [
            "ebe93f63-e3ea-4f3f-ac8e-4febd1c3a012"
        ],
        "d158bb97-8107-458c-8d7a-6c3c1f722120": [
            "5c1d93a6-df99-4c97-9014-2ca0f0c06927"
        ],
        "661c2dfd-0847-48a6-baf2-183400ae6d36": [
            "5c1d93a6-df99-4c97-9014-2ca0f0c06927"
        ],
        "21e81d45-10b6-438a-93a4-2b887236da6b": [
            "6c34551c-572c-4638-9709-f073d8c19f20"
        ],
        "bcf4d16c-6f7c-495b-aebf-09d04c675b1f": [
            "6c34551c-572c-4638-9709-f073d8c19f20"
        ],
        "411c3ecc-e455-4974-8f82-439c2caa23f8": [
            "f60195af-ac97-4a9b-82a2-983fc22a6a5c"
        ],
        "a4a6d124-8125-4a96-b87e-a61a3fbacf93": [
            "f60195af-ac97-4a9b-82a2-983fc22a6a5c"
        ],
        "c696171d-eaa1-40d3-a330-812650fb2918": [
            "f60195af-ac97-4a9b-82a2-983fc22a6a5c"
        ],
        "f271a979-2181-4729-aee6-ebe2b021d4e6": [
            "129ed859-b0ae-4e77-b178-d0b348652ac1"
        ],
        "a97524fb-b56b-4872-9c79-9f49885da4b6": [
            "129ed859-b0ae-4e77-b178-d0b348652ac1"
        ],
        "4e7a746c-98dc-4d9d-ac67-4da16ee8ec14": [
            "129ed859-b0ae-4e77-b178-d0b348652ac1"
        ],
        "d0c2b425-8fd8-4833-afb3-170a3bb03271": [
            "129ed859-b0ae-4e77-b178-d0b348652ac1"
        ],
        "6588557f-661e-41d0-a650-1ff43d8eafb7": [
            "129ed859-b0ae-4e77-b178-d0b348652ac1"
        ],
        "1b5daa9f-80cd-4771-bb5c-2b2aa817d979": [
            "63563aaf-19ec-421e-b6ef-f9f27de694a8"
        ],
        "1cea773f-ff10-4424-bc59-98bbff36e4f3": [
            "63563aaf-19ec-421e-b6ef-f9f27de694a8"
        ],
        "711b6892-29e1-4e1d-96c5-d96c6676c4cc": [
            "63563aaf-19ec-421e-b6ef-f9f27de694a8"
        ],
        "001be1d9-0fce-4278-9ace-d59701641120": [
            "63563aaf-19ec-421e-b6ef-f9f27de694a8"
        ],
        "f3539d53-08d9-4406-a854-95b3a34e2b00": [
            "63563aaf-19ec-421e-b6ef-f9f27de694a8"
        ],
        "b1f941b3-a532-4510-98bc-7226b115e76a": [
            "860faaec-9749-47ec-9cab-d3dc78ab07b9"
        ],
        "4c0ee949-46cf-4c25-b9aa-04e225804609": [
            "860faaec-9749-47ec-9cab-d3dc78ab07b9"
        ],
        "cad3436a-b422-43e6-998e-9dccddc3b3e7": [
            "860faaec-9749-47ec-9cab-d3dc78ab07b9"
        ],
        "8d86f751-612d-4b5d-a1dd-ec8e963b09c3": [
            "860faaec-9749-47ec-9cab-d3dc78ab07b9"
        ],
        "91fbebe7-01e7-4ee9-8e7c-9fcd9f4c1ee3": [
            "860faaec-9749-47ec-9cab-d3dc78ab07b9"
        ],
        "7814abce-589c-4cbe-8437-75473474aa8c": [
            "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e"
        ],
        "2384f235-f265-4371-b565-454a07d61790": [
            "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e"
        ],
        "7e78d5ac-d42f-4ed5-832c-96edb01ebb45": [
            "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e"
        ],
        "3a8f96a7-87ff-4920-b423-bb5dddfb80a3": [
            "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e"
        ],
        "43c7f4e6-7edb-4e02-bfa5-7e956b381b54": [
            "6cacd53e-b0b0-46d1-a4e0-175d84f2cf7e"
        ],
        "0ec5b9ea-ebdf-4e40-a145-83dc0d0df9cb": [
            "97eea3ea-b4d2-4f1b-b52b-197ae0fdb55d"
        ],
        "888d91c0-d35c-4edc-8a50-151ffcf3c5b8": [
            "97eea3ea-b4d2-4f1b-b52b-197ae0fdb55d"
        ],
        "9c34875f-2fca-44e3-9f84-93d837b57bbb": [
            "265ec4ca-778b-4942-a5a6-4f5f699d4559"
        ],
        "76ea313e-3723-47ec-ba56-4b9b5428b6d2": [
            "265ec4ca-778b-4942-a5a6-4f5f699d4559"
        ],
        "3b63814d-ed1a-47d4-95c4-28214df9eb66": [
            "265ec4ca-778b-4942-a5a6-4f5f699d4559"
        ],
        "e1c1c736-6cdf-47fe-89a9-ef6271b1d5a0": [
            "265ec4ca-778b-4942-a5a6-4f5f699d4559"
        ],
        "cb8becd2-0664-4255-9de9-b8ded0bed247": [
            "265ec4ca-778b-4942-a5a6-4f5f699d4559"
        ],
        "3fa12716-b8b5-45c8-9e6c-a5a70fc4812b": [
            "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101"
        ],
        "be7d54c2-753a-4ea9-8613-3003c916d045": [
            "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101"
        ],
        "9e73693f-cb30-4c9d-a677-70efc7132378": [
            "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101"
        ],
        "131ab2c3-1c48-4826-8523-bceb6cca7295": [
            "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101"
        ],
        "63972ce4-dc5b-428c-9de6-74f62a4df24b": [
            "bf4f2cd7-2b47-46bf-bfe5-c9d3f4412101"
        ],
        "8938f915-3843-490d-9c21-9db75e89088c": [
            "4722aa7e-9971-4e4c-80b9-4dcad378e2ed"
        ],
        "4e98742c-6d89-4e4e-9320-3c7abedbe199": [
            "4722aa7e-9971-4e4c-80b9-4dcad378e2ed"
        ],
        "3305db2e-0040-4340-ab12-dd8a7605370b": [
            "fc8a9558-8135-4c7e-9143-8c8743ca0243"
        ],
        "ee6acdbe-8182-4bd3-850e-41dd473d062b": [
            "fc8a9558-8135-4c7e-9143-8c8743ca0243"
        ],
        "39232b1e-0194-47ce-a7ed-10116b16d86f": [
            "fc8a9558-8135-4c7e-9143-8c8743ca0243"
        ],
        "53ddd453-e252-4d96-8868-6ede82bd114c": [
            "fc8a9558-8135-4c7e-9143-8c8743ca0243"
        ],
        "fffb81aa-fb8f-41b6-8ae5-2335826c0d07": [
            "fc8a9558-8135-4c7e-9143-8c8743ca0243"
        ],
        "d83c0bf2-76cb-4b9c-a72e-3336c5d554e7": [
            "e033034e-5a0e-454f-b149-f89ed7ada6aa"
        ],
        "34d4fb5a-3229-4c2f-ac52-5658c721b336": [
            "e033034e-5a0e-454f-b149-f89ed7ada6aa"
        ],
        "07e8706f-5b05-4dcb-8e2a-d47e3fc41579": [
            "e033034e-5a0e-454f-b149-f89ed7ada6aa"
        ],
        "49805ba9-52cf-439a-8c9f-c9c8f2c6a874": [
            "e033034e-5a0e-454f-b149-f89ed7ada6aa"
        ],
        "60e4b6ab-49f0-42ac-a59d-dcc30213f69b": [
            "e033034e-5a0e-454f-b149-f89ed7ada6aa"
        ],
        "375991c8-6241-46c9-a39d-18ccea2e885e": [
            "9603b668-c292-4721-a97c-3d8f34b9d1b9"
        ],
        "4597fb41-ed58-4c7d-aaa4-cee81c3e157b": [
            "9603b668-c292-4721-a97c-3d8f34b9d1b9"
        ],
        "7b48bd9a-5f72-4ce9-ab2b-01b6c6c3e796": [
            "9603b668-c292-4721-a97c-3d8f34b9d1b9"
        ],
        "624019ac-2fb4-4099-af82-8429b4ee7d7b": [
            "9603b668-c292-4721-a97c-3d8f34b9d1b9"
        ],
        "0de2d76a-3b10-413b-898c-7462e8c8c9e8": [
            "9603b668-c292-4721-a97c-3d8f34b9d1b9"
        ],
        "027eb436-1981-46a8-8b63-45b569c71ba9": [
            "3c2da02b-c1cb-4e40-b401-84a7d13de26a"
        ],
        "8275c17a-99cd-45bd-b63a-06dffd311dd3": [
            "3c2da02b-c1cb-4e40-b401-84a7d13de26a"
        ],
        "530747df-5197-4e9a-bda8-5bcbe7d6c6ee": [
            "a1344fb0-a0f2-42b9-b6c6-d716057f9517"
        ],
        "c35b5412-2f32-43ed-a446-30b8282e6b12": [
            "a1344fb0-a0f2-42b9-b6c6-d716057f9517"
        ],
        "c7a5d16c-bc11-4b9b-99fa-3eac4f24cb61": [
            "a1344fb0-a0f2-42b9-b6c6-d716057f9517"
        ],
        "651f2736-77aa-4480-9110-6bc218ee2e5f": [
            "a1344fb0-a0f2-42b9-b6c6-d716057f9517"
        ],
        "ceadae88-93d6-4dcd-add5-c42e61e85e4b": [
            "a1344fb0-a0f2-42b9-b6c6-d716057f9517"
        ],
        "55038f41-95da-4c7d-816c-03e8a905694e": [
            "6e0c5c8b-0357-49f3-b32f-45221dceed76"
        ],
        "f8eda07f-7f12-4a23-9eb2-9765711cdc5b": [
            "6e0c5c8b-0357-49f3-b32f-45221dceed76"
        ],
        "67e2b89f-b261-4a2f-9dce-85850fbce864": [
            "6e0c5c8b-0357-49f3-b32f-45221dceed76"
        ],
        "73067615-4c62-4fdb-8e59-72649569bcb9": [
            "6e0c5c8b-0357-49f3-b32f-45221dceed76"
        ],
        "6cf0a717-47b0-48f0-97bc-af0708ca036c": [
            "6e0c5c8b-0357-49f3-b32f-45221dceed76"
        ],
        "3ad02f47-4cbc-4dfd-85e1-9bbd573f9306": [
            "a162a527-dae7-4a16-8397-3514db7c3bfb"
        ],
        "905919c2-76e1-4042-9df0-d9c85cd5f99b": [
            "a162a527-dae7-4a16-8397-3514db7c3bfb"
        ],
        "e4cdc669-00b9-4f74-9e89-8cc3b1d2fe78": [
            "a162a527-dae7-4a16-8397-3514db7c3bfb"
        ],
        "72b723dd-3204-493a-a3c1-65f96053cbbb": [
            "a162a527-dae7-4a16-8397-3514db7c3bfb"
        ],
        "52ea1dc2-7653-47bf-b51f-37b337f98615": [
            "a162a527-dae7-4a16-8397-3514db7c3bfb"
        ],
        "6424aa1d-fc5a-4f49-85c4-5dc49630106c": [
            "2fe89c5b-3002-42da-98d1-50312fa0c62b"
        ],
        "5ee458b4-c4ef-4835-ac68-c25a87ab5194": [
            "2fe89c5b-3002-42da-98d1-50312fa0c62b"
        ],
        "a23ee0e1-63de-418d-b2cc-d708860f646e": [
            "2fe89c5b-3002-42da-98d1-50312fa0c62b"
        ],
        "daa66898-4be7-438a-978f-bf53ec6597c3": [
            "7dd3c318-c49f-4d74-8e68-28fb3b08c9b4"
        ],
        "6f4606b2-1b2f-4e47-a566-bde6393fae7f": [
            "7dd3c318-c49f-4d74-8e68-28fb3b08c9b4"
        ],
        "5539d346-071a-4572-95bb-9bf025254539": [
            "7dd3c318-c49f-4d74-8e68-28fb3b08c9b4"
        ],
        "c515a967-6c14-4083-a9e2-c550cd86fa88": [
            "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1"
        ],
        "1060071a-e62f-48e3-8c70-405b779ea844": [
            "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1"
        ],
        "15c4e5dc-0ad9-49d5-988f-9a55088fdebf": [
            "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1"
        ],
        "1621d3a0-5855-41c4-86f3-1eb31d01e4e8": [
            "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1"
        ],
        "7ac4efc7-d93c-4322-bccd-8738c714413b": [
            "fa25fb81-dcd3-43f0-b9b8-fc57054ce8c1"
        ],
        "95957b23-d259-496a-9d4d-d7317fd913c4": [
            "0299a496-1c7c-4512-8e8c-69b09b2849a4"
        ],
        "0daa7d76-acb4-4a36-a35d-cecc7d2b11d7": [
            "0299a496-1c7c-4512-8e8c-69b09b2849a4"
        ],
        "29fe09b9-560c-483e-8533-323bd09791a0": [
            "0299a496-1c7c-4512-8e8c-69b09b2849a4"
        ],
        "7834bdf8-329e-4ddb-9ba5-715773058e82": [
            "2d3ef750-4597-45af-8ed4-28a3cf223d9e"
        ],
        "c5663509-c6fd-4f3e-8fbb-fb357fc8b315": [
            "2d3ef750-4597-45af-8ed4-28a3cf223d9e"
        ],
        "1a1486fd-1454-475b-a0c3-12f6cbf9cdaf": [
            "2d3ef750-4597-45af-8ed4-28a3cf223d9e"
        ],
        "7e0dec2f-125b-4a5e-a150-7e0385001194": [
            "2d3ef750-4597-45af-8ed4-28a3cf223d9e"
        ],
        "bc9d8ca8-7408-4df7-a833-865cc5ee176c": [
            "2d3ef750-4597-45af-8ed4-28a3cf223d9e"
        ],
        "ea28c667-2155-42cc-afc1-61f224ce6050": [
            "17b7ef06-16eb-418e-a268-64e76685858e"
        ],
        "af45681d-a0d7-4b2f-ae3d-8328cf335aad": [
            "17b7ef06-16eb-418e-a268-64e76685858e"
        ],
        "08348b93-1d97-45f9-b0da-1f0cf949f731": [
            "17b7ef06-16eb-418e-a268-64e76685858e"
        ],
        "a1fd3416-9253-4e31-9676-6b5be8e3fb06": [
            "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f"
        ],
        "3234b533-933e-4f01-89f6-bc4f8f67fa3a": [
            "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f"
        ],
        "c963dbe7-96bf-438c-a7c7-880f1521be66": [
            "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f"
        ],
        "5f62bdc6-6760-4454-8ad0-ae2613ae2224": [
            "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f"
        ],
        "0d5491c9-354b-4ce5-ab99-93a62a22b058": [
            "e75b8aa8-c3b8-4957-9342-eb7a85a20b7f"
        ],
        "38d1d241-5f62-4c42-bf44-a027f39e12bd": [
            "dff7d8e0-1ff3-4125-9b9b-a87d022938b4"
        ],
        "3e5b11a3-055d-47e2-ac09-760a61911592": [
            "dff7d8e0-1ff3-4125-9b9b-a87d022938b4"
        ],
        "ffa754ee-ff1f-482e-90d8-770d273f5909": [
            "dff7d8e0-1ff3-4125-9b9b-a87d022938b4"
        ],
        "d1908cab-fa5b-4215-bd25-81cd8bb479ac": [
            "dff7d8e0-1ff3-4125-9b9b-a87d022938b4"
        ],
        "1d7b9eda-baf6-4881-9a0d-23df572bfda3": [
            "dff7d8e0-1ff3-4125-9b9b-a87d022938b4"
        ],
        "e87cfec6-f930-45b4-ada9-62bf8e49106e": [
            "45ca9b40-7aa6-42bf-8f67-9abc7d65171c"
        ],
        "a61f6d6c-2ef8-4a67-9c7b-092e1b9a5d3a": [
            "45ca9b40-7aa6-42bf-8f67-9abc7d65171c"
        ],
        "ca65be3d-7024-4c5a-82e2-d4233fc9bb50": [
            "45ca9b40-7aa6-42bf-8f67-9abc7d65171c"
        ],
        "8c94e486-2bdf-48b8-a085-720112fad2ff": [
            "45ca9b40-7aa6-42bf-8f67-9abc7d65171c"
        ],
        "bd12527f-c32b-48e3-b074-27bca976b93d": [
            "45ca9b40-7aa6-42bf-8f67-9abc7d65171c"
        ],
        "8d06d22e-a544-4827-9870-6717a7ea61c2": [
            "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27"
        ],
        "e58b3c11-78e0-4b0f-988a-b57f885fb0f2": [
            "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27"
        ],
        "56eb1903-9304-4cf6-9ac4-f42636fcbc52": [
            "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27"
        ],
        "62f14be2-2bee-478a-86a2-3a8b218f5ce3": [
            "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27"
        ],
        "f794f434-baca-456d-8602-17350c839ec4": [
            "fe3740f5-2aa4-4c04-9bbf-6fc814dd5c27"
        ],
        "023c5bbf-414d-4a96-9e9b-6144d91545e8": [
            "43a314c5-5bb1-4e98-997a-9d80fe399ccc"
        ],
        "dc46cc13-e5c1-4cc4-a131-26a73938ddfb": [
            "43a314c5-5bb1-4e98-997a-9d80fe399ccc"
        ],
        "3641b8dd-6130-4f9f-983e-cc0bab419e19": [
            "43a314c5-5bb1-4e98-997a-9d80fe399ccc"
        ],
        "7790ca39-12fb-41c3-a7ac-9779b63ae9ea": [
            "43a314c5-5bb1-4e98-997a-9d80fe399ccc"
        ],
        "b3616607-53cd-433f-aafc-3e30d1b9b3a8": [
            "43a314c5-5bb1-4e98-997a-9d80fe399ccc"
        ],
        "c95878ce-58cc-4b17-af3f-2d1fd30c1e19": [
            "94b89bc7-6af1-49e2-981c-a13d981e0441"
        ],
        "f1a5e89c-7050-4c4e-97c9-a74f045d0936": [
            "94b89bc7-6af1-49e2-981c-a13d981e0441"
        ],
        "178347b2-94f4-442c-ad00-35eb192339bd": [
            "94b89bc7-6af1-49e2-981c-a13d981e0441"
        ],
        "0854d23e-0bd8-49c8-8006-3b304f030b49": [
            "94b89bc7-6af1-49e2-981c-a13d981e0441"
        ],
        "da71a8c4-5480-425b-bca7-4f988a5599b4": [
            "94b89bc7-6af1-49e2-981c-a13d981e0441"
        ],
        "a4fd731b-c364-4b3d-9bc0-b37d4992ae1c": [
            "dc555c9e-a52d-4ea3-b1c5-e213c533e443"
        ],
        "e4b24e8b-246b-4ee6-a5b1-7fb0dcb97687": [
            "dc555c9e-a52d-4ea3-b1c5-e213c533e443"
        ],
        "1aac4c72-ffd9-443a-814f-49f4d35e2879": [
            "dc555c9e-a52d-4ea3-b1c5-e213c533e443"
        ],
        "031e768e-ec68-4326-a523-6a0a3cd4a098": [
            "dc555c9e-a52d-4ea3-b1c5-e213c533e443"
        ],
        "8a19b284-1e6f-4ed3-aba0-d8fd54de0535": [
            "dc555c9e-a52d-4ea3-b1c5-e213c533e443"
        ],
        "0e7b9aa5-4070-4d26-9de4-9cd052df5ceb": [
            "86163975-231f-471e-8e82-703faac466e9"
        ],
        "3acd148e-29e7-459a-af97-5541b4c62df5": [
            "86163975-231f-471e-8e82-703faac466e9"
        ],
        "177569c1-013d-4095-a1de-fc8b107a1f0a": [
            "86163975-231f-471e-8e82-703faac466e9"
        ],
        "864fc6bc-ff96-43b4-9731-f561e04deab3": [
            "86163975-231f-471e-8e82-703faac466e9"
        ],
        "00fa352f-fcbb-4f22-950f-3fdcedbba35f": [
            "86163975-231f-471e-8e82-703faac466e9"
        ],
        "f15afc9c-63eb-4268-b359-6ae85f3ae495": [
            "40ba310b-d549-407d-9c03-93fd01d2199a"
        ],
        "be2fb6da-9301-43dc-9859-1060b2c58e72": [
            "40ba310b-d549-407d-9c03-93fd01d2199a"
        ],
        "e43f3a4c-5740-47da-938f-bfcfb20310ff": [
            "40ba310b-d549-407d-9c03-93fd01d2199a"
        ],
        "6530a7ad-06bf-4f76-8dfb-92a7d0ccb6c7": [
            "40ba310b-d549-407d-9c03-93fd01d2199a"
        ],
        "5b8cc74e-d0c3-4d83-b894-5114bd031441": [
            "40ba310b-d549-407d-9c03-93fd01d2199a"
        ],
        "79ffb640-e128-4b12-95ae-35c3902368f4": [
            "8dd05b68-c22c-451f-aae3-7895f0e43502"
        ],
        "62e84cba-26f3-4a67-ba62-df5bb0329bc3": [
            "8dd05b68-c22c-451f-aae3-7895f0e43502"
        ],
        "a57bc2c4-58d6-43e2-9bfb-6146d1b9a399": [
            "8dd05b68-c22c-451f-aae3-7895f0e43502"
        ],
        "a225a501-fd6d-4797-9301-e5df24d82d75": [
            "8dd05b68-c22c-451f-aae3-7895f0e43502"
        ],
        "ed2556c7-4e95-4972-b43e-986667f02a1a": [
            "8dd05b68-c22c-451f-aae3-7895f0e43502"
        ],
        "a793c174-eecc-493d-b6e2-c5bb6b0b349e": [
            "c6296cfa-9003-45dd-b079-2496789e2689"
        ],
        "81979fb4-1f75-4cb3-b75e-a83b7f1dcd01": [
            "c6296cfa-9003-45dd-b079-2496789e2689"
        ],
        "7d6f72d3-effc-4097-a7e7-f5a47b31171e": [
            "c6296cfa-9003-45dd-b079-2496789e2689"
        ],
        "6f9c4753-8222-4617-a293-610650fa96e7": [
            "c6296cfa-9003-45dd-b079-2496789e2689"
        ],
        "698f5dd5-479e-418e-8339-1b4733318d76": [
            "c6296cfa-9003-45dd-b079-2496789e2689"
        ],
        "9908084e-51ed-44a8-86e4-6c708c81fec6": [
            "557a5f88-548a-4357-9ec1-e808708d0743"
        ],
        "1ecc63f7-9128-47b0-afd9-708111a17597": [
            "557a5f88-548a-4357-9ec1-e808708d0743"
        ],
        "fe423b53-eb26-48e1-80fc-b3affc73d687": [
            "557a5f88-548a-4357-9ec1-e808708d0743"
        ],
        "24cfbf2f-03f2-407e-9d47-5c62795b6bcd": [
            "557a5f88-548a-4357-9ec1-e808708d0743"
        ],
        "900e34fe-7599-4fd5-9bbc-fcdf5a7fa4b9": [
            "5e557e8c-6b50-4dde-bc71-5ce92840bb13"
        ],
        "81e8ace4-d3c5-490c-941d-711e13d2e045": [
            "5e557e8c-6b50-4dde-bc71-5ce92840bb13"
        ],
        "6e0d631e-d8a2-4818-92c8-bf01650e7f60": [
            "5e557e8c-6b50-4dde-bc71-5ce92840bb13"
        ],
        "565b0d41-cdfa-4bbc-b6e8-bd1a51e4e1eb": [
            "5e557e8c-6b50-4dde-bc71-5ce92840bb13"
        ],
        "f8cfd6d5-05dc-4b72-a393-d6fa98b2c412": [
            "5e557e8c-6b50-4dde-bc71-5ce92840bb13"
        ],
        "6ddfd7ff-e99e-44ae-a6b8-6c5a52fd259a": [
            "5b00f618-97b6-44b2-879b-953a9ac45d1e"
        ],
        "341d350a-c830-4b05-9c92-434d8a5d20a5": [
            "5b00f618-97b6-44b2-879b-953a9ac45d1e"
        ],
        "c58517ef-253f-48ca-831f-a5432a0ba718": [
            "5b00f618-97b6-44b2-879b-953a9ac45d1e"
        ],
        "e14e3b37-8aa3-4b3a-ab96-b9ae005379eb": [
            "fc986e0c-1fbb-42b8-8fb7-b55583c48d9e"
        ],
        "1ca25f7e-a863-49f2-a25e-59c730debb5c": [
            "fc986e0c-1fbb-42b8-8fb7-b55583c48d9e"
        ],
        "2f26c025-5a0e-4ebc-925d-c0cb18bcdff4": [
            "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90"
        ],
        "c5772051-208a-4700-b7c6-4ce7ff97511a": [
            "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90"
        ],
        "30369ed8-2c0b-4ffa-b206-756a469195f8": [
            "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90"
        ],
        "e4939a4d-5268-469d-b1d2-bf764ca07626": [
            "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90"
        ],
        "7d578867-c531-415f-bbae-e5facdc5d6a1": [
            "81c8bf5e-687b-4f9a-b1c0-215dc7c20a90"
        ],
        "98c127a4-b66c-4faf-a16e-4eae82a97163": [
            "2c9ebd87-9851-4ca2-b805-22f59b650244"
        ],
        "76ff5397-752b-4d5e-b43f-d36d1c5f4a50": [
            "2c9ebd87-9851-4ca2-b805-22f59b650244"
        ],
        "8c4417a8-50b6-453d-9e80-730a1796e187": [
            "2c9ebd87-9851-4ca2-b805-22f59b650244"
        ],
        "659bf38a-a558-436e-8cec-273e639342d3": [
            "87f44cf4-ec69-4f61-80ba-420865b22cad"
        ],
        "3487f54d-1a1b-469e-a076-aebdaedc8f43": [
            "87f44cf4-ec69-4f61-80ba-420865b22cad"
        ],
        "87b41ceb-f304-42cd-8096-e1855eb0518f": [
            "87f44cf4-ec69-4f61-80ba-420865b22cad"
        ],
        "6ac119b8-5d48-436e-b623-0e8361c81acf": [
            "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008"
        ],
        "f9d57c8e-2dc1-4427-88b0-68923780d216": [
            "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008"
        ],
        "f35c5ca3-b7c5-4c3f-bdcc-d0ccc3d2f400": [
            "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008"
        ],
        "54742a09-fad8-4db7-8ba1-c2e0ba053a9f": [
            "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008"
        ],
        "49f6a12b-1ba3-40dd-adef-8622b73c8fab": [
            "9bf0c5ec-a630-41ce-8009-c4dcdb2d3008"
        ],
        "c67d2c2b-e11c-49da-b8c4-c2e156a71b6c": [
            "69220555-9f3b-445d-9721-a931d531cc11"
        ],
        "87e5adec-d3cf-474a-942c-5a42fbacd041": [
            "69220555-9f3b-445d-9721-a931d531cc11"
        ],
        "44ba2a02-9d51-443c-ab77-d833414abb98": [
            "69220555-9f3b-445d-9721-a931d531cc11"
        ],
        "f6f1e40a-5536-4028-b6d8-7d51912818c8": [
            "e2d137d8-3d2c-4e11-9d38-df694a09dcdc"
        ],
        "2955bb49-3c24-4e80-afd6-a2177deebd41": [
            "e2d137d8-3d2c-4e11-9d38-df694a09dcdc"
        ],
        "af9c49b1-d4db-451f-b88f-b0a5703065ae": [
            "e2d137d8-3d2c-4e11-9d38-df694a09dcdc"
        ],
        "ae68f120-0ae4-469e-a30d-b2575b837784": [
            "adc9c7e3-bfd5-45b0-9f49-a9769705b806"
        ],
        "6a9def58-fe36-4fff-b0c0-d88e8c27c6ab": [
            "adc9c7e3-bfd5-45b0-9f49-a9769705b806"
        ],
        "92d042b4-fba3-4ac4-a567-922ec406d8e9": [
            "183d6d60-4edf-4737-b474-74ad60375c6b"
        ],
        "9824521b-480c-4583-bdd4-3d5382a9b040": [
            "183d6d60-4edf-4737-b474-74ad60375c6b"
        ],
        "2ebf1650-5783-4814-a5fd-a88d3f10daad": [
            "183d6d60-4edf-4737-b474-74ad60375c6b"
        ],
        "4ed72206-427f-4e9c-802f-f366d7e35ec6": [
            "183d6d60-4edf-4737-b474-74ad60375c6b"
        ],
        "f918c5e5-3fdc-4d3f-b97f-7554b553d70d": [
            "aae6a10d-66b1-4095-8d1b-85279734d1bc"
        ],
        "7c674722-e74a-4238-9bc1-1d55eb6b8df7": [
            "aae6a10d-66b1-4095-8d1b-85279734d1bc"
        ],
        "1dada06b-922d-43ed-aed1-18184c985c7f": [
            "86c366bd-d571-4368-a5fa-d178e7f25026"
        ],
        "90a29253-0867-4520-aaab-f24f075d763a": [
            "86c366bd-d571-4368-a5fa-d178e7f25026"
        ],
        "42b18c4b-8b1b-40fe-88b2-9a2eedc2c976": [
            "86c366bd-d571-4368-a5fa-d178e7f25026"
        ],
        "63bb78f4-73de-46b2-82dc-541631cb35bc": [
            "86c366bd-d571-4368-a5fa-d178e7f25026"
        ],
        "349561f8-8cbc-4e41-81e6-81b9d6af7c90": [
            "22099506-9d51-4f92-b600-fd72a5039db0"
        ],
        "fd4242eb-2907-42e3-98f4-0c58dd53a96a": [
            "22099506-9d51-4f92-b600-fd72a5039db0"
        ],
        "8ae19823-d74f-4f4b-bd6f-16dd17770801": [
            "22099506-9d51-4f92-b600-fd72a5039db0"
        ],
        "d223f16b-4448-42df-90ce-600e9708fba3": [
            "22099506-9d51-4f92-b600-fd72a5039db0"
        ],
        "ffeb8df7-2a6e-450b-821b-e9baaed57149": [
            "22099506-9d51-4f92-b600-fd72a5039db0"
        ],
        "cc4da85d-9c29-430f-8ffc-e5acf59ff457": [
            "2acdb36f-6941-43bc-a94c-808f00fe7cc2"
        ],
        "58b4499b-0465-49c2-b76f-c281789bf7f0": [
            "2acdb36f-6941-43bc-a94c-808f00fe7cc2"
        ],
        "dbd48569-ebfe-4cac-a73c-4a70864dcdad": [
            "2acdb36f-6941-43bc-a94c-808f00fe7cc2"
        ],
        "85bc52d2-7a86-4e6e-b0fe-2077afdaeca4": [
            "2acdb36f-6941-43bc-a94c-808f00fe7cc2"
        ],
        "023f62a8-bb03-42c4-ba2f-194f0ebb85ce": [
            "2acdb36f-6941-43bc-a94c-808f00fe7cc2"
        ],
        "e6bbc08b-1ffe-43ac-b1eb-55aaf3e28043": [
            "e66a3366-ab88-4caf-8ff5-200d82e9eaa7"
        ],
        "479df248-9cc3-4065-a927-930bc0e83e0d": [
            "e66a3366-ab88-4caf-8ff5-200d82e9eaa7"
        ],
        "d3e2c8dd-f09b-4910-99ee-b886be7b9fb2": [
            "e66a3366-ab88-4caf-8ff5-200d82e9eaa7"
        ],
        "5333089a-0887-4482-8453-7b20243f2a11": [
            "e66a3366-ab88-4caf-8ff5-200d82e9eaa7"
        ],
        "5d85170c-7fd2-43de-b611-2dd62ac2d54f": [
            "e66a3366-ab88-4caf-8ff5-200d82e9eaa7"
        ],
        "1544e8b0-1dd8-490d-9b5a-a7ae09dfbac8": [
            "99ac9b18-811d-499c-b94f-a55012ac2c47"
        ],
        "ad72cafd-ebc6-40a5-acad-086719585649": [
            "99ac9b18-811d-499c-b94f-a55012ac2c47"
        ],
        "53cf0bad-e132-4781-ac3c-fe26a2a8d28b": [
            "99ac9b18-811d-499c-b94f-a55012ac2c47"
        ],
        "16fc9297-cf33-4da2-b910-f101d812b40d": [
            "99ac9b18-811d-499c-b94f-a55012ac2c47"
        ],
        "d8ef7cb6-42e8-4560-b21d-f89f4e7d087d": [
            "99ac9b18-811d-499c-b94f-a55012ac2c47"
        ],
        "6f724a77-1997-4e09-92f4-90146860a1ba": [
            "4e5ae620-3616-4817-9dec-46ebb620359c"
        ],
        "1ef6596e-7662-4d0c-9f46-9c1f3d853716": [
            "4e5ae620-3616-4817-9dec-46ebb620359c"
        ],
        "048e226a-0c9c-4b52-b0ed-f6c2cdc5c82d": [
            "4e5ae620-3616-4817-9dec-46ebb620359c"
        ],
        "8882bf11-7934-43b7-b820-0255fc7253f5": [
            "4e5ae620-3616-4817-9dec-46ebb620359c"
        ],
        "1a848b1a-00d2-49c0-a94b-31741fe6f3e1": [
            "4e5ae620-3616-4817-9dec-46ebb620359c"
        ],
        "7aeab9d5-2f1f-4f43-82e7-d7a7757fb17f": [
            "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251"
        ],
        "344d31c7-8ee4-4293-9c13-6a43ad1ee4d2": [
            "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251"
        ],
        "e252862f-ac69-4418-b269-4a2dc70f361b": [
            "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251"
        ],
        "019177ee-7807-4189-a758-64e0291aec06": [
            "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251"
        ],
        "8879ee9c-cf0f-4a18-8632-bf2d32a5f519": [
            "1a6b3ebc-f4b1-424e-b7bb-5d9e4df76251"
        ],
        "83f02247-012f-4362-8fb7-68618569e8d3": [
            "b85218a9-cc38-4662-affb-d26f4ac0ec92"
        ],
        "89220be5-0274-47f0-9850-5fa96fab3b9d": [
            "b85218a9-cc38-4662-affb-d26f4ac0ec92"
        ],
        "f553bfd7-a7e2-492f-95fb-9f9e51060469": [
            "b85218a9-cc38-4662-affb-d26f4ac0ec92"
        ],
        "7117b07a-2f6e-49ef-9e07-cbfa111b9d01": [
            "b75f87cd-5dbc-4061-aa74-16ae328b754b"
        ],
        "d29ef299-f3a3-4fb7-a8d9-f5ad6419beab": [
            "b75f87cd-5dbc-4061-aa74-16ae328b754b"
        ],
        "1f01bdaa-c6e2-470a-aed8-1c3baac696a7": [
            "b75f87cd-5dbc-4061-aa74-16ae328b754b"
        ],
        "a6c15101-4f42-47ed-b074-85216d14d0e5": [
            "5124075c-8aa4-4617-8be8-b6fc9d88993b"
        ],
        "e8349c00-a242-4268-b48c-1e2489361a7a": [
            "5124075c-8aa4-4617-8be8-b6fc9d88993b"
        ],
        "bcea2cd5-41d7-4388-9f5d-db949802d273": [
            "5124075c-8aa4-4617-8be8-b6fc9d88993b"
        ],
        "654206f6-2977-47a5-ad79-9735c64bc8df": [
            "5124075c-8aa4-4617-8be8-b6fc9d88993b"
        ],
        "99ed0a29-c679-4b3c-80a2-c64196292e60": [
            "ef04511c-24a6-491b-a237-af425f7a60ef"
        ],
        "7abb4e36-539a-4e49-9eed-51a23d53b105": [
            "ef04511c-24a6-491b-a237-af425f7a60ef"
        ],
        "b106006a-4557-421a-9ba2-16a2bde109cb": [
            "ef04511c-24a6-491b-a237-af425f7a60ef"
        ],
        "e35822d0-cde4-40c8-9b93-a81a513c448d": [
            "4a5872b3-8202-4028-8b7b-573f8d0c0fec"
        ],
        "ed22d48f-955c-44f4-a5bb-31d0e2019859": [
            "4a5872b3-8202-4028-8b7b-573f8d0c0fec"
        ],
        "af5c5ee2-5532-4446-8a45-199e45e710da": [
            "4a5872b3-8202-4028-8b7b-573f8d0c0fec"
        ],
        "065efa5d-0d3e-4e1c-bb7e-6e6dd9d405d1": [
            "ac9410c1-a1bf-460a-8389-87af13a62fb9"
        ],
        "b0b1098c-8a0e-4dbc-9c75-43c049f14613": [
            "ac9410c1-a1bf-460a-8389-87af13a62fb9"
        ],
        "16f3874a-2169-43a1-831c-1b8a52e92799": [
            "2451027a-456b-4b67-8d85-340eb5ca2878"
        ],
        "9fff82f4-4d40-4965-82fb-1af4a7a20b36": [
            "2451027a-456b-4b67-8d85-340eb5ca2878"
        ],
        "f32bd394-f754-48af-8c5a-8621b9582d33": [
            "2451027a-456b-4b67-8d85-340eb5ca2878"
        ],
        "2a56770f-81bc-44e4-a136-aee216ce37c6": [
            "2451027a-456b-4b67-8d85-340eb5ca2878"
        ],
        "57223901-bd6b-4614-97d7-08885cb9c00e": [
            "392cdbf6-cad4-4d9a-b6ed-7008bfe6d77f"
        ],
        "7887fb7c-cad3-4361-bc18-37e3651bb2a2": [
            "392cdbf6-cad4-4d9a-b6ed-7008bfe6d77f"
        ],
        "815034aa-f818-4001-a16c-fb4f69ac8292": [
            "392cdbf6-cad4-4d9a-b6ed-7008bfe6d77f"
        ],
        "a4bad5ad-a9a4-44ce-8982-0a7218576b62": [
            "392cdbf6-cad4-4d9a-b6ed-7008bfe6d77f"
        ],
        "e1ce2742-c3c1-471a-85e7-0398f5c1bbd0": [
            "497d872d-cc12-4d96-a92e-9384cf47e421"
        ],
        "09158262-68c2-4bbb-a43b-35d154d68bfe": [
            "497d872d-cc12-4d96-a92e-9384cf47e421"
        ],
        "0d1a9c0d-e21d-40ac-a9d0-e4e43d10d030": [
            "497d872d-cc12-4d96-a92e-9384cf47e421"
        ],
        "44caaa64-bf4d-4105-b692-36fa43dd94fb": [
            "16dbd297-f1d2-4648-9bfc-dc1665869dbc"
        ],
        "73ca2706-9c1e-4ecb-aa74-1c7b2124c10f": [
            "16dbd297-f1d2-4648-9bfc-dc1665869dbc"
        ],
        "804c4e8b-0191-4a03-a55e-8c3a2fe03f79": [
            "16dbd297-f1d2-4648-9bfc-dc1665869dbc"
        ],
        "1c1e7876-e339-4a1b-89f6-a1fb54876d78": [
            "16dbd297-f1d2-4648-9bfc-dc1665869dbc"
        ],
        "efef5ec3-fd4b-4432-8fac-96337df80f34": [
            "16dbd297-f1d2-4648-9bfc-dc1665869dbc"
        ],
        "756c08b0-09b6-4cc1-9122-a353235b4309": [
            "9f42ba3f-8e68-4a11-82c2-211a8df9b99f"
        ],
        "d35cbfdd-cf16-4a83-9330-b4f42980691f": [
            "9f42ba3f-8e68-4a11-82c2-211a8df9b99f"
        ],
        "864fa996-5d91-4ecd-9892-1940922d6a50": [
            "9f42ba3f-8e68-4a11-82c2-211a8df9b99f"
        ],
        "4f8e2435-d1dc-47f0-96af-7358c2c15355": [
            "d81d0b97-1536-41bd-84b9-bb8df5dfeca7"
        ],
        "9ad427b7-b2d9-44ab-84a2-c9c3b7c8e575": [
            "d81d0b97-1536-41bd-84b9-bb8df5dfeca7"
        ],
        "12056360-bd4b-4cc2-932a-47608d4ea9d8": [
            "d81d0b97-1536-41bd-84b9-bb8df5dfeca7"
        ],
        "14e61a08-897d-49d0-b15f-3747bf3d1185": [
            "d81d0b97-1536-41bd-84b9-bb8df5dfeca7"
        ],
        "28d7f632-9d93-4763-a2a4-8ea88d7a816b": [
            "d81d0b97-1536-41bd-84b9-bb8df5dfeca7"
        ],
        "22524f50-aab7-47f8-9199-ae7924a1a197": [
            "678c751d-9b82-497b-b06d-4a8043c898ab"
        ],
        "76762738-e659-4405-91ec-413fad5ac72e": [
            "678c751d-9b82-497b-b06d-4a8043c898ab"
        ],
        "ac75888d-6548-4112-bc0a-830a0a4e015a": [
            "678c751d-9b82-497b-b06d-4a8043c898ab"
        ],
        "0298520c-46a1-4bf1-8aab-3c4dff459f4c": [
            "678c751d-9b82-497b-b06d-4a8043c898ab"
        ],
        "80b0d9f4-287e-448c-9733-88b2ad8fe9e7": [
            "678c751d-9b82-497b-b06d-4a8043c898ab"
        ],
        "b51264ae-e045-4323-8d41-846f186e0a3a": [
            "b269883b-4761-4009-b399-24b72e80790c"
        ],
        "8dcc48c5-7db9-4aa2-aae0-412360d16066": [
            "b269883b-4761-4009-b399-24b72e80790c"
        ],
        "642fe7aa-dd73-4934-8769-87cde55813ef": [
            "b269883b-4761-4009-b399-24b72e80790c"
        ],
        "b54c4eeb-fab5-4412-833e-4b2be776bc54": [
            "b269883b-4761-4009-b399-24b72e80790c"
        ],
        "0251b150-608d-4d70-8310-28219e699157": [
            "29370a68-265d-4090-8014-b3c989190c12"
        ],
        "e061b3e7-f6f2-4599-9d20-113041af7fec": [
            "29370a68-265d-4090-8014-b3c989190c12"
        ],
        "7a6f0f3d-073f-45ca-8857-7f7014e739eb": [
            "29370a68-265d-4090-8014-b3c989190c12"
        ],
        "33d65f52-4db1-4e8d-b0e0-2e1b0aa280a5": [
            "315471c9-4e32-4823-a5bd-978ef710f82c"
        ],
        "533c8d2b-43f4-4410-9c67-396978d8a7c8": [
            "315471c9-4e32-4823-a5bd-978ef710f82c"
        ],
        "db0b9270-5c73-4266-8b3b-d3653472dbaa": [
            "315471c9-4e32-4823-a5bd-978ef710f82c"
        ],
        "876218db-274f-4b2e-b74e-ba0613ee1ee3": [
            "315471c9-4e32-4823-a5bd-978ef710f82c"
        ],
        "98a3034d-b1a7-4101-ad8a-e2b85567a3fb": [
            "315471c9-4e32-4823-a5bd-978ef710f82c"
        ],
        "cbd37fe5-9096-438f-b9dc-928a8ae396bf": [
            "459efc1c-bc8e-4bf3-a493-7b98644e9bcc"
        ],
        "fc8ee21c-a23c-4ba0-9e39-df997ecda49b": [
            "459efc1c-bc8e-4bf3-a493-7b98644e9bcc"
        ],
        "d395d7a1-1b69-47cb-ace7-78d2ce130b7f": [
            "459efc1c-bc8e-4bf3-a493-7b98644e9bcc"
        ],
        "206cf94b-fcc5-4f08-9fff-1a5af4d60246": [
            "459efc1c-bc8e-4bf3-a493-7b98644e9bcc"
        ],
        "f74a5e52-3b4c-4c35-b5c0-7fd3c0d38fa7": [
            "f699a84d-4d6a-43c6-9658-d7c528597797"
        ],
        "097ccc32-6077-4d45-922d-7bc5b10863cf": [
            "f699a84d-4d6a-43c6-9658-d7c528597797"
        ],
        "1e843066-399e-49fd-9cec-2ecd29960c40": [
            "f699a84d-4d6a-43c6-9658-d7c528597797"
        ],
        "cccb101f-b403-472d-af93-dcb5973f14c3": [
            "f699a84d-4d6a-43c6-9658-d7c528597797"
        ],
        "1bf79129-6e49-4fe5-a9cd-dba797199d4f": [
            "f699a84d-4d6a-43c6-9658-d7c528597797"
        ],
        "8d7c3362-12fe-49a1-842f-f1adad75bcc3": [
            "b3850b77-2a76-4afc-84cd-97b8271a3581"
        ],
        "f68b21a0-dde9-4535-97aa-a35092ae8d58": [
            "b3850b77-2a76-4afc-84cd-97b8271a3581"
        ],
        "f027596f-9560-4b0a-9338-0d20644790f7": [
            "76fde090-43ec-4dc9-98c4-c6738c3c09ed"
        ],
        "44b555f2-2bf1-4bea-ac90-4fb59872adae": [
            "76fde090-43ec-4dc9-98c4-c6738c3c09ed"
        ],
        "5c292f8c-0d09-4983-a864-080521831ab1": [
            "76fde090-43ec-4dc9-98c4-c6738c3c09ed"
        ],
        "8decb837-7f5b-483e-9bb9-35c3611de551": [
            "76fde090-43ec-4dc9-98c4-c6738c3c09ed"
        ],
        "d2336d9e-3b59-4d6f-ae33-ca28cbf3ccde": [
            "76fde090-43ec-4dc9-98c4-c6738c3c09ed"
        ],
        "c3959835-c655-4fb8-8ab9-2b62a7dfdb17": [
            "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98"
        ],
        "5b3a7c82-6a1a-46dc-bcbf-045a7cb898c4": [
            "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98"
        ],
        "7b7d437e-fac2-484b-a87c-85c0dfec4a18": [
            "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98"
        ],
        "4efc2515-49fc-491f-bab9-0933d1032843": [
            "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98"
        ],
        "78cc8776-fa12-4313-b858-22be3a7d8666": [
            "3d7cf5f1-d5d3-4fe1-9ab4-e6e1fe15ba98"
        ],
        "49982ad8-9974-4cd3-b181-edbdbdc918e9": [
            "d6d98e26-1b03-426c-b9d3-265988b7d534"
        ],
        "12aa510c-6585-44c3-a293-6ae4a2c061ae": [
            "d6d98e26-1b03-426c-b9d3-265988b7d534"
        ],
        "b8f7c972-f1dd-451f-9e0a-280b2ae6c456": [
            "d6d98e26-1b03-426c-b9d3-265988b7d534"
        ],
        "1ef76681-f640-4866-8592-a8c1caef6a41": [
            "14591a5c-68b6-471b-94d3-3c1d835fd73d"
        ],
        "354e6d24-d521-4d5c-91ee-a638bbb2cc5b": [
            "14591a5c-68b6-471b-94d3-3c1d835fd73d"
        ],
        "003d9865-4854-4398-8853-3ba68bbee15c": [
            "26863519-3ca9-44a4-b4aa-e68af3be5a7a"
        ],
        "a1a4eb64-b6a0-4c45-b47d-b935ba7fb15d": [
            "26863519-3ca9-44a4-b4aa-e68af3be5a7a"
        ],
        "98b6b790-ad38-4a12-b658-ca9794ace3d0": [
            "26863519-3ca9-44a4-b4aa-e68af3be5a7a"
        ],
        "2fd5cfa9-3b0a-4e79-9214-f389647ea58f": [
            "26863519-3ca9-44a4-b4aa-e68af3be5a7a"
        ],
        "66947fb0-cfc3-42b6-ae2d-58eafe697d80": [
            "9e249fba-0770-41d1-95f7-d97d5b64945d"
        ],
        "23b5143e-c493-4215-b0b9-81a05e175fc3": [
            "9e249fba-0770-41d1-95f7-d97d5b64945d"
        ],
        "92611f50-63e3-4355-b694-855963a0d313": [
            "9e249fba-0770-41d1-95f7-d97d5b64945d"
        ],
        "a03352b9-a148-45e1-8a57-6740bcfcffce": [
            "9e249fba-0770-41d1-95f7-d97d5b64945d"
        ],
        "03aef07d-d853-4882-97d1-b065a03436c1": [
            "9e249fba-0770-41d1-95f7-d97d5b64945d"
        ],
        "20d7df73-b6f8-4df6-ab1b-e2245ccbc6c5": [
            "7b71e183-6d43-4aa6-8c35-a71635ffe38e"
        ],
        "629e24a7-8eed-456c-95ad-81f08c9e32e3": [
            "7b71e183-6d43-4aa6-8c35-a71635ffe38e"
        ],
        "84cc5982-9bfd-4081-a23c-5b09321afb75": [
            "7b71e183-6d43-4aa6-8c35-a71635ffe38e"
        ],
        "b491640b-5f65-4de8-8e71-7069dfe70820": [
            "7b71e183-6d43-4aa6-8c35-a71635ffe38e"
        ],
        "4bfe1815-e6ee-4ecf-8f19-6302dd14ea8f": [
            "7b71e183-6d43-4aa6-8c35-a71635ffe38e"
        ],
        "4c731a40-9146-4f76-9de8-073f824224be": [
            "25530425-2315-42cf-8c01-0f22e924e79b"
        ],
        "f43678aa-a16c-4d7c-bbb5-49d5e675f35f": [
            "25530425-2315-42cf-8c01-0f22e924e79b"
        ],
        "de5a6de1-f861-4d2e-a8d6-dcaf04be7d45": [
            "25530425-2315-42cf-8c01-0f22e924e79b"
        ],
        "43221aad-4c20-4510-af86-c22d03511ff0": [
            "ce006e9f-386f-41ca-93dd-037bf3cb2122"
        ],
        "fa11dfbd-e63a-404e-a95d-9eca169004db": [
            "ce006e9f-386f-41ca-93dd-037bf3cb2122"
        ],
        "f3f2bc9a-4843-4aca-876e-59e694a73773": [
            "d9d4a246-4091-42c2-ad28-7d68117a6644"
        ],
        "911280ab-3079-46b5-a935-364c8169f003": [
            "d9d4a246-4091-42c2-ad28-7d68117a6644"
        ],
        "32f54477-722b-4eeb-8287-3fe28fd2bcfd": [
            "5a056a36-8d46-4c2d-82a5-a496f87d2da2"
        ],
        "057a1be1-4434-4124-8a23-0e1c8f1a6914": [
            "5a056a36-8d46-4c2d-82a5-a496f87d2da2"
        ],
        "f5b234d1-65fc-444f-88ea-9088df55ed7d": [
            "5a056a36-8d46-4c2d-82a5-a496f87d2da2"
        ],
        "b31151db-4f43-4338-bd1f-f98fa0ec6a82": [
            "5a056a36-8d46-4c2d-82a5-a496f87d2da2"
        ],
        "bd2e1ad0-2620-46ab-8857-c3652c72fcd0": [
            "5a056a36-8d46-4c2d-82a5-a496f87d2da2"
        ],
        "4e9e7afe-c963-4b6f-906f-ef385a973f3c": [
            "605bdd85-aa56-4408-aebe-2733f9324422"
        ],
        "1b3299cc-f851-4df6-b0d5-7ea7a5363eba": [
            "605bdd85-aa56-4408-aebe-2733f9324422"
        ],
        "f8fd2c12-2373-4ce0-a262-f8ef7b9d65c3": [
            "605bdd85-aa56-4408-aebe-2733f9324422"
        ],
        "ca63fa2e-ca98-48c8-adf4-81f9aad404f1": [
            "605bdd85-aa56-4408-aebe-2733f9324422"
        ],
        "3a35fcac-3fc3-4644-83e6-9353f852aa4f": [
            "605bdd85-aa56-4408-aebe-2733f9324422"
        ],
        "5acdfd01-8ed6-4c76-b7b1-01f1ba4f931e": [
            "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3"
        ],
        "8a30c65e-2953-4df2-9e75-e3ff6d811529": [
            "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3"
        ],
        "50255251-b740-4f68-bc75-8eace7864adc": [
            "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3"
        ],
        "12711d86-a0a9-4ab0-bf56-e838ae69b808": [
            "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3"
        ],
        "e5737226-db4b-4de5-946d-77abb7ecc91d": [
            "7ec695b0-1ef6-4bdc-b3d3-8ccfa56ea5d3"
        ],
        "13f8f73c-754b-4e14-b9c6-b6edb5b3af24": [
            "35c49909-93eb-4800-95a1-42885e625575"
        ],
        "161a9983-3584-4ed9-a7e5-7ff09cfd1f25": [
            "35c49909-93eb-4800-95a1-42885e625575"
        ],
        "39aa38d8-d0ff-4e7d-84ac-34b8998cbdf4": [
            "35c49909-93eb-4800-95a1-42885e625575"
        ],
        "10097212-6bfd-4c9e-8e8d-e627dcfc44b2": [
            "35c49909-93eb-4800-95a1-42885e625575"
        ],
        "e6dae53d-d4c8-4e2a-9c33-81eb42f5e588": [
            "7ff2cbe3-765f-4340-a882-114b743e38e5"
        ],
        "e67b2b70-be6c-4048-8b12-5155ec62bb08": [
            "7ff2cbe3-765f-4340-a882-114b743e38e5"
        ],
        "0ed1bef3-2754-4dfe-8ce2-c140a86adc80": [
            "7ff2cbe3-765f-4340-a882-114b743e38e5"
        ],
        "06e2af1f-f0a7-40e1-a357-e3c006c978c2": [
            "7ff2cbe3-765f-4340-a882-114b743e38e5"
        ],
        "c664e3a7-4677-4f56-8b02-c904749b4763": [
            "7ff2cbe3-765f-4340-a882-114b743e38e5"
        ],
        "b323d91a-6351-447c-99ab-dc33ac626099": [
            "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4"
        ],
        "ac2e81d7-6041-4924-8492-634e707934dc": [
            "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4"
        ],
        "034ddd48-944f-439f-9cea-48de6f01faef": [
            "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4"
        ],
        "7aeb4068-dc3f-4e88-beb4-32fc3708439b": [
            "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4"
        ],
        "a490f8d6-5427-4e7d-9694-d1c2ba3303ec": [
            "68dc663b-7ac6-4af3-afb8-3bbcd46c3cb4"
        ],
        "f74f20f5-525f-4cee-bcaf-ef975a10de96": [
            "73742d1b-b8a6-4294-ab4a-d4b528675576"
        ],
        "649e98e7-6340-449f-8660-4167afeefb5c": [
            "73742d1b-b8a6-4294-ab4a-d4b528675576"
        ],
        "46bb7c48-f9e7-41eb-a71b-68bbae4ab921": [
            "73742d1b-b8a6-4294-ab4a-d4b528675576"
        ],
        "cda2017f-6052-4127-b88d-a6ae6f42bdb4": [
            "73742d1b-b8a6-4294-ab4a-d4b528675576"
        ],
        "95de8a82-acd7-4d61-8716-2a8e3fb9a6f9": [
            "73742d1b-b8a6-4294-ab4a-d4b528675576"
        ],
        "924d9304-1dd2-4bfd-b0ef-2654328a98ac": [
            "9497da6f-772f-4249-9c89-7d2c4bb08977"
        ],
        "fa2b491a-4a5a-4fb9-ae9b-6b7a3126237b": [
            "9497da6f-772f-4249-9c89-7d2c4bb08977"
        ],
        "f3b9c7db-040d-4dc8-8cb2-8101916b5f8a": [
            "9497da6f-772f-4249-9c89-7d2c4bb08977"
        ],
        "2329a286-c3a6-4795-8314-3193d7b26415": [
            "3f64143a-3245-423b-a626-e94005fc3ef0"
        ],
        "19e8b710-70d8-4654-afec-1722c7290636": [
            "3f64143a-3245-423b-a626-e94005fc3ef0"
        ],
        "9e2accf4-58fc-49a4-81e8-c58554a40de7": [
            "3f64143a-3245-423b-a626-e94005fc3ef0"
        ],
        "37ad5a84-ecaf-44c0-920b-cf308931f445": [
            "3f64143a-3245-423b-a626-e94005fc3ef0"
        ],
        "4bd1ca3e-898e-4dbd-9c71-67ddc8798b6b": [
            "f457f437-5780-4380-9834-4d04bbe9242b"
        ],
        "8d05648f-f9dd-4b60-9d16-abef0a993c61": [
            "f457f437-5780-4380-9834-4d04bbe9242b"
        ],
        "cb661c62-8483-4c7d-b5e1-f365e85084c8": [
            "f457f437-5780-4380-9834-4d04bbe9242b"
        ],
        "202a3cf3-327c-4246-927c-7b02acd59df0": [
            "ada7a6ce-8f09-4a8a-ab3c-c0d0aa3d6cba"
        ],
        "91681c94-1147-4207-a209-253c7e8d2739": [
            "ada7a6ce-8f09-4a8a-ab3c-c0d0aa3d6cba"
        ],
        "efc8fa8a-9c9a-451c-838b-c1e8cd1913e0": [
            "ada7a6ce-8f09-4a8a-ab3c-c0d0aa3d6cba"
        ],
        "dad1e8a3-8a90-4167-a7bc-25b6aea725b9": [
            "a5466468-1762-4e22-a233-cbd82d7eb77d"
        ],
        "93994702-a3b4-451c-812d-064b92793940": [
            "a5466468-1762-4e22-a233-cbd82d7eb77d"
        ],
        "8a804230-9d59-4eb7-a222-0d8751167b77": [
            "a5466468-1762-4e22-a233-cbd82d7eb77d"
        ],
        "161058a3-be85-4ee5-9d13-ebcfa5c5eb94": [
            "a5466468-1762-4e22-a233-cbd82d7eb77d"
        ],
        "942a8b0a-58d7-45c2-94be-9ac14bf5faaa": [
            "a5466468-1762-4e22-a233-cbd82d7eb77d"
        ],
        "52d361bd-8bda-4382-82b3-1d44d64e3b04": [
            "1a7fb1be-bd49-4b0d-ad9c-86beed902bcd"
        ],
        "7bb0d513-906d-4bbc-b050-ace8b60a6fb0": [
            "1a7fb1be-bd49-4b0d-ad9c-86beed902bcd"
        ],
        "66e26295-0926-4baa-8de4-8ee51f4f5736": [
            "c9211a67-866e-490d-8e0d-8d51ab4241a6"
        ],
        "486b0f46-4187-4d14-932c-884f1d3722e2": [
            "c9211a67-866e-490d-8e0d-8d51ab4241a6"
        ],
        "143c99ba-7f3b-48a7-9d6f-16fb06d5a329": [
            "460c0b61-1c48-4b45-b2f9-0ffb19161952"
        ],
        "0a1e50e8-bc96-432e-ac22-e83f6f216426": [
            "460c0b61-1c48-4b45-b2f9-0ffb19161952"
        ],
        "6798e893-c63b-497b-97d9-25644080c7dc": [
            "460c0b61-1c48-4b45-b2f9-0ffb19161952"
        ],
        "d09ec54b-7564-437c-8491-08756dd87661": [
            "460c0b61-1c48-4b45-b2f9-0ffb19161952"
        ],
        "af5d635c-794d-4d49-aa37-90448bd88f41": [
            "460c0b61-1c48-4b45-b2f9-0ffb19161952"
        ],
        "e3dca307-a5b4-4652-9d3a-1289816cdd19": [
            "ed6ec4f2-f7de-40cf-a92a-1249badb0dd2"
        ],
        "794fdbe5-b38e-46af-bc2e-061f91c0d522": [
            "ed6ec4f2-f7de-40cf-a92a-1249badb0dd2"
        ],
        "99291476-fc0e-4bcb-b114-c7c3115cd9e2": [
            "ed6ec4f2-f7de-40cf-a92a-1249badb0dd2"
        ],
        "2e4f9bbf-ac6f-4082-98c1-03028cb643a5": [
            "ed6ec4f2-f7de-40cf-a92a-1249badb0dd2"
        ],
        "659861e0-aef2-415f-b462-1039c86088d5": [
            "731114e7-d6ff-43a1-b64c-f1f0547e411b"
        ],
        "6cab749e-8ed7-40e0-9219-1f8106fc43d5": [
            "731114e7-d6ff-43a1-b64c-f1f0547e411b"
        ],
        "2d0eebd6-f019-471d-8abf-68e25810f9db": [
            "1c3dd3c5-5f5d-4d9c-8dee-724cb8f586f2"
        ],
        "5e1c6bf0-c426-464e-9176-1acc1249ba24": [
            "1c3dd3c5-5f5d-4d9c-8dee-724cb8f586f2"
        ],
        "e509e225-099c-4858-9aa3-99a85bc8966d": [
            "1c3dd3c5-5f5d-4d9c-8dee-724cb8f586f2"
        ],
        "2df27e20-16b0-4788-88fa-5458af0b7940": [
            "1c3dd3c5-5f5d-4d9c-8dee-724cb8f586f2"
        ],
        "790d951d-4056-4ef2-8edc-d6977a8326e6": [
            "e0d214e7-c05c-4452-80ff-79382eece746"
        ],
        "92cd0350-eddd-48b4-bfde-774440ae7781": [
            "e0d214e7-c05c-4452-80ff-79382eece746"
        ],
        "64b08ec3-2497-49df-a378-420f86141215": [
            "e0d214e7-c05c-4452-80ff-79382eece746"
        ],
        "8780d056-8de7-4916-837d-26419e651030": [
            "e0d214e7-c05c-4452-80ff-79382eece746"
        ],
        "661666e5-c9ec-44a7-9d84-67f8652d5fdf": [
            "e0d214e7-c05c-4452-80ff-79382eece746"
        ],
        "cf9b8d18-f1e5-486d-b4bf-c6ba5f98c636": [
            "6ceb7709-fc92-4c21-b126-15f5e622c83b"
        ],
        "12a9c3a0-1cfb-4f41-88be-7bc1764a1b8d": [
            "6ceb7709-fc92-4c21-b126-15f5e622c83b"
        ],
        "0470874c-ad29-474e-8dd3-25692e17489d": [
            "6ceb7709-fc92-4c21-b126-15f5e622c83b"
        ],
        "dd7add59-02b3-443f-9451-b7a4fa7c8d06": [
            "6ceb7709-fc92-4c21-b126-15f5e622c83b"
        ],
        "2bc58d67-3c16-4dd8-a6af-b5a23f679631": [
            "6ceb7709-fc92-4c21-b126-15f5e622c83b"
        ],
        "3f573720-d4d9-4394-9be8-0e6ca9953d52": [
            "5c3c5e4c-ccb8-4915-af80-adc7a667daf4"
        ],
        "dc1952e3-3d03-4b2c-a4e9-2ec9a419739a": [
            "5c3c5e4c-ccb8-4915-af80-adc7a667daf4"
        ],
        "5eaa50be-0eab-41b0-8095-1e14a2a252a7": [
            "5c3c5e4c-ccb8-4915-af80-adc7a667daf4"
        ],
        "6d604f4b-ed04-4027-ae48-049f8585744c": [
            "54901690-7e9f-4112-9582-bebb286bc44d"
        ],
        "d7ee352d-34dc-4496-827e-a0fd5954eedd": [
            "54901690-7e9f-4112-9582-bebb286bc44d"
        ],
        "b8fde8a1-b5d1-47e3-b855-c5b7e332ebfa": [
            "54901690-7e9f-4112-9582-bebb286bc44d"
        ],
        "eb057023-f2bb-4cdb-8eed-df29378b9d50": [
            "54901690-7e9f-4112-9582-bebb286bc44d"
        ],
        "4648609e-25e9-4a5f-be3f-0a3a080ecad8": [
            "54901690-7e9f-4112-9582-bebb286bc44d"
        ],
        "82d6b3b4-18be-4d79-8001-daad46e36cb4": [
            "43f1b3b9-3661-456a-81fc-fd9728a19e53"
        ],
        "1aa452b0-3ca2-490b-898a-b44fa99d9526": [
            "43f1b3b9-3661-456a-81fc-fd9728a19e53"
        ],
        "17dccdb7-dd4e-4a94-8690-48b201e9b743": [
            "43f1b3b9-3661-456a-81fc-fd9728a19e53"
        ],
        "67332738-625f-4859-829a-ef10478d6215": [
            "43f1b3b9-3661-456a-81fc-fd9728a19e53"
        ],
        "b9b9f507-c807-49d2-b408-f400436149c9": [
            "43f1b3b9-3661-456a-81fc-fd9728a19e53"
        ],
        "d4975b55-22d2-4d0c-b2af-72813943864a": [
            "877425de-0e10-4378-9488-d4df19756fe1"
        ],
        "fa03c118-03dd-423c-a212-bf5fadc5315b": [
            "877425de-0e10-4378-9488-d4df19756fe1"
        ],
        "53a9a5b7-7999-4927-9d41-d5242900cf55": [
            "877425de-0e10-4378-9488-d4df19756fe1"
        ],
        "6c88a6ee-3684-4d60-a299-d1986e9fb340": [
            "877425de-0e10-4378-9488-d4df19756fe1"
        ],
        "5da218a1-c579-4491-b505-3b2f671223c7": [
            "877425de-0e10-4378-9488-d4df19756fe1"
        ],
        "07f7372c-3dd8-4ed1-9ac6-3e94dacc8e7c": [
            "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5"
        ],
        "093b97e5-589f-4abc-803d-c109417c4240": [
            "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5"
        ],
        "ad0f1b9e-6ee1-422f-88b5-b4a09745a26f": [
            "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5"
        ],
        "6501f092-7ab3-457a-84ec-158c22107416": [
            "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5"
        ],
        "95b0ef71-594b-4ba0-a8b5-4414fda9249d": [
            "5b6b6891-ef73-4eb8-b8b9-7a9ccea172a5"
        ],
        "edea2a07-3083-4b95-8de4-df8413a24f17": [
            "48249f21-c82b-4151-a1f3-24778c309a3b"
        ],
        "41198372-404f-4f75-ab9f-8b2021883564": [
            "48249f21-c82b-4151-a1f3-24778c309a3b"
        ],
        "0c4429a2-e294-4304-9db7-3d2362c65f3e": [
            "48249f21-c82b-4151-a1f3-24778c309a3b"
        ],
        "5e379ad7-3371-4ae4-8aef-540657d88c94": [
            "48249f21-c82b-4151-a1f3-24778c309a3b"
        ],
        "00e57918-f0fd-46dd-b335-a2e517f3c64b": [
            "48249f21-c82b-4151-a1f3-24778c309a3b"
        ],
        "81ab2f96-8ab5-4258-917a-f25297c222ac": [
            "0842dfc8-98cc-4063-ae45-903d4237329a"
        ],
        "71184d77-8c8f-4e30-8192-1ff5d2d1d4d4": [
            "0842dfc8-98cc-4063-ae45-903d4237329a"
        ],
        "175cbc85-9f32-4475-9885-943cbb822b9e": [
            "0842dfc8-98cc-4063-ae45-903d4237329a"
        ],
        "0a6ea92c-3b21-4342-9420-571a5dd49b68": [
            "0842dfc8-98cc-4063-ae45-903d4237329a"
        ],
        "9fc05aa3-b232-4b18-a882-e6f97b6a97bd": [
            "0842dfc8-98cc-4063-ae45-903d4237329a"
        ],
        "a251cb58-85a0-4808-9b51-f825b2e0a543": [
            "a3ba1560-813e-4666-8321-e5f07b0aa551"
        ],
        "f0a02d8c-f511-4b7d-9650-a7c5f57d5339": [
            "a3ba1560-813e-4666-8321-e5f07b0aa551"
        ],
        "89ed69ea-a9f9-488d-bb90-1d6c8e6f14fa": [
            "a3ba1560-813e-4666-8321-e5f07b0aa551"
        ],
        "156f94da-61fe-4475-9e67-e6c578730844": [
            "a3ba1560-813e-4666-8321-e5f07b0aa551"
        ],
        "6b35baef-c980-49b5-ad9a-d650a4ffa5f3": [
            "a3ba1560-813e-4666-8321-e5f07b0aa551"
        ],
        "6050885e-864c-4e31-8abf-1acfd1a211af": [
            "080e7fa7-7959-4061-9955-8f27948863a9"
        ],
        "4f16248c-044f-43b2-b488-0e3e8e94a825": [
            "080e7fa7-7959-4061-9955-8f27948863a9"
        ],
        "74a77a86-47b8-4e6c-930d-4842c56894b2": [
            "080e7fa7-7959-4061-9955-8f27948863a9"
        ],
        "7a5a248e-c3f5-4ba1-be8a-ba940c9684df": [
            "080e7fa7-7959-4061-9955-8f27948863a9"
        ],
        "4ec538a2-6af2-4e83-bf20-6870a7cc1daa": [
            "080e7fa7-7959-4061-9955-8f27948863a9"
        ],
        "d5637243-103e-4aef-861d-a19bcd1039c3": [
            "8429c806-222c-4bd2-b6dc-0e46b00cdd3b"
        ],
        "5356c70c-e168-426e-87aa-09c8ebf41e2d": [
            "8429c806-222c-4bd2-b6dc-0e46b00cdd3b"
        ],
        "141cae02-bbc1-4bc7-bb7c-69f40c88640c": [
            "8429c806-222c-4bd2-b6dc-0e46b00cdd3b"
        ],
        "3bed213e-5d27-4364-ab69-e610f77c66d4": [
            "8429c806-222c-4bd2-b6dc-0e46b00cdd3b"
        ],
        "5770ab2d-08cb-4e6f-b186-42fe0ce54d99": [
            "8429c806-222c-4bd2-b6dc-0e46b00cdd3b"
        ],
        "58c0c0ec-c0e5-429f-b1f0-d16ec39bcbbb": [
            "ba5b35f6-e3c5-4d08-aefa-711db9dd8ef9"
        ],
        "7c0ae6a1-de7a-4518-9f0c-b026cf18e000": [
            "ba5b35f6-e3c5-4d08-aefa-711db9dd8ef9"
        ],
        "05665f64-7d76-4444-ad2b-b11594aea606": [
            "ba5b35f6-e3c5-4d08-aefa-711db9dd8ef9"
        ],
        "3a626526-5fd8-4584-bd73-51f8bceed7da": [
            "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd"
        ],
        "3a306eeb-cd3e-4b72-bb5f-7db090d93f5e": [
            "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd"
        ],
        "2054b201-178a-41a0-8c68-c211bf77ddc2": [
            "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd"
        ],
        "41e410e1-1e06-430d-be8a-09018e7ff361": [
            "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd"
        ],
        "85c61ae9-0e0f-46e6-a74a-d64bdf4f879e": [
            "9165e7ad-a6bf-4f4a-b3ce-0daed70428dd"
        ],
        "d7a628b8-1de7-452c-868a-3ff744296a81": [
            "59bcb2c1-bdb2-4631-9e28-f5fc9610e9b6"
        ],
        "51fbe082-75d3-4ba8-884e-64ee9e13f586": [
            "59bcb2c1-bdb2-4631-9e28-f5fc9610e9b6"
        ],
        "cf34b67b-f268-4709-98b5-bb34abc4145d": [
            "229c72e8-adee-40b1-a1c9-d4270155a1ad"
        ],
        "ec9013a3-7252-43b8-9ea3-bbe14aec026a": [
            "229c72e8-adee-40b1-a1c9-d4270155a1ad"
        ],
        "23a663b7-1ccf-4fd4-8670-229a6cdfe239": [
            "229c72e8-adee-40b1-a1c9-d4270155a1ad"
        ],
        "f622dd81-bd08-41fd-9561-23be7dafa22c": [
            "229c72e8-adee-40b1-a1c9-d4270155a1ad"
        ],
        "3f510c16-a682-4403-8bf9-c736b9f51b52": [
            "229c72e8-adee-40b1-a1c9-d4270155a1ad"
        ],
        "f8be00c8-d1dc-4d9c-b0e9-9bd0200e5096": [
            "e0fc2709-1cf5-4b4f-8497-4d68b11ae008"
        ],
        "d378c8a0-9676-4142-9bb3-6d78d2578ff8": [
            "e0fc2709-1cf5-4b4f-8497-4d68b11ae008"
        ],
        "bb24b49a-56dd-4687-8785-254b3e55dfc6": [
            "e0fc2709-1cf5-4b4f-8497-4d68b11ae008"
        ],
        "1cb46303-3400-4e16-933e-3e464f133474": [
            "e0fc2709-1cf5-4b4f-8497-4d68b11ae008"
        ],
        "27e1c989-870e-470d-8b31-d4374f6a622f": [
            "edb6ee27-4900-409c-82c0-b6ad447712c6"
        ],
        "63557a16-1f14-44f5-b9e4-a37a03fb2cfb": [
            "edb6ee27-4900-409c-82c0-b6ad447712c6"
        ],
        "bdbf6ecf-3217-47d7-b1c5-a0d2a3f3a958": [
            "edb6ee27-4900-409c-82c0-b6ad447712c6"
        ],
        "87416b6b-3708-4184-b2a2-b60e16f39d04": [
            "edb6ee27-4900-409c-82c0-b6ad447712c6"
        ],
        "e69d3e7d-3008-4181-b8c2-3727866f5749": [
            "edb6ee27-4900-409c-82c0-b6ad447712c6"
        ],
        "c6c5b543-cb01-4de9-b2df-6e60b3d757b7": [
            "5d96f0bf-4d4d-4b81-846b-7453a83b7554"
        ],
        "f43e40f8-51ae-4365-847b-47e890d04ae4": [
            "5d96f0bf-4d4d-4b81-846b-7453a83b7554"
        ],
        "698f6d99-4b0f-4adf-9d42-a4a64710e416": [
            "3cbe1897-367d-47d3-9291-1bedf70366a1"
        ],
        "12dbe42d-327b-4d50-8386-3057b72079f0": [
            "3cbe1897-367d-47d3-9291-1bedf70366a1"
        ],
        "50259719-75d2-45de-9e08-014081a26b50": [
            "ebf0b555-e717-43e5-88fe-96f92de8d76f"
        ],
        "9455e181-1eb4-492d-b33f-1170577ae911": [
            "ebf0b555-e717-43e5-88fe-96f92de8d76f"
        ],
        "c6c8bfeb-6c57-447e-a33a-c6a8d31ba53b": [
            "bc4b70f6-1b9c-4340-83c3-03360f5e3d89"
        ],
        "1a372927-90a2-49c1-a990-e1f082153101": [
            "bc4b70f6-1b9c-4340-83c3-03360f5e3d89"
        ],
        "937e41f0-fbdf-4e0d-acc2-a22c8cd2c535": [
            "bc4b70f6-1b9c-4340-83c3-03360f5e3d89"
        ],
        "75e76ce1-8ea0-43ac-91cf-71aa5adabfc7": [
            "ca277acd-f083-4c2b-931d-e01f804f048a"
        ],
        "7c0c8fee-c298-4c35-a40c-bb02cb85073c": [
            "ca277acd-f083-4c2b-931d-e01f804f048a"
        ],
        "d91f2fd6-ef73-4aab-8c26-f3954498604f": [
            "ca277acd-f083-4c2b-931d-e01f804f048a"
        ],
        "7d5495cb-f025-4ef9-a2ec-a9fdb377d280": [
            "ca277acd-f083-4c2b-931d-e01f804f048a"
        ],
        "eb816074-2cd4-475f-8374-6d33bb435598": [
            "ca277acd-f083-4c2b-931d-e01f804f048a"
        ],
        "de54ce67-adfb-4816-9ba7-095c81b74978": [
            "ecbbc79c-ae02-49d4-ae93-13650c0458bf"
        ],
        "9c587d54-a22d-4027-b7f4-0d9ce5df2e1a": [
            "ecbbc79c-ae02-49d4-ae93-13650c0458bf"
        ],
        "2b64890d-1740-4518-80ad-9ae56518db9a": [
            "ecbbc79c-ae02-49d4-ae93-13650c0458bf"
        ],
        "13514cef-459d-46a0-a3b8-dd10efb5390e": [
            "ecbbc79c-ae02-49d4-ae93-13650c0458bf"
        ],
        "204298fa-3fa2-4789-a765-fd0d16b3c38d": [
            "ee2660c9-d070-4c13-9f4b-c6c371c407d0"
        ],
        "209e7858-7b96-4a37-9efc-beab4226333d": [
            "ee2660c9-d070-4c13-9f4b-c6c371c407d0"
        ],
        "d035adbc-765b-4703-9270-5961eff983ab": [
            "ee2660c9-d070-4c13-9f4b-c6c371c407d0"
        ],
        "f6fc6141-55fc-418e-9848-439f460034db": [
            "ee2660c9-d070-4c13-9f4b-c6c371c407d0"
        ],
        "6393a96e-1dae-4ba7-8336-0d7844d228ef": [
            "ee2660c9-d070-4c13-9f4b-c6c371c407d0"
        ],
        "f0162586-ca1c-42b2-8e53-866775af22d7": [
            "90c185c8-41e2-4642-a8ae-830fa3809fac"
        ],
        "08b13e28-0fa8-48b9-a578-fe0a82bbe4d5": [
            "90c185c8-41e2-4642-a8ae-830fa3809fac"
        ],
        "b4302c0b-aea5-4878-b1e4-2f45029443cb": [
            "90c185c8-41e2-4642-a8ae-830fa3809fac"
        ],
        "614c9562-3bab-426e-aaca-afaa39b57798": [
            "62811350-736e-4f5f-ba5c-e9b3d767ec7a"
        ],
        "3072918f-63ab-44f4-826a-37ecad540b62": [
            "62811350-736e-4f5f-ba5c-e9b3d767ec7a"
        ],
        "585d9326-8905-486f-92f8-ccdfda1ab7c2": [
            "62811350-736e-4f5f-ba5c-e9b3d767ec7a"
        ],
        "1a91a0e1-192c-4998-af9e-506b43c52d70": [
            "4748cc60-ab41-413a-be1b-fe5abfed0acf"
        ],
        "faaf1168-edd8-4c68-be27-bfa6a0411940": [
            "4748cc60-ab41-413a-be1b-fe5abfed0acf"
        ],
        "29a739b3-3b41-4f8c-a3ad-fe47f1b17b15": [
            "4748cc60-ab41-413a-be1b-fe5abfed0acf"
        ],
        "d50e8650-3e81-4aaf-a5bf-6353eeca8911": [
            "4748cc60-ab41-413a-be1b-fe5abfed0acf"
        ],
        "c61b3beb-3e88-41a1-bba1-05868f5ba838": [
            "4748cc60-ab41-413a-be1b-fe5abfed0acf"
        ],
        "f5e333fd-66b7-4bc2-8f42-94f4288021ed": [
            "27e84570-b7f7-43f4-86ed-582d09b3e250"
        ],
        "45a9ae6f-976a-47b7-a92a-145a59224d18": [
            "27e84570-b7f7-43f4-86ed-582d09b3e250"
        ],
        "ddfdf4bb-b05c-4c97-9145-40f79134f08d": [
            "27e84570-b7f7-43f4-86ed-582d09b3e250"
        ],
        "fd0f5fdb-52b7-4659-844d-0ab4d945428c": [
            "806e94f3-ef63-4ca5-8e9c-256ab0a731f2"
        ],
        "86ad7e1c-04b0-461b-acec-aa819cde28cd": [
            "806e94f3-ef63-4ca5-8e9c-256ab0a731f2"
        ],
        "0617f108-4287-4db3-938c-dc0b72f3e8be": [
            "806e94f3-ef63-4ca5-8e9c-256ab0a731f2"
        ],
        "642f5549-30a6-4b76-a7cc-a0bdff8dafa0": [
            "806e94f3-ef63-4ca5-8e9c-256ab0a731f2"
        ],
        "0149dc08-41e2-4b3e-bed2-6fe6ca83e800": [
            "f245eb97-4360-4adb-a1ad-4d9bfff540c9"
        ],
        "a8cae3b6-20eb-4ebd-8aa1-aef45059502b": [
            "f245eb97-4360-4adb-a1ad-4d9bfff540c9"
        ],
        "746703a1-7aae-4bdc-ad3f-0e8922b32284": [
            "f245eb97-4360-4adb-a1ad-4d9bfff540c9"
        ],
        "71c60b74-1cb6-4b4f-9f6c-c860e3615402": [
            "18c65a55-8d90-44b8-88b5-09a500b7a64c"
        ],
        "30367ca8-0ad4-4bd8-bb4e-1c2685afa51b": [
            "18c65a55-8d90-44b8-88b5-09a500b7a64c"
        ],
        "276dfccc-f6f6-4ee0-b195-34baf3d4e2b8": [
            "6e5046ac-6386-428b-9a41-b2669372fc0f"
        ],
        "d77f55bf-c125-41fb-8b40-6b78182a3f91": [
            "6e5046ac-6386-428b-9a41-b2669372fc0f"
        ],
        "2df10a72-6a80-4293-8216-1da58dd279f8": [
            "6e5046ac-6386-428b-9a41-b2669372fc0f"
        ],
        "17dd1136-4cdc-4ea0-afe0-e065b9327147": [
            "0ec49777-138b-472e-909c-ea918d632b5f"
        ],
        "cdcc94e9-2395-4184-8c25-9b8b76a1a929": [
            "0ec49777-138b-472e-909c-ea918d632b5f"
        ],
        "11db8368-8421-4118-b5c4-148e86ed52ea": [
            "0ec49777-138b-472e-909c-ea918d632b5f"
        ],
        "7c493d61-472a-4664-811f-7a1cf378e26b": [
            "0ec49777-138b-472e-909c-ea918d632b5f"
        ],
        "5ec81c0e-bd3e-4de1-883b-c72e3c68bc27": [
            "8daca4a3-d167-49f3-990b-cbd448d96d81"
        ],
        "eb405520-3000-48cd-8790-8fd9eea3ab24": [
            "8daca4a3-d167-49f3-990b-cbd448d96d81"
        ],
        "1d76ea38-d692-474f-8dd3-9777e49f3faf": [
            "8daca4a3-d167-49f3-990b-cbd448d96d81"
        ],
        "34d7444e-2cc2-4003-8596-7b5c13ce2871": [
            "79dc952e-2935-49ce-93ec-0421ec411ddd"
        ],
        "db51dac3-d639-4062-96ef-912d5f00b464": [
            "79dc952e-2935-49ce-93ec-0421ec411ddd"
        ],
        "d24c76ca-a45a-4162-a67f-fa4ca7edd3f2": [
            "79dc952e-2935-49ce-93ec-0421ec411ddd"
        ],
        "a5b80ca8-80b3-4a5c-96fc-093831417789": [
            "79dc952e-2935-49ce-93ec-0421ec411ddd"
        ],
        "3526b2fe-2898-4425-863c-332a045e295d": [
            "79dc952e-2935-49ce-93ec-0421ec411ddd"
        ],
        "23b3b34b-cc1b-427d-944d-ab646159ea1f": [
            "e4ac8d47-17f0-4b14-996e-4a19f728fe8b"
        ],
        "0301410c-97b4-4419-8ff9-06207574cfc8": [
            "e4ac8d47-17f0-4b14-996e-4a19f728fe8b"
        ],
        "d4fd7f29-b386-4dd1-a8ce-f9ec788f1554": [
            "e4ac8d47-17f0-4b14-996e-4a19f728fe8b"
        ],
        "6310afd7-c05d-4db4-a1d4-974f03ef3dff": [
            "391f4c2a-f856-481f-8dcb-ff29ee963881"
        ],
        "95c777dc-b9df-4c7b-9ef7-f130ae47cf20": [
            "391f4c2a-f856-481f-8dcb-ff29ee963881"
        ],
        "be3f874f-f069-458f-bbff-280605953357": [
            "391f4c2a-f856-481f-8dcb-ff29ee963881"
        ],
        "762a1aa5-7aa6-4b68-be2d-64dfcd4dd4f7": [
            "391f4c2a-f856-481f-8dcb-ff29ee963881"
        ],
        "6d921640-9686-45e5-8614-3f679bb97c29": [
            "391f4c2a-f856-481f-8dcb-ff29ee963881"
        ],
        "4ae9b02c-095c-4707-96c9-80d81f1878d2": [
            "e3d5006e-0145-4a79-9131-a3028d80af64"
        ],
        "edf94837-6283-4fff-b84c-85697b77fa8c": [
            "e3d5006e-0145-4a79-9131-a3028d80af64"
        ],
        "cd927a76-3459-4dd5-83a1-3872c8273c12": [
            "e3d5006e-0145-4a79-9131-a3028d80af64"
        ],
        "f2383c24-16cd-415b-9610-ec6364d9bdfd": [
            "e3d5006e-0145-4a79-9131-a3028d80af64"
        ],
        "49c13283-e01c-4e60-a272-a9a3357b9be5": [
            "be78bb13-3e46-4c1d-abef-f131a40cf72f"
        ],
        "22eb640d-e8e8-4230-abbe-4abc3b7003bb": [
            "be78bb13-3e46-4c1d-abef-f131a40cf72f"
        ],
        "a6d9a45d-40cc-43fd-8b2e-ca78a7802476": [
            "be78bb13-3e46-4c1d-abef-f131a40cf72f"
        ],
        "8c17b9d9-66ac-4b0f-b75d-e5bcb148d8e2": [
            "be78bb13-3e46-4c1d-abef-f131a40cf72f"
        ],
        "bdcf4f1e-5077-4ecd-9f16-7a64f09258a2": [
            "be78bb13-3e46-4c1d-abef-f131a40cf72f"
        ],
        "456fbd83-b34b-4d0b-a158-5efe4468a98b": [
            "46062741-82a7-445f-87c1-f08910f7c8fd"
        ],
        "b58e40de-78f8-444b-9f07-d88e2089f842": [
            "46062741-82a7-445f-87c1-f08910f7c8fd"
        ],
        "e029e3ed-7954-4ec5-a0b3-141cb2b960af": [
            "46062741-82a7-445f-87c1-f08910f7c8fd"
        ],
        "72b0e059-0392-4182-92f7-48f35a51c96d": [
            "b7d634c9-4b9c-4a51-aab6-5ff697a05248"
        ],
        "de2f00a7-412c-4bac-b48f-f2f0b7322874": [
            "b7d634c9-4b9c-4a51-aab6-5ff697a05248"
        ],
        "a9455638-8721-4833-85c2-de0101fc63d8": [
            "b7d634c9-4b9c-4a51-aab6-5ff697a05248"
        ],
        "f56ddf0c-dbb5-4d87-9d52-78dc2ed560cc": [
            "b7d634c9-4b9c-4a51-aab6-5ff697a05248"
        ],
        "ffeb5b1c-4676-483b-b9c9-0b92fd138c30": [
            "b7d634c9-4b9c-4a51-aab6-5ff697a05248"
        ],
        "e1c7caec-6fac-4613-9107-bdf09c21027b": [
            "1673c6ec-906e-4d25-852c-cacee830590b"
        ],
        "d331564a-2310-4b90-a597-084432886a4a": [
            "1673c6ec-906e-4d25-852c-cacee830590b"
        ],
        "38b559ed-f686-43fa-b94e-e60a5ef2d7b9": [
            "1673c6ec-906e-4d25-852c-cacee830590b"
        ],
        "3e4df84e-570b-4567-afb0-5c040d5e3cda": [
            "1673c6ec-906e-4d25-852c-cacee830590b"
        ],
        "a87087f4-f501-4994-8428-616ba2435473": [
            "1673c6ec-906e-4d25-852c-cacee830590b"
        ],
        "e9dc63cc-7ec5-4a21-abf9-c86c53e2e740": [
            "c41136fd-5d65-435c-bf51-9600fa340b34"
        ],
        "4c9fda47-6052-47b6-b566-d8c87ae72053": [
            "c41136fd-5d65-435c-bf51-9600fa340b34"
        ],
        "30a5b7df-5528-47cf-9975-b892fa957e79": [
            "c41136fd-5d65-435c-bf51-9600fa340b34"
        ],
        "76861533-434d-445a-a4d5-7519fab78c45": [
            "c41136fd-5d65-435c-bf51-9600fa340b34"
        ],
        "449640f9-8188-47f7-bfcf-8deb26e68ad8": [
            "c41136fd-5d65-435c-bf51-9600fa340b34"
        ],
        "c12707e7-99fc-4d74-abdd-79004c8e45a0": [
            "678858bf-682f-4d01-a6ba-128cb42331f0"
        ],
        "14383229-5ddb-426a-842e-d7b426a26107": [
            "678858bf-682f-4d01-a6ba-128cb42331f0"
        ],
        "784e98ac-60ff-4d3a-a2a9-bd9544a9a6b4": [
            "678858bf-682f-4d01-a6ba-128cb42331f0"
        ],
        "f56882ea-afbc-443f-8ad7-a353b11a1d9f": [
            "678858bf-682f-4d01-a6ba-128cb42331f0"
        ],
        "bf29c046-4324-43d2-8753-e8622f05dc49": [
            "b16095d9-1386-4fb7-9917-e443c6f175bb"
        ],
        "a2381bb5-29de-4b64-abb0-5637eb630a95": [
            "b16095d9-1386-4fb7-9917-e443c6f175bb"
        ],
        "9492b885-89a8-472a-8b74-3a3094212a64": [
            "b16095d9-1386-4fb7-9917-e443c6f175bb"
        ],
        "fc6741e2-ef2d-4123-8c23-a101598ffd4a": [
            "b16095d9-1386-4fb7-9917-e443c6f175bb"
        ],
        "021bdf9e-0d1f-4c60-b73a-86534fa42abe": [
            "b16095d9-1386-4fb7-9917-e443c6f175bb"
        ],
        "8e243682-fa8a-43b3-8ba1-b6c68f27ba88": [
            "c5930ee0-f3e3-474b-8d8b-28afbd5895dc"
        ],
        "537dba5e-2ff3-4308-83b7-83d95c3ab5a8": [
            "c5930ee0-f3e3-474b-8d8b-28afbd5895dc"
        ],
        "a01bef87-8d70-4cd7-bc3a-586e3d64ca80": [
            "c5930ee0-f3e3-474b-8d8b-28afbd5895dc"
        ],
        "1adc8b90-b5f2-49d9-a82e-fbd6786e2211": [
            "c5930ee0-f3e3-474b-8d8b-28afbd5895dc"
        ],
        "c64ce0e8-966a-4b0b-abdb-b4c2aea2ab57": [
            "c5930ee0-f3e3-474b-8d8b-28afbd5895dc"
        ],
        "52ce3183-2a55-4c81-95e0-d73ad34bc463": [
            "377d9b81-8efe-4ab4-8b48-ba715772bef1"
        ],
        "2b3fdfd0-b38e-4cd5-8384-87a01c2ce08c": [
            "377d9b81-8efe-4ab4-8b48-ba715772bef1"
        ],
        "fb292328-01cb-4d51-9443-a80998d4db40": [
            "377d9b81-8efe-4ab4-8b48-ba715772bef1"
        ],
        "16e76459-291a-4051-b29a-05c6f5ae6c23": [
            "87ee4951-cb10-4844-905e-29f77a4d53f8"
        ],
        "48974b05-a151-4687-b3eb-410bfbfb575c": [
            "87ee4951-cb10-4844-905e-29f77a4d53f8"
        ],
        "5c2aa13d-27a5-460a-a24a-c9165df2ff83": [
            "87ee4951-cb10-4844-905e-29f77a4d53f8"
        ],
        "6eaae6fd-60e7-453b-9737-93fcbb300821": [
            "87ee4951-cb10-4844-905e-29f77a4d53f8"
        ],
        "ce10d19e-c32d-4daa-a8ac-41a523a58fe1": [
            "87ee4951-cb10-4844-905e-29f77a4d53f8"
        ],
        "d83aeb8b-ebab-4820-b3ec-0f675ba04ba5": [
            "667f9665-2cd2-49d2-9853-cd2c5b18f213"
        ],
        "bf14d2fa-c5a7-4b56-abfb-d82a335b154e": [
            "667f9665-2cd2-49d2-9853-cd2c5b18f213"
        ],
        "2e686e7e-2cd6-417a-97dc-5c8e44bb2824": [
            "667f9665-2cd2-49d2-9853-cd2c5b18f213"
        ],
        "36b6a1c6-fb1f-4eaa-9a5c-2fdc1805f89c": [
            "667f9665-2cd2-49d2-9853-cd2c5b18f213"
        ],
        "30130c0f-3a7f-4abf-9888-b447cfa8ec56": [
            "667f9665-2cd2-49d2-9853-cd2c5b18f213"
        ],
        "a47424c7-3f51-4c07-812b-8e6a4ce5dd25": [
            "7f799c73-ab01-47a2-98bc-20ca737c634c"
        ],
        "f3847573-9c46-43a0-86ed-32aad22ff15a": [
            "7f799c73-ab01-47a2-98bc-20ca737c634c"
        ],
        "ec5c5918-eb06-44a0-add1-a2aaa9a6d368": [
            "7f799c73-ab01-47a2-98bc-20ca737c634c"
        ],
        "d987bc76-c65b-4918-8a92-0f66f1592e59": [
            "7f799c73-ab01-47a2-98bc-20ca737c634c"
        ],
        "5fccc15b-49ce-45f8-84a2-e1f8643d9920": [
            "7f799c73-ab01-47a2-98bc-20ca737c634c"
        ],
        "568f8ebf-c14f-4e42-881a-de4f0aabc851": [
            "e5716ee1-4d40-4a9d-b764-55fdf6293b80"
        ],
        "25284ecb-942d-4a70-88c4-c64bc57e6aed": [
            "e5716ee1-4d40-4a9d-b764-55fdf6293b80"
        ],
        "6ddc8428-832b-4697-a2e7-36b72bc2b84b": [
            "e5716ee1-4d40-4a9d-b764-55fdf6293b80"
        ],
        "dcaee940-6e74-4faf-8325-30f4d5b02544": [
            "031229cd-d9d4-4ea4-bdba-cb8ebf85d680"
        ],
        "6eb8d77d-1acd-41b0-9524-e00919e41974": [
            "031229cd-d9d4-4ea4-bdba-cb8ebf85d680"
        ],
        "d3f90820-e3ed-44ba-92b9-06e05aa5a562": [
            "031229cd-d9d4-4ea4-bdba-cb8ebf85d680"
        ],
        "59957a32-1985-45f7-867f-f8d805ca0179": [
            "031229cd-d9d4-4ea4-bdba-cb8ebf85d680"
        ],
        "523dc148-26ae-425c-93dc-061424a7e2c6": [
            "031229cd-d9d4-4ea4-bdba-cb8ebf85d680"
        ],
        "85a88e10-9b5d-465b-84da-f483b53e9326": [
            "2da75a84-be69-4a55-8c06-438399f38946"
        ],
        "5cef9d1b-56f7-4a44-b090-4e8dfaedb961": [
            "2da75a84-be69-4a55-8c06-438399f38946"
        ],
        "5037b6c3-4ede-4aaa-afc9-3e47059295fd": [
            "2da75a84-be69-4a55-8c06-438399f38946"
        ],
        "854de804-2884-41db-9086-0af57068b43a": [
            "2da75a84-be69-4a55-8c06-438399f38946"
        ],
        "8d672015-701e-49f7-ad0b-6e5c1b224930": [
            "2da75a84-be69-4a55-8c06-438399f38946"
        ],
        "c6471f07-17dd-4353-838a-abe476f7baf7": [
            "7917381b-d1b4-4396-848e-213504390975"
        ],
        "1df81698-f4be-49c1-acf8-dfc5f2d9e195": [
            "7917381b-d1b4-4396-848e-213504390975"
        ],
        "7d3adbc0-9800-4fdb-9b9e-be6a6ba8d75b": [
            "7917381b-d1b4-4396-848e-213504390975"
        ],
        "f17cd43e-a00f-4940-b403-09373ffd45b3": [
            "7917381b-d1b4-4396-848e-213504390975"
        ],
        "934f4cfb-fb76-4d25-b020-28356658928f": [
            "7917381b-d1b4-4396-848e-213504390975"
        ],
        "05e32dca-08b7-4f55-9771-caa7327d6222": [
            "dfc07fc5-0319-41c2-9347-47c02c95ef69"
        ],
        "44b7239a-d42a-4822-8fe4-e520aaf2454a": [
            "dfc07fc5-0319-41c2-9347-47c02c95ef69"
        ],
        "68a1fb97-7fcc-4443-b6a5-ea5679e845ec": [
            "dfc07fc5-0319-41c2-9347-47c02c95ef69"
        ],
        "b6fd7db0-df25-42ea-bdab-3140ab75f5c8": [
            "dfc07fc5-0319-41c2-9347-47c02c95ef69"
        ],
        "f71dd069-4c40-4a4c-83c3-a724f43b547e": [
            "dfc07fc5-0319-41c2-9347-47c02c95ef69"
        ],
        "1e974e6c-b8c3-4c2a-80c0-a6d284eff6b0": [
            "25f8accc-3d44-4335-b5d1-20bb1642e36e"
        ],
        "6b0c2dd3-4a5c-4e0f-b17d-c9e7537e424c": [
            "25f8accc-3d44-4335-b5d1-20bb1642e36e"
        ],
        "a3909f0b-ebbe-4177-ba5f-4945d1c0f23a": [
            "25f8accc-3d44-4335-b5d1-20bb1642e36e"
        ],
        "468313c5-76ae-463b-98e7-f6c36930f4c3": [
            "25f8accc-3d44-4335-b5d1-20bb1642e36e"
        ],
        "8e86809d-ebc5-49fd-ba95-c2fccf353b68": [
            "25f8accc-3d44-4335-b5d1-20bb1642e36e"
        ],
        "652600bd-8cdb-4225-b86b-d180587e421a": [
            "23292280-a560-46ee-a164-a4fe71d1ccd8"
        ],
        "59c883ec-1b4d-4bd3-8008-32aa5022e07f": [
            "23292280-a560-46ee-a164-a4fe71d1ccd8"
        ],
        "647c7baf-d858-48be-a7b6-95e5adb0e5ee": [
            "23292280-a560-46ee-a164-a4fe71d1ccd8"
        ],
        "b56a299e-4ca6-4313-a7d3-323d1d02cc33": [
            "c461cb46-c4e8-4c9e-b50f-2831d02d1bc7"
        ],
        "2f972066-de12-44a0-9a16-ffea75f19257": [
            "c461cb46-c4e8-4c9e-b50f-2831d02d1bc7"
        ],
        "403e3a2f-1ddd-47c8-9933-0059f6aceb49": [
            "c461cb46-c4e8-4c9e-b50f-2831d02d1bc7"
        ],
        "4cc67e14-e4bf-4557-88ea-4fd4f5401e72": [
            "89cd255c-76f6-4fa4-91af-06f16a8213b5"
        ],
        "dee5bd82-5d89-4a35-bafd-ddc7df82158f": [
            "89cd255c-76f6-4fa4-91af-06f16a8213b5"
        ],
        "772b4fbd-a54a-460e-bf60-0da4866ae0ae": [
            "89cd255c-76f6-4fa4-91af-06f16a8213b5"
        ],
        "54205779-1f4f-437a-ae98-cc5339fdbadf": [
            "89cd255c-76f6-4fa4-91af-06f16a8213b5"
        ],
        "1afbcbb7-a244-47f2-a570-5b6db6b7c88b": [
            "89cd255c-76f6-4fa4-91af-06f16a8213b5"
        ],
        "e91059ac-55ac-416d-b398-7df01644ef1e": [
            "9c92bd0e-84cc-4c7f-8a50-1840da7c25a9"
        ],
        "b284eeb1-5ed8-499d-917c-df3c0250c31c": [
            "9c92bd0e-84cc-4c7f-8a50-1840da7c25a9"
        ],
        "47cce76d-159d-4cf0-880f-291ef9b6b2c1": [
            "9c92bd0e-84cc-4c7f-8a50-1840da7c25a9"
        ],
        "d8b09e35-d4f1-44f1-927a-8fe3e5dff146": [
            "9c92bd0e-84cc-4c7f-8a50-1840da7c25a9"
        ],
        "ac22369f-2161-4448-b5de-04edf59be335": [
            "69e7cc46-78c5-4b9c-918d-16f7ea04b5f0"
        ],
        "b27a990a-f6b7-4031-8d44-82d6940fa4f0": [
            "69e7cc46-78c5-4b9c-918d-16f7ea04b5f0"
        ],
        "3cacd207-5856-4b6c-b03e-c1d76afe3ad8": [
            "a4d6bfd8-0bb2-4069-bcae-03754be015e5"
        ],
        "35b269de-0360-4b27-a750-9b20b91b9f13": [
            "a4d6bfd8-0bb2-4069-bcae-03754be015e5"
        ],
        "88821746-789a-4191-97cb-65ef92a0462c": [
            "a4d6bfd8-0bb2-4069-bcae-03754be015e5"
        ],
        "7894bafd-950d-444f-a4f1-80980ae5aca4": [
            "c5aaba65-4e41-4486-a254-62f08f50674c"
        ],
        "de2ca1e0-3a0e-4995-8db6-1753bc97288c": [
            "c5aaba65-4e41-4486-a254-62f08f50674c"
        ],
        "19c382fb-ce5c-4e5a-94b1-43ba3416caee": [
            "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb"
        ],
        "735bfa9d-469d-4042-8706-2a51c20efbd2": [
            "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb"
        ],
        "d065dcdb-2e18-432c-94ce-400297959a51": [
            "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb"
        ],
        "a65f672d-8e2b-4faf-b1d3-b97e87cce602": [
            "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb"
        ],
        "d3dd32f8-d114-4284-8433-738a5a56d61d": [
            "3f0f5c82-16a4-4a3e-87f6-674a3803d4bb"
        ],
        "c8d38d11-d741-4080-86fb-81ae71eabe52": [
            "3a533c6a-f294-4e80-b83a-b702a6792b59"
        ],
        "7f79c83c-d69c-4f56-8555-c923b5833338": [
            "3a533c6a-f294-4e80-b83a-b702a6792b59"
        ],
        "182accb2-a0ca-40aa-966b-d981b3f00461": [
            "1cd81b3e-4937-49f4-9067-aa1d7669398d"
        ],
        "eafad432-b70f-4bf3-b6b8-5d1509256cdd": [
            "1cd81b3e-4937-49f4-9067-aa1d7669398d"
        ],
        "cd199930-1e19-4f2d-a6d8-ace768b575e9": [
            "1cd81b3e-4937-49f4-9067-aa1d7669398d"
        ],
        "4bac5f93-3362-4336-8304-3fecd4df90e8": [
            "1cd81b3e-4937-49f4-9067-aa1d7669398d"
        ],
        "b1035858-c356-4b76-a4d4-023d079f8a96": [
            "1cd81b3e-4937-49f4-9067-aa1d7669398d"
        ],
        "411929ea-bfb9-4e01-965b-54da7d1081b3": [
            "3d32efb8-59aa-4a7d-8d50-b5052aa597b5"
        ],
        "2151e597-3f5c-4fc1-a1a3-81c01dee8abb": [
            "3d32efb8-59aa-4a7d-8d50-b5052aa597b5"
        ],
        "fafa224f-dbdc-449b-b7bb-c32f8df18e78": [
            "3d32efb8-59aa-4a7d-8d50-b5052aa597b5"
        ],
        "4e9c5abe-85e0-4676-a8b0-e63f4515c097": [
            "3d32efb8-59aa-4a7d-8d50-b5052aa597b5"
        ],
        "eae5c8ad-04ce-4091-82c2-a02e9e23ce4b": [
            "3d32efb8-59aa-4a7d-8d50-b5052aa597b5"
        ],
        "1e5e4e7f-02ff-40a2-95f3-bd371b5a42c5": [
            "7dcbc37d-0c94-4c01-8a93-26edd9020474"
        ],
        "29c54ea7-d667-4138-bcde-d9ad5e9dd968": [
            "7dcbc37d-0c94-4c01-8a93-26edd9020474"
        ],
        "577f05ed-713f-475a-a33c-7a1f39f90a3e": [
            "7dcbc37d-0c94-4c01-8a93-26edd9020474"
        ],
        "6128e7eb-9273-42f8-b6e4-522822e6c13b": [
            "7dcbc37d-0c94-4c01-8a93-26edd9020474"
        ],
        "dc3683ba-3ea3-421b-a362-410e9551a4c1": [
            "7dcbc37d-0c94-4c01-8a93-26edd9020474"
        ],
        "4ed17cd9-3662-45c0-a2f4-80d7f5689ae3": [
            "e8f06d09-39f8-4250-a2d2-59c452085922"
        ],
        "c22f728c-faad-486c-ac09-ecc342b03a2e": [
            "e8f06d09-39f8-4250-a2d2-59c452085922"
        ],
        "cf16dd48-198f-43f9-a10b-6a43be964fd2": [
            "e8f06d09-39f8-4250-a2d2-59c452085922"
        ],
        "f6b41439-ff1b-4c58-8973-5206306cd5da": [
            "e8f06d09-39f8-4250-a2d2-59c452085922"
        ],
        "479f971e-d64f-404b-93ce-36fc892896cf": [
            "e8f06d09-39f8-4250-a2d2-59c452085922"
        ],
        "1db45ff5-d7e6-449a-8ff0-73f5e545ee7d": [
            "9466031c-5dde-41ec-bf34-3d0cc9065329"
        ],
        "4a09b8aa-91ee-45ac-9b7e-d50c1b0d881b": [
            "9466031c-5dde-41ec-bf34-3d0cc9065329"
        ],
        "830ec017-b244-4577-919a-8a29b6326365": [
            "9466031c-5dde-41ec-bf34-3d0cc9065329"
        ],
        "afea48f9-38fb-4654-b58c-5861c8211743": [
            "9466031c-5dde-41ec-bf34-3d0cc9065329"
        ],
        "13d20c24-3e93-4562-b72b-6707c94c7709": [
            "9466031c-5dde-41ec-bf34-3d0cc9065329"
        ],
        "f50d953a-f153-49d1-8bf3-8bda7829427f": [
            "6563f83e-5b12-42fd-9cf5-dbe5f9dc035d"
        ],
        "f1a75769-863b-40d4-9289-100b8047e263": [
            "6563f83e-5b12-42fd-9cf5-dbe5f9dc035d"
        ],
        "9ab7722a-5850-4366-a9c7-2cc068af598b": [
            "6563f83e-5b12-42fd-9cf5-dbe5f9dc035d"
        ],
        "aabf4001-b521-4769-8b59-d43411076749": [
            "1ecfcd7f-e8c0-41b3-9782-d1b9983166bc"
        ],
        "3304b424-12f7-4bbb-8639-bcf6b6e8fbc8": [
            "1ecfcd7f-e8c0-41b3-9782-d1b9983166bc"
        ],
        "e5acdc06-2f9d-4412-b39f-baacad338dfd": [
            "b0894c37-378e-4b0d-9709-aa440ab8aaa5"
        ],
        "c1a3504b-ded6-48d8-bfad-8276fe0143c8": [
            "b0894c37-378e-4b0d-9709-aa440ab8aaa5"
        ],
        "5c5298a5-9079-4ae1-9b3d-b83e90bace4f": [
            "42eff7a7-3c97-406f-a6e1-6dbb83a9706b"
        ],
        "e39aaf66-9eb8-4ac2-aec1-2229b46755cd": [
            "42eff7a7-3c97-406f-a6e1-6dbb83a9706b"
        ],
        "f5685311-4124-4f36-8e7f-148c19f7be2d": [
            "672574b1-6370-488b-b79f-6e41c3eedc07"
        ],
        "4cb7c25e-7c22-44f0-961c-e656dd7d43f9": [
            "672574b1-6370-488b-b79f-6e41c3eedc07"
        ],
        "4ea9e695-8ce7-43e4-a4f3-7f3c2deca326": [
            "d0951a55-9953-4323-8fcb-2db5e812f5d8"
        ],
        "8b6585fc-d56f-49f5-b6ff-43a21bff1357": [
            "d0951a55-9953-4323-8fcb-2db5e812f5d8"
        ],
        "6f67a7f5-99e7-4ff9-bd71-43c95f035aed": [
            "d0951a55-9953-4323-8fcb-2db5e812f5d8"
        ],
        "76af0645-efe5-47ba-bba6-6e18bb2a85d0": [
            "712001d9-0dd1-48ff-92f5-d304365dc855"
        ],
        "13e9516f-d289-4b43-99c0-df3bc0b5f9d7": [
            "712001d9-0dd1-48ff-92f5-d304365dc855"
        ],
        "3acd93c5-2aa6-4d9f-a679-acb1b07ec4a9": [
            "03cf226c-20af-498b-91d8-3828ed3d4832"
        ],
        "c442b223-0dd5-4d0d-aee1-bf3b8af98ce3": [
            "03cf226c-20af-498b-91d8-3828ed3d4832"
        ],
        "e5e5c353-6143-4673-8215-d5b4a7368da2": [
            "93c4cdca-8bc8-4c11-ba3a-88f030e150cd"
        ],
        "fb0afc67-1a4d-4056-beec-22cf68687834": [
            "93c4cdca-8bc8-4c11-ba3a-88f030e150cd"
        ],
        "8d9b4395-5d2e-4d06-978f-5599b233bc2b": [
            "93c4cdca-8bc8-4c11-ba3a-88f030e150cd"
        ],
        "ab001046-f324-44db-a51d-5da343f517e6": [
            "93c4cdca-8bc8-4c11-ba3a-88f030e150cd"
        ],
        "30e09d84-1e4e-4598-9a63-47a3531720bf": [
            "93c4cdca-8bc8-4c11-ba3a-88f030e150cd"
        ],
        "877c8fc5-80e5-4c0d-a665-61f6e12929cf": [
            "331c7fce-9520-451c-b215-b114c698a45b"
        ],
        "2f8d7319-8797-4c9c-bd06-ff5e5419cae8": [
            "331c7fce-9520-451c-b215-b114c698a45b"
        ],
        "7eb61441-eca1-4b19-85fa-c2ae215e5d70": [
            "331c7fce-9520-451c-b215-b114c698a45b"
        ],
        "b842b46b-ae18-472d-999d-45300d5c6565": [
            "1ff2df31-95cf-487a-b44a-83b21b1f2647"
        ],
        "9cc2912d-a760-4818-86ac-e59aa748d5d1": [
            "1ff2df31-95cf-487a-b44a-83b21b1f2647"
        ],
        "5277cb6e-a539-4160-8f0e-27991bb5bbfd": [
            "1ff2df31-95cf-487a-b44a-83b21b1f2647"
        ],
        "ebbe2391-96ca-4145-98ae-03adce1e5c78": [
            "44f29973-cc07-42c6-b3d1-29518a044620"
        ],
        "10f1450d-54f5-466c-929d-1af02226364b": [
            "44f29973-cc07-42c6-b3d1-29518a044620"
        ],
        "e9f889f7-d154-4d2b-a451-c02c872c87ea": [
            "44f29973-cc07-42c6-b3d1-29518a044620"
        ],
        "601bd8e0-0353-442b-b7d0-e4deaecfaf25": [
            "44f29973-cc07-42c6-b3d1-29518a044620"
        ],
        "dac0681e-76ca-4871-a768-2f9daccc97d3": [
            "e1ca0619-8065-49cf-afe8-df1d5aabf2a3"
        ],
        "726fca23-6f09-441c-a2a2-798a0c373115": [
            "e1ca0619-8065-49cf-afe8-df1d5aabf2a3"
        ],
        "9b28c710-73ab-477b-a3e0-0ecb9de27582": [
            "e1ca0619-8065-49cf-afe8-df1d5aabf2a3"
        ],
        "b366ddb8-1721-4b95-b1f6-d4996f4e4c86": [
            "e1ca0619-8065-49cf-afe8-df1d5aabf2a3"
        ],
        "b5c7a8d9-de30-47a5-ab8c-2d311dbf052b": [
            "e1ca0619-8065-49cf-afe8-df1d5aabf2a3"
        ],
        "ac49ef16-9089-470d-a700-7b4ecfa8048c": [
            "610698d8-3f47-4e39-99ea-208edb87f351"
        ],
        "0ccc3f4f-812d-4830-b541-4158bd951d9f": [
            "610698d8-3f47-4e39-99ea-208edb87f351"
        ],
        "3553ae3c-3f37-440a-8638-fee768fcfad4": [
            "610698d8-3f47-4e39-99ea-208edb87f351"
        ],
        "f4944e79-b03f-47a3-9cd0-5131c8fe8687": [
            "cc538936-855b-4561-a382-96926d69b783"
        ],
        "a12f8121-6ded-4faa-92af-bc56c74a15d1": [
            "cc538936-855b-4561-a382-96926d69b783"
        ],
        "6e3538f2-0a50-4c12-aa32-857c3800027d": [
            "afd5dca0-0e82-4a6a-88fb-63a3aa26b9b3"
        ],
        "d6c13ed5-4f8c-45ec-ba51-acf13c9b41e9": [
            "afd5dca0-0e82-4a6a-88fb-63a3aa26b9b3"
        ],
        "1c5d016b-cce6-48ee-8f2b-8c3f818acdae": [
            "274561f3-500a-4650-9c03-709dc3394b65"
        ],
        "ccb736b8-1d01-4906-a98f-41ee6be0629e": [
            "274561f3-500a-4650-9c03-709dc3394b65"
        ],
        "b437d5cd-b6d3-4f0c-8a8e-280dad91e233": [
            "274561f3-500a-4650-9c03-709dc3394b65"
        ],
        "4ac42d30-69d2-471f-9be1-5e2013d070d8": [
            "274561f3-500a-4650-9c03-709dc3394b65"
        ],
        "736269c0-c299-4771-9c42-bfbd708dd2c1": [
            "274561f3-500a-4650-9c03-709dc3394b65"
        ],
        "86ad2d59-aa57-454e-b20b-a1f446d3a367": [
            "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4"
        ],
        "4fb70bb1-3da6-44f6-81e8-b77a7ece001c": [
            "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4"
        ],
        "fb7e11da-ef1a-4cce-bed1-864ddfd1bf92": [
            "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4"
        ],
        "5ffdb99a-6821-4140-84e0-1f6708125689": [
            "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4"
        ],
        "9d1a5daf-643a-4aa9-b8bd-f8ae86fdf714": [
            "5b8ce3c5-c7ab-4891-bd67-9a879adad5b4"
        ],
        "fdcfe074-5677-4ab9-976a-e1fb48250384": [
            "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc"
        ],
        "1f645005-631b-4409-9173-9a08f78d33ac": [
            "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc"
        ],
        "856b0aef-8625-4950-b752-db701f871313": [
            "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc"
        ],
        "a8a34ed1-3f92-4d45-bfe6-05978d6ed205": [
            "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc"
        ],
        "38a87c47-4f3a-4a71-8821-36c4e8dcf378": [
            "cc11ef37-99a5-494a-ae04-80a0ca4fe0fc"
        ],
        "adf612f9-9be5-49fe-a8e3-033d7c1bab85": [
            "2a71fb63-90dd-49d9-8b04-553b03098168"
        ],
        "bfcf3a71-8c58-4a76-ac7b-7879ed2e185a": [
            "2a71fb63-90dd-49d9-8b04-553b03098168"
        ],
        "89a1f790-7e83-46cb-9427-964e47186232": [
            "2a71fb63-90dd-49d9-8b04-553b03098168"
        ],
        "49c30f2e-68ca-4023-a449-ec6dbea6deb0": [
            "2a71fb63-90dd-49d9-8b04-553b03098168"
        ],
        "0f0150e0-553d-4957-aa10-ecacace3daf1": [
            "2a71fb63-90dd-49d9-8b04-553b03098168"
        ],
        "d0c45014-b931-4135-a6e3-84439a684cb3": [
            "e5e90176-83c9-40bc-886d-886ef16004c7"
        ],
        "8d19c6fb-08ae-4e5a-949b-13dc643b3fa1": [
            "e5e90176-83c9-40bc-886d-886ef16004c7"
        ],
        "0b53445f-4a94-4f20-b01d-89d9aaffbab9": [
            "e5e90176-83c9-40bc-886d-886ef16004c7"
        ],
        "753a14cd-c546-4024-af31-84bfd5d97d5c": [
            "b933ee97-825f-4512-8227-bdf59686af7b"
        ],
        "19e0eb04-a876-4966-95c2-1c5fd2c20dc5": [
            "b933ee97-825f-4512-8227-bdf59686af7b"
        ],
        "58d20f8d-0607-41c8-8848-7dec1d0dd1e5": [
            "b933ee97-825f-4512-8227-bdf59686af7b"
        ],
        "68df4dfd-796e-42ca-96c3-b205602e064d": [
            "d892da6e-f46f-49b3-824d-f3a5032695e4"
        ],
        "1cec7837-c3c6-43b1-a35f-7b7b8e597f71": [
            "d892da6e-f46f-49b3-824d-f3a5032695e4"
        ],
        "c5c23cb3-e716-4f2c-b565-0a91f2a713ef": [
            "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e"
        ],
        "783b15f2-5762-44e4-8361-d6bf28d69770": [
            "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e"
        ],
        "c304191a-6164-4862-8320-9b9b1e655fe7": [
            "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e"
        ],
        "4cf21c40-98d4-4a43-8632-77520eafadb3": [
            "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e"
        ],
        "e3931b5d-5482-40a9-b657-1c01d05f78ac": [
            "cb9f88f8-cbf8-4cb3-9bca-d1e4554f3b6e"
        ],
        "a4fe542a-c77c-4a24-8bff-46b584396794": [
            "f094f6af-059f-46d7-80b8-bd614650ab99"
        ],
        "89a9c377-1936-4434-a348-b53080d2df24": [
            "f094f6af-059f-46d7-80b8-bd614650ab99"
        ],
        "4492f02a-af5c-4c4f-910d-4feb0944bf99": [
            "f094f6af-059f-46d7-80b8-bd614650ab99"
        ],
        "b4162267-4fc7-42c5-a729-6f0ffa44a247": [
            "f094f6af-059f-46d7-80b8-bd614650ab99"
        ],
        "d9190e9c-735b-4d28-aba5-7da7807d1409": [
            "f094f6af-059f-46d7-80b8-bd614650ab99"
        ],
        "33ec0786-aceb-4c5b-b630-7bd5a865a925": [
            "df3372be-ebf5-4591-9a61-20f3d143fd71"
        ],
        "9f1a3106-ef82-4a15-8f20-06c8b17dc1e8": [
            "df3372be-ebf5-4591-9a61-20f3d143fd71"
        ],
        "9cf95f91-cde6-48c7-a48d-525806779a4d": [
            "4cd4cf05-ada0-4361-932d-244968ea5f4b"
        ],
        "b170e925-1db9-442d-8551-46b82b859e14": [
            "4cd4cf05-ada0-4361-932d-244968ea5f4b"
        ],
        "1495e930-fedc-4a32-bae2-fb77b8b44b0b": [
            "5c823895-429c-4d6c-acf1-1e2ad7a727bc"
        ],
        "138c5c08-4172-4446-b556-547560ebc4a6": [
            "5c823895-429c-4d6c-acf1-1e2ad7a727bc"
        ],
        "5a2da332-30c2-443c-add7-7dd8f3d9015f": [
            "5c823895-429c-4d6c-acf1-1e2ad7a727bc"
        ],
        "eb07569a-2e5e-4d8d-8870-3e7c3e3ba0dd": [
            "0c2ec292-cb09-4fb8-9c29-82a387221bba"
        ],
        "66963d34-0d2a-4301-a4f2-01e817a058fc": [
            "0c2ec292-cb09-4fb8-9c29-82a387221bba"
        ],
        "bbd8baa8-cd3a-4fb9-80b1-c32bf3e23963": [
            "25e2c3ce-52b9-43b8-9422-c3c088c8379c"
        ],
        "600fae38-9db1-4057-9ee1-5b1f47a1ce6c": [
            "25e2c3ce-52b9-43b8-9422-c3c088c8379c"
        ],
        "3dfa7fc6-d25a-4b71-8ab9-425c664d4cea": [
            "25e2c3ce-52b9-43b8-9422-c3c088c8379c"
        ],
        "026fe193-7e49-4c0d-9ee4-cc4372d62ffe": [
            "25e2c3ce-52b9-43b8-9422-c3c088c8379c"
        ],
        "aabe89ce-5f2d-483e-8b99-5bb8aafa515d": [
            "25e2c3ce-52b9-43b8-9422-c3c088c8379c"
        ],
        "9a61529c-8a9c-4b89-89f3-c82a3b44a5ef": [
            "fe4e0050-9a7a-4428-bc5b-70a39332f076"
        ],
        "2f3e4bfb-4340-4f3a-b0c3-02d79da1e27d": [
            "fe4e0050-9a7a-4428-bc5b-70a39332f076"
        ],
        "e8c1e68f-d86d-469d-938e-675de33e9a7d": [
            "fe4e0050-9a7a-4428-bc5b-70a39332f076"
        ],
        "a9e5780f-7cea-4e42-a324-292e9e9ad8d9": [
            "fe4e0050-9a7a-4428-bc5b-70a39332f076"
        ],
        "d39c8cad-ab3f-43c0-baeb-ef32dea45960": [
            "fe4e0050-9a7a-4428-bc5b-70a39332f076"
        ],
        "6d39b841-a9b6-4b17-90e7-4df9a29dcc4a": [
            "0e9c223b-bc53-4626-9922-87fe2dd4d5b6"
        ],
        "0a3bf95f-d7c3-4ed4-ae90-0c54145c9dfe": [
            "0e9c223b-bc53-4626-9922-87fe2dd4d5b6"
        ],
        "fa6697d1-f5fe-405b-874a-7a32bb8ce718": [
            "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889"
        ],
        "5337e778-b15d-4056-8db3-a858ff1fd904": [
            "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889"
        ],
        "7d67e93c-3aa7-4bf3-ba61-7c0dd3ac6482": [
            "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889"
        ],
        "4bf68fee-e2a0-47e4-bb7a-75966763feb4": [
            "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889"
        ],
        "9cac18e6-a9aa-4f06-8869-0ad240897890": [
            "ff5601be-e1cb-474f-9c8c-cf9dbd3ce889"
        ],
        "2c9e9eb6-57f8-47a6-bb70-37cbd5db2b14": [
            "6914ce46-288e-4505-afd5-837c6aae1d56"
        ],
        "bbe1daac-c2d4-451c-90a3-cb02a4448408": [
            "6914ce46-288e-4505-afd5-837c6aae1d56"
        ],
        "ed208b1d-012b-4370-b6bf-66d639b56117": [
            "6914ce46-288e-4505-afd5-837c6aae1d56"
        ],
        "6e14aa81-1347-4f21-a101-65c43e608b13": [
            "6914ce46-288e-4505-afd5-837c6aae1d56"
        ],
        "047f96be-6762-4fb7-acba-dd0db9bba57c": [
            "6914ce46-288e-4505-afd5-837c6aae1d56"
        ],
        "93430de5-91e3-40fd-b5a6-eb6fbb117eb9": [
            "8eacf552-96dc-4ffe-b843-2db4d1b6b396"
        ],
        "19917214-af47-4e54-a2f0-8ee8bda36a44": [
            "8eacf552-96dc-4ffe-b843-2db4d1b6b396"
        ],
        "ee1d22d5-94d7-42ca-bccd-5d514967b2b3": [
            "50df9315-bd20-421a-bc4c-331c72ab1875"
        ],
        "24e15fdd-ad10-4070-9c7f-156621662965": [
            "50df9315-bd20-421a-bc4c-331c72ab1875"
        ],
        "2d5212ea-f39e-4072-a3ef-b16602843f03": [
            "50df9315-bd20-421a-bc4c-331c72ab1875"
        ],
        "fd140fab-d8cc-41aa-9c0b-e2983e56051a": [
            "50df9315-bd20-421a-bc4c-331c72ab1875"
        ],
        "15a08f4b-d77c-4d93-8ead-1f2ccb6be6e0": [
            "50df9315-bd20-421a-bc4c-331c72ab1875"
        ],
        "97446e7d-895a-4a15-9630-e4a7b676c4c7": [
            "e74506c9-54f8-4b17-b72c-8123182e5a74"
        ],
        "13b73801-cfee-4655-a046-77410e2a5569": [
            "e74506c9-54f8-4b17-b72c-8123182e5a74"
        ],
        "d8782af3-e3f1-408b-9638-7acfc22e2bd9": [
            "e74506c9-54f8-4b17-b72c-8123182e5a74"
        ],
        "149744ba-90ef-44b3-9588-eb2a03cf3ad5": [
            "e74506c9-54f8-4b17-b72c-8123182e5a74"
        ],
        "4e669bec-0ade-4760-abce-10e023baa6d8": [
            "e74506c9-54f8-4b17-b72c-8123182e5a74"
        ],
        "911bc345-a477-47f8-8e74-80601e08f868": [
            "98a121be-14b1-4ba9-bf05-c75218e957c9"
        ],
        "f0129c5c-2132-4105-9340-1e5761a15ef9": [
            "98a121be-14b1-4ba9-bf05-c75218e957c9"
        ],
        "465ccd61-e08a-43c8-a0f7-519cdfa9f767": [
            "98a121be-14b1-4ba9-bf05-c75218e957c9"
        ],
        "1c84d781-7dc7-4c6f-a397-d24baca77dc2": [
            "98a121be-14b1-4ba9-bf05-c75218e957c9"
        ],
        "6f4a108a-b8d2-4158-94d2-4c8a362b90e0": [
            "98a121be-14b1-4ba9-bf05-c75218e957c9"
        ],
        "a77df864-27ab-412a-82f1-9f742bca6368": [
            "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b"
        ],
        "78990526-f016-4318-87b2-8c8059a4ba83": [
            "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b"
        ],
        "12c15db5-3aaa-4e8d-ae6a-d1643ceb6213": [
            "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b"
        ],
        "085e0c6e-b764-4e07-a0aa-efa5ec6ac315": [
            "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b"
        ],
        "ea32aa59-f56b-4c42-8dcf-940bb2805d56": [
            "334509ee-3ba7-4c8c-9b86-ddb4ffa6253b"
        ],
        "922ab79e-992f-496e-8354-bdca5f319364": [
            "cf511d8c-69d2-4a76-9f4a-b938f797b405"
        ],
        "313f021b-81cd-4887-9764-913dbd6680b8": [
            "cf511d8c-69d2-4a76-9f4a-b938f797b405"
        ],
        "1bfaac07-6c8a-49da-805e-aaa818e3e61d": [
            "cf511d8c-69d2-4a76-9f4a-b938f797b405"
        ],
        "2546868b-109f-452d-8f7f-ea1288dcdde8": [
            "cf511d8c-69d2-4a76-9f4a-b938f797b405"
        ],
        "3a85f27a-c063-4882-a3ea-93692e5a8d08": [
            "cf511d8c-69d2-4a76-9f4a-b938f797b405"
        ],
        "2f76a288-f644-4994-afa3-cce024c84f95": [
            "44d0c323-8fce-4b2a-85df-9db648d9d202"
        ],
        "fd525b99-7fae-48b4-a00b-f34c66e4fc4e": [
            "44d0c323-8fce-4b2a-85df-9db648d9d202"
        ],
        "ec6f4056-bbea-401a-a207-6150a836b005": [
            "44d0c323-8fce-4b2a-85df-9db648d9d202"
        ],
        "d3b9549f-391a-41a1-8bac-aecd68281057": [
            "6d610ff2-80d5-4d0b-8bd2-53005bab6dea"
        ],
        "a587dbe3-dca7-4747-8bca-8ea0cdbf4b1c": [
            "6d610ff2-80d5-4d0b-8bd2-53005bab6dea"
        ],
        "7e4841db-f1ec-4287-abb3-7a35a2fc741d": [
            "6d610ff2-80d5-4d0b-8bd2-53005bab6dea"
        ],
        "f9878610-0dcc-4bd2-82c0-19414e3ada3f": [
            "6d610ff2-80d5-4d0b-8bd2-53005bab6dea"
        ],
        "30141654-54d4-4f13-b241-bd546de55b3c": [
            "6d610ff2-80d5-4d0b-8bd2-53005bab6dea"
        ],
        "0231f39d-0c9e-464b-9b4c-f44cc9f4e5ee": [
            "7c001067-3f0d-45a5-a148-de7840007abb"
        ],
        "f74b1bdb-c6d9-4c15-afcb-fd1dc3264d9b": [
            "7c001067-3f0d-45a5-a148-de7840007abb"
        ],
        "38479ecd-5e6d-43f0-9b50-f2f943d5dbe5": [
            "7c001067-3f0d-45a5-a148-de7840007abb"
        ],
        "a7d4196d-784f-49bd-9922-a991d5f40a87": [
            "7c001067-3f0d-45a5-a148-de7840007abb"
        ],
        "85fa7698-932d-4e2d-bcbf-5ae173089b5b": [
            "7c001067-3f0d-45a5-a148-de7840007abb"
        ],
        "ea434952-1c3d-4246-9cf3-fc2d6795ddda": [
            "185cd77d-c865-42a0-a7e8-3677bcb99e72"
        ],
        "ef64f244-3ce7-453a-ac99-d3ef41a580cd": [
            "185cd77d-c865-42a0-a7e8-3677bcb99e72"
        ],
        "a7cd0c72-a70b-4e95-aef0-ddc6a74a004c": [
            "185cd77d-c865-42a0-a7e8-3677bcb99e72"
        ],
        "4e0cb885-5cb1-4078-8745-e2f4b162c87e": [
            "185cd77d-c865-42a0-a7e8-3677bcb99e72"
        ],
        "6917ecc9-9416-484e-adc1-8d87a6d829dc": [
            "185cd77d-c865-42a0-a7e8-3677bcb99e72"
        ],
        "77c8b62d-23d9-4f8e-bd04-46d4afe564eb": [
            "1a802d3f-bbe1-43cf-b884-44d305542192"
        ],
        "58fbc138-46ca-43b6-943d-634aefd9bdb6": [
            "1a802d3f-bbe1-43cf-b884-44d305542192"
        ],
        "56b0853b-dcc2-4b6a-ae69-df7c0aba531c": [
            "a80ff16b-89c9-49c2-a9b0-d58d4b539e68"
        ],
        "5e211c6d-b0d7-4f1e-b82c-dde81870ec53": [
            "a80ff16b-89c9-49c2-a9b0-d58d4b539e68"
        ],
        "5ff904a3-d6f9-4b82-850a-67c43cac7b1f": [
            "a80ff16b-89c9-49c2-a9b0-d58d4b539e68"
        ],
        "4875de5e-cf0c-4ec9-a3f8-29528bfe87b5": [
            "a80ff16b-89c9-49c2-a9b0-d58d4b539e68"
        ],
        "5b95c675-d9e2-48f8-85de-5a6226970663": [
            "a80ff16b-89c9-49c2-a9b0-d58d4b539e68"
        ],
        "17ca23df-3d48-4215-b9e1-2e0903233bf7": [
            "6a60caca-b559-43eb-9d41-445ca2cf4cd2"
        ],
        "f6fb9cfa-46b7-4700-a45b-6ff3263d34eb": [
            "6a60caca-b559-43eb-9d41-445ca2cf4cd2"
        ],
        "c8b64ddb-c54f-40e6-81de-1ed2675f6b9a": [
            "6a60caca-b559-43eb-9d41-445ca2cf4cd2"
        ],
        "c6846c75-c0e2-4bdf-b197-a8f2f260fd07": [
            "6a60caca-b559-43eb-9d41-445ca2cf4cd2"
        ],
        "fa8290a5-f1d5-4812-a691-3c6c3ae6fc26": [
            "6a60caca-b559-43eb-9d41-445ca2cf4cd2"
        ],
        "cd44375e-4fca-4115-bb90-2cdafb265db7": [
            "a5bbc50f-1da0-452c-b35f-8225945de20e"
        ],
        "2f2e1629-5fb4-4bda-ac89-ec85a0f76266": [
            "a5bbc50f-1da0-452c-b35f-8225945de20e"
        ],
        "57cbbb9d-9de0-400e-a376-9e810adfc7ec": [
            "a5bbc50f-1da0-452c-b35f-8225945de20e"
        ],
        "ef1188a2-8760-4045-acdb-041f5fc27ecf": [
            "a5bbc50f-1da0-452c-b35f-8225945de20e"
        ],
        "8d03f6d3-c349-4d95-b4b5-63a66a3af668": [
            "a5bbc50f-1da0-452c-b35f-8225945de20e"
        ],
        "39c6f4b3-ae54-47b9-8462-57e00d22721c": [
            "ace7a56d-f862-4b93-bd81-720163fcf947"
        ],
        "3d1fd3bb-72ad-48cc-863e-03fa51fb54a5": [
            "ace7a56d-f862-4b93-bd81-720163fcf947"
        ],
        "2a1c8dea-9cf3-4e85-9e5f-24c56ba352be": [
            "ace7a56d-f862-4b93-bd81-720163fcf947"
        ],
        "a1f4b627-49f3-4c74-a272-b7f1c5b77f1f": [
            "ace7a56d-f862-4b93-bd81-720163fcf947"
        ],
        "38ed1d95-ac99-4615-960e-b9a71e9ce6ab": [
            "ace7a56d-f862-4b93-bd81-720163fcf947"
        ],
        "fdbc218f-092e-4a16-ac7b-6a4cd4d3824f": [
            "fe793593-c220-433a-8518-818aa6c39007"
        ],
        "1309a41c-e22a-4ba9-bebf-7fdd6f5c17fb": [
            "fe793593-c220-433a-8518-818aa6c39007"
        ],
        "e8e58c67-a7ff-4a49-9393-d31b0677529b": [
            "bfe5ccc1-3df0-41d9-a0d6-b1ac017a0fd1"
        ],
        "b842bf68-8195-454e-a919-929c7a590e8f": [
            "bfe5ccc1-3df0-41d9-a0d6-b1ac017a0fd1"
        ],
        "a03cc3b8-117c-460e-a317-d1e032d50e85": [
            "56dad008-3878-4100-9128-1429c4a52b70"
        ],
        "432aeeb8-3332-4b22-a1d7-57d2fd848626": [
            "56dad008-3878-4100-9128-1429c4a52b70"
        ],
        "45d3fa29-3a02-4677-acf5-aaef4e3beaab": [
            "56dad008-3878-4100-9128-1429c4a52b70"
        ],
        "09990c92-5a81-4657-8b9f-dfc7b5b55088": [
            "56dad008-3878-4100-9128-1429c4a52b70"
        ],
        "fa9c0077-377c-4268-bbd7-013af8e8ce41": [
            "56dad008-3878-4100-9128-1429c4a52b70"
        ],
        "4a94df6d-6f18-4173-9ebf-5db3fe3a17a2": [
            "556270c0-4bac-4ae8-95e1-a4844787c889"
        ],
        "bfa23b12-8ca7-4b53-bd69-fddeedd3baea": [
            "556270c0-4bac-4ae8-95e1-a4844787c889"
        ],
        "9131c3f3-403f-49ba-ba42-5157369408ee": [
            "556270c0-4bac-4ae8-95e1-a4844787c889"
        ],
        "eeb91105-c104-4b27-88d5-43de5c9ad689": [
            "9f8fe4fe-131d-491f-b2be-ab5b692ddf87"
        ],
        "58b5d612-8c60-4a09-8250-351db547fe30": [
            "9f8fe4fe-131d-491f-b2be-ab5b692ddf87"
        ],
        "824dd9e3-b226-43cb-bd8c-a71be211aeef": [
            "9f8fe4fe-131d-491f-b2be-ab5b692ddf87"
        ],
        "fbf87613-ab44-49b7-b544-5a34e3c65caa": [
            "9f8fe4fe-131d-491f-b2be-ab5b692ddf87"
        ],
        "592986f4-ce72-4ffb-bf39-97028e01ab8d": [
            "9f8fe4fe-131d-491f-b2be-ab5b692ddf87"
        ],
        "aa7e7026-9d2d-4d9c-892c-249b720d4bd8": [
            "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f"
        ],
        "6b18e481-3c43-473e-aed1-acd90d7f840c": [
            "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f"
        ],
        "088e8254-bc09-4b31-9299-2a6be0915e2d": [
            "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f"
        ],
        "9a7f1e7e-3e9d-4c7e-b8dd-83b6af4a403b": [
            "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f"
        ],
        "d0ba8151-9e6f-4726-9836-d4882da2f7ec": [
            "5d8a03e8-b0c8-410d-884d-5ab1e4b9dd2f"
        ],
        "fcf25c33-17d2-4bd9-b6ae-3cbaa3d0cb29": [
            "0e2c9060-409f-4afc-9f18-87bbb298200e"
        ],
        "66704757-bb2a-4d13-a608-63ffe582a9e2": [
            "0e2c9060-409f-4afc-9f18-87bbb298200e"
        ],
        "e1ee0929-0ffc-435f-a9b4-e9ffabb6245f": [
            "0e2c9060-409f-4afc-9f18-87bbb298200e"
        ],
        "b11bfc3a-cd23-4f6a-9d1a-9c85c4a356d3": [
            "0e2c9060-409f-4afc-9f18-87bbb298200e"
        ],
        "63f158a4-bced-4ab7-bf5e-6dc7c737f2ea": [
            "0e2c9060-409f-4afc-9f18-87bbb298200e"
        ],
        "d98bb21c-d850-4e5b-a7fd-7a259dc3d0ea": [
            "c53957a8-9bab-430c-a3b5-b548ce35b7fa"
        ],
        "80d306f2-1ef6-45e0-8f59-9e2703e60a1d": [
            "c53957a8-9bab-430c-a3b5-b548ce35b7fa"
        ],
        "3937f2ab-3006-4cba-9d29-79b33ebb58dd": [
            "c53957a8-9bab-430c-a3b5-b548ce35b7fa"
        ],
        "9e6c6fa3-2c87-4980-bb4f-e925d1665ab6": [
            "5fd8151c-1c5f-4053-ad99-14f7a52394cc"
        ],
        "2ca61430-34e6-4ad3-a3fc-39840c9a06be": [
            "5fd8151c-1c5f-4053-ad99-14f7a52394cc"
        ],
        "d5640bbb-0c9e-46e3-8643-64d5461d0ae7": [
            "5fd8151c-1c5f-4053-ad99-14f7a52394cc"
        ],
        "cac9f757-9d40-4316-b4c3-6b595621035c": [
            "5fd8151c-1c5f-4053-ad99-14f7a52394cc"
        ],
        "38a4bdc5-f206-440e-aae3-0e3d449020e5": [
            "5fd8151c-1c5f-4053-ad99-14f7a52394cc"
        ],
        "d73b41e4-281c-45ae-8763-dcf7d14d89e4": [
            "0adea7ee-e226-4d2e-934b-61380dec9205"
        ],
        "6adce29a-0b9d-4e63-9b5c-26db19cbd830": [
            "0adea7ee-e226-4d2e-934b-61380dec9205"
        ],
        "c81e8c5c-085f-4d26-be10-8c6bb5dea412": [
            "0adea7ee-e226-4d2e-934b-61380dec9205"
        ],
        "b39acfed-9663-42c5-b2ba-1b89648740cf": [
            "0adea7ee-e226-4d2e-934b-61380dec9205"
        ],
        "3a1d2b28-3731-4dae-9d0a-36104a4cf30d": [
            "0adea7ee-e226-4d2e-934b-61380dec9205"
        ],
        "24692404-b6ba-4e63-8b80-d057f22f96d0": [
            "fc362cd3-fc2e-42af-ae6a-326b94bd888a"
        ],
        "50aad40f-b587-47c2-918d-b067bfb619ab": [
            "fc362cd3-fc2e-42af-ae6a-326b94bd888a"
        ],
        "9526f376-eaca-4c92-b961-0664d900923a": [
            "fc362cd3-fc2e-42af-ae6a-326b94bd888a"
        ],
        "7bee7d51-62fd-41b7-8944-c9b2e0853053": [
            "fc362cd3-fc2e-42af-ae6a-326b94bd888a"
        ],
        "d09bf6fa-e0e8-4561-af8c-290f1f817a1e": [
            "fc362cd3-fc2e-42af-ae6a-326b94bd888a"
        ],
        "4c4eb01a-48a0-4fdc-adb8-f9b506a8c333": [
            "896960c2-3e17-4bc6-8956-63b40c9d7d2e"
        ],
        "c9acad36-8339-4f00-acae-11d247a859df": [
            "896960c2-3e17-4bc6-8956-63b40c9d7d2e"
        ],
        "f5ab47b4-964b-40f5-b3db-901fe5e97872": [
            "896960c2-3e17-4bc6-8956-63b40c9d7d2e"
        ],
        "d302f359-87b3-4247-b2a3-9c0528ca342a": [
            "896960c2-3e17-4bc6-8956-63b40c9d7d2e"
        ],
        "f8a144e7-adf2-49f7-b7e3-437d4f51771b": [
            "bb763235-9793-45ad-91b6-e05855a7e8bf"
        ],
        "5c050d77-9f73-4c6b-bc01-781e3b7fdb12": [
            "bb763235-9793-45ad-91b6-e05855a7e8bf"
        ],
        "a3ada4af-4acd-4f8c-bd0c-9fd02cc9d911": [
            "bb763235-9793-45ad-91b6-e05855a7e8bf"
        ],
        "96df7835-0492-4fa6-b59e-8062c9c7a2cd": [
            "bb763235-9793-45ad-91b6-e05855a7e8bf"
        ],
        "73612d38-ec9c-4ead-8c69-d3aeed0e1d42": [
            "bb763235-9793-45ad-91b6-e05855a7e8bf"
        ],
        "a7b91af8-0d7d-45f6-be4b-cdf9ff47005f": [
            "a76e3f81-4575-43b6-9888-660022c1f8c9"
        ],
        "2ad8f267-9df5-4901-8a4f-a98ddd92cdcf": [
            "a76e3f81-4575-43b6-9888-660022c1f8c9"
        ],
        "2a807c2c-25f2-4733-83d2-6d5e62bbe4d0": [
            "a76e3f81-4575-43b6-9888-660022c1f8c9"
        ],
        "ebc1a6f7-37fa-4d0d-93c1-2c5eccfb5159": [
            "a76e3f81-4575-43b6-9888-660022c1f8c9"
        ],
        "742bf95e-304c-48ad-9f8a-ade7d7cc8483": [
            "a76e3f81-4575-43b6-9888-660022c1f8c9"
        ],
        "88fc9c7b-0252-456d-a4ce-02bc0ca90828": [
            "b3ce1d16-79cb-431e-b1a1-585d6b26c8ce"
        ],
        "331b3274-1c08-44a4-9a13-f393417b918f": [
            "b3ce1d16-79cb-431e-b1a1-585d6b26c8ce"
        ],
        "ab4b84eb-731c-4b5f-ac89-75184f04286a": [
            "75460117-65d6-4d3d-a003-4dc019cffed0"
        ],
        "a9d9c690-d9c5-4417-b126-a8f07969074d": [
            "75460117-65d6-4d3d-a003-4dc019cffed0"
        ],
        "88e9e4c5-454b-414e-bd13-0861f32d3382": [
            "75460117-65d6-4d3d-a003-4dc019cffed0"
        ],
        "b7a71b29-0e26-4388-a92d-93ac73d64643": [
            "42369608-687f-4633-86b7-2704427759a1"
        ],
        "8037537f-0833-4847-83ce-611179ef3141": [
            "42369608-687f-4633-86b7-2704427759a1"
        ],
        "aa239fc2-5bdf-40d1-ae61-a4c534795f5d": [
            "42369608-687f-4633-86b7-2704427759a1"
        ],
        "7079bb05-a53c-4085-b986-1a39ebacd803": [
            "42369608-687f-4633-86b7-2704427759a1"
        ],
        "7139dd1b-c754-42e8-838d-43ef415e74a3": [
            "42369608-687f-4633-86b7-2704427759a1"
        ],
        "5806110e-cdca-434f-b593-d8f436f949ee": [
            "544e7103-8d62-4115-b0b8-f0341dab95a3"
        ],
        "4860a02a-95e9-4ee9-8f20-62dbe5c9a747": [
            "544e7103-8d62-4115-b0b8-f0341dab95a3"
        ],
        "2117ca08-51f7-4461-8d98-945507cf3759": [
            "3ea893d6-93fe-404c-9b9d-d02baec3e5c5"
        ],
        "8c518111-0ea8-4d8f-87e5-2781d1da71cf": [
            "3ea893d6-93fe-404c-9b9d-d02baec3e5c5"
        ],
        "c4765881-7e7d-4b84-b400-25f967414f85": [
            "3ea893d6-93fe-404c-9b9d-d02baec3e5c5"
        ],
        "98a37763-3f9d-4318-96e9-789717f19e13": [
            "3ea893d6-93fe-404c-9b9d-d02baec3e5c5"
        ],
        "ceb94edd-45f3-42ae-8aa8-474a8ae95b4d": [
            "3ea893d6-93fe-404c-9b9d-d02baec3e5c5"
        ],
        "314fecd4-4a18-457f-aea5-170deac4acc9": [
            "4ed8955a-4e2f-4b5e-8447-ad8719f369f9"
        ],
        "83958818-ded2-4a3d-8c7d-8562f5fd44e4": [
            "4ed8955a-4e2f-4b5e-8447-ad8719f369f9"
        ],
        "9fc32296-a07d-4aea-8575-5893c9b04a5d": [
            "b13cd79e-4df0-4a9f-a1e6-3547370e0899"
        ],
        "a8d162ef-a089-4a64-98b3-1be64a85cccd": [
            "b13cd79e-4df0-4a9f-a1e6-3547370e0899"
        ],
        "e3e37b08-6ef5-43c0-b207-9912a4f19693": [
            "b13cd79e-4df0-4a9f-a1e6-3547370e0899"
        ],
        "e1e9fdb6-59ee-47cf-a4f4-c86030785ca4": [
            "b13cd79e-4df0-4a9f-a1e6-3547370e0899"
        ],
        "e5882c85-9b03-4df0-913e-93915c648385": [
            "b13cd79e-4df0-4a9f-a1e6-3547370e0899"
        ],
        "ddcd21f4-3289-4aa1-b7ab-5f26d7a5d89c": [
            "0b26fe19-d8ba-4a6d-baa0-40cbe0e3a39d"
        ],
        "f2584d67-ad98-4a45-9d94-8d9f814714c6": [
            "0b26fe19-d8ba-4a6d-baa0-40cbe0e3a39d"
        ],
        "3c67cc7c-719b-4dcd-a02c-1d2bd4c5fbdd": [
            "84d29e0e-25f7-4f5c-a066-b3c5621144a6"
        ],
        "f0455ebd-d1a6-413e-8edc-b6b21f398720": [
            "84d29e0e-25f7-4f5c-a066-b3c5621144a6"
        ],
        "ed1f754b-ebd4-43a4-8ab8-b4003339dd5a": [
            "10681c4c-8a95-4475-8dda-367b52031752"
        ],
        "1d9e0894-7678-4749-b8eb-41f2d271e20c": [
            "10681c4c-8a95-4475-8dda-367b52031752"
        ],
        "5bba8f5a-20a5-4b09-9801-db942e0e8be8": [
            "10681c4c-8a95-4475-8dda-367b52031752"
        ],
        "000a4a4d-6a93-47c6-9cea-8c5c60e03e1e": [
            "10681c4c-8a95-4475-8dda-367b52031752"
        ],
        "f1a22ac0-d790-4f3b-956f-d2c5d2587ab2": [
            "10681c4c-8a95-4475-8dda-367b52031752"
        ],
        "ad59414f-2e5d-45fe-bd0d-fe6c593f570f": [
            "ec3152b8-a408-4e9a-aec0-92d6e21918bc"
        ],
        "934641a8-63fc-43e6-8785-2b2b1954bf23": [
            "ec3152b8-a408-4e9a-aec0-92d6e21918bc"
        ],
        "96fefd92-3096-44a4-ada6-ffc6ddda21c7": [
            "ec3152b8-a408-4e9a-aec0-92d6e21918bc"
        ],
        "4d0c3e35-3360-47f5-ac27-37ef35d6c957": [
            "ec3152b8-a408-4e9a-aec0-92d6e21918bc"
        ],
        "1039439e-44ef-4283-8689-178f348eda0b": [
            "ec3152b8-a408-4e9a-aec0-92d6e21918bc"
        ],
        "001d4307-4ec7-4764-87ce-ece4ad26d9bc": [
            "7586021c-06cb-4bbf-af31-207827f5464d"
        ],
        "7279946f-e7b0-4ebe-9c3b-ae92a8240a5d": [
            "7586021c-06cb-4bbf-af31-207827f5464d"
        ],
        "be1233ed-d81f-4bdf-b2e0-eec0b5363981": [
            "7586021c-06cb-4bbf-af31-207827f5464d"
        ],
        "0c686a3a-8ef3-4810-8674-0f8d9e3b40bc": [
            "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d"
        ],
        "aea1cdec-d9a4-46db-8675-4ee8975bed49": [
            "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d"
        ],
        "046e98cd-7d49-49de-9b11-17d42d0360d5": [
            "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d"
        ],
        "8fc4ed59-2ed2-42a3-ac66-e8e1f874cdb6": [
            "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d"
        ],
        "92e25078-8abe-4874-abb0-a5417375aa00": [
            "5235a4fd-d5b1-4da4-bfb9-3d636f37dd6d"
        ],
        "861c5862-92de-44c2-8374-2f87b28c7c42": [
            "68d1e877-772d-42e2-924a-a7272eb774b7"
        ],
        "09575657-2eb6-4431-afd4-840db5d7390b": [
            "68d1e877-772d-42e2-924a-a7272eb774b7"
        ],
        "cc4d3e50-0338-4c80-876b-44e3c343e30e": [
            "68d1e877-772d-42e2-924a-a7272eb774b7"
        ],
        "313a759e-6f43-4757-995c-545461949c54": [
            "68d1e877-772d-42e2-924a-a7272eb774b7"
        ],
        "5e9f8f65-fad8-4346-9545-f763a4d4209b": [
            "68d1e877-772d-42e2-924a-a7272eb774b7"
        ],
        "3b821306-295d-4826-a850-80018df3c7e3": [
            "186f5b60-9c0f-46fa-b723-6832c450f2ec"
        ],
        "b9585c37-3d2f-47b2-92cf-f37c9313c0ea": [
            "186f5b60-9c0f-46fa-b723-6832c450f2ec"
        ],
        "b607e83e-6d6e-461d-a1a7-53f87bba26b6": [
            "c54124f5-331c-40dc-8829-ba419a9326ac"
        ],
        "5c917f2d-5fc4-4da3-92e2-85c2d2bb811e": [
            "c54124f5-331c-40dc-8829-ba419a9326ac"
        ],
        "55de8272-9545-4ec9-a664-767e273ff86e": [
            "c54124f5-331c-40dc-8829-ba419a9326ac"
        ],
        "be79df6a-5e41-4367-9191-973287f68264": [
            "c54124f5-331c-40dc-8829-ba419a9326ac"
        ],
        "c7368894-d2cc-4d1c-8541-3dd170082bfb": [
            "c54124f5-331c-40dc-8829-ba419a9326ac"
        ],
        "576b3434-1b05-485e-bd61-284211eb8f10": [
            "500abd46-fdd9-4866-9a62-4caf6c532212"
        ],
        "8461a1c2-eb9d-4932-8596-d556d4d85ef4": [
            "500abd46-fdd9-4866-9a62-4caf6c532212"
        ],
        "7a184328-d666-4ddf-9120-08281a3b826b": [
            "500abd46-fdd9-4866-9a62-4caf6c532212"
        ],
        "23570530-f722-4b12-832c-1ee1f3b1f35d": [
            "500abd46-fdd9-4866-9a62-4caf6c532212"
        ],
        "5233ffa7-bb46-46ee-aba8-6819165c1325": [
            "500abd46-fdd9-4866-9a62-4caf6c532212"
        ],
        "0c69f20a-0ef2-4e75-b871-3dc3af01218f": [
            "6058fa69-a58a-41c2-8b06-eeb4066a321e"
        ],
        "743a808d-eb8e-4bd5-a627-4553aa72bcaf": [
            "6058fa69-a58a-41c2-8b06-eeb4066a321e"
        ],
        "a22498ee-7883-470f-bbae-5ae6b2de8dac": [
            "6058fa69-a58a-41c2-8b06-eeb4066a321e"
        ],
        "146caf11-a5b1-4b0f-832f-f3db1e0abf9d": [
            "6058fa69-a58a-41c2-8b06-eeb4066a321e"
        ],
        "1e1e4c0c-7148-4fef-8340-b39b46c905b2": [
            "6058fa69-a58a-41c2-8b06-eeb4066a321e"
        ],
        "95650467-b03e-4304-9891-a0d147d1fab3": [
            "84dcf72d-a76d-4451-af49-f489f1b1a761"
        ],
        "bcd6ac04-bb87-47ed-b806-a48e4d732d04": [
            "84dcf72d-a76d-4451-af49-f489f1b1a761"
        ],
        "8f8ba067-109e-48b7-8553-f819a9d24106": [
            "84dcf72d-a76d-4451-af49-f489f1b1a761"
        ],
        "f054d068-c39f-489c-bff3-d4791820ffc9": [
            "84dcf72d-a76d-4451-af49-f489f1b1a761"
        ],
        "c71085ca-afbf-4c6c-9d62-52dffba433e4": [
            "84dcf72d-a76d-4451-af49-f489f1b1a761"
        ],
        "0c68b460-3491-44e9-91a4-1b940e2c2b5f": [
            "ac1189ed-6f00-414c-ab32-ff09d75b087f"
        ],
        "3a1a7adf-dfd7-44fe-8727-f0d54ccb7e13": [
            "ac1189ed-6f00-414c-ab32-ff09d75b087f"
        ],
        "dddf6615-3568-4379-b4f1-9de5496860bd": [
            "ac1189ed-6f00-414c-ab32-ff09d75b087f"
        ],
        "ed4dfccd-a401-4787-9572-184a7daf6071": [
            "ac1189ed-6f00-414c-ab32-ff09d75b087f"
        ],
        "1fc667a5-fa55-4c5f-aa6d-ebd492837813": [
            "ac1189ed-6f00-414c-ab32-ff09d75b087f"
        ],
        "def38685-5c39-437e-998d-62097d0cfb69": [
            "3144735b-8daa-472e-a7c7-6ee81ad37e49"
        ],
        "fe3f034e-1fcb-4e98-8a5f-873f1def1625": [
            "3144735b-8daa-472e-a7c7-6ee81ad37e49"
        ],
        "d9f83b46-bca7-48d2-a3db-a3b5be3fc534": [
            "3144735b-8daa-472e-a7c7-6ee81ad37e49"
        ],
        "e07e32c6-90ed-4c8a-aa9f-fa3614a0e9d2": [
            "3144735b-8daa-472e-a7c7-6ee81ad37e49"
        ],
        "103035ef-0f34-4ca7-99ac-fffd0f079fb8": [
            "3144735b-8daa-472e-a7c7-6ee81ad37e49"
        ],
        "0b963cfe-cac9-4560-abcb-89645517596d": [
            "846db9d3-4b4b-4ea2-a5c2-b802928ec4e5"
        ],
        "f883ac14-3a1d-4828-be4f-689927836c44": [
            "846db9d3-4b4b-4ea2-a5c2-b802928ec4e5"
        ],
        "576d8fd1-153e-49cc-8641-1c5ba269c4ac": [
            "9f5a416b-dc7f-4299-ab82-9a1c23790cb9"
        ],
        "2d132bc9-b386-4487-989b-0ab7d4b2c129": [
            "9f5a416b-dc7f-4299-ab82-9a1c23790cb9"
        ],
        "a3b7a1d5-7dc0-47ad-85f3-906fd5d9e0c1": [
            "9f5a416b-dc7f-4299-ab82-9a1c23790cb9"
        ],
        "647ff9fd-133d-4579-a459-aed85456e6ee": [
            "6d595caf-8bbd-45e0-a887-a9475b421a5a"
        ],
        "b45bb0b2-3cf7-4dc5-91b7-4885b9fc0535": [
            "6d595caf-8bbd-45e0-a887-a9475b421a5a"
        ],
        "2c28d095-581a-4ce6-84b2-b8da41e25006": [
            "6d595caf-8bbd-45e0-a887-a9475b421a5a"
        ],
        "ef5e6d4f-1827-4959-addb-352a7e9585e5": [
            "6d595caf-8bbd-45e0-a887-a9475b421a5a"
        ],
        "44340f91-11f8-4fe1-bb6a-92f0f4e8b7cc": [
            "6d595caf-8bbd-45e0-a887-a9475b421a5a"
        ],
        "89b8c664-27e7-4507-bf65-1f4543b5351c": [
            "cbe21760-9a27-462a-bdf4-4be4f9c53a29"
        ],
        "74eb2865-c8f4-48c7-ab5a-5a13aabdf45d": [
            "cbe21760-9a27-462a-bdf4-4be4f9c53a29"
        ],
        "3cdcb0bd-4f9c-4ee7-9528-eccfd14dd2d6": [
            "cbe21760-9a27-462a-bdf4-4be4f9c53a29"
        ],
        "08243e09-5c74-429a-bc5f-e35ff95f6ba5": [
            "cbe21760-9a27-462a-bdf4-4be4f9c53a29"
        ],
        "2a799ec9-d25b-44ec-aea9-474cef72a719": [
            "cbe21760-9a27-462a-bdf4-4be4f9c53a29"
        ],
        "e21a4d8d-070b-4074-8a51-45097bb81a41": [
            "ada94f87-b83a-42d7-b9fc-6003d8f72825"
        ],
        "b03e592e-93d4-4c37-bcba-058ce157fb21": [
            "ada94f87-b83a-42d7-b9fc-6003d8f72825"
        ],
        "a86a5f11-517a-4520-947a-c85a9a07891c": [
            "a642f6dc-1149-4c5e-bd5f-87be054b6d05"
        ],
        "b5dd8499-44f5-4c2b-8ca3-e3ea224194e8": [
            "a642f6dc-1149-4c5e-bd5f-87be054b6d05"
        ],
        "3a351357-00c6-4dc8-991e-2e4d16fe3074": [
            "a642f6dc-1149-4c5e-bd5f-87be054b6d05"
        ],
        "49b812ab-4d5f-4a41-899d-f5e48ae9005e": [
            "a642f6dc-1149-4c5e-bd5f-87be054b6d05"
        ],
        "2542ec1c-3223-427e-be46-be6ee62c0aac": [
            "a642f6dc-1149-4c5e-bd5f-87be054b6d05"
        ],
        "4d79b442-d715-47b8-af76-ebd90d202b40": [
            "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb"
        ],
        "6f9ae28b-1574-4e66-8214-31142ea4ff1b": [
            "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb"
        ],
        "6fb035ad-461b-4466-9b13-9e599f68aa68": [
            "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb"
        ],
        "9660277b-93c5-40a6-8de1-116f80068bc8": [
            "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb"
        ],
        "9419959d-6ca3-4afc-af25-3fdf5e2db882": [
            "82387ae8-16e2-42c3-a9e1-2c1ce576ecfb"
        ],
        "43c2be9a-b76e-4bae-b0c7-06d7d87d9b57": [
            "4c831f5a-c4ae-47e4-a05f-64cf3f3c4853"
        ],
        "465b4e1c-ae1b-42c3-bc7a-13fa1875d465": [
            "4c831f5a-c4ae-47e4-a05f-64cf3f3c4853"
        ],
        "337140e5-f572-46da-867a-e3df4c464b5d": [
            "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771"
        ],
        "b95a3619-d5ff-4c22-83d1-4a42eb808953": [
            "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771"
        ],
        "a07dc4ff-433c-4e69-af9f-ae230020a538": [
            "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771"
        ],
        "469e3012-8567-40e7-b3f5-a10fcb34dc47": [
            "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771"
        ],
        "0692e3ab-847d-41a9-a806-f59ca19a2e56": [
            "25bd6b10-3d8f-4c9b-a0d3-5bb3ce183771"
        ],
        "dc2b0e79-fab6-4abd-9daa-5d1ec591cd83": [
            "7acbe339-ca92-45fc-9b39-8b7c259d945a"
        ],
        "92933f94-aa3f-4bff-8b85-563a7a93e11b": [
            "7acbe339-ca92-45fc-9b39-8b7c259d945a"
        ],
        "52c341f5-1d5e-49c2-8c87-763b273a7c16": [
            "42ec581e-7aa8-4796-bb20-b5c7b6811056"
        ],
        "936fd818-7895-4f3c-b6ab-430b0cb666dc": [
            "42ec581e-7aa8-4796-bb20-b5c7b6811056"
        ],
        "79a5fd39-0be1-4eee-a0ec-956e41f14420": [
            "42ec581e-7aa8-4796-bb20-b5c7b6811056"
        ],
        "1a0c21fa-8db4-441f-bb2b-bd3cd02224d5": [
            "42ec581e-7aa8-4796-bb20-b5c7b6811056"
        ],
        "a0b49971-1329-4e05-8dba-67369b795675": [
            "2f7ec96a-5c87-4eec-9115-12314e10d4f2"
        ],
        "d506980e-7754-4a1b-bb89-35ac6e9252fe": [
            "2f7ec96a-5c87-4eec-9115-12314e10d4f2"
        ],
        "1bec1238-f58e-4f27-9fb1-88dc3b586378": [
            "2f7ec96a-5c87-4eec-9115-12314e10d4f2"
        ],
        "88755055-dfdd-4399-9783-14388b8fa8b4": [
            "2f7ec96a-5c87-4eec-9115-12314e10d4f2"
        ],
        "d7fd7fb5-4685-42d1-a17f-54775d90d57a": [
            "2f7ec96a-5c87-4eec-9115-12314e10d4f2"
        ],
        "30f39978-2491-4f25-a06a-3f4600b9367d": [
            "476c68ee-bd93-497f-bbb9-0572dbc356ce"
        ],
        "4744c16f-ad78-46dd-838a-05a48c2005f5": [
            "476c68ee-bd93-497f-bbb9-0572dbc356ce"
        ],
        "1f4fd06e-700e-4466-aed5-dac7d26ea432": [
            "476c68ee-bd93-497f-bbb9-0572dbc356ce"
        ],
        "3348523c-3715-4c92-aa35-d2b3ffa4daee": [
            "e18c239b-c919-4b7f-928d-45fb3e157308"
        ],
        "20042984-1a89-4c00-a78a-e44826049709": [
            "e18c239b-c919-4b7f-928d-45fb3e157308"
        ],
        "cd17ed71-2eec-49db-8855-39de45b91efb": [
            "e18c239b-c919-4b7f-928d-45fb3e157308"
        ],
        "b1f1948f-7130-4b76-9e49-6185b6f2997b": [
            "e18c239b-c919-4b7f-928d-45fb3e157308"
        ],
        "c313e0c2-3080-4095-b2b9-cb11b38fab86": [
            "e18c239b-c919-4b7f-928d-45fb3e157308"
        ],
        "3dbb5193-7250-4464-8d2c-86f1baefaaf9": [
            "5d096cfc-2076-422d-8155-799e85f9e4af"
        ],
        "a0597241-eb44-4f26-abdf-29aecc47670d": [
            "5d096cfc-2076-422d-8155-799e85f9e4af"
        ],
        "b70160e3-bacd-42dd-8c76-daa68130fa98": [
            "5d096cfc-2076-422d-8155-799e85f9e4af"
        ],
        "3fa5dace-c445-44b9-a76e-28da0782dd91": [
            "5d096cfc-2076-422d-8155-799e85f9e4af"
        ],
        "09df2e45-e6eb-4387-8832-77eaaeb65a70": [
            "5d096cfc-2076-422d-8155-799e85f9e4af"
        ],
        "cbe6f873-f6d4-4bb4-ad1a-81b8c2fdf8f7": [
            "771b2917-040e-4891-a157-1f1d04250b99"
        ],
        "b9c97deb-3b23-4890-a7d6-9f6c1a8de94a": [
            "771b2917-040e-4891-a157-1f1d04250b99"
        ],
        "0aecbc41-ecc7-4c56-a9e9-6cad1854fb89": [
            "7d9cb1b2-5399-421e-a5aa-1119b0989ff9"
        ],
        "8b18dc2c-a0ba-4dd7-917e-be51fb832b5e": [
            "7d9cb1b2-5399-421e-a5aa-1119b0989ff9"
        ],
        "331d00c8-119c-470d-9a00-008c6922fe79": [
            "7d9cb1b2-5399-421e-a5aa-1119b0989ff9"
        ],
        "dd4de403-3896-4c94-93d1-9c3bd9518f71": [
            "7d9cb1b2-5399-421e-a5aa-1119b0989ff9"
        ],
        "dcab5551-1797-4210-bf47-3e6c68150638": [
            "7d9cb1b2-5399-421e-a5aa-1119b0989ff9"
        ],
        "f100507b-c548-4e48-97fc-3f24c7fc4be1": [
            "323e2233-3581-460e-b3d2-45c7c5612328"
        ],
        "ef4d4b50-b862-49bb-b46b-6e190e5ee17a": [
            "323e2233-3581-460e-b3d2-45c7c5612328"
        ],
        "aba5763c-8733-433c-bb17-537e1b26e20a": [
            "323e2233-3581-460e-b3d2-45c7c5612328"
        ],
        "3cc61a1a-6e28-4a5a-8d63-a5fed11fc757": [
            "323e2233-3581-460e-b3d2-45c7c5612328"
        ],
        "5ef1900b-9c1a-4dc4-afce-337409c1bf68": [
            "323e2233-3581-460e-b3d2-45c7c5612328"
        ],
        "e6286a17-55d0-4093-9dc6-9fa2dc6e57d3": [
            "dc5a7e3d-aae4-4c76-9bdd-4d860c701852"
        ],
        "05aa1c11-895c-48a5-819d-820b905a5c64": [
            "dc5a7e3d-aae4-4c76-9bdd-4d860c701852"
        ],
        "2a497321-290b-412e-a5d6-26cdb04959c1": [
            "dc5a7e3d-aae4-4c76-9bdd-4d860c701852"
        ],
        "664d940f-5f77-435e-bd87-f2712bb76dcb": [
            "dc5a7e3d-aae4-4c76-9bdd-4d860c701852"
        ],
        "0e9aa17c-43a6-4e9b-b150-58ee200bf02f": [
            "dc5a7e3d-aae4-4c76-9bdd-4d860c701852"
        ],
        "c064c3dd-c2e1-4a2d-8260-4729d70259b9": [
            "547e3605-5337-421e-89bd-1e48481e0ee4"
        ],
        "4bb6fb8e-a02a-460b-a608-ed7dc824b87a": [
            "547e3605-5337-421e-89bd-1e48481e0ee4"
        ],
        "bf2df4e3-eba4-420a-ae76-87631c4ba7e0": [
            "11b4de39-24f7-4b1f-903e-a31f63d8149f"
        ],
        "12543ede-2d2d-44fc-a0ca-7d178ae22bae": [
            "11b4de39-24f7-4b1f-903e-a31f63d8149f"
        ],
        "a2432765-7312-4d0e-8115-242ef034e773": [
            "11b4de39-24f7-4b1f-903e-a31f63d8149f"
        ],
        "3c1df9fc-c749-4c88-8da2-a347b903f9b5": [
            "11b4de39-24f7-4b1f-903e-a31f63d8149f"
        ],
        "520d64dc-6f8b-4e8e-958d-8d5285ca4a43": [
            "11b4de39-24f7-4b1f-903e-a31f63d8149f"
        ],
        "c339336f-bb78-4fe8-835e-c20c574c90d1": [
            "76220002-3d46-4e44-a303-4125ef2a623b"
        ],
        "93af2951-9201-41d1-bc92-dc1ade321815": [
            "76220002-3d46-4e44-a303-4125ef2a623b"
        ],
        "f3d9f0e5-5afb-4948-9596-c21badf8f386": [
            "0a391e09-68d8-4ac5-bcf6-7d38ef088f35"
        ],
        "9e1c9bb8-ea94-4229-a49b-9652cc667200": [
            "0a391e09-68d8-4ac5-bcf6-7d38ef088f35"
        ],
        "7dce0a84-7d41-4187-aa26-0055b6966819": [
            "0a391e09-68d8-4ac5-bcf6-7d38ef088f35"
        ],
        "1b8aa497-2a3b-4d8e-a6d3-3ba75a8cc092": [
            "0a391e09-68d8-4ac5-bcf6-7d38ef088f35"
        ],
        "ab66bf89-b67c-4c9e-839a-6f5ad75e75dc": [
            "0a391e09-68d8-4ac5-bcf6-7d38ef088f35"
        ],
        "27073bf2-bbe5-4146-b45a-f0a01a60d82e": [
            "77f97faa-0cef-406c-99bf-665955ef8e62"
        ],
        "cdfe3d3f-5adb-4b01-9fc3-3a84ce1c61a2": [
            "77f97faa-0cef-406c-99bf-665955ef8e62"
        ],
        "2a520c95-e267-4949-a885-5d094827922e": [
            "545b41da-4b45-4637-b972-70577e5acc6a"
        ],
        "7d126ec8-4368-4fe3-baa6-658da5b21a6f": [
            "545b41da-4b45-4637-b972-70577e5acc6a"
        ],
        "8b3425d5-bbdc-4e0f-8c9a-5167a33bea15": [
            "545b41da-4b45-4637-b972-70577e5acc6a"
        ],
        "bc924a4e-8c61-4002-9d86-9592604c915b": [
            "545b41da-4b45-4637-b972-70577e5acc6a"
        ],
        "d4c497de-e15d-48ba-95ff-bc25dd7247c1": [
            "545b41da-4b45-4637-b972-70577e5acc6a"
        ],
        "bdda92d4-d36a-4843-b340-037ba3de6d6b": [
            "fcc654c6-ce14-4f55-85eb-5096089d3fa3"
        ],
        "42ee6314-5530-4191-8b76-7348156381af": [
            "fcc654c6-ce14-4f55-85eb-5096089d3fa3"
        ],
        "a47fbd5b-73ee-484c-9624-c7b409046ba2": [
            "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d"
        ],
        "75d1393b-e4ee-49a4-8653-83f1eebbb50a": [
            "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d"
        ],
        "8678f5ae-c519-4aba-9747-516ab43b6d77": [
            "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d"
        ],
        "efb22109-0c2d-4a94-aca7-fedaaf38a73a": [
            "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d"
        ],
        "394be7da-4653-43f2-8306-aef5602fa620": [
            "b5c21fbd-4a31-4b8b-9cf9-5126e13d714d"
        ],
        "a9120303-243e-4d3f-b4f8-c4b9bfdc9fc1": [
            "90337e69-77f0-49dd-86c0-dea2e4aee6a6"
        ],
        "2eebb745-5988-4f15-bb26-f5dd83fdcce7": [
            "90337e69-77f0-49dd-86c0-dea2e4aee6a6"
        ],
        "86664d84-44c2-49f5-81f3-c5ea292a65a5": [
            "90337e69-77f0-49dd-86c0-dea2e4aee6a6"
        ],
        "0db412b0-dcee-4661-82fe-a551217e2f40": [
            "90337e69-77f0-49dd-86c0-dea2e4aee6a6"
        ],
        "76d2424a-8ec4-4e1b-b5c3-4cb26c427140": [
            "90337e69-77f0-49dd-86c0-dea2e4aee6a6"
        ],
        "d0e97e04-2a2c-44b7-b69b-398a9e2e7310": [
            "4525a9c8-d56f-4322-8868-958f652368f9"
        ],
        "66bf7740-67e1-4390-be68-6644199c6b87": [
            "4525a9c8-d56f-4322-8868-958f652368f9"
        ],
        "bb5354cb-87b1-4019-9457-0d8b789dab96": [
            "7ae0e732-82de-463c-b429-b06b07022e66"
        ],
        "c8294095-fd09-446c-be1e-fbf7ac2464bb": [
            "7ae0e732-82de-463c-b429-b06b07022e66"
        ],
        "8c9f4c5e-78c4-44d3-ad88-23c992d82491": [
            "7ae0e732-82de-463c-b429-b06b07022e66"
        ],
        "25bf54de-6c40-4e45-ba7c-288ba31230cc": [
            "7ae0e732-82de-463c-b429-b06b07022e66"
        ],
        "674740cb-ef53-44eb-84ea-ddcca0272ae4": [
            "7ae0e732-82de-463c-b429-b06b07022e66"
        ],
        "1159bff1-5b23-4481-bec6-e919ed1da1ec": [
            "19f38fa9-6e93-4fe7-bdca-73e930c0b318"
        ],
        "a5fcf3d6-b630-41a6-9f17-c6c5bbc64ee2": [
            "19f38fa9-6e93-4fe7-bdca-73e930c0b318"
        ],
        "f03c0a2b-bf96-408a-a039-0539a0035fa9": [
            "19f38fa9-6e93-4fe7-bdca-73e930c0b318"
        ],
        "8a7d8c5a-2c96-4c90-b2d8-ac6d64d2019e": [
            "19f38fa9-6e93-4fe7-bdca-73e930c0b318"
        ],
        "b096c8f1-7c22-4da9-9a63-af5572dc6cee": [
            "19f38fa9-6e93-4fe7-bdca-73e930c0b318"
        ],
        "c2a6167a-0a6e-4237-a61c-e2a7e4c463e6": [
            "47cb5e54-120b-47ea-88e2-e536da8f555f"
        ],
        "64574e73-5cd6-4004-81c0-f01cf36edb84": [
            "47cb5e54-120b-47ea-88e2-e536da8f555f"
        ],
        "13fadca4-a60b-4ad8-a053-f88375ec52a0": [
            "47cb5e54-120b-47ea-88e2-e536da8f555f"
        ],
        "27c8b167-81d2-42d6-96ea-bfcd36efca33": [
            "47cb5e54-120b-47ea-88e2-e536da8f555f"
        ],
        "6a44f812-210e-4133-ac0e-b22c7a0cedc7": [
            "47cb5e54-120b-47ea-88e2-e536da8f555f"
        ],
        "7eccd965-ba5c-4236-af44-ec19ba668f06": [
            "a3328510-bcd4-453b-b3cb-0e28d818e8d4"
        ],
        "e5dbb9b8-7a82-4a29-9fe0-aa9b658fe6a0": [
            "a3328510-bcd4-453b-b3cb-0e28d818e8d4"
        ],
        "7e87066c-c886-43aa-9ff7-c65918576c43": [
            "a3328510-bcd4-453b-b3cb-0e28d818e8d4"
        ],
        "f30cd5b6-adf8-48e5-b568-8851f011a37d": [
            "a3328510-bcd4-453b-b3cb-0e28d818e8d4"
        ],
        "21d9afb4-377d-40d1-8096-49a553bb6ee5": [
            "a3328510-bcd4-453b-b3cb-0e28d818e8d4"
        ],
        "6c8b0cb0-74c9-4ca6-aca1-01cdc5a5e82f": [
            "13b9c2c3-e3c5-4170-b91e-733340579a5f"
        ],
        "b6ee45bc-a8cf-4923-a1d6-48ced1c923c4": [
            "13b9c2c3-e3c5-4170-b91e-733340579a5f"
        ],
        "d0680d92-a783-4dae-94a9-88b5e85e367e": [
            "13b9c2c3-e3c5-4170-b91e-733340579a5f"
        ],
        "0acf23ca-882a-40c4-af9e-fa1cecdde729": [
            "13b9c2c3-e3c5-4170-b91e-733340579a5f"
        ],
        "0d930bf2-ff52-4d9d-99af-b602418e1941": [
            "13b9c2c3-e3c5-4170-b91e-733340579a5f"
        ],
        "4b7ea2a3-1034-429c-a053-ad845dca8a4c": [
            "14710cca-f23a-4f7f-8744-cced0d97eae2"
        ],
        "1adf3529-fac7-4743-a2fd-51b74b5708a1": [
            "14710cca-f23a-4f7f-8744-cced0d97eae2"
        ],
        "8754fbb1-a897-4885-8834-7b1b7333c9f4": [
            "14710cca-f23a-4f7f-8744-cced0d97eae2"
        ],
        "029b84b0-13f5-4034-8c30-130dcc2cf941": [
            "14710cca-f23a-4f7f-8744-cced0d97eae2"
        ],
        "b4ec98d1-b15b-4714-949b-ced20bba2687": [
            "14710cca-f23a-4f7f-8744-cced0d97eae2"
        ],
        "6ed3a6fe-9b6b-4f86-8a60-73a865fbb8fc": [
            "75d1e09d-ef01-44c2-8555-e0141e9970b4"
        ],
        "550ca23e-da45-4ee0-ad79-7513bc87bda6": [
            "75d1e09d-ef01-44c2-8555-e0141e9970b4"
        ],
        "3a5de9fa-b658-43cc-a7ec-fc5dd86f6958": [
            "75d1e09d-ef01-44c2-8555-e0141e9970b4"
        ],
        "a096a72e-a581-4985-a70e-2e72520e2d24": [
            "75d1e09d-ef01-44c2-8555-e0141e9970b4"
        ],
        "289a3498-bacb-4c98-8324-f7550c4a7ddb": [
            "75d1e09d-ef01-44c2-8555-e0141e9970b4"
        ],
        "ef8bc08a-5e20-40e9-8a64-c827ec84bfc5": [
            "2c93147d-617f-492d-ac36-12c3daccb17f"
        ],
        "c4f5ca5e-8188-4c3f-9d95-75afe3aa9bdc": [
            "2c93147d-617f-492d-ac36-12c3daccb17f"
        ],
        "a1216cb8-48d4-4948-8a01-ff2942ba1b38": [
            "2c93147d-617f-492d-ac36-12c3daccb17f"
        ],
        "e05b369a-8ca2-434b-8f31-b540b601c891": [
            "2c93147d-617f-492d-ac36-12c3daccb17f"
        ],
        "ba7555e8-19a8-4bac-8258-f70cc2d0213c": [
            "2c93147d-617f-492d-ac36-12c3daccb17f"
        ],
        "38348547-bf81-4ad4-bc6e-49078f8cb94f": [
            "5bd14723-1535-4bd0-b479-585845013fe0"
        ],
        "b885d8e7-1d64-4f86-ad09-01b6e5bafaed": [
            "5bd14723-1535-4bd0-b479-585845013fe0"
        ],
        "bb8a4f6a-0d73-497d-9d5d-48c579453007": [
            "5bd14723-1535-4bd0-b479-585845013fe0"
        ],
        "53dc36c4-a60f-4711-980d-8f0a2479b40f": [
            "5bd14723-1535-4bd0-b479-585845013fe0"
        ],
        "4947c59b-4119-4fef-af72-bc64b7994131": [
            "5bd14723-1535-4bd0-b479-585845013fe0"
        ],
        "97ea5c82-9ac4-4a22-a600-559d876681c9": [
            "1f39c964-f137-4782-8f76-6fdde4e7b0dc"
        ],
        "50aad2c5-8af8-48f9-8f86-cf96a8f1658a": [
            "1f39c964-f137-4782-8f76-6fdde4e7b0dc"
        ],
        "eb64b1fb-e705-4768-858e-e5708405f8b2": [
            "1f39c964-f137-4782-8f76-6fdde4e7b0dc"
        ],
        "b113e7c3-32b3-4a7c-8a08-acf41d1c670b": [
            "1f39c964-f137-4782-8f76-6fdde4e7b0dc"
        ],
        "b21af34a-730e-4976-8881-b2917b929cfb": [
            "1f39c964-f137-4782-8f76-6fdde4e7b0dc"
        ],
        "c6ed621e-dca5-4730-adc4-049c692b308c": [
            "621223d9-d564-4317-8676-a775a9448a97"
        ],
        "32081bd5-15c8-4963-b87f-6f283ed4d61e": [
            "621223d9-d564-4317-8676-a775a9448a97"
        ],
        "a82fe042-a443-4f82-be5c-7a385925e400": [
            "621223d9-d564-4317-8676-a775a9448a97"
        ],
        "0e4feb69-1d09-45d6-88bb-724d8b21e43e": [
            "621223d9-d564-4317-8676-a775a9448a97"
        ],
        "f2c06130-69fc-402a-9e03-1d8b5d634191": [
            "621223d9-d564-4317-8676-a775a9448a97"
        ],
        "1506be28-3099-4d9b-94c3-62e8a3911bc9": [
            "f5d377f1-e270-4dcf-859e-aab5e10dbb0d"
        ],
        "a95ec513-151e-45b1-8c0b-7a825b30e577": [
            "f5d377f1-e270-4dcf-859e-aab5e10dbb0d"
        ],
        "59d2808a-eb47-4fcf-af93-eef1d678b2da": [
            "f5d377f1-e270-4dcf-859e-aab5e10dbb0d"
        ],
        "5615fcc1-b19a-4033-afe8-f477e9561660": [
            "f5d377f1-e270-4dcf-859e-aab5e10dbb0d"
        ],
        "d5b39437-938b-41e0-9a89-9052a5e810a0": [
            "f5d377f1-e270-4dcf-859e-aab5e10dbb0d"
        ],
        "3d0f0bfa-a900-4166-a24d-efdd0ae73ab0": [
            "1316c9df-42ce-41ad-9a46-e04a04ec59fd"
        ],
        "46210930-e1cf-4a4c-8281-89e4290e953a": [
            "1316c9df-42ce-41ad-9a46-e04a04ec59fd"
        ],
        "abf5e3ec-c21c-436b-ab86-c525e59a00d5": [
            "b6ffe80f-563f-46c6-860e-a33f81abd002"
        ],
        "1140dd69-91f7-4295-a164-7a00b118a21d": [
            "7fac2d94-c6a4-4753-b3ea-9141fe971896"
        ],
        "398241ca-5f15-4369-9211-752ec5ef27bc": [
            "4d6dbbc0-3bcb-4d02-b537-d84ca011f451"
        ],
        "2765dd6c-1712-4664-bd65-94d81ea8a1df": [
            "4d6dbbc0-3bcb-4d02-b537-d84ca011f451"
        ],
        "7b8004a5-5a8d-4349-8efd-471bcbbef30d": [
            "6b9bd6a2-3aae-44ff-bc32-7eb20d6595f9"
        ],
        "d6c6532b-54b7-4f9b-b21a-91e05ae5ee51": [
            "6b9bd6a2-3aae-44ff-bc32-7eb20d6595f9"
        ],
        "21bf0ae8-44d3-4675-a3b1-3449451b6831": [
            "7b25cf46-d2e1-42a2-90d3-c3032f8582a0"
        ],
        "8d4e6c04-c4ce-45e3-bf21-be94c51fc719": [
            "7b25cf46-d2e1-42a2-90d3-c3032f8582a0"
        ],
        "ef772b3c-9c12-42e2-a9cb-fe52894e88e0": [
            "5f1e741f-82ce-4d4a-a8c8-1c8c6008901a"
        ],
        "720924b1-c01f-4a33-9283-aee89938b973": [
            "0862ecb0-802e-4500-b4a7-1960afe03651"
        ],
        "58024763-1b69-4d80-8d00-9db11bf9a69a": [
            "0862ecb0-802e-4500-b4a7-1960afe03651"
        ],
        "235126fc-c6f1-4c2e-8f1d-68408494fd93": [
            "d0c828a1-3f9b-4864-9d6f-33c75ce008e5"
        ],
        "b92c53f0-2665-47e5-9365-1e82859bc1c4": [
            "51efc490-0c31-41f2-b299-2af80e5d6a89"
        ],
        "1c952bdb-42c3-4e15-af50-773cdd40bd94": [
            "51efc490-0c31-41f2-b299-2af80e5d6a89"
        ],
        "7b55cca4-8bea-4b43-8038-99a7a61a90c1": [
            "303652fd-a1b9-4f4c-81d3-1837f74f93e3"
        ],
        "a6245ed1-9e79-4635-83e8-ed0a9fd2d75d": [
            "7303b680-feae-44d0-87c0-f68bb282488e"
        ],
        "107aaacc-7220-487e-80f1-ef2d8aa4571c": [
            "29d849c7-9e70-4849-b4e2-0758fb264e9f"
        ],
        "4a2bbf14-6fce-4c8a-bad0-1a3e5abedff9": [
            "7fa11f66-941f-44e2-9a4d-1b612b3f6249"
        ],
        "d34f1458-662b-471b-9fad-c03b02925f0a": [
            "ba571bc4-6ceb-46b3-befa-feecc1ff773d"
        ],
        "3feb1652-8e0c-4ff3-9b78-6ea7d0eaa77b": [
            "6192f3e7-204f-42f1-bab0-60aeb1ce9443"
        ],
        "29fbfc33-2c0c-4755-bcf3-e575a24cdc7d": [
            "6192f3e7-204f-42f1-bab0-60aeb1ce9443"
        ],
        "720da86c-cf8c-4856-8c6d-93644e614b51": [
            "d94164a7-e021-4ed0-8d8e-e364fc8bc34a"
        ],
        "63c8cd66-0b3e-4199-a259-a2593dd2c8a5": [
            "d94164a7-e021-4ed0-8d8e-e364fc8bc34a"
        ],
        "ca930f2c-f12b-484d-9f70-989d93ad8be0": [
            "4bf7d494-b7ee-46a2-92fa-089d7be46494"
        ],
        "3e587ead-003a-4748-934d-3705391ffde6": [
            "68d3b212-4740-4b35-b82b-9232c06551c9"
        ],
        "d960d097-a993-4b5f-8543-09562b52beb8": [
            "68d3b212-4740-4b35-b82b-9232c06551c9"
        ],
        "51cfb640-5df7-4eb0-a744-3ea50994fe9d": [
            "5f0d7cf2-3144-487f-b1e4-d2ca121a6c82"
        ],
        "a87d158b-b189-428f-94ac-7d25458e96ae": [
            "5f0d7cf2-3144-487f-b1e4-d2ca121a6c82"
        ],
        "e24068cb-1690-49aa-8a00-1739f6f2c9cc": [
            "96ac833e-7830-4283-b27e-3b214399bd7f"
        ],
        "dfaea2d9-6f57-442c-b0ec-b09ac8185b1c": [
            "96ac833e-7830-4283-b27e-3b214399bd7f"
        ],
        "54baeca8-672a-4263-a0d8-4a22f29792ba": [
            "cb7a05cc-56ac-4595-9b10-acceb86172b2"
        ],
        "0892ac9c-cc56-4d6a-9263-791eea7f1e64": [
            "1c8a7bb2-65e6-4e96-a83d-7df4cdcacd73"
        ],
        "d1927d4d-778e-4c4c-bfdf-b1fef892c02e": [
            "e0c75985-3ff1-4c23-abbe-c08b68ea7180"
        ],
        "92198546-fc74-4365-8cdb-bc24258f2026": [
            "e0c75985-3ff1-4c23-abbe-c08b68ea7180"
        ],
        "dffe4bd4-a0bc-444e-91ba-ce18be9755fa": [
            "ff25b706-4d86-4d9a-b097-5edd904b9a33"
        ],
        "328db0b2-f81b-41c7-a8d6-f9ddd842308a": [
            "539f6a55-c8db-45a1-bf6e-b9433438cf16"
        ],
        "ea66a0b8-61e5-4f9b-84fe-9cf9e8127653": [
            "4b3fb072-fb3b-47d5-b12d-978959072f06"
        ],
        "de393764-db00-417b-b849-e7c1925610e8": [
            "4b3fb072-fb3b-47d5-b12d-978959072f06"
        ],
        "df263050-177c-4f77-a92e-463415daf5aa": [
            "f73a0f25-b31a-490b-bf7e-01347b63749a"
        ],
        "271ae001-640a-464a-ae54-c44de1960be9": [
            "f73a0f25-b31a-490b-bf7e-01347b63749a"
        ],
        "20a791f8-31a8-4bf2-bf91-b6a82883957a": [
            "79f6e067-baed-475f-987d-f1bacb6e2dba"
        ],
        "cd91b56b-7363-4421-ad0c-03a0cf806c85": [
            "79f6e067-baed-475f-987d-f1bacb6e2dba"
        ],
        "759e5741-9ca7-4d6e-80ab-037ab54969cb": [
            "e6082d15-af36-44e6-8146-80ecf28dc653"
        ],
        "ed876c85-52a6-4588-b232-941ecccb2bb9": [
            "e6082d15-af36-44e6-8146-80ecf28dc653"
        ],
        "392c94bb-6332-4ea4-9005-24e369899d7c": [
            "e6082d15-af36-44e6-8146-80ecf28dc653"
        ],
        "939e091f-a852-4358-8d34-96982a30f6e5": [
            "ba3a5e1c-1129-4201-b2ed-90364696616d"
        ],
        "5ed62716-9ce6-446f-bbb4-db08f4559205": [
            "ba3a5e1c-1129-4201-b2ed-90364696616d"
        ],
        "e2ae48a0-3d20-4fbf-b305-0dd8239d7690": [
            "ba3a5e1c-1129-4201-b2ed-90364696616d"
        ],
        "848d0363-bc99-4129-b746-6b53cd560a3a": [
            "107485df-b507-4ba1-a34a-097acacd324a"
        ],
        "5cc3df7c-ce66-47df-9239-39ca13b0da70": [
            "107485df-b507-4ba1-a34a-097acacd324a"
        ],
        "909318ed-fbcf-499d-8307-459904d360de": [
            "b48abc17-bae5-4f12-bdce-a224348abd6d"
        ],
        "9d7a5b7b-9ffd-48d4-9c72-1abc3a5c747e": [
            "6d59231d-30a1-4b15-b1a9-30c7d23699d9"
        ],
        "9ab88254-c0db-4949-aa98-01922f457502": [
            "6d59231d-30a1-4b15-b1a9-30c7d23699d9"
        ],
        "28d6740c-7746-416f-9149-10e83f146275": [
            "981a1b11-2631-4149-b1a9-0b8efa11e9b8"
        ],
        "b70c4890-531b-4745-97a5-39583ffb2ec3": [
            "981a1b11-2631-4149-b1a9-0b8efa11e9b8"
        ],
        "870865c8-fb50-4eb1-bd27-c31ab2d93b7c": [
            "8e516b8e-0854-4102-abf0-39b19d4f3360"
        ],
        "992a5fdb-0020-49ea-bb6b-002c4e565679": [
            "8e516b8e-0854-4102-abf0-39b19d4f3360"
        ],
        "c57cb76d-c243-4fb2-98bb-c7fe95a92a6a": [
            "e743f6b9-8ecd-47e0-aead-880c9de1a0ec"
        ],
        "082b7ebf-a0c7-4178-a7de-179eb617ebb1": [
            "e743f6b9-8ecd-47e0-aead-880c9de1a0ec"
        ],
        "2da08d9d-9abf-43df-9720-0409d3dde74f": [
            "2fc8607c-a98b-4e36-ab52-a869b98cd08c"
        ],
        "b92b3cec-b869-4f7b-b22d-f62e57478372": [
            "f2af29e0-e1e8-4c7f-85ae-f17e2ed757b1"
        ],
        "167b014b-9fd8-450d-bf42-b18ba76d2907": [
            "120aaf13-3d31-4efd-8299-20efc8f78e19"
        ],
        "75772d32-78e9-41ea-a79f-b20e74c30d23": [
            "120aaf13-3d31-4efd-8299-20efc8f78e19"
        ],
        "c0eef7eb-8a7d-434f-8ed5-74e4836719bf": [
            "5cf18ea9-c0a0-4851-80f9-94d3b5a59116"
        ],
        "77ade70f-a791-4ff6-886c-fcff9c0757a1": [
            "5cf18ea9-c0a0-4851-80f9-94d3b5a59116"
        ],
        "f4d2b834-55c0-46ac-8c7d-9fc4e6359e2c": [
            "7b7e6cb8-a4e7-4860-b4e3-a582f2ed813f"
        ],
        "d981dd0f-c590-4508-b531-b84fc21bf04e": [
            "7b7e6cb8-a4e7-4860-b4e3-a582f2ed813f"
        ],
        "c85957fb-141f-4634-b1a3-269c7c52dff8": [
            "220dd70f-7c9d-4080-a1d7-d9560d1c91ea"
        ],
        "548f44fd-3203-4bb3-80bb-b25fa1a641d1": [
            "5d3a99e5-dea9-4879-bcbc-2180b007b2ba"
        ],
        "04684985-f00a-47c1-8638-69dd10bbef9a": [
            "b61443e9-2f9d-4dfc-8548-0117f4be4b23"
        ],
        "26b8073b-01db-42f6-bbc8-9db251827b25": [
            "b61443e9-2f9d-4dfc-8548-0117f4be4b23"
        ],
        "395cb73f-a57e-44e8-986f-15995299d2e9": [
            "050d8316-6c64-4c86-a8c7-406c63d09cf3"
        ],
        "7cff876d-5a64-437f-87df-9ca1453e8d74": [
            "050d8316-6c64-4c86-a8c7-406c63d09cf3"
        ],
        "7e4a70cb-f81d-4aca-a168-7fc24b1ee39a": [
            "ba7dd23b-b780-48f0-b805-766b6fd25873"
        ],
        "84f2923c-34d1-4d17-abc4-902404d19d58": [
            "ba7dd23b-b780-48f0-b805-766b6fd25873"
        ],
        "c89c009f-dec6-4417-b7f5-dc7f163be383": [
            "60c25781-b327-4fa2-be57-185a8baf6545"
        ],
        "1a116e44-1386-48ee-9848-5c11477d4d69": [
            "60c25781-b327-4fa2-be57-185a8baf6545"
        ],
        "d16d1915-266e-49fe-8097-715b5a0e2271": [
            "c187f805-57e9-4c48-8e5c-c0de2b453c1b"
        ],
        "2092afd5-fbdd-4485-b06b-5b5ca38b8f6a": [
            "e655b8ef-c41a-4596-9156-274d151bf055"
        ],
        "1eaf7417-a89a-455b-8006-3822526bb747": [
            "e655b8ef-c41a-4596-9156-274d151bf055"
        ],
        "4d1423b2-0afe-46dc-9e5b-18f72b735ef3": [
            "b26d4a03-5fa5-4ea9-b513-27c83357a3b2"
        ],
        "d7b04364-37aa-48f3-b676-ee6e8a3739b7": [
            "b26d4a03-5fa5-4ea9-b513-27c83357a3b2"
        ],
        "b2fb4ff2-ec79-4871-ad1a-638565d42eaf": [
            "62cf9597-3ebc-4113-9166-c23f992df1bf"
        ],
        "ca98c8cd-4cc7-4995-bb0c-33cc4cdca4bb": [
            "62cf9597-3ebc-4113-9166-c23f992df1bf"
        ],
        "4f6864b3-fb6c-4a07-a444-691de0489e44": [
            "9aa8043e-005a-4b9a-915a-4985fcfb466c"
        ],
        "792267a8-fa7b-49b3-b1e6-0150aa83163d": [
            "8fcf9fe0-c222-4b61-bb2e-eb99b50e8c68"
        ],
        "a5311387-727a-4005-b6d3-1762c7150440": [
            "8fcf9fe0-c222-4b61-bb2e-eb99b50e8c68"
        ],
        "a2893555-9306-4522-b7e3-6adddaa6d99b": [
            "8fcf9fe0-c222-4b61-bb2e-eb99b50e8c68"
        ],
        "fc355e0c-aba6-4a60-85a4-83f0defbc406": [
            "52c4ce34-e0a1-46a4-a350-ffabd91e9c7e"
        ],
        "c4cbd214-b09e-491a-a8dd-693201ad5608": [
            "f398a719-ed97-4da4-9116-06e1706aea47"
        ],
        "e5ae96fd-35e2-4e29-a58a-4ae2e2a7a28a": [
            "1436dc47-e876-460a-917b-db6bf153e5e8"
        ],
        "a4379c39-2941-49d1-8898-c84c890f4f31": [
            "1436dc47-e876-460a-917b-db6bf153e5e8"
        ],
        "bb7759c3-8751-46b8-9ceb-686efff02b84": [
            "456fe4d6-ef37-4ca5-9784-267a9a156017"
        ],
        "1c6892fa-ed78-4499-bbec-a3dcb5604b06": [
            "456fe4d6-ef37-4ca5-9784-267a9a156017"
        ],
        "5095fbf8-e2b4-443e-84db-20af6480a8fa": [
            "b729c360-d497-4581-a88d-068d1cf27ff2"
        ],
        "62fa032c-4b3c-4a65-af13-dfb26d403c95": [
            "b729c360-d497-4581-a88d-068d1cf27ff2"
        ],
        "b6a4b49c-c658-471c-a159-38ddf37ce4cf": [
            "95a712b6-9891-43a9-9994-8a0587057407"
        ],
        "c006c02f-3180-42cd-a328-074aa3290063": [
            "95a712b6-9891-43a9-9994-8a0587057407"
        ],
        "9e38f140-bef7-469a-a577-dc6eab23e051": [
            "00850a17-8e00-481d-aa04-32b1ac9f2771"
        ],
        "924ef69f-b1c1-43b9-8c10-83dd543d8309": [
            "0bc2c3e8-94d8-43ef-befc-136b7ae08eb7"
        ],
        "d3006a00-d4ac-4bb6-85b2-b3d4690ca5cb": [
            "18f6542e-8638-4eee-9d51-c94e37d7a7ae"
        ],
        "ed9bbd8b-160b-493e-b594-97fd3021bd83": [
            "18f6542e-8638-4eee-9d51-c94e37d7a7ae"
        ],
        "761c6dc9-e170-4985-a3f1-6aefbe619ce2": [
            "690367d5-07a0-456b-a36c-4e5693f4bc7e"
        ],
        "255b0f50-0365-454e-a79c-fc8e1d62efe8": [
            "690367d5-07a0-456b-a36c-4e5693f4bc7e"
        ],
        "60ac03dc-e2ac-4866-aa64-34c0de0f0d83": [
            "690367d5-07a0-456b-a36c-4e5693f4bc7e"
        ],
        "de286b33-4fe5-473d-b8b9-d0db3c0e56a7": [
            "690367d5-07a0-456b-a36c-4e5693f4bc7e"
        ],
        "a7765b99-f656-4c8d-9118-571a1aa34eb8": [
            "690367d5-07a0-456b-a36c-4e5693f4bc7e"
        ],
        "63e09c00-a2af-4407-b1d4-dba1b4f5960b": [
            "566e76bc-9e10-4952-8cd9-843a60a3ed40"
        ],
        "8b6dc6fd-da80-4ebb-bff2-cf6082621ddf": [
            "566e76bc-9e10-4952-8cd9-843a60a3ed40"
        ],
        "492c7e57-c40d-46ec-8ed7-da300978e7ef": [
            "40d6c4a3-7e9d-45c4-b82e-cfe0db95d046"
        ],
        "0f8f776f-f03d-48de-b1e8-9c02fbf8317a": [
            "40d6c4a3-7e9d-45c4-b82e-cfe0db95d046"
        ],
        "59acfdd1-2488-4582-bcbf-5ecba8e8216d": [
            "03b47759-2bbd-4033-815e-0098429cb1ce"
        ],
        "932a1c8c-1aed-43b4-b76b-9be52dbee15a": [
            "03b47759-2bbd-4033-815e-0098429cb1ce"
        ],
        "97cd2cb6-c3dc-4a5b-ae62-31dd7efb5bad": [
            "03b47759-2bbd-4033-815e-0098429cb1ce"
        ],
        "2eb0c761-eb41-4055-8fab-12272c712470": [
            "03b47759-2bbd-4033-815e-0098429cb1ce"
        ],
        "96b98ae4-0965-4783-b5b5-24f4bbb2a201": [
            "03b47759-2bbd-4033-815e-0098429cb1ce"
        ],
        "01175685-2be5-49b4-bfaa-63397a5e0afc": [
            "87f3ed11-746d-4765-bbca-bf9ad82999ed"
        ],
        "e57f6038-e7a3-4407-9e9d-edf0dd9c520c": [
            "87f3ed11-746d-4765-bbca-bf9ad82999ed"
        ],
        "7db5dbc8-2eea-491f-92e1-ab16282b568d": [
            "87f3ed11-746d-4765-bbca-bf9ad82999ed"
        ],
        "3b94ccaa-d185-452c-880a-aa16eb2ee39a": [
            "87f3ed11-746d-4765-bbca-bf9ad82999ed"
        ],
        "79c69eeb-0ef1-4b93-9916-9802cde2cffa": [
            "87f3ed11-746d-4765-bbca-bf9ad82999ed"
        ],
        "119dd2ce-f072-4c49-ac0c-e751994d06a5": [
            "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8"
        ],
        "8e851787-3cda-4b1b-93cb-4017d732f8fd": [
            "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8"
        ],
        "db0bbe81-ad80-4c89-ab28-2e9a4c491af0": [
            "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8"
        ],
        "6a3c0432-157f-4441-9c5d-ae799b1706a3": [
            "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8"
        ],
        "c105d217-6973-4be6-a6f6-17ffe2e6038a": [
            "bb7fa2e0-c970-4b18-8db9-cb1d0ba75aa8"
        ],
        "bd8d946e-1e90-4e9b-8c80-35bc46e88ce3": [
            "b0627309-95f0-42fc-9a91-3f7cfce2b5b4"
        ],
        "906b6169-e399-4158-b5d6-4a8bd2ca413f": [
            "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b"
        ],
        "c387f0a7-a7ad-4526-ada3-721adf9eefe6": [
            "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b"
        ],
        "a6035d59-43ed-4fac-924c-c0126c74db75": [
            "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b"
        ],
        "e20d3852-3e2d-4ba0-82d7-12dc8d93f85a": [
            "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b"
        ],
        "93d7d6e3-565a-4215-b12e-0c0d33f079bb": [
            "a6082c19-9a9b-4c3c-8fc1-5cfaef5fd00b"
        ],
        "ea090b42-248d-44c8-9343-20dc1ded8b12": [
            "15eefdc1-4605-4ff9-928c-d0eedacb6aa5"
        ],
        "3a1f4c35-a210-4ef0-9fa4-2f8567bc2551": [
            "15eefdc1-4605-4ff9-928c-d0eedacb6aa5"
        ],
        "c6594448-7daf-4ce6-bf05-30967db3f869": [
            "15eefdc1-4605-4ff9-928c-d0eedacb6aa5"
        ],
        "3ab2709f-9793-47a8-8a43-f01a110c90a7": [
            "15eefdc1-4605-4ff9-928c-d0eedacb6aa5"
        ],
        "83150b33-c19d-402b-ac91-0850445a81b7": [
            "15eefdc1-4605-4ff9-928c-d0eedacb6aa5"
        ],
        "3efa13bf-3ddc-4cc2-91d5-848ef385bcb3": [
            "7b2c028c-533e-4528-a28e-532818bbb4a8"
        ],
        "97b1e330-13ce-4e89-bec5-1e89668faf48": [
            "7b2c028c-533e-4528-a28e-532818bbb4a8"
        ],
        "30df58b5-90f0-4b41-925f-7091c5bb8f44": [
            "7b2c028c-533e-4528-a28e-532818bbb4a8"
        ],
        "826b74a8-4013-419b-937c-41918eda591c": [
            "7b2c028c-533e-4528-a28e-532818bbb4a8"
        ],
        "58c4bbcf-8337-4c2f-a093-6ec66661fac2": [
            "7b2c028c-533e-4528-a28e-532818bbb4a8"
        ],
        "475cb9a6-b698-47ba-a8e9-50c29188b052": [
            "4377b038-ed8a-4415-8e56-7bd8210e6fee"
        ],
        "e41cd965-5bd1-4eee-bf13-7a3a18fddc20": [
            "4377b038-ed8a-4415-8e56-7bd8210e6fee"
        ],
        "f15f9f9f-e66b-44e9-982d-bfd593bc42a6": [
            "4377b038-ed8a-4415-8e56-7bd8210e6fee"
        ],
        "5b40cff4-e6fe-4c61-9160-530e65748ca9": [
            "4377b038-ed8a-4415-8e56-7bd8210e6fee"
        ],
        "30b370f2-d555-485f-8975-71b3c66ea0b4": [
            "4377b038-ed8a-4415-8e56-7bd8210e6fee"
        ],
        "09d60d94-9678-4278-a39d-a337146e1a67": [
            "02a8b02d-f6e2-4504-a515-e7778e4e01d5"
        ],
        "e1dc374f-8dae-4860-8888-d3db82e65fe2": [
            "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed"
        ],
        "29fd5d6c-98f8-4197-bfcd-1f7604f39828": [
            "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed"
        ],
        "371cec3e-7b25-4185-960d-9fa7c37f7694": [
            "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed"
        ],
        "94d9d4ce-5cb3-4d02-a822-d28616bb2869": [
            "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed"
        ],
        "1e4ce3ea-9406-45c7-a983-2aabccc3b5f7": [
            "b56f1b73-16f5-4f9f-b3e6-7292e59cc4ed"
        ],
        "ef0a3bc0-3e3a-4cab-82c7-e455269c89ea": [
            "9b7ca718-35b2-4613-be2a-d7dac02f6b7f"
        ],
        "22631ce9-1ae2-4540-b17c-1dcca08f6560": [
            "bba5d4b1-baab-4996-9f27-e22a53afa40d"
        ],
        "d48ac364-c046-4a45-885f-b7338b64c749": [
            "bf0d3075-21ba-4f2b-8b03-4739b5bde415"
        ],
        "dea604bb-ffb8-44d1-97e6-c94af73fd26b": [
            "bf0d3075-21ba-4f2b-8b03-4739b5bde415"
        ],
        "0641b875-4480-48aa-b17c-fe5221538a38": [
            "bf0d3075-21ba-4f2b-8b03-4739b5bde415"
        ],
        "36cbeb6c-c25b-4f40-9e3a-f1aa4318c4a2": [
            "bf0d3075-21ba-4f2b-8b03-4739b5bde415"
        ],
        "96d2436e-20e3-4ea7-9a6e-a2734777e6d4": [
            "bf0d3075-21ba-4f2b-8b03-4739b5bde415"
        ],
        "30a27d50-7ac9-4e79-89de-aeb893306c64": [
            "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4"
        ],
        "3798b860-9462-4ab8-b612-e651ad1644cd": [
            "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4"
        ],
        "80f8f362-d40e-495c-bf3b-f1cecf4b9ef9": [
            "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4"
        ],
        "30439c61-ffd0-4ee6-8787-7058eecf10ed": [
            "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4"
        ],
        "f1246010-4ac4-4b77-beae-3421aab4aab2": [
            "ca4dedf4-3fd8-4f3f-b962-0bf2d44c3fa4"
        ],
        "0b5405f2-d7dd-46a5-9fac-1f2f623fcd5f": [
            "d870d02b-d9ed-41df-b207-daa6435cc24c"
        ],
        "912a8892-cfea-4c63-a6c9-284364009d8d": [
            "d870d02b-d9ed-41df-b207-daa6435cc24c"
        ],
        "11d39845-9713-4474-bd9b-1ca92efee5bb": [
            "5ed9f213-841d-4176-bccf-fe27c2c0ca1d"
        ],
        "024e6bc3-a425-4fb9-a796-b5f0ed505357": [
            "89de1df1-68ad-4d4a-9afb-1fedb2cab839"
        ],
        "be030726-e3aa-4e67-9b1a-4ecedac95a38": [
            "1a147719-08e4-4f5d-9fca-62c5e040241f"
        ],
        "f4df8bd4-4556-45da-b017-487e6808af21": [
            "1a147719-08e4-4f5d-9fca-62c5e040241f"
        ],
        "050dea33-2460-4eaf-a8d2-ab6589c4acd7": [
            "8b3b3bdb-3a4f-480f-9f4e-111b93c136af"
        ],
        "f1a87b42-a12f-4e16-9934-8bbd8ad5bcea": [
            "8b3b3bdb-3a4f-480f-9f4e-111b93c136af"
        ],
        "5af7e0c2-395e-45d8-b337-b3876a920845": [
            "8b3b3bdb-3a4f-480f-9f4e-111b93c136af"
        ],
        "32037b93-f7a9-4a6f-be71-236a5fcee68b": [
            "8b3b3bdb-3a4f-480f-9f4e-111b93c136af"
        ],
        "8cf07dd3-7318-4ba6-accc-8b196bfdf24f": [
            "8b3b3bdb-3a4f-480f-9f4e-111b93c136af"
        ],
        "e38506d3-8d3d-43ab-a6c9-89fcf0a5e250": [
            "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343"
        ],
        "1ca4ef6a-c212-43b6-846a-b19b117fcb7b": [
            "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343"
        ],
        "da34bc48-1c25-4b01-8f7f-0ed2ec0c1b11": [
            "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343"
        ],
        "b2a9cb6f-5a8c-49ab-8845-d9d2c8b7df06": [
            "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343"
        ],
        "43d99f34-3a5e-414f-be7a-bbf8d859ef2a": [
            "8f3f5171-ee8d-411f-9bc1-9bb9db5c9343"
        ],
        "8dec2602-5bea-4853-aabf-c3c9cef9a8eb": [
            "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9"
        ],
        "c9aba70c-c8e9-467a-8b41-e1d51adffb50": [
            "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9"
        ],
        "52077523-ce4e-424b-9d01-3267b54f5860": [
            "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9"
        ],
        "a77e2ab1-c109-45a6-857f-d08d36225c8e": [
            "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9"
        ],
        "bf1d8a64-f314-472d-87c1-ce115e2a102c": [
            "188b7c7f-9188-4d7d-9c21-84d4fd74ffb9"
        ],
        "9e3bf3ae-4737-4f7f-bc9c-e96b942a6720": [
            "627b11ca-8bde-4dfc-b1ea-bb0f4c6f2e12"
        ],
        "51cd6365-243d-4961-ba78-16d2fcf7fcd4": [
            "627b11ca-8bde-4dfc-b1ea-bb0f4c6f2e12"
        ],
        "3fc81b6b-adf5-4454-8446-1877b55b7d07": [
            "242c74bd-dbb2-4312-aa1b-51818c0a02cb"
        ],
        "adcdc95e-e463-4c79-900f-07b71b1565c2": [
            "242c74bd-dbb2-4312-aa1b-51818c0a02cb"
        ],
        "8d0f4dd3-341e-490e-8a55-ed47dfa78c67": [
            "2f5613ef-ef71-47cb-a232-b7f427f294f4"
        ],
        "0e30a2d7-0c0a-4a49-88c6-cdbf4c98f4f3": [
            "2f5613ef-ef71-47cb-a232-b7f427f294f4"
        ],
        "7621620c-7af0-4db8-a106-145cb4a2063d": [
            "6f16f638-86ff-4dc3-af58-0683faaa7235"
        ],
        "dfbb0c21-0082-48b0-aa4e-a288ce455f6e": [
            "6f16f638-86ff-4dc3-af58-0683faaa7235"
        ],
        "281134a6-18ad-456e-95a2-297b2ad60d6a": [
            "1783f958-e54b-487a-b553-37a674e58dc7"
        ],
        "92c0cde2-d369-4296-8ace-8a80bb4a2d3a": [
            "1783f958-e54b-487a-b553-37a674e58dc7"
        ],
        "04560412-f6b1-4df1-b4cb-94b1b07b3bbe": [
            "1783f958-e54b-487a-b553-37a674e58dc7"
        ],
        "994fab51-3ccd-4f45-b62f-408b17ead6a1": [
            "1783f958-e54b-487a-b553-37a674e58dc7"
        ],
        "e33fbf51-f25b-4a6a-b6fa-15f7e1a54619": [
            "1783f958-e54b-487a-b553-37a674e58dc7"
        ],
        "e3d421b5-b77c-402d-87b1-c638007f43bf": [
            "18e7d1ef-398c-4757-b5bb-e68a125f0046"
        ],
        "cddf15a6-0501-49d4-8912-9eadc0196751": [
            "18e7d1ef-398c-4757-b5bb-e68a125f0046"
        ],
        "aa46744a-c0ce-47a7-ad8d-229e4e91d874": [
            "18e7d1ef-398c-4757-b5bb-e68a125f0046"
        ],
        "866406e2-a69f-44b1-a8af-8f76f08fd753": [
            "60fe6772-d507-4875-a61e-c28cdb119c84"
        ],
        "e4793d90-04b9-49c6-8f2f-4161fe9a4961": [
            "60fe6772-d507-4875-a61e-c28cdb119c84"
        ],
        "b7f9382a-15e2-42cc-bb95-b157b699a93f": [
            "60fe6772-d507-4875-a61e-c28cdb119c84"
        ],
        "ae8b4fe9-8a14-4a10-93b0-c807ff227562": [
            "a74aca60-1490-498f-8a8f-33a3fd9fb48c"
        ],
        "be9e5c65-c26f-4dad-ab42-337f1f9ba904": [
            "a74aca60-1490-498f-8a8f-33a3fd9fb48c"
        ],
        "4ce80d52-8af6-42a1-b0a7-301093c316b5": [
            "a74aca60-1490-498f-8a8f-33a3fd9fb48c"
        ],
        "cd8f354d-a461-4262-9ca5-a9ee7a3e81b6": [
            "a74aca60-1490-498f-8a8f-33a3fd9fb48c"
        ],
        "529b46f8-1da6-4719-9dd5-5e16b687b1ae": [
            "a74aca60-1490-498f-8a8f-33a3fd9fb48c"
        ],
        "93462b4f-b99e-4431-b331-dedd3c9c1273": [
            "9937a5f7-caee-49f6-9a3f-c5aa775425ca"
        ],
        "69dc7f15-bcb6-4f66-8866-a713b5605a29": [
            "9937a5f7-caee-49f6-9a3f-c5aa775425ca"
        ],
        "c1aaa089-b0af-43a4-9b79-924925b34546": [
            "9937a5f7-caee-49f6-9a3f-c5aa775425ca"
        ],
        "a4eafe29-a8d4-4242-a03d-231d2fe13c2a": [
            "0e5b497a-c67f-4527-bcbe-67bc369d3467"
        ],
        "527a8ee7-abab-4a6f-8147-d1ab0dd8fc3f": [
            "0e5b497a-c67f-4527-bcbe-67bc369d3467"
        ]
    },
    "mode": "text"
}